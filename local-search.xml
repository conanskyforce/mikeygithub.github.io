<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>面试自我介绍</title>
    <link href="/2020/11/19/%E9%9D%A2%E8%AF%95%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/"/>
    <url>/2020/11/19/%E9%9D%A2%E8%AF%95%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="自我介绍"><a href="#自我介绍" class="headerlink" title="自我介绍"></a>自我介绍</h1><p>面试官您好，很高兴能参加这次面试。我叫，就读于梧州学院软件工程专业。目前主要学习的方向是Java的后端开发。</p><h2 id="学习方面："><a href="#学习方面：" class="headerlink" title="学习方面："></a>学习方面：</h2><p>出于个人的兴趣，选择了计算机相关专业，在校期间学习的主要一些计算机基础知识。从大一开始加入学校软件开发中心机构，在老师的带领下接触项目开发，通过不断的锻炼和学习，现在可以带领团队独立开发项目。期间也接触过挺多项目的开发。</p><p>在校期间积极参加相关学科竞赛，先后取得一些不错奖项，像计算机设计大赛，中国软件杯，广西人工智能大赛，互联网+大赛，多项软件著作权等等。</p><h2 id="实践方面："><a href="#实践方面：" class="headerlink" title="实践方面："></a>实践方面：</h2><p>2019年,曾在一家小公司实习过三个月，主要负责业务系统的后台开发，（难点：数据查询十分缓慢，优化方法：1.使用redis进行数据缓存 2.通过explain工具对SQL进行分析,对表进行建立索引）</p><h2 id="兴趣爱好："><a href="#兴趣爱好：" class="headerlink" title="兴趣爱好："></a>兴趣爱好：</h2><p>渴望学习技术，平时喜欢逛一些技术论坛，通过教学视频学习一些主流技术，写写相关技术博客。</p><h2 id="参与项目："><a href="#参与项目：" class="headerlink" title="参与项目："></a>参与项目：</h2><ul><li>《大学生创新创业管理系统》<br>项目难点：<br>业务需求的频繁变更、</li></ul><ul><li>《高校毕业设计及过程监管平台》<br>项目难点：<br>聊天室的实现、</li></ul><ul><li>《公共地点人流量预警监控平台》<br>项目难点：<br>多线程视频窗口显示、</li></ul><ul><li><p>《基于区块链政校企信息共享平台》<br>项目难点：<br>区块链网络的搭建、</p></li><li><p>《智慧农业监控平台》<br>项目难点：</p></li></ul><h2 id="提问问题"><a href="#提问问题" class="headerlink" title="提问问题"></a>提问问题</h2><ul><li>加班情况</li><li>加班费</li><li>薪资结构</li></ul>]]></content>
    
    
    <categories>
      
      <category>hide</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hide</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode刷题记录</title>
    <link href="/2020/11/19/LeetCode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/11/19/LeetCode%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h1><h1 id="树"><a href="#树" class="headerlink" title="树"></a>树</h1><h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><h2 id="礼物的最大价值"><a href="#礼物的最大价值" class="headerlink" title="礼物的最大价值"></a>礼物的最大价值</h2><h3 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h3><blockquote><p>在一个 m*n 的棋盘的每一格都放有一个礼物，每个礼物都有一定的价值（价值大于 0）。你可以从棋盘的左上角开始拿格子里的礼物，并每次向右或者向下移动一格、直到到达棋盘的右下角。给定一个棋盘及其上面的礼物的价值，请计算你最多能拿到多少价值的礼物？</p></blockquote><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>输入:</p><blockquote><p>[<br>   &emsp;[1,3,1],<br>   &emsp;[1,5,1],<br>   &emsp;[4,2,1]<br>]</p></blockquote><p>输出: 12<br>解释: 路径 1→3→5→2→1 可以拿到最多价值的礼物</p><h3 id="解题思路"><a href="#解题思路" class="headerlink" title="解题思路"></a>解题思路</h3><p>动态规划+dp数组，自底向上，状态转移方程 <code>f(i, j) = max{f(i - 1, j), f(i, j - 1)} + grid[i][j]</code></p><pre><code class="java">class Solution {    public int maxValue(int[][] grid) {        int m = grid.length, n = grid[0].length;//获取数组长度        int[] dp = new int[n + 1];//dp数组 最长长度为n+1 用于存放        for (int i = 1; i &lt;= m; i++) {//两层循环            for (int j = 1; j &lt;= n; j++) {                dp[j] = Math.max(dp[j], dp[j - 1]) + grid[i - 1][j - 1];//结合状态转移方程            }         }        return dp[n];    }}</code></pre><h2 id="丑数"><a href="#丑数" class="headerlink" title="丑数"></a>丑数</h2><h3 id="题目描述-1"><a href="#题目描述-1" class="headerlink" title="题目描述"></a>题目描述</h3><blockquote><p>我们把只包含质因子 2、3 和 5 的数称作丑数（Ugly Number）。求按从小到大的顺序的第 n 个丑数。</p></blockquote><h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><blockquote><p>输入: n = 10<br>输出: 12<br>解释: 1, 2, 3, 4, 5, 6, 8, 9, 10, 12 是前 10 个丑数。</p></blockquote><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><p>1 是丑数。<br>n 不超过1690。</p><h3 id="解题思路-1"><a href="#解题思路-1" class="headerlink" title="解题思路"></a>解题思路</h3><p>状态定义： 设动态规划列表 dp ，dp[i] 代表第 i + 1 个丑数。</p><p>转移方程：<br>当索引 a, b, c 满足以下条件时， dp[i] 为三种情况的最小值；<br>每轮计算 dp[i] 后，需要更新索引 a, b, c 的值，使其始终满足方程条件。</p><p>实现方法：分别独立判断 dp[i] 和 dp[a]×2 , dp[b]×3 , dp[c]×5 的大小关系，若相等则将对应索引 a , b , c 加 1 。</p><p>⎧<br>⎪ dp[a]×2&gt;dp[i−1]≥dp[a−1]×2<br>⎪<br>⎨ dp[b]×3&gt;dp[i−1]≥dp[b−1]×3<br>⎪<br>⎪ dp[c]×5&gt;dp[i−1]≥dp[c−1]×5<br>​⎩    </p><p><code>dp[i] = min(dp[a]×2,dp[b]×3,dp[c]×5)</code></p><p>初始状态： dp[0] = 1 ，即第一个丑数为 1.<br>返回值： dp[n-1] ，即返回第 n 个丑数.</p><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><pre><code class="java">class Solution {    public int nthUglyNumber(int n) {        int a = 0, b = 0, c = 0;        int[] dp = new int[n];//dp数组        dp[0] = 1;        for(int i = 1; i &lt; n; i++) {            int n2 = dp[a] * 2, n3 = dp[b] * 3, n5 = dp[c] * 5;//状态转移方程            dp[i] = Math.min(n2, n3, n5);            if(dp[i] == n2) a++;            if(dp[i] == n3) b++;            if(dp[i] == n5) c++;        }        return dp[n - 1];    }}</code></pre><h2 id="数组中的逆序对"><a href="#数组中的逆序对" class="headerlink" title="数组中的逆序对"></a>数组中的逆序对</h2><h3 id="题目描述-2"><a href="#题目描述-2" class="headerlink" title="题目描述"></a>题目描述</h3><p>在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。输入一个数组，求出这个数组中的逆序对的总数。</p><h3 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h3><p>输入: [7,5,6,4]<br>输出: 5</p><h3 id="解题思路-2"><a href="#解题思路-2" class="headerlink" title="解题思路"></a>解题思路</h3><blockquote></blockquote>]]></content>
    
    
    <categories>
      
      <category>刷题</category>
      
    </categories>
    
    
    <tags>
      
      <tag>刷题</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL 经典一百道面试题</title>
    <link href="/2020/11/18/MySQL-%E7%BB%8F%E5%85%B8%E4%B8%80%E7%99%BE%E9%81%93%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
    <url>/2020/11/18/MySQL-%E7%BB%8F%E5%85%B8%E4%B8%80%E7%99%BE%E9%81%93%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/PvWAYwfeflWB3UxotxnduQ" target="_blank" rel="noopener">原文链接</a></p><h1 id="1-MySQL索引使用有哪些注意事项呢？"><a href="#1-MySQL索引使用有哪些注意事项呢？" class="headerlink" title="1. MySQL索引使用有哪些注意事项呢？"></a>1. MySQL索引使用有哪些注意事项呢？</h1><blockquote><p>可以从三个维度回答这个问题：索引哪些情况会失效，索引不适合哪些场景，索引规则</p></blockquote><h2 id="索引哪些情况会失效"><a href="#索引哪些情况会失效" class="headerlink" title="索引哪些情况会失效"></a>索引哪些情况会失效</h2><ul><li><p>查询条件包含or，可能导致索引失效</p></li><li><p>如何字段类型是字符串，where时一定用引号括起来，否则索引失效</p></li><li><p>like通配符可能导致索引失效。</p></li><li><p>联合索引，查询时的条件列不是联合索引中的第一个列，索引失效。</p></li><li><p>在索引列上使用mysql的内置函数，索引失效。</p></li><li><p>对索引列运算（如，+、-、*、/），索引失效。</p></li><li><p>索引字段上使用（！= 或者 &lt; &gt;，not in）时，可能会导致索引失效。</p></li><li><p>索引字段上使用is null， is not null，可能导致索引失效。</p></li><li><p>左连接查询或者右连接查询查询关联的字段编码格式不一样，可能导致索引失效。</p></li><li><p>mysql估计使用全表扫描要比使用索引快,则不使用索引。</p></li></ul><h2 id="索引不适合哪些场景"><a href="#索引不适合哪些场景" class="headerlink" title="索引不适合哪些场景"></a>索引不适合哪些场景</h2><ul><li><p>数据量少的不适合加索引</p></li><li><p>更新比较频繁的也不适合加索引</p></li><li><p>区分度低的字段不适合加索引（如性别）</p></li></ul><h2 id="索引的一些潜规则"><a href="#索引的一些潜规则" class="headerlink" title="索引的一些潜规则"></a>索引的一些潜规则</h2><ul><li><p>覆盖索引</p></li><li><p>回表</p></li><li><p>索引数据结构（B+树）</p></li><li><p>最左前缀原则</p></li><li><p>索引下推</p></li></ul><h1 id="2-MySQL遇到过死锁问题吗，你是如何解决的？"><a href="#2-MySQL遇到过死锁问题吗，你是如何解决的？" class="headerlink" title="2. MySQL遇到过死锁问题吗，你是如何解决的？"></a>2. MySQL遇到过死锁问题吗，你是如何解决的？</h1><p>我排查死锁的一般步骤是酱紫的：</p><ul><li><p>查看死锁日志   <code>show engine innodb status</code>;</p></li><li><p>找出死锁Sql</p></li><li><p>分析sql加锁情况</p></li><li><p>模拟死锁案发</p></li><li><p>分析死锁日志</p></li><li><p>分析死锁结果</p></li></ul><h1 id="3-中你是怎么优化SQL的？"><a href="#3-中你是怎么优化SQL的？" class="headerlink" title="3.中你是怎么优化SQL的？"></a>3.中你是怎么优化SQL的？</h1><p>可以从这几个维度回答这个问题：</p><ul><li><p>加索引</p></li><li><p>避免返回不必要的数据</p></li><li><p>适当分批量进行</p></li><li><p>优化sql结构</p></li><li><p>分库分表</p></li><li><p>读写分离</p></li></ul><h1 id="4-说说分库与分表的设计"><a href="#4-说说分库与分表的设计" class="headerlink" title="4. 说说分库与分表的设计"></a>4. 说说分库与分表的设计</h1><p>分库分表方案，分库分表中间件，分库分表可能遇到的问题</p><h2 id="分库分表方案"><a href="#分库分表方案" class="headerlink" title="分库分表方案:"></a>分库分表方案:</h2><ul><li><p>水平分库：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。</p></li><li><p>水平分表：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。</p></li><li><p>垂直分库：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。</p></li><li><p>垂直分表：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。</p></li></ul><h2 id="常用的分库分表中间件："><a href="#常用的分库分表中间件：" class="headerlink" title="常用的分库分表中间件："></a>常用的分库分表中间件：</h2><ul><li><p>sharding-jdbc（当当）</p></li><li><p>Mycat</p></li><li><p>TDDL（淘宝）</p></li><li><p>Oceanus(58同城数据库中间件)</p></li><li><p>vitess（谷歌开发的数据库中间件）</p></li><li><p>Atlas(Qihoo 360)</p></li></ul><h2 id="分库分表可能遇到的问题"><a href="#分库分表可能遇到的问题" class="headerlink" title="分库分表可能遇到的问题"></a>分库分表可能遇到的问题</h2><p>事务问题：需要用分布式事务啦</p><p>跨节点Join的问题：解决这一问题可以分两次查询实现</p><p>跨节点的count,order by,group by以及聚合函数问题：分别在各个节点上得到结果后在应用程序端进行合并。</p><p>数据迁移，容量规划，扩容等问题</p><p>ID问题：数据库被切分后，不能再依赖数据库自身的主键生成机制啦，最简单可以考虑UUID</p><p>跨分片的排序分页问题（后台加大pagesize处理？）</p><h1 id="5-InnoDB与MyISAM的区别"><a href="#5-InnoDB与MyISAM的区别" class="headerlink" title="5. InnoDB与MyISAM的区别"></a>5. InnoDB与MyISAM的区别</h1><p>InnoDB支持事务，MyISAM不支持事务</p><p>InnoDB支持外键，MyISAM不支持外键</p><p>InnoDB 支持 MVCC(多版本并发控制)，MyISAM 不支持</p><p>select count(*) from table时，MyISAM更快，因为它有一个变量保存了整个表的总行数，可以直接读取，InnoDB就需要全表扫描。</p><p>Innodb不支持全文索引，而MyISAM支持全文索引（5.7以后的InnoDB也支持全文索引）</p><p>InnoDB支持表、行级锁，而MyISAM支持表级锁。</p><p>InnoDB表必须有主键，而MyISAM可以没有主键</p><p>Innodb表需要更多的内存和存储，而MyISAM可被压缩，存储空间较小，。</p><p>Innodb按主键大小有序插入，MyISAM记录插入顺序是，按记录插入顺序保存。</p><p>InnoDB 存储引擎提供了具有提交、回滚、崩溃恢复能力的事务安全，与 MyISAM 比 InnoDB 写的效率差一些，并且会占用更多的磁盘空间以保留数据和索引</p><h1 id="6-数据库索引的原理，为什么要用B-树，为什么不用二叉树？"><a href="#6-数据库索引的原理，为什么要用B-树，为什么不用二叉树？" class="headerlink" title="6. 数据库索引的原理，为什么要用B+树，为什么不用二叉树？"></a>6. 数据库索引的原理，为什么要用B+树，为什么不用二叉树？</h1><p>可以从几个维度去看这个问题，查询是否够快，效率是否稳定，存储数据多少，以及查找磁盘次数，为什么不是二叉树，为什么不是平衡二叉树，为什么不是B树，而偏偏是B+树呢？</p><p>为什么不是一般二叉树？</p><p>如果二叉树特殊化为一个链表，相当于全表扫描。平衡二叉树相比于二叉查找树来说，查找效率更稳定，总体的查找速度也更快。</p><p>为什么不是平衡二叉树呢？</p><p>我们知道，在内存比在磁盘的数据，查询效率快得多。如果树这种数据结构作为索引，那我们每查找一次数据就需要从磁盘中读取一个节点，也就是我们说的一个磁盘块，但是平衡二叉树可是每个节点只存储一个键值和数据的，如果是B树，可以存储更多的节点数据，树的高度也会降低，因此读取磁盘的次数就降下来啦，查询效率就快啦。</p><p>那为什么不是B树而是B+树呢？</p><p>1）B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快。</p><p>2）B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。</p><p>可以看这篇文章哈：再有人问你为什么MySQL用B+树做索引，就把这篇文章发给她</p><h1 id="7-聚集索引与非聚集索引的区别"><a href="#7-聚集索引与非聚集索引的区别" class="headerlink" title="7. 聚集索引与非聚集索引的区别"></a>7. 聚集索引与非聚集索引的区别</h1><p>一个表中只能拥有一个聚集索引，而非聚集索引一个表可以存在多个。</p><p>聚集索引，索引中键值的逻辑顺序决定了表中相应行的物理顺序；非聚集索引，索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。</p><p>索引是通过二叉树的数据结构来描述的，我们可以这么理解聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。</p><p>聚集索引：物理存储按照索引排序；非聚集索引：物理存储不按照索引排序；</p><p>何时使用聚集索引或非聚集索引？</p><h1 id="8-limit-1000000加载很慢的话，你是怎么解决的呢？"><a href="#8-limit-1000000加载很慢的话，你是怎么解决的呢？" class="headerlink" title="8. limit 1000000加载很慢的话，你是怎么解决的呢？"></a>8. limit 1000000加载很慢的话，你是怎么解决的呢？</h1><p>方案一：如果id是连续的，可以这样，返回上次查询的最大记录(偏移量)，再往下limit</p><pre><code class="sql">select id,name from employee where id &gt; 1000000 limit 10</code></pre><p>方案二：在业务允许的情况下限制页数：</p><p>建议跟业务讨论，有没有必要查这么后的分页啦。因为绝大多数用户都不会往后翻太多页。</p><p>方案三：order by + 索引（id为索引）</p><pre><code class="sql">select id,name from employee order by id  limit 1000000,10</code></pre><p>方案四：利用延迟关联或者子查询优化超多分页场景。（先快速定位需要获取的id段，然后再关联）</p><pre><code class="sql">SELECT a.* FROM employee a,(select id from employee where 条件 LIMIT 1000000,10) b where a.id=b.id</code></pre><h1 id="9-如何选择合适的分布式主键方案呢？"><a href="#9-如何选择合适的分布式主键方案呢？" class="headerlink" title="9. 如何选择合适的分布式主键方案呢？"></a>9. 如何选择合适的分布式主键方案呢？</h1><h2 id="数据库自增长序列或字段。"><a href="#数据库自增长序列或字段。" class="headerlink" title="数据库自增长序列或字段。"></a>数据库自增长序列或字段。</h2><ul><li><p>UUID。</p></li><li><p>Redis生成ID</p></li><li><p>Twitter的snowflake算法</p></li><li><p>利用zookeeper生成唯一ID</p></li><li><p>MongoDB的ObjectId</p></li></ul><h1 id="10-事务的隔离级别有哪些？MySQL的默认隔离级别是什么？"><a href="#10-事务的隔离级别有哪些？MySQL的默认隔离级别是什么？" class="headerlink" title="10. 事务的隔离级别有哪些？MySQL的默认隔离级别是什么？"></a>10. 事务的隔离级别有哪些？MySQL的默认隔离级别是什么？</h1><ul><li><p>读未提交（Read Uncommitted）</p></li><li><p>读已提交（Read Committed）</p></li><li><p>可重复读（Repeatable Read）</p></li><li><p>串行化（Serializable）</p></li></ul><p>Mysql默认的事务隔离级别是可重复读(Repeatable Read)</p><p>可以看我这篇文章哈：一文彻底读懂MySQL事务的四大隔离级别</p><h1 id="11-什么是幻读，脏读，不可重复读呢？"><a href="#11-什么是幻读，脏读，不可重复读呢？" class="headerlink" title="11. 什么是幻读，脏读，不可重复读呢？"></a>11. 什么是幻读，脏读，不可重复读呢？</h1><p>事务A、B交替执行，事务A被事务B干扰到了，因为事务A读取到事务B未提交的数据,这就是脏读</p><p>在一个事务范围内，两个相同的查询，读取同一条记录，却返回了不同的数据，这就是不可重复读。</p><p>事务A查询一个范围的结果集，另一个并发事务B往这个范围中插入/删除了数据，并静悄悄地提交，然后事务A再次查询相同的范围，两次读取得到的结果集不一样了，这就是幻读。</p><p>可以看我这篇文章哈：一文彻底读懂MySQL事务的四大隔离级别</p><h1 id="12-在高并发情况下，如何做到安全的修改同一行数据？"><a href="#12-在高并发情况下，如何做到安全的修改同一行数据？" class="headerlink" title="12. 在高并发情况下，如何做到安全的修改同一行数据？"></a>12. 在高并发情况下，如何做到安全的修改同一行数据？</h1><p>要安全的修改同一行数据，就要保证一个线程在修改时其它线程无法更新这行记录。一般有悲观锁和乐观锁两种方案~</p><h3 id="使用悲观锁"><a href="#使用悲观锁" class="headerlink" title="使用悲观锁"></a>使用悲观锁</h3><p>悲观锁思想就是，当前线程要进来修改数据时，别的线程都得拒之门外~</p><p>比如，可以使用<code>select…for update ~</code></p><pre><code class="sql">select * from User where name=&#39;jay&#39; for update</code></pre><p>以上这条sql语句会锁定了User表中所有符合检索条件（name=‘jay’）的记录。本次事务提交之前，别的线程都无法修改这些记录。</p><h3 id="使用乐观锁"><a href="#使用乐观锁" class="headerlink" title="使用乐观锁"></a>使用乐观锁</h3><p>乐观锁思想就是，有线程过来，先放过去修改，如果看到别的线程没修改过，就可以修改成功，如果别的线程修改过，就修改失败或者重试。实现方式：乐观锁一般会使用版本号机制或CAS算法实现。</p><h1 id="13-数据库的乐观锁和悲观锁。"><a href="#13-数据库的乐观锁和悲观锁。" class="headerlink" title="13. 数据库的乐观锁和悲观锁。"></a>13. 数据库的乐观锁和悲观锁。</h1><p>悲观锁：<br>悲观锁她专一且缺乏安全感了，她的心只属于当前事务，每时每刻都担心着它心爱的数据可能被别的事务修改，所以一个事务拥有（获得）悲观锁后，其他任何事务都不能对数据进行修改啦，只能等待锁被释放才可以执行。</p><p>乐观锁：<br>乐观锁的“乐观情绪”体现在，它认为数据的变动不会太频繁。因此，它允许多个事务同时对数据进行变动。实现方式：乐观锁一般会使用版本号机制或CAS算法实现。</p><h1 id="14-SQL优化的一般步骤是什么，怎么看执行计划（explain），如何理解其中各个字段的含义。"><a href="#14-SQL优化的一般步骤是什么，怎么看执行计划（explain），如何理解其中各个字段的含义。" class="headerlink" title="14. SQL优化的一般步骤是什么，怎么看执行计划（explain），如何理解其中各个字段的含义。"></a>14. SQL优化的一般步骤是什么，怎么看执行计划（explain），如何理解其中各个字段的含义。</h1><p>show status 命令了解各种 sql 的执行频率</p><p>通过慢查询日志定位那些执行效率较低的 sql 语句</p><p>explain 分析低效 sql 的执行计划（这点非常重要，日常开发中用它分析Sql，会大大降低Sql导致的线上事故）</p><h1 id="15-select-for-update有什么含义，会锁表还是锁行还是其他。"><a href="#15-select-for-update有什么含义，会锁表还是锁行还是其他。" class="headerlink" title="15. select for update有什么含义，会锁表还是锁行还是其他。"></a>15. select for update有什么含义，会锁表还是锁行还是其他。</h1><p>select for update 含义<br>select查询语句是不会加锁的，但是select for update除了有查询的作用外，还会加锁呢，而且它是悲观锁哦。至于加了是行锁还是表锁，这就要看是不是用了索引/主键啦。</p><p>没用索引/主键的话就是表锁，否则就是是行锁。</p><p>select for update 加锁验证<br>表结构：</p><p>//id 为主键，name为唯一索引</p><p>CREATE TABLE<br><code>account</code></p><p>(</p><p><code>id</code></p><p>int<br>(<br>11<br>)<br> NOT NULL AUTO_INCREMENT<br>,</p><p><code>name</code><br> varchar<br>(<br>255<br>)<br> DEFAULT NULL<br>,</p><p><code>balance</code></p><p>int<br>(<br>11<br>)<br> DEFAULT NULL<br>,</p><p>  PRIMARY KEY<br>(<br><code>id</code><br>),</p><p>  KEY<br><code>idx_name</code></p><p>(<br><code>name</code><br>)<br> USING BTREE</p><p>)<br> ENGINE<br>=<br>InnoDB<br> AUTO_INCREMENT<br>=<br>1570068<br> DEFAULT CHARSET<br>=<br>utf8</p><p>id为主键，select for update 1270070这条记录时，再开一个事务对该记录更新，发现更新阻塞啦，其实是加锁了。如下图：</p><p>我们再开一个事务对另外一条记录1270071更新，发现更新成功，因此，如果查询条件用了索引/主键，会加行锁~</p><p>我们继续一路向北吧，换普通字段balance吧，发现又阻塞了。因此，没用索引/主键的话，select for update加的就是表锁</p><h1 id="16-MySQL事务得四大特性以及实现原理"><a href="#16-MySQL事务得四大特性以及实现原理" class="headerlink" title="16. MySQL事务得四大特性以及实现原理"></a>16. MySQL事务得四大特性以及实现原理</h1><p>原子性：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。</p><p>一致性：指在事务开始之前和事务结束以后，数据不会被破坏，假如A账户给B账户转10块钱，不管成功与否，A和B的总金额是不变的。</p><p>隔离性：多个事务并发访问时，事务之间是相互隔离的，即一个事务不影响其它事务运行效果。简言之，就是事务之间是进水不犯河水的。</p><p>持久性：表示事务完成以后，该事务对数据库所作的操作更改，将持久地保存在数据库之中。</p><p>事务ACID特性的实现思想</p><p>原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。</p><p>持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。</p><p>隔离性：通过锁以及MVCC,使事务相互隔离开。</p><p>一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。</p><h1 id="17-如果某个表有近千万数据，CRUD比较慢，如何优化。"><a href="#17-如果某个表有近千万数据，CRUD比较慢，如何优化。" class="headerlink" title="17. 如果某个表有近千万数据，CRUD比较慢，如何优化。"></a>17. 如果某个表有近千万数据，CRUD比较慢，如何优化。</h1><p>分库分表<br>某个表有近千万数据，可以考虑优化表结构，分表（水平分表，垂直分表），当然，你这样回答，需要准备好面试官问你的分库分表相关问题呀，如</p><p>分表方案（水平分表，垂直分表，切分规则hash等）</p><p>分库分表中间件（Mycat，sharding-jdbc等）</p><p>分库分表一些问题（事务问题？跨节点Join的问题）</p><p>解决方案（分布式事务等）</p><p>索引优化<br>除了分库分表，优化表结构，当然还有所以索引优化等方案~</p><h1 id="18-如何写sql能够有效的使用到复合索引。"><a href="#18-如何写sql能够有效的使用到复合索引。" class="headerlink" title="18. 如何写sql能够有效的使用到复合索引。"></a>18. 如何写sql能够有效的使用到复合索引。</h1><p>复合索引，也叫组合索引，用户可以在多个列上建立索引,这种索引叫做复合索引。</p><p>当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。</p><p>select</p><p>*</p><p>from<br> table<br>where<br> k1<br>=<br>A AND k2<br>=<br>B AND k3<br>=<br>D</p><p>有关于复合索引，我们需要关注查询Sql条件的顺序，确保最左匹配原则有效，同时可以删除不必要的冗余索引。</p><h1 id="19-mysql中in-和exists的区别。"><a href="#19-mysql中in-和exists的区别。" class="headerlink" title="19. mysql中in 和exists的区别。"></a>19. mysql中in 和exists的区别。</h1><p>这个，跟一下demo来看更刺激吧，啊哈哈</p><p>假设表A表示某企业的员工表，表B表示部门表，查询所有部门的所有员工，很容易有以下SQL:</p><p>select</p><p>*</p><p>from<br> A<br>where<br> deptId<br>in</p><p>(<br>select<br> deptId<br>from<br> B<br>);</p><p>这样写等价于：</p><p>先查询部门表B</p><p>select deptId from B</p><p>再由部门deptId，查询A的员工</p><p>select * from A where A.deptId = B.deptId</p><p>可以抽象成这样的一个循环：</p><p>List<br>&lt;&gt;<br> resultSet<br>;</p><p>for<br>(<br>int<br> i<br>=<br>0<br>;<br>i<br>&lt;<br>B<br>.<br>length<br>;<br>i<br>++)</p><p>{</p><p>for<br>(<br>int<br> j<br>=<br>0<br>;<br>j<br>&lt;<br>A<br>.<br>length<br>;<br>j<br>++)</p><p>{</p><p>if<br>(<br>A<br>[<br>i<br>].<br>id<br>==<br>B<br>[<br>j<br>].<br>id<br>)</p><p>{</p><pre><code>         resultSet</code></pre><p>.<br>add<br>(<br>A<br>[<br>i<br>]);</p><p>break<br>;</p><p>}</p><p>}</p><p>}</p><p>显然，除了使用in，我们也可以用exists实现一样的查询功能，如下：</p><p>select</p><p>*</p><p>from<br> A<br>where<br> exists<br>(<br>select</p><p>1</p><p>from<br> B<br>where<br> A<br>.<br>deptId<br>=<br> B<br>.<br>deptId<br>);</p><p>因为exists查询的理解就是，先执行主查询，获得数据后，再放到子查询中做条件验证，根据验证结果（true或者false），来决定主查询的数据结果是否得意保留。</p><p>那么，这样写就等价于：</p><p>select * from A,先从A表做循环</p><p>select * from B where A.deptId = B.deptId,再从B表做循环.</p><p>同理，可以抽象成这样一个循环：</p><p>List<br>&lt;&gt;<br> resultSet<br>;</p><p>for<br>(<br>int<br> i<br>=<br>0<br>;<br>i<br>&lt;<br>A<br>.<br>length<br>;<br>i<br>++)</p><p>{</p><p>for<br>(<br>int<br> j<br>=<br>0<br>;<br>j<br>&lt;<br>B<br>.<br>length<br>;<br>j<br>++)</p><p>{</p><p>if<br>(<br>A<br>[<br>i<br>].<br>deptId<br>==<br>B<br>[<br>j<br>].<br>deptId<br>)</p><p>{</p><pre><code>         resultSet</code></pre><p>.<br>add<br>(<br>A<br>[<br>i<br>]);</p><p>break<br>;</p><p>}</p><p>}</p><p>}</p><p>数据库最费劲的就是跟程序链接释放。假设链接了两次，每次做上百万次的数据集查询，查完就走，这样就只做了两次；相反建立了上百万次链接，申请链接释放反复重复，这样系统就受不了了。即mysql优化原则，就是小表驱动大表，小的数据集驱动大的数据集，从而让性能更优。</p><p>因此，我们要选择最外层循环小的，也就是，如果B的数据量小于A，适合使用in，如果B的数据量大于A，即适合选择exists，这就是in和exists的区别。</p><h1 id="20-数据库自增主键可能遇到什么问题。"><a href="#20-数据库自增主键可能遇到什么问题。" class="headerlink" title="20. 数据库自增主键可能遇到什么问题。"></a>20. 数据库自增主键可能遇到什么问题。</h1><p>使用自增主键对数据库做分库分表，可能出现诸如主键重复等的问题。解决方案的话，简单点的话可以考虑使用UUID哈</p><p>自增主键会产生表锁，从而引发问题</p><p>自增主键可能用完问题。</p><h1 id="21-MVCC熟悉吗，它的底层原理？"><a href="#21-MVCC熟悉吗，它的底层原理？" class="headerlink" title="21. MVCC熟悉吗，它的底层原理？"></a>21. MVCC熟悉吗，它的底层原理？</h1><p>MVCC,多版本并发控制,它是通过读取历史版本的数据，来降低并发事务冲突，从而提高并发性能的一种机制。</p><p>MVCC需要关注这几个知识点：</p><p>事务版本号</p><p>表的隐藏列</p><p>undo log</p><p>read view</p><h1 id="22-数据库中间件了解过吗，sharding-jdbc，mycat？"><a href="#22-数据库中间件了解过吗，sharding-jdbc，mycat？" class="headerlink" title="22. 数据库中间件了解过吗，sharding jdbc，mycat？"></a>22. 数据库中间件了解过吗，sharding jdbc，mycat？</h1><p>sharding-jdbc目前是基于jdbc驱动，无需额外的proxy，因此也无需关注proxy本身的高可用。</p><p>Mycat 是基于 Proxy，它复写了 MySQL 协议，将 Mycat Server 伪装成一个 MySQL 数据库，而 Sharding-JDBC 是基于 JDBC 接口的扩展，是以 jar 包的形式提供轻量级服务的。</p><h1 id="23-MYSQL的主从延迟，你怎么解决？"><a href="#23-MYSQL的主从延迟，你怎么解决？" class="headerlink" title="23. MYSQL的主从延迟，你怎么解决？"></a>23. MYSQL的主从延迟，你怎么解决？</h1><p>嘻嘻，先复习一下主从复制原理吧，如图：主从复制分了五个步骤进行：</p><p>步骤一：主库的更新事件(update、insert、delete)被写到binlog</p><p>步骤二：从库发起连接，连接到主库。</p><p>步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库。</p><p>步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log</p><p>步骤五：还会创建一个SQL线程，从relay log里面读取内容，从ExecMasterLog_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db</p><p>主从同步延迟的原因<br>一个服务器开放Ｎ个链接给客户端来连接的，这样有会有大并发的更新操作, 但是从服务器的里面读取binlog的线程仅有一个，当某个SQL在从服务器上执行的时间稍长 或者由于某个SQL要进行锁表就会导致，主服务器的SQL大量积压，未被同步到从服务器里。这就导致了主从不一致， 也就是主从延迟。</p><p>主从同步延迟的解决办法<br>主服务器要负责更新操作，对安全性的要求比从服务器要高，所以有些设置参数可以修改，比如syncbinlog=1，innodbflushlogattrxcommit = 1 之类的设置等。</p><p>选择更好的硬件设备作为slave。</p><p>把一台从服务器当度作为备份使用， 而不提供查询， 那边他的负载下来了， 执行relay log 里面的SQL效率自然就高了。</p><p>增加从服务器喽，这个目的还是分散读的压力，从而降低服务器负载。</p><h1 id="24-说一下大表查询的优化方案"><a href="#24-说一下大表查询的优化方案" class="headerlink" title="24. 说一下大表查询的优化方案"></a>24. 说一下大表查询的优化方案</h1><p>优化shema、sql语句+索引；</p><p>可以考虑加缓存，memcached, redis，或者JVM本地缓存；</p><p>主从复制，读写分离；</p><p>分库分表；</p><h1 id="25-什么是数据库连接池-为什么需要数据库连接池呢"><a href="#25-什么是数据库连接池-为什么需要数据库连接池呢" class="headerlink" title="25. 什么是数据库连接池?为什么需要数据库连接池呢?"></a>25. 什么是数据库连接池?为什么需要数据库连接池呢?</h1><p>连接池基本原理：数据库连接池原理：在内部对象池中，维护一定数量的数据库连接，并对外暴露数据库连接的获取和返回方法。</p><p>应用程序和数据库建立连接的过程：</p><p>通过TCP协议的三次握手和数据库服务器建立连接</p><p>发送数据库用户账号密码，等待数据库验证用户身份</p><p>完成身份验证后，系统可以提交SQL语句到数据库执行</p><p>把连接关闭，TCP四次挥手告别。</p><p>数据库连接池好处：</p><p>资源重用 (连接复用)</p><p>更快的系统响应速度</p><p>新的资源分配手段</p><p>统一的连接管理，避免数据库连接泄漏</p><ol start="26"><li>一条SQL语句在MySQL中如何执行的？<br>先看一下Mysql的逻辑架构图吧~</li></ol><p>查询语句：</p><p>先检查该语句是否有权限</p><p>如果没有权限，直接返回错误信息</p><p>如果有权限，在 MySQL8.0 版本以前，会先查询缓存。</p><p>如果没有缓存，分析器进行词法分析，提取 sql 语句select等的关键元素。然后判断sql 语句是否有语法错误，比如关键词是否正确等等。</p><p>优化器进行确定执行方案</p><p>进行权限校验，如果没有权限就直接返回错误信息，如果有权限就会调用数据库引擎接口，返回执行结果。</p><ol start="27"><li>InnoDB引擎中的索引策略，了解过吗？<br>覆盖索引</li></ol><p>最左前缀原则</p><p>索引下推</p><p>索引下推优化是 MySQL 5.6 引入的， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。</p><ol start="28"><li>数据库存储日期格式时，如何考虑时区转换问题？<br>datetime类型适合用来记录数据的原始的创建时间，修改记录中其他字段的值，datetime字段的值不会改变，除非手动修改它。</li></ol><p>timestamp类型适合用来记录数据的最后修改时间，只要修改了记录中其他字段的值，timestamp字段的值都会被自动更新。</p><ol start="29"><li>一条sql执行过长的时间，你如何优化，从哪些方面入手？<br>查看是否涉及多表和子查询，优化Sql结构，如去除冗余字段，是否可拆表等</li></ol><p>优化索引结构，看是否可以适当添加索引</p><p>数量大的表，可以考虑进行分离/分表（如交易流水表）</p><p>数据库主从分离，读写分离</p><p>explain分析sql语句，查看执行计划，优化sql</p><p>查看mysql执行日志，分析是否有其他方面的问题</p><ol start="30"><li>MYSQL数据库服务器性能分析的方法命令有哪些?<br>Show status, 一些值得监控的变量值：</li></ol><p>Bytesreceived和Bytessent 和服务器之间来往的流量。</p><p>Com_*服务器正在执行的命令。</p><p>Created_*在查询执行期限间创建的临时表和文件。</p><p>Handler_*存储引擎操作。</p><p>Select_*不同类型的联接执行计划。</p><p>Sort_*几种排序信息。</p><p> Show profiles 是MySql用来分析当前会话SQL语句执行的资源消耗情况</p><ol start="31"><li>Blob和text有什么区别？<br>Blob用于存储二进制数据，而Text用于存储大字符串。</li></ol><p>Blob值被视为二进制字符串（字节字符串）,它们没有字符集，并且排序和比较基于列值中的字节的数值。</p><p>text值被视为非二进制字符串（字符字符串）。它们有一个字符集，并根据字符集的排序规则对值进行排序和比较。</p><ol start="32"><li>mysql里记录货币用什么字段类型比较好？<br>货币在数据库中MySQL常用Decimal和Numric类型表示，这两种类型被MySQL实现为同样的类型。他们被用于保存与金钱有关的数据。</li></ol><p>salary DECIMAL(9,2)，9(precision)代表将被用于存储值的总的小数位数，而2(scale)代表将被用于存储小数点后的位数。存储在salary列中的值的范围是从-9999999.99到9999999.99。</p><p>DECIMAL和NUMERIC值作为字符串存储，而不是作为二进制浮点数，以便保存那些值的小数精度。</p><ol start="33"><li>Mysql中有哪几种锁，列举一下？</li></ol><p>如果按锁粒度划分，有以下3种：</p><p>表锁：开销小，加锁快；锁定力度大，发生锁冲突概率高，并发度最低;不会出现死锁。</p><p>行锁：开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突的概率低，并发度高。</p><p>页锁：开销和加锁速度介于表锁和行锁之间；会出现死锁；锁定粒度介于表锁和行锁之间，并发度一般</p><ol start="34"><li>Hash索引和B+树区别是什么？你在设计索引是怎么抉择的？<br>B+树可以进行范围查询，Hash索引不能。</li></ol><p>B+树支持联合索引的最左侧原则，Hash索引不支持。</p><p>B+树支持order by排序，Hash索引不支持。</p><p>Hash索引在等值查询上比B+树效率更高。</p><p>B+树使用like 进行模糊查询的时候，like后面（比如%开头）的话可以起到优化的作用，Hash索引根本无法进行模糊查询。</p><ol start="35"><li>mysql 的内连接、左连接、右连接有什么区别？<br>Inner join 内连接，在两张表进行连接查询时，只保留两张表中完全匹配的结果集</li></ol><p>left join 在两张表进行连接查询时，会返回左表所有的行，即使在右表中没有匹配的记录。</p><p>right join 在两张表进行连接查询时，会返回右表所有的行，即使在左表中没有匹配的记录。</p><ol start="36"><li>说说MySQL 的基础架构图<br>Mysql逻辑架构图主要分三层：</li></ol><p>第一层负责连接处理，授权认证，安全等等</p><p>第二层负责编译并优化SQL</p><p>第三层是存储引擎。</p><ol start="37"><li>什么是内连接、外连接、交叉连接、笛卡尔积呢？<br>内连接（inner join）：取得两张表中满足存在连接匹配关系的记录。</li></ol><p>外连接（outer join）：取得两张表中满足存在连接匹配关系的记录，以及某张表（或两张表）中不满足匹配关系的记录。</p><p>交叉连接（cross join）：显示两张表所有记录一一对应，没有匹配关系进行筛选，也被称为：笛卡尔积。</p><ol start="38"><li>说一下数据库的三大范式<br>第一范式：数据表中的每一列（每个字段）都不可以再拆分。</li></ol><p>第二范式：在第一范式的基础上，分主键列完全依赖于主键，而不能是依赖于主键的一部分。</p><p>第三范式：在满足第二范式的基础上，表中的非主键只依赖于主键，而不依赖于其他非主键。</p><ol start="39"><li>mysql有关权限的表有哪几个呢？<br>MySQL服务器通过权限表来控制用户对数据库的访问，权限表存放在mysql数据库里，由mysqlinstalldb脚本初始化。这些权限表分别user，db，tablepriv，columnspriv和host。</li></ol><p>user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。</p><p>db权限表：记录各个帐号在各个数据库上的操作权限。</p><p>table_priv权限表：记录数据表级的操作权限。</p><p>columns_priv权限表：记录数据列级的操作权限。</p><p>host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。这个权限表不受GRANT和REVOKE语句的影响。</p><ol start="40"><li>Mysql的binlog有几种录入格式？分别有什么区别？<br>有三种格式哈，statement，row和mixed。</li></ol><p>statement，每一条会修改数据的sql都会记录在binlog中。不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。</p><p>row，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)，因此这种模式的文件保存的信息太多，日志量太大。</p><p>mixed，一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。</p><ol start="41"><li>InnoDB引擎的4大特性，了解过吗<br>插入缓冲（insert buffer)</li></ol><p>二次写(double write)</p><p>自适应哈希索引(ahi)</p><p>预读(read ahead)</p><ol start="42"><li>索引有哪些优缺点？<br>优点：</li></ol><p>唯一索引可以保证数据库表中每一行的数据的唯一性</p><p>索引可以加快数据查询速度，减少查询时间</p><p>缺点：</p><p>创建索引和维护索引要耗费时间</p><p>索引需要占物理空间，除了数据表占用数据空间之外，每一个索引还要占用一定的物理空间</p><p>以表中的数据进行增、删、改的时候，索引也要动态的维护。</p><ol start="43"><li>索引有哪几种类型？<br>主键索引: 数据列不允许重复，不允许为NULL，一个表只能有一个主键。</li></ol><p>唯一索引: 数据列不允许重复，允许为NULL值，一个表允许多个列创建唯一索引。</p><p>普通索引: 基本的索引类型，没有唯一性的限制，允许为NULL值。</p><p>全文索引：是目前搜索引擎使用的一种关键技术，对文本的内容进行分词、搜索。</p><p>覆盖索引：查询列要被所建的索引覆盖，不必读取数据行</p><p>组合索引：多列值组成一个索引，用于组合搜索，效率大于索引合并</p><ol start="44"><li>创建索引有什么原则呢？<br>最左前缀匹配原则</li></ol><p>频繁作为查询条件的字段才去创建索引</p><p>频繁更新的字段不适合创建索引</p><p>索引列不能参与计算，不能有函数操作</p><p>优先考虑扩展索引，而不是新建索引，避免不必要的索引</p><p>在order by或者group by子句中，创建索引需要注意顺序</p><p>区分度低的数据列不适合做索引列(如性别）</p><p>定义有外键的数据列一定要建立索引。</p><p>对于定义为text、image数据类型的列不要建立索引。</p><p>删除不再使用或者很少使用的索引</p><ol start="45"><li>创建索引的三种方式<br>在执行CREATE TABLE时创建索引</li></ol><p>CREATE TABLE<br><code>employee</code></p><p>(</p><p><code>id</code></p><p>int<br>(<br>11<br>)<br> NOT NULL<br>,</p><p><code>name</code><br> varchar<br>(<br>255<br>)<br> DEFAULT NULL<br>,</p><p><code>age</code></p><p>int<br>(<br>11<br>)<br> DEFAULT NULL<br>,</p><p><code>date</code><br> datetime DEFAULT NULL<br>,</p><p><code>sex</code></p><p>int<br>(<br>1<br>)<br> DEFAULT NULL<br>,</p><p>  PRIMARY KEY<br>(<br><code>id</code><br>),</p><p>  KEY<br><code>idx_name</code></p><p>(<br><code>name</code><br>)<br> USING BTREE</p><p>)<br> ENGINE<br>=<br>InnoDB<br> DEFAULT CHARSET<br>=<br>utf8<br>;</p><p>使用ALTER TABLE命令添加索引</p><p>ALTER TABLE table_name ADD INDEX index_name<br>(<br>column<br>);</p><p>使用CREATE INDEX命令创建</p><p>CREATE INDEX index_name ON table_name<br>(<br>column<br>);</p><ol start="46"><li>百万级别或以上的数据，你是如何删除的？<br>我们想要删除百万数据的时候可以先删除索引</li></ol><p>然后批量删除其中无用数据</p><p>删除完成后重新创建索引。</p><ol start="47"><li>什么是最左前缀原则？什么是最左匹配原则？<br>最左前缀原则，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。</li></ol><p>当我们创建一个组合索引的时候，如(k1,k2,k3)，相当于创建了（k1）、(k1,k2)和(k1,k2,k3)三个索引，这就是最左匹配原则。。</p><ol start="48"><li>B树和B+树的区别，数据库为什么使用B+树而不是B树？<br>在B树中，键和值即存放在内部节点又存放在叶子节点；在B+树中，内部节点只存键，叶子节点则同时存放键和值。</li></ol><p>B+树的叶子节点有一条链相连，而B树的叶子节点各自独立的。</p><p>B+树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的，链表连着的。那么B+树使得范围查找，排序查找，分组查找以及去重查找变得异常简单。.</p><p>B+树非叶子节点上是不存储数据的，仅存储键值，而B树节点中不仅存储键值，也会存储数据。innodb中页的默认大小是16KB，如果不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，如此一来我们查找数据进行磁盘的IO次数有会再次减少，数据查询的效率也会更快.</p><ol start="49"><li>覆盖索引、回表等这些，了解过吗？<br>覆盖索引：查询列要被所建的索引覆盖，不必从数据表中读取，换句话说查询列要被所使用的索引覆盖。</li></ol><p>回表：二级索引无法直接查询所有列的数据，所以通过二级索引查询到聚簇索引后，再查询到想要的数据，这种通过二级索引查询出来的过程，就叫做回表。</p><ol start="50"><li>B+树在满足聚簇索引和覆盖索引的时候不需要回表查询数据？<br>在B+树的索引中，叶子节点可能存储了当前的key值，也可能存储了当前的key值以及整行的数据，这就是聚簇索引和非聚簇索引。在InnoDB中，只有主键索引是聚簇索引，如果没有主键，则挑选一个唯一键建立聚簇索引。如果没有唯一键，则隐式的生成一个键来建立聚簇索引。</li></ol><p>当查询使用聚簇索引时，在对应的叶子节点，可以获取到整行数据，因此不用再次进行回表查询。</p><ol start="51"><li>何时使用聚簇索引与非聚簇索引</li></ol><ol start="52"><li>非聚簇索引一定会回表查询吗？<br>不一定，如果查询语句的字段全部命中了索引，那么就不必再进行回表查询（哈哈，覆盖索引就是这么回事）。</li></ol><p>举个简单的例子，假设我们在学生表的上建立了索引，那么当进行select age from student where age &lt; 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。</p><ol start="53"><li>组合索引是什么？为什么需要注意组合索引中的顺序？<br>组合索引，用户可以在多个列上建立索引,这种索引叫做组合索引。</li></ol><p>因为InnoDB引擎中的索引策略的最左原则，所以需要注意组合索引中的顺序。</p><ol start="54"><li><p>什么是数据库事务？<br>数据库事务（简称：事务），是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。</p></li><li><p>隔离级别与锁的关系<br>回答这个问题，可以先阐述四种隔离级别，再阐述它们的实现原理。隔离级别就是依赖锁和MVCC实现的。</p></li><li><p>按照锁的粒度分，数据库锁有哪些呢？锁机制与InnoDB锁算法</p></li></ol><p>按锁粒度分有：表锁，页锁，行锁</p><p>按锁机制分有：乐观锁，悲观锁</p><ol start="57"><li>从锁的类别角度讲，MySQL都有哪些锁呢？<br>从锁的类别上来讲，有共享锁和排他锁。</li></ol><p>共享锁: 又叫做读锁。当用户要进行数据的读取时，对数据加上共享锁。共享锁可以同时加上多个。</p><p>排他锁: 又叫做写锁。当用户要进行数据的写入时，对数据加上排他锁。排他锁只可以加一个，他和其他的排他锁，共享锁都相斥。</p><p>锁兼容性如下：</p><ol start="58"><li>MySQL中InnoDB引擎的行锁是怎么实现的？<br>基于索引来完成行锁的。</li></ol><p>select</p><p>*</p><p>from<br> t<br>where<br> id<br>=</p><p>666</p><p>for<br> update<br>;</p><p>for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将实行表锁。</p><ol start="59"><li>什么是死锁？怎么解决？<br>死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。看图形象一点，如下：死锁有四个必要条件：互斥条件，请求和保持条件，环路等待条件，不剥夺条件。</li></ol><p>解决死锁思路，一般就是切断环路，尽量避免并发形成环路。</p><p>如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。</p><p>在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；</p><p>对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；</p><p>如果业务处理不好可以用分布式事务锁或者使用乐观锁</p><p>死锁与索引密不可分，解决索引问题，需要合理优化你的索引，</p><ol start="60"><li>为什么要使用视图？什么是视图？<br>为什么要使用视图？</li></ol><p>为了提高复杂SQL语句的复用性和表操作的安全性，MySQL数据库管理系统提供了视图特性。</p><p>什么是视图？</p><p>视图是一个虚拟的表，是一个表中的数据经过某种筛选后的显示方式，视图由一个预定义的查询select语句组成。</p><ol start="61"><li>视图有哪些特点？哪些使用场景？<br>视图特点：</li></ol><p>视图的列可以来自不同的表，是表的抽象和在逻辑意义上建立的新关系。</p><p>视图是由基本表(实表)产生的表(虚表)。</p><p>视图的建立和删除不影响基本表。</p><p>对视图内容的更新(添加，删除和修改)直接影响基本表。</p><p>当视图来自多个基本表时，不允许添加和删除数据。</p><p>视图用途： 简化sql查询，提高开发效率，兼容老的表结构。</p><p>视图的常见使用场景：</p><p>重用SQL语句；</p><p>简化复杂的SQL操作。</p><p>使用表的组成部分而不是整个表；</p><p>保护数据</p><p>更改数据格式和表示。视图可返回与底层表的表示和格式不同的数据。</p><ol start="62"><li>视图的优点，缺点，讲一下？<br>查询简单化。视图能简化用户的操作</li></ol><p>数据安全性。视图使用户能以多种角度看待同一数据，能够对机密数据提供安全保护</p><p>逻辑数据独立性。视图对重构数据库提供了一定程度的逻辑独立性</p><ol start="63"><li>count(1)、count(<em>) 与 count(列名) 的区别？<br>count(</em>)包括了所有的列，相当于行数，在统计结果的时候，不会忽略列值为NULL</li></ol><p>count(1)包括了忽略所有列，用1代表代码行，在统计结果的时候，不会忽略列值为NULL</p><p>count(列名)只包括列名那一列，在统计结果的时候，会忽略列值为空（这里的空不是只空字符串或者0，而是表示null）的计数，即某个字段值为NULL时，不统计。</p><ol start="64"><li><p>什么是游标？<br>游标提供了一种对从表中检索出的数据进行操作的灵活手段，就本质而言，游标实际上是一种能从包括多条数据记录的结果集中每次提取一条记录的机制。</p></li><li><p>什么是存储过程？有哪些优缺点？<br>存储过程，就是一些编译好了的SQL语句，这些SQL语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后给这些代码块取一个名字，在用到这个功能的时候调用即可。</p></li></ol><p>优点：</p><p>存储过程是一个预编译的代码块，执行效率比较高</p><p>存储过程在服务器端运行，减少客户端的压力</p><p>允许模块化程序设计，只需要创建一次过程，以后在程序中就可以调用该过程任意次，类似方法的复用</p><p>一个存储过程替代大量T_SQL语句 ，可以降低网络通信量，提高通信速率</p><p>可以一定程度上确保数据安全</p><p>缺点：</p><p>调试麻烦</p><p>可移植性不灵活</p><p>重新编译问题</p><ol start="66"><li>什么是触发器？触发器的使用场景有哪些？<br>触发器，指一段代码，当触发某个事件时，自动执行这些代码。</li></ol><p>使用场景：</p><p>可以通过数据库中的相关表实现级联更改。</p><p>实时监控某张表中的某个字段的更改而需要做出相应的处理。</p><p>例如可以生成某些业务的编号。</p><p>注意不要滥用，否则会造成数据库及应用程序的维护困难。</p><ol start="67"><li>MySQL中都有哪些触发器？<br>MySQL 数据库中有六种触发器：</li></ol><p>Before Insert</p><p>After Insert</p><p>Before Update</p><p>After Update</p><p>Before Delete</p><p>After Delete</p><ol start="68"><li>超键、候选键、主键、外键分别是什么？<br>超键：在关系模式中，能唯一知标识元组的属性集称为超键。</li></ol><p>候选键：是最小超键，即没有冗余元素的超键。</p><p>主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。</p><p>外键：在一个表中存在的另一个表的主键称此表的外键。。</p><ol start="69"><li>SQL 约束有哪几种呢？<br>NOT NULL: 约束字段的内容一定不能为NULL。</li></ol><p>UNIQUE: 约束字段唯一性，一个表允许有多个 Unique 约束。</p><p>PRIMARY KEY: 约束字段唯一，不可重复，一个表只允许存在一个。</p><p>FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键。</p><p>CHECK: 用于控制字段的值范围。</p><ol start="70"><li>谈谈六种关联查询，使用场景。<br>交叉连接</li></ol><p>内连接</p><p>外连接</p><p>联合查询</p><p>全连接</p><p>交叉连接</p><ol start="71"><li>varchar(50)中50的涵义<br>字段最多存放 50 个字符</li></ol><p>如 varchar(50) 和 varchar(200) 存储 “jay” 字符串所占空间是一样的，后者在排序时会消耗更多内存</p><ol start="72"><li>mysql中int(20)和char(20)以及varchar(20)的区别<br>int(20) 表示字段是int类型，显示长度是 20</li></ol><p>char(20)表示字段是固定长度字符串，长度为 20</p><p>varchar(20) 表示字段是可变长度字符串，长度为 20</p><ol start="73"><li>drop、delete与truncate的区别</li></ol><p>delete    truncate    drop<br>类型    DML    DDL    DDL<br>回滚    可回滚    不可回滚    不可回滚<br>删除内容    表结构还在，删除表的全部或者一部分数据行    表结构还在，删除表中的所有数据    从数据库中删除表，所有的数据行，索引和权限也会被删除<br>删除速度    删除速度慢，逐行删除    删除速度快    删除速度最快<br>74. UNION与UNION ALL的区别？<br>Union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；</p><p>Union All：对两个结果集进行并集操作，包括重复行，不进行排序；</p><p>UNION的效率高于 UNION ALL</p><ol start="75"><li>SQL的生命周期？<br>服务器与数据库建立连接</li></ol><p>数据库进程拿到请求sql</p><p>解析并生成执行计划，执行</p><p>读取数据到内存，并进行逻辑处理</p><p>通过步骤一的连接，发送结果到客户端</p><p>关掉连接，释放资源</p><ol start="76"><li>一条Sql的执行顺序？</li></ol><ol start="77"><li>列值为NULL时，查询是否会用到索引？<br>列值为NULL也是可以走索引的</li></ol><p>计划对列进行索引，应尽量避免把它设置为可空，因为这会让 MySQL 难以优化引用了可空列的查询，同时增加了引擎的复杂度</p><ol start="78"><li>关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？<br>我们平时写Sql时，都要养成用explain分析的习惯。</li></ol><p>慢查询的统计，运维会定期统计给我们</p><p>优化慢查询：</p><p>分析语句，是否加载了不必要的字段/数据。</p><p>分析SQl执行句话，是否命中索引等。</p><p>如果SQL很复杂，优化SQL结构</p><p>如果表数据量太大，考虑分表</p><p>可以看我这篇文章哈：后端程序员必备：书写高质量SQL的30条建议</p><ol start="79"><li>主键使用自增ID还是UUID，为什么？<br>如果是单机的话，选择自增ID；如果是分布式系统，优先考虑UUID吧，但还是最好自己公司有一套分布式唯一ID生产方案吧。</li></ol><p>自增ID：数据存储空间小，查询效率高。但是如果数据量过大,会超出自增长的值范围，多库合并，也有可能有问题。</p><p>uuid：适合大量数据的插入和更新操作，但是它无序的，插入数据效率慢，占用空间大。</p><ol start="80"><li><p>mysql自增主键用完了怎么办？<br>自增主键一般用int类型，一般达不到最大值，可以考虑提前分库分表的。</p></li><li><p>字段为什么要求定义为not null？<br>null值会占用更多的字节，并且null有很多坑的。</p></li><li><p>如果要存储用户的密码散列，应该使用什么字段进行存储？<br>密码散列，盐，用户身份证号等固定长度的字符串，应该使用char而不是varchar来存储，这样可以节省空间且提高检索效率。</p></li><li><p>Mysql驱动程序是什么？<br>这个jar包：mysql-connector-java-5.1.18.jar</p></li></ol><p>Mysql驱动程序主要帮助编程语言与 MySQL服务端进行通信，如连接、传输数据、关闭等。</p><ol start="84"><li>如何优化长难的查询语句？有实战过吗？<br>将一个大的查询分为多个小的相同的查询</li></ol><p>减少冗余记录的查询。</p><p>一个复杂查询可以考虑拆成多个简单查询</p><p>分解关联查询，让缓存的效率更高。</p><ol start="85"><li>优化特定类型的查询语句<br>平时积累吧：</li></ol><p>比如使用select 具体字段代替 select *</p><p>使用count(*) 而不是count(列名)</p><p>在不影响业务的情况，使用缓存</p><p>explain 分析你的SQL</p><ol start="86"><li>MySQL数据库cpu飙升的话，要怎么处理呢？<br>排查过程：</li></ol><p>使用top 命令观察，确定是mysqld导致还是其他原因。</p><p>如果是mysqld导致的，show processlist，查看session情况，确定是不是有消耗资源的sql在运行。</p><p>找出消耗高的 sql，看看执行计划是否准确， 索引是否缺失，数据量是否太大。</p><p>处理：</p><p>kill 掉这些线程(同时观察 cpu 使用率是否下降)，</p><p>进行相应的调整(比如说加索引、改 sql、改内存参数)</p><p>重新跑这些 SQL。</p><p>其他情况：</p><p>也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等</p><ol start="87"><li>读写分离常见方案？<br>应用程序根据业务逻辑来判断，增删改等写操作命令发给主库，查询命令发给备库。</li></ol><p>利用中间件来做代理，负责对数据库的请求识别出读还是写，并分发到不同的数据库中。（如：amoeba，mysql-proxy）</p><ol start="88"><li>MySQL的复制原理以及流程<br>主从复制原理，简言之，就三步曲，如下：</li></ol><p>主数据库有个bin-log二进制文件，纪录了所有增删改Sql语句。（binlog线程）</p><p>从数据库把主数据库的bin-log文件的sql语句复制过来。（io线程）</p><p>从数据库的relay-log重做日志文件中再执行一次这些sql语句。（Sql执行线程）</p><p>如下图所示：</p><p>上图主从复制分了五个步骤进行：</p><p>步骤一：主库的更新事件(update、insert、delete)被写到binlog</p><p>步骤二：从库发起连接，连接到主库。</p><p>步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库。</p><p>步骤四：从库启动之后，创建一个I/O线程，读取主库传过来的binlog内容并写入到relay log</p><p>步骤五：还会创建一个SQL线程，从relay log里面读取内容，从ExecMasterLog_Pos位置开始执行读取到的更新事件，将更新内容写入到slave的db</p><ol start="89"><li>MySQL中DATETIME和TIMESTAMP的区别<br>存储精度都为秒</li></ol><p>区别：</p><p>DATETIME 的日期范围是 1001——9999 年；TIMESTAMP 的时间范围是 1970——2038 年</p><p>DATETIME 存储时间与时区无关；TIMESTAMP 存储时间与时区有关，显示的值也依赖于时区</p><p>DATETIME 的存储空间为 8 字节；TIMESTAMP 的存储空间为 4 字节</p><p>DATETIME 的默认值为 null；TIMESTAMP 的字段默认不为空(not null)，默认值为当前时间(CURRENT_TIMESTAMP)</p><ol start="90"><li>Innodb的事务实现原理？<br>原子性：是使用 undo log来实现的，如果事务执行过程中出错或者用户执行了rollback，系统通过undo log日志返回事务开始的状态。</li></ol><p>持久性：使用 redo log来实现，只要redo log日志持久化了，当系统崩溃，即可通过redo log把数据恢复。</p><p>隔离性：通过锁以及MVCC,使事务相互隔离开。</p><p>一致性：通过回滚、恢复，以及并发情况下的隔离性，从而实现一致性。</p><ol start="91"><li>谈谈MySQL的Explain<br>Explain 执行计划包含字段信息如下：分别是 id、selecttype、table、partitions、type、possiblekeys、key、key_len、ref、rows、filtered、Extra 等12个字段。</li></ol><p>我们重点关注的是type，它的属性排序如下：</p><p>system  </p><blockquote></blockquote><p>const</p><blockquote></blockquote><p> eq_ref </p><blockquote></blockquote><p>ref</p><blockquote></blockquote><p> ref_or_null </p><blockquote></blockquote><p>index_merge </p><blockquote></blockquote><p> unique_subquery </p><blockquote></blockquote><p> index_subquery </p><blockquote></blockquote><p>range </p><blockquote></blockquote><p> index </p><blockquote></blockquote><p> ALL</p><ol start="92"><li>Innodb的事务与日志的实现方式<br>有多少种日志<br>innodb两种日志redo和undo。</li></ol><p>日志的存放形式<br>redo：在页修改的时候，先写到 redo log buffer 里面， 然后写到 redo log 的文件系统缓存里面(fwrite)，然后再同步到磁盘文件（ fsync）。</p><p>Undo：在 MySQL5.5 之前， undo 只能存放在 ibdata文件里面， 5.6 之后，可以通过设置 innodbundotablespaces 参数把 undo log 存放在 ibdata之外。</p><p>事务是如何通过日志来实现的<br>因为事务在修改页时，要先记 undo，在记 undo 之前要记 undo 的 redo， 然后修改数据页，再记数据页修改的 redo。Redo（里面包括 undo 的修改） 一定要比数据页先持久化到磁盘。</p><p>当事务需要回滚时，因为有 undo，可以把数据页回滚到前镜像的 状态，崩溃恢复时，如果 redo log 中事务没有对应的 commit 记录，那么需要用 undo把该事务的修改回滚到事务开始之前。</p><p>如果有 commit 记录，就用 redo 前滚到该事务完成时并提交掉。</p><ol start="93"><li>MySQL中TEXT数据类型的最大长度<br>TINYTEXT：256 bytes</li></ol><p>TEXT：65,535 bytes(64kb)</p><p>MEDIUMTEXT：16,777,215 bytes(16MB)</p><p>LONGTEXT：4,294,967,295 bytes(4GB)</p><ol start="94"><li>500台db，在最快时间之内重启。<br>可以使用批量 ssh 工具 pssh 来对需要重启的机器执行重启命令。</li></ol><p>也可以使用 salt（前提是客户端有安装 salt）或者 ansible（ ansible 只需要 ssh 免登通了就行）等多线程工具同时操作多台服务</p><ol start="95"><li><p>你是如何监控你们的数据库的？你们的慢日志都是怎么查询的？<br>监控的工具有很多，例如zabbix，lepus，我这里用的是lepus</p></li><li><p>你是否做过主从一致性校验，如果有，怎么做的，如果没有，你打算怎么做？<br>主从一致性校验有多种工具 例如checksum、mysqldiff、pt-table-checksum等</p></li><li><p>你们数据库是否支持emoji表情存储，如果不支持，如何操作？<br>更换字符集utf8–&gt;utf8mb4</p></li><li><p>MySQL如何获取当前日期？<br>SELECT CURRENT_DATE();</p></li><li><p>一个6亿的表a，一个3亿的表b，通过外间tid关联，你如何最快的查询出满足条件的第50000到第50200中的这200条数据记录。<br>1、如果A表TID是自增长,并且是连续的,B表的ID为索引<br>select * from a,b where a.tid = b.id and a.tid&gt;500000 limit 200;</p></li></ol><p>2、如果A表的TID不是连续的,那么就需要使用覆盖索引.TID要么是主键,要么是辅助索引,B表ID也需要有索引。select * from b , (select tid from a limit 50000,200) a where b.id = a .tid;</p><ol start="100"><li>Mysql一条SQL加锁分析<br>一条SQL加锁，可以分9种情况进行哈：</li></ol><p>组合一：id列是主键，RC隔离级别</p><p>组合二：id列是二级唯一索引，RC隔离级别</p><p>组合三：id列是二级非唯一索引，RC隔离级别</p><p>组合四：id列上没有索引，RC隔离级别</p><p>组合五：id列是主键，RR隔离级别</p><p>组合六：id列是二级唯一索引，RR隔离级别</p><p>组合七：id列是二级非唯一索引，RR隔离级别</p><p>组合八：id列上没有索引，RR隔离级别</p><p>组合九：Serializable隔离级别</p>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>讯龙创威面经</title>
    <link href="/2020/11/17/%E8%AE%AF%E9%BE%99%E5%88%9B%E5%A8%81%E9%9D%A2%E7%BB%8F/"/>
    <url>/2020/11/17/%E8%AE%AF%E9%BE%99%E5%88%9B%E5%A8%81%E9%9D%A2%E7%BB%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="一面-一个多小时"><a href="#一面-一个多小时" class="headerlink" title="一面(一个多小时)"></a>一面(一个多小时)</h1><p>DNS寻址</p><p>Http/Https区别</p><p>TCP/IP</p><p>Nginx：ssl端口</p><p>跨域:原因+解决方案</p><p>Mysql引擎</p><p>Int(1)和Int(10)</p><p>MySQL然后提升性能</p><p>SQL基本操作</p><p>数据库事务是什么</p><p>事务隔离级别:</p><p>事务的特性:ACID</p><p>面向对象编程思想:封装,继承,多态</p><p>设计模式:种类,作用</p><h1 id="二面-半个小时"><a href="#二面-半个小时" class="headerlink" title="二面(半个小时)"></a>二面(半个小时)</h1><p>MySQL索引</p><p>如何协调团队开发</p><p>能不能开发php</p><p>手撕代码:求一个递增数组中两个数和为target数的方法，返回对应的下标</p><pre><code class="java">public class Solution{    public static int[] method(int[] nums,int target){       Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();         for (int i = 0; i &lt; nums.length; i++) {           int complement = target - nums[i];             if (map.containsKey(complement)) {                  return new int[] { map.get(complement), i };              }              map.put(nums[i], i);           }           throw new IllegalArgumentException(&quot;No two sum solution&quot;);    }}</code></pre><h1 id="三面-半个小时"><a href="#三面-半个小时" class="headerlink" title="三面(半个小时)"></a>三面(半个小时)</h1><p>问项目</p><p>家庭情况</p><p>项目中遇到的困难</p><p>自己的缺点</p><p>朋友的评价</p><p>打游戏不</p><p>所获奖项</p>]]></content>
    
    
    <categories>
      
      <category>hide</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hide</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>算法框架</title>
    <link href="/2020/11/14/%E7%AE%97%E6%B3%95%E6%A1%86%E6%9E%B6/"/>
    <url>/2020/11/14/%E7%AE%97%E6%B3%95%E6%A1%86%E6%9E%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h1><blockquote><p>动态规划问题的一般形式就是求最值。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求最长递增子序列呀，最小编辑距离呀等等。<br> 既然是要求最值，核心问题是什么呢？求解动态规划的核心问题是穷举。因为要求最值，肯定要把所有可行的答案穷举出来，然后在其中找最值呗。<br> 动态规划就这么简单，就是穷举就完事了？我看到的动态规划问题都很难啊！<br> 首先，动态规划的穷举有点特别，因为这类问题存在「重叠子问题」，如果暴力穷举的话效率会极其低下，所以需要「备忘录」或者「DP table」来优化穷举过程，避免不必要的计算。<br> 而且，动态规划问题一定会具备「最优子结构」，才能通过子问题的最值得到原问题的最值。<br> 另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出正确的「状态转移方程」才能正确地穷举。<br> 以上提到的重叠子问题、最优子结构、状态转移方程就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，写出状态转移方程是最困难的，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程：<br> <code>明确「状态」 -&gt; 定义 dp 数组/函数的含义 -&gt; 明确「选择」-&gt; 明确 base case。</code></p></blockquote><h2 id="算法框架"><a href="#算法框架" class="headerlink" title="算法框架"></a>算法框架</h2><blockquote><p>列出动态转移方程，就是在解决“如何穷举”的问题。之所以说它难，一是因为很多穷举需要递归实现，二是因为有的问题本身的解空间复杂，不那么容易穷举完整。</p></blockquote><blockquote><p>备忘录、DP table 就是在追求“如何聪明地穷举”。用空间换时间的思路，是降低时间复杂度的不二法门，除此之外，试问，还能玩出啥花活？</p></blockquote><h1 id="回溯算法"><a href="#回溯算法" class="headerlink" title="回溯算法"></a>回溯算法</h1><blockquote><p>解决一个回溯问题，实际上就是一个决策树的遍历过程</p></blockquote><pre><code class="text">路径：也就是已经做出的选择。选择列表：也就是你当前可以做的选择。结束条件：也就是到达决策树底层，无法再做选择的条件。</code></pre><h2 id="算法框架-1"><a href="#算法框架-1" class="headerlink" title="算法框架"></a>算法框架</h2><details>  <summary><span>点击展开</span></summary><pre><code class="cgo">result = []def backtrack(路径, 选择列表):    if 满足结束条件:        result.add(路径)        return    for 选择 in 选择列表:        做选择        backtrack(路径, 选择列表)        撤销选择</code></pre></details><h1 id="广度遍历"><a href="#广度遍历" class="headerlink" title="广度遍历"></a>广度遍历</h1><blockquote><p>BFS 的核心思想应该不难理解的，就是把一些问题抽象成图，从一个点开始，向四周开始扩散。一般来说，我们写 BFS 算法都是用「队列」这种数据结构，每次将一个节点周围的所有节点加入队列。</p></blockquote><h2 id="算法框架-2"><a href="#算法框架-2" class="headerlink" title="算法框架"></a>算法框架</h2><details>  <summary><span>点击展开</span></summary><pre><code class="cgo">// 计算从起点 start 到终点 target 的最近距离int BFS(Node start, Node target) {    Queue&lt;Node&gt; q; // 核心数据结构    Set&lt;Node&gt; visited; // 避免走回头路    q.offer(start); // 将起点加入队列    visited.add(start);    int step = 0; // 记录扩散的步数    while (q not empty) {        int sz = q.size();        /* 将当前队列中的所有节点向四周扩散 */        for (int i = 0; i &lt; sz; i++) {            Node cur = q.poll();            /* 划重点：这里判断是否到达终点 */            if (cur is target)                return step;            /* 将 cur 的相邻节点加入队列 */            for (Node x : cur.adj())                if (x not in visited) {                    q.offer(x);                    visited.add(x);                }        }        /* 划重点：更新步数在这里 */        step++;    }}</code></pre></details><h1 id="深度遍历"><a href="#深度遍历" class="headerlink" title="深度遍历"></a>深度遍历</h1><h1 id="窗口滑动"><a href="#窗口滑动" class="headerlink" title="窗口滑动"></a>窗口滑动</h1><p>时间复杂度:  <code>T(n)=O(n)</code></p><h2 id="算法框架-3"><a href="#算法框架-3" class="headerlink" title="算法框架"></a>算法框架</h2><details>  <summary><span>点击展开</span></summary><pre><code class="cgo">  /* 滑动窗口算法框架 */  void slidingWindow(string s, string t) {      unordered_map&lt;char, int&gt; need, window;      for (char c : t) need[c]++;//初始化      int left = 0, right = 0;//左右指针      int valid = 0;//      while (right &lt; s.size()) {          // c 是将移入窗口的字符          char c = s[right];          // 右移窗口          right++;          // 进行窗口内数据的一系列更新          ...          /*** debug 输出的位置 ***/          printf(&quot;window: [%d, %d)\n&quot;, left, right);          // 判断左侧窗口是否要收缩          while (window needs shrink) {              // d 是将移出窗口的字符              char d = s[left];              // 左移窗口              left++;              // 进行窗口内数据的一系列更新              ...          }      }  }</code></pre></details><h2 id="参考例子"><a href="#参考例子" class="headerlink" title="参考例子"></a>参考例子</h2>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法框架</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>排序算法</title>
    <link href="/2020/11/09/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"/>
    <url>/2020/11/09/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="时间复杂度"><a href="#时间复杂度" class="headerlink" title="时间复杂度"></a>时间复杂度</h1><p>时间复杂度：<code>T(n)=O(f(n))</code></p><p>渐进时间复杂度（asymptotic time complexity）的概念，官方的定义如下：<br>若存在函数 f（n），使得当n趋近于无穷大时，T（n）/ f（n）的极限值为不等于零的常数，则称 f（n）是T（n）的同数量级函数。<br>记作 T（n）= O（f（n）），称O（f（n）） 为算法的渐进时间复杂度，简称时间复杂度。</p><p>如何推导出时间复杂度呢？有如下几个原则：<br> 1.如果运行时间是常数量级，用常数1表示；<br> 2.只保留时间函数中的最高阶项；<br> 3.如果最高阶项存在，则省去最高阶项前面的系数。  </p><blockquote><p>常数阶O(1) &lt; 对数阶O(logN) &lt; 线性阶O(n) &lt; 线性对数阶O(nlogN) &lt; 平方阶O(n²) &lt; 立方阶O(n³) &lt; K次方阶O(n^k) &lt; 指数阶(2^n)</p></blockquote><h1 id="快速排序"><a href="#快速排序" class="headerlink" title="快速排序"></a>快速排序</h1><blockquote><p>1.选择基准(一般取第一个)<br>2.从右往左查找比基准小的数，进行位置交换<br>3.从左往右查找比基准大的数，进行位置交换<br>4.重复执行2、3直到比较完成<br>5.分别对两边重复执行1-4</p></blockquote><pre><code class="java">public class Sort {    public static void quicksort(int[] arr,int left,int right){        if (left &lt; right) {            int low = left, height = right, x = arr[left];            while (low &lt; height)            {                while(low &lt; height &amp;&amp; arr[height] &gt;= x) // 从右向左找第一个小于x的数                    height--;                if(low &lt; height)                    arr[low++] = arr[height];                while(low &lt; height &amp;&amp; arr[low] &lt; x) // 从左向右找第一个大于等于x的数                    low++;                if(low &lt; height)                    arr[height--] = arr[low];            }            arr[low] = x;            quicksort(arr, left, low - 1); // 递归调用            quicksort(arr, low + 1, right);        }    }}</code></pre><h1 id="直接插入排序"><a href="#直接插入排序" class="headerlink" title="直接插入排序"></a>直接插入排序</h1><blockquote><p>1.分为有序和无序两段数组<br>2.从无序中取第一个数插入有序半段中的适合位置<br>3.重复执行2步骤直到无序数组为长度为零</p></blockquote><p><code>T(n)=O(n^2)</code></p><pre><code class="java">class Sort{    public static void straightInsertSort(int[] arr){        int j = 0;        int tmp = 0;        for (int i = 1; i &lt; arr.length; i++) {            if (arr[i]&lt;arr[i-1]){//插入i-1前面                tmp = arr[i];                for (j = i - 1; j &gt;= 0 &amp;&amp; tmp &lt; arr[j]; j--) {                    arr[j+1] = arr[j];                }                arr[j+1] = tmp;            }        }    }}</code></pre><h1 id="选择排序"><a href="#选择排序" class="headerlink" title="选择排序"></a>选择排序</h1><blockquote><p>1.在长度为N的无序数组中，第一次遍历n-1个数，找到最小的数值与第一个元素交换；</p></blockquote><blockquote><p>2.第二次遍历n-2个数，找到最小的数值与第二个元素交换；</p></blockquote><blockquote><p>3.第n-1次遍历，找到最小的数值与第n-1个元素交换，排序完成。</p></blockquote><pre><code class="java">public class Sort{        public static void selectSort(int[] arr){            int min;            for (int i = 0; i &lt; arr.length; i++) {                min=arr[i];                for (int j = i+1; j &lt;arr.length; j++) {                    if (arr[j]&lt;min){                        int tmp = arr[i];                        min=arr[j];                        arr[i]=arr[j];                        arr[j]=tmp;                    }            }       }   }}</code></pre><h1 id="希尔排序-Shell-Sort"><a href="#希尔排序-Shell-Sort" class="headerlink" title="希尔排序(Shell Sort)"></a>希尔排序(Shell Sort)</h1><p>数据序列1： 13-17-20-42-28 利用插入排序，13-17-20-28-42. Number of swap:1;<br>数据序列2： 13-17-20-42-14 利用插入排序，13-14-17-20-42. Number of swap:3;<br>如果数据序列基本有序，使用插入排序会更加高效。</p><p>基本思想：<br>    在要排序的一组数中，根据某一增量分为若干子序列，并对子序列分别进行插入排序。<br>    然后逐渐将增量减小,并重复上述过程。直至增量为1,此时数据序列基本有序,最后进行插入排序。</p><pre><code class="java">public class Sort{    public static void shellSort(int[] arr){        int incre = arr.length;        while (true){            incre = incre&gt;&gt;1;            for (int i = 0; i &lt; incre; i++) {                for (int j = i; j &lt;arr.length ; j+=incre) {                    for (int k = j; k &gt;i ; k-=incre) {                        if (arr[k]&lt;arr[k-incre]){                            int tmp = arr[k];                            arr[k-incre]=arr[k];                            arr[k]=tmp;                        }else break;                    }                }            }            if (incre==1)break;        }    }}</code></pre><h1 id="冒泡排序"><a href="#冒泡排序" class="headerlink" title="冒泡排序"></a>冒泡排序</h1><p>基本思想：两个数比较大小，较大的数下沉，较小的数冒起来。</p><p>过程：</p><blockquote><p>比较相邻的两个数据，如果第二个数小，就交换位置。<br>从后向前两两比较，一直到比较最前两个数据。最终最小数被交换到起始的位置，这样第一个最小数的位置就排好了。<br>继续重复上述过程，依次将第2.3…n-1个最小数排好位置。</p></blockquote><p>时间复杂度: <code>T(n)=O(n^2)</code></p><pre><code class="java">class Sort{public static void BubbleSort(int [] arr){     int temp;//临时变量     for(int i=0; i&lt;arr.length-1; i++){   //表示趟数，一共arr.length-1次。         for(int j=arr.length-1; j&gt;i; j--){             if(arr[j] &lt; arr[j-1]){                 temp = arr[j];                 arr[j] = arr[j-1];                 arr[j-1] = temp;             }         }     } }}</code></pre><h1 id="归并排序"><a href="#归并排序" class="headerlink" title="归并排序"></a>归并排序</h1><p>平均时间复杂度：<code>O(NlogN)</code></p><p>基本思路:</p><blockquote><p>归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。</p></blockquote><blockquote><p>首先考虑下如何将将二个有序数列合并。这个非常简单，只要从比较二个数列的第一个数，谁小就先取谁，取了后就在对应数列中删除这个数。然后再进行比较，如果有数列为空，那直接将另一个数列的数据依次取出即可。</p></blockquote><blockquote><blockquote><p>归并排序的效率是比较高的，设数列长为 N，将数列分开成小数列一共要 logN 步，每步都是一个合并有序数列的过程，时间复杂度可以记为 O(N)，故一共为 O(N<em>logN)。因为归并排序每次都是在相邻的数据中进行操作，所以归并排序在 O(N</em>logN) 的几种排序方法（快速排序，归并排序，希尔排序，堆排序）也是效率比较高的。</p></blockquote></blockquote><pre><code class="java">public class Sort{    /**    *程序入口    * @param arr    */    void MergeSort(int[] arr){        int[] temp = new int[arr.length];        mergeSort(arr,0,arr.length-1,temp);    }    /**    * 递归    * @param a    * @param first    * @param last    * @param temp    */    public static void mergeSort(int[] a, int first, int last, int[] temp) {        if (first &lt; last) {            int mid = (first + last) / 2;            mergeSort(a, first, mid, temp);            mergeSort(a, mid + 1, last, temp);            mergeArray(a, first, mid, last, temp);        }    }    /**    * 合并数组    * @param a    * @param first    * @param mid    * @param last    * @param temp    */    private static void mergeArray(int[] a, int first, int mid, int last, int[] temp) {        int i = first, j = mid + 1;        int m = mid, n = last;        int k = 0;        while (i &lt;= m &amp;&amp; j &lt;= n) {            if (a[i] &lt;= a[j]) temp[k++] = a[i++];            else temp[k++] = a[j++];        }        while (i &lt;= m) temp[k++] = a[i++];        while (j &lt;= n) temp[k++] = a[j++];        for (int l = 0; l &lt; k; l++) a[first + i] = temp[i];    }}</code></pre><h1 id="堆排序"><a href="#堆排序" class="headerlink" title="堆排序"></a>堆排序</h1><blockquote><p>堆排序的基本思想是：将待排序序列构造成一个大顶堆，此时，整个序列的最大值就是堆顶的根节点。将其与末尾元素进行交换，此时末尾就为最大值。然后将剩余n-1个元素重新构造成一个堆，这样会得到n个元素的次小值。如此反复执行，便能得到一个有序序列了</p></blockquote><h1 id="基数排序-RadixSort"><a href="#基数排序-RadixSort" class="headerlink" title="基数排序(RadixSort)"></a>基数排序(RadixSort)</h1><p>基本思想：<br>BinSort想法非常简单，首先创建数组A[MaxValue]；然后将每个数放到相应的位置上（例如17放在下标17的数组位置）；最后遍历数组，即为排序后的结果。</p>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>排序算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式缓存</title>
    <link href="/2020/09/07/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/"/>
    <url>/2020/09/07/%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><p>缓存雪崩我们可以简单的理解为:由于原有缓存失效,新缓存未到期间所有原本应该访问缓存的请求都去查询数据库了,而对数据库 CPU 和内存造成巨大压力,严重的会造成数据库宕机。从而形成一系列连锁反应,造成整个系统崩溃。一般有三种处理办法:</p><ol><li>一般并发量不是特别多的时候,使用最多的解决方案是加锁排队。</li><li>给每一个缓存数据增加相应的缓存标记,记录缓存的是否失效,如果缓存标记失效,则更新数据缓存。</li><li>为 key 设置不同的缓存失效时间。</li></ol><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><p>缓存穿透是指用户查询数据,在数据库没有,自然在缓存中也不会有。这样就导致用户查询的时候,在缓存中找不到,每次都要去数据库再查询一遍,然后返回空(相当于进行了两次无用的查询)。这样请求就绕过缓存直接查数据库,这也是经常提的缓存命中率问题。<br>有很多种方法可以有效地解决缓存穿透问题,最常见的则是采用布隆过滤器,将所有可能存在的数据哈希到一个足够大的 bitmap 中,一个一定不存在的数据会被这个 bitmap 拦截掉,从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法,如果一个查询返回的数据为空(不管是数据不存在,还是系统故障),我们仍然把这个空结果进行缓存,但它的过期时间会很短,最长不超过五分钟。通过这个直接设置的默认值存放到缓存,这样第二次到缓冲中获取就有值了,而不会继续访问数据库。</p><h1 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h1><p>缓存预热就是系统上线后,将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候,先查询数据库,然后再将数据缓存的问题!用户直接查询事先被预热的缓存数据!</p><h1 id="缓存更新"><a href="#缓存更新" class="headerlink" title="缓存更新"></a>缓存更新</h1><p>缓存更新除了缓存服务器自带的缓存失效策略之外(Redis 默认的有 6 中策略可供选择),我们还可以根据具体的业务需求进行自定义的缓存淘汰,常见的策略有两种:</p><p>(1)定时去清理过期的缓存;<br>(2)当有用户请求过来时,再判断这个请求所用到的缓存是否过期,过期的话就去底层系统得到新数据并更新缓存。</p><h1 id="缓存降级"><a href="#缓存降级" class="headerlink" title="缓存降级"></a>缓存降级</h1><p>当访问量剧增、服务出现问题(如响应时间慢或不响应)或非核心服务影响到核心流程的性能时,仍然需要保证服务还是可用的,即使是有损服务。系统可以根据一些关键数据进行自动降级,也可以配置开关实现人工降级。降级的最终目的是保证核心服务可用,即使是有损的。而且有些服务是无法降级的(如加入购物车、结算)。</p>]]></content>
    
    
    <categories>
      
      <category>中间件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式缓存</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>加密算法</title>
    <link href="/2020/09/06/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/"/>
    <url>/2020/09/06/%E5%8A%A0%E5%AF%86%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="AES"><a href="#AES" class="headerlink" title="AES"></a>AES</h1><p>高级加密标准(AES,Advanced Encryption Standard)为最常见的对称加密算法(微信小程序加密传输就是用这个加密算法的)。对称加密算法也就是加密和解密用相同的密钥,具体的加密流程如下图:</p><p><img src="/resource/img/aes.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="RSA"><a href="#RSA" class="headerlink" title="RSA"></a>RSA</h1><p>RSA 加密算法是一种典型的非对称加密算法,它基于大数的因式分解数学难题,它也是应用最广泛的非对称加密算法。非对称加密是通过两个密钥(公钥-私钥)来实现对数据的加密和解密的。公钥用于加密,私钥用于解密。</p><p><img src="/resource/img/rsa.png" srcset="/img/loading.gif" alt="avatar"></p><p><img src="/resource/img/rsa-1.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="CRC"><a href="#CRC" class="headerlink" title="CRC"></a>CRC</h1><p>循环冗余校验(Cyclic Redundancy Check, CRC)是一种根据网络数据包或电脑文件等数据产生简短固定位数校验码的一种散列函数,主要用来检测或校验数据传输或者保存后可能出现的错误。<br>它是利用除法及余数的原理来作错误侦测的。</p><h1 id="MD5"><a href="#MD5" class="headerlink" title="MD5"></a>MD5</h1><p>MD5 常常作为文件的签名出现,我们在下载文件的时候,常常会看到文件页面上附带一个扩展名为.MD5 的文本或者一行字符,这行字符就是就是把整个文件当作原数据通过 MD5 计算后的值,我们下载文件后,可以用检查文件 MD5 信息的软件对下载到的文件在进行一次计算。两次结果对比就可以确保下载到文件的准确性。 另一种常见用途就是网站敏感信息加密,比如用户名密码,支付签名等等。随着 https 技术的普及,现在的网站广泛采用前台明文传输到后台,MD5 加密(使用偏移量)的方式保护敏感数据保护站点和数据安全。</p>]]></content>
    
    
    <categories>
      
      <category>加密算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数据结构</title>
    <link href="/2020/09/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    <url>/2020/09/06/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h1 id="栈-stack"><a href="#栈-stack" class="headerlink" title="栈(stack)"></a>栈(stack)</h1><p>栈(stack)是限制插入和删除只能在一 个位置上进行的表,该位置是表的末端,叫做栈顶(top)。它是后进先出(LIFO)的。对栈的基本操作只有 push(进栈)和 pop(出栈)两种,  前者相当于插入,后者相当于删除最后的元素。</p><p><img src="/resource/img/stack.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="队列-queue"><a href="#队列-queue" class="headerlink" title="队列(queue)"></a>队列(queue)</h1><p>队列是一种特殊的 线性表 ,特殊之处在于它只允许在表的前端(front)进行删除操作,而在表的后端(rear)进行插入操作,和栈一样,队列是一种操作受限制的线性表。进行插入操作的端称为队尾,进行删除操作的端称为队头。</p><p><img src="/resource/img/queue.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="链表-Link"><a href="#链表-Link" class="headerlink" title="链表(Link)"></a>链表(Link)</h1><p>链表是一种数据结构,和数组同级。比如,Java 中我们使用的 ArrayList,其实现原理是数组。而LinkedList 的实现原理就是链表了。链表在进行循环遍历时效率不高,但是插入和删除时优势明显。</p><p><img src="/resource/img/link.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="散列表-Hash-Table"><a href="#散列表-Hash-Table" class="headerlink" title="散列表(Hash Table)"></a>散列表(Hash Table)</h1><p>散列表(Hash table,也叫哈希表)是一种查找算法,与链表、树等算法不同的是,散列表算法在查找时不需要进行一系列和关键字(关键字是数据元素中某个数据项的值,用以标识一个数据元素)的比较操作。</p><p>散列表算法希望能尽量做到不经过任何比较,通过一次存取就能得到所查找的数据元素,因而必须要在数据元素的存储位置和它的关键字(可用 key 表示)之间建立一个确定的对应关系,使每个关键字和散列表中一个唯一的存储位置相对应。因此在查找时,只要根据这个对应关系找到给定关键字在散列表中的位置即可。这种对应关系被称为散列函数(可用 h(key)表示)。</p><p>用的构造散列函数的方法有:<br>(1)直接定址法: 取关键字或关键字的某个线性函数值为散列地址。即:h(key) = key 或 h(key) = a * key + b,其中 a 和 b 为常数。<br>(2)数字分析法<br>(3)平方取值法: 取关键字平方后的中间几位为散列地址。<br>(4)折叠法:将关键字分割成位数相同的几部分,然后取这几部分的叠加和作为散列地址。<br>(5)除留余数法:取关键字被某个不大于散列表表长 m 的数 p 除后所得的余数为散列地址,即:h(key) = key MOD p p ≤ m<br>(6)随机数法:选择一个随机函数,取关键字的随机函数值为它的散列地址,即:h(key) = random(key)</p><h1 id="排序二叉树"><a href="#排序二叉树" class="headerlink" title="排序二叉树"></a>排序二叉树</h1><p>首先如果普通二叉树每个节点满足:左子树所有节点值小于它的根节点值,且右子树所有节点值大于它的根节点值,则这样的二叉树就是排序二叉树。</p><h2 id="插入操作"><a href="#插入操作" class="headerlink" title="插入操作"></a>插入操作</h2><p>首先要从根节点开始往下找到自己要插入的位置(即新节点的父节点);具体流程是:新节点与当前节点比较,如果相同则表示已经存在且不能再重复插入;如果小于当前节点,则到左子树中寻找,如果左子树为空则当前节点为要找的父节点,新节点插入到当前节点的左子树即可;如果大于当前节点,则到右子树中寻找,如果右子树为空则当前节点为要找的父节点,新节点插入到当前节点的右子树即可。</p><p><img src="/resource/img/sort-2-tree.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="删除操作"><a href="#删除操作" class="headerlink" title="删除操作"></a>删除操作</h2><p>删除操作主要分为三种情况,即要删除的节点无子节点,要删除的节点只有一个子节点,要删除的节点有两个子节点。</p><ol><li>对于要删除的节点无子节点可以直接删除,即让其父节点将该子节点置空即可。</li><li>对于要删除的节点只有一个子节点,则替换要删除的节点为其子节点。</li><li>对于要删除的节点有两个子节点,则首先找该节点的替换节点(即右子树中最小的节点),接着替换要删除的节点为替换节点,然后删除替换节点。</li></ol><p><img src="/resource/img/delete-2-tree.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="查询操作"><a href="#查询操作" class="headerlink" title="查询操作"></a>查询操作</h2><p>查找操作的主要流程为:先和根节点比较,如果相同就返回,如果小于根节点则到左子树中递归查找,如果大于根节点则到右子树中递归查找。因此在排序二叉树中可以很容易获取最大(最右最深子节点)和最小(最左最深子节点)值。</p><h2 id="红黑树"><a href="#红黑树" class="headerlink" title="红黑树"></a>红黑树</h2><p>R-B Tree,全称是 Red-Black Tree,又称为“红黑树”,它一种特殊的二叉查找树。红黑树的每个节点上都有存储位表示节点的颜色,可以是红(Red)或黑(Black)。</p><h3 id="红黑树的特性"><a href="#红黑树的特性" class="headerlink" title="红黑树的特性"></a>红黑树的特性</h3><p>(1)每个节点或者是黑色,或者是红色。<br>(2)根节点是黑色。<br>(3)每个叶子节点(NIL)是黑色。 [注意:这里叶子节点,是指为空(NIL 或 NULL)的叶子节点!]<br>(4)如果一个节点是红色的,则它的子节点必须是黑色的。<br>(5)从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。</p><h3 id="左旋"><a href="#左旋" class="headerlink" title="左旋"></a>左旋</h3><p>对 x 进行左旋,意味着,将“x 的右孩子”设为“x 的父亲节点”;即,将 x 变成了一个左节点(x成了为 z 的左孩子)!。 因此,左旋中的“左”,意味着“被旋转的节点将变成一个左节点”。</p><p><img src="/resource/img/left-spin.png" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="cgo">LEFT-ROTATE(T, x)y ← right[x]// 前提:这里假设 x 的右孩子为 y。下面开始正式操作right[x] ← left[y]// 将 “y 的左孩子” 设为 “x 的右孩子”,即 将β设为 x 的右孩子p[left[y]] ← x // 将 “x” 设为 “y 的左孩子的父亲”,即 将β的父亲设为 xp[y] ← p[x] // 将 “x 的父亲” 设为 “y 的父亲”if p[x] = nil[T]then root[T] ← y// 情况 1:如果 “x 的父亲” 是空节点,则将 y 设为根节点else if x = left[p[x]]then left[p[x]] ← y// 情况 2:如果 x 是它父节点的左孩子,则将 y 设为“x 的父节点的左孩子”else right[p[x]] ← y // 情况 3:(x 是它父节点的右孩子) 将 y 设为“x 的父节点的右孩子”left[y] ← x // 将 “x” 设为 “y 的左孩子”p[x] ← y // 将 “x 的父节点” 设为 “y”</code></pre><p><img src="/resource/img/left-spin-sub.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="右旋"><a href="#右旋" class="headerlink" title="右旋"></a>右旋</h3><p>对 x 进行右旋,意味着,将“x 的左孩子”设为“x 的父亲节点”;即,将 x 变成了一个右节点(x成了为 y 的右孩子)! 因此,右旋中的“右”,意味着“被旋转的节点将变成一个右节点”。</p><p><img src="/resource/img/right-spin.png" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="cgo">RIGHT-ROTATE(T, y)x ← left[y]// 前提:这里假设 y 的左孩子为 x。下面开始正式操作left[y] ← right[x] // 将 “x 的右孩子” 设为 “y 的左孩子”,即 将β设为 y 的左孩子p[right[x]] ← y // 将 “y” 设为 “x 的右孩子的父亲”,即 将β的父亲设为 yp[x] ← p[y]// 将 “y 的父亲” 设为 “x 的父亲”if p[y] = nil[T]then root[T] ← x// 情况 1:如果 “y 的父亲” 是空节点,则将 x 设为根节点else if y = right[p[y]]then right[p[y]] ← x// 情况 2:如果 y 是它父节点的右孩子,则将 x 设为“y 的父节点的左孩子”else left[p[y]] ← x// 情况 3:(y 是它父节点的左孩子) 将 x 设为“y 的父节点的左孩子”right[x] ← yp[y] ← x// 将 “y” 设为 “x 的右孩子”// 将 “y 的父节点” 设为 “x”</code></pre><h4 id="添加"><a href="#添加" class="headerlink" title="添加"></a>添加</h4><p>第一步: 将红黑树当作一颗二叉查找树,将节点插入。</p><p>第二步:将插入的节点着色为”红色”。根据被插入节点的父节点的情况,可以将”当节点 z 被着色为红色节点,并插入二叉树”划分为三种情况来处理。</p><p>1 情况说明:被插入的节点是根节点。</p><blockquote><p>处理方法:直接把此节点涂为黑色。</p></blockquote><p>2 情况说明:被插入的节点的父节点是黑色。</p><blockquote><p>处理方法:什么也不需要做。节点被插入后,仍然是红黑树。</p></blockquote><p>3 情况说明:被插入的节点的父节点是红色。这种情况下,被插入节点是一定存在非空祖父节点的;进一步的讲,被插入节点也一定存在叔叔节点(即使叔叔节点为空,我们也视之为存在,空节点本身就是黑色节点)。理解这点之后,我们依据”叔叔节点的情况”,将这种情况进一步划分为 3种情况(Case)。</p><p><img src="/resource/img/case-1-3.png" srcset="/img/loading.gif" alt="avatar"></p><p>第三步: 通过一系列的旋转或着色等操作,使之重新成为一颗红黑树。</p><h4 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h4><p>第一步:将红黑树当作一颗二叉查找树,将节点删除。这和”删除常规二叉查找树中删除节点的方法是一样的”。分 3 种情况:<br>1 被删除节点没有儿子,即为叶节点。那么,直接将该节点删除就 OK 了。<br>2 被删除节点只有一个儿子。那么,直接删除该节点,并用该节点的唯一子节点顶替它的位置。<br>3 被删除节点有两个儿子。那么,先找出它的后继节点;然后把“它的后继节点的内容”复制给“该节点的内容”;之后,删除“它的后继节点”。</p><p>第二步:通过”旋转和重新着色”等一系列来修正该树,使之重新成为一棵红黑树。</p><p>因为”第一步”中删除节点之后,可能会违背红黑树的特性。所以需要通过”旋转和重新着色”来修正该树,使之重新成为一棵红黑树。</p><p>选择重着色 3 种情况。</p><p>1 情况说明:x 是“红+黑”节点。</p><blockquote><p>处理方法:直接把 x 设为黑色,结束。此时红黑树性质全部恢复。</p></blockquote><p>2 情况说明:x 是“黑+黑”节点,且 x 是根。</p><blockquote><p>处理方法:什么都不做,结束。此时红黑树性质全部恢复。</p></blockquote><p>3 情况说明:x 是“黑+黑”节点,且 x 不是根。</p><blockquote><p>处理方法:这种情况又可以划分为 4 种子情况。这 4 种子情况如下表所示:</p></blockquote><p><img src="/resource/img/case-1-4.png" srcset="/img/loading.gif" alt="avatar"></p><p><a href="https://www.jianshu.com/p/038585421b73" target="_blank" rel="noopener">参考</a></p><p><a href="https://www.cnblogs.com/skywang12345/p/3624343.html" target="_blank" rel="noopener">代码实现</a></p><h1 id="B-TREE"><a href="#B-TREE" class="headerlink" title="B-TREE"></a>B-TREE</h1><p>B-tree 又叫平衡多路查找树。一棵 m 阶的 B-tree (m 叉树)的特性如下(其中 ceil(x)是一个取上限的函数):</p><ol><li><p>树中每个结点至多有 m 个孩子;</p></li><li><p>除根结点和叶子结点外,其它每个结点至少有有 ceil(m / 2)个孩子;</p></li><li><p>若根结点不是叶子结点,则至少有 2 个孩子(特殊情况:没有孩子的根结点,即根结点为叶子结点,整棵树只有一个根节点);</p></li><li><p>所有叶子结点都出现在同一层,叶子结点不包含任何关键字信息(可以看做是外部结点或查询失败的结点,实际上这些结点不存在,指向这些结点的指针都为 null);</p></li><li><p>每个非终端结点中包含有 n 个关键字信息: (n,P0,K1,P1,K2,P2,……,Kn,Pn)。其中:</p></li></ol><p>a) Ki (i=1…n)为关键字,且关键字按顺序排序 K(i-1)&lt; Ki。<br>b) Pi 为指向子树根的接点,且指针 P(i-1)指向子树种所有结点的关键字均小于 Ki,但都大于 K(i-1)。<br>c) 关键字的个数 n 必须满足: ceil(m / 2)-1 &lt;= n &lt;= m-1。</p><p><img src="/resource/img/balance-tree.png" srcset="/img/loading.gif" alt="avatar"></p><p>一棵 m 阶的 B+tree 和 m 阶的 B-tree 的差异在于:<br>1.有 n 棵子树的结点中含有 n 个关键字; (B-tree 是 n 棵子树有 n-1 个关键字)<br>2.所有的叶子结点中包含了全部关键字的信息,及指向含有这些关键字记录的指针,且叶子结点本身依关键字的大小自小而大的顺序链接。 (B-tree 的叶子节点并没有包括全部需要查找的信息)<br>3.所有的非终端结点可以看成是索引部分,结点中仅含有其子树根结点中最大(或最小)关键字。<br>(B-tree 的非终节点也包含需要查找的有效信息)</p><p><img src="/resource/img/balance-tree-detail.png" srcset="/img/loading.gif" alt="avatar"></p><p><a href="https://www.jianshu.com/p/1ed61b4cca12" target="_blank" rel="noopener">参考</a></p><h1 id="位图"><a href="#位图" class="headerlink" title="位图"></a>位图</h1><blockquote><p>位图的原理就是用一个 bit 来标识一个数字是否存在,采用一个 bit 来存储一个数据,所以这样可以大大的节省空间。 bitmap 是很常用的数据结构,比如用于 Bloom Filter 中;用于无重复整数的排序等等。bitmap 通常基于数组来实现,数组中每个元素可以看成是一系列二进制数,所有元素组成更大的二进制集合。</p></blockquote><p><a href="https://www.cnblogs.com/polly333/p/4760275.html" target="_blank" rel="noopener">参考资料</a></p>]]></content>
    
    
    <categories>
      
      <category>数据结构</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据结构</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java基础算法</title>
    <link href="/2020/09/06/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/"/>
    <url>/2020/09/06/%E5%9F%BA%E7%A1%80%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h1><p>又叫折半查找,要求待查找的序列有序。每次取中间位置的值与待查关键字比较,如果中间位置的值比待查关键字大,则在前半部分循环这个查找的过程,如果中间位置的值比待查关键字小,则在后半部分循环这个查找的过程。直到查找到了为止,否则序列中没有待查的关键字。</p><pre><code class="java">    /**     * 二分查找     * @param array     * @param a     * @return     */    public static int biSearch(int []array,int a){        int lo = 0;        int hi = array.length-1;        int mid;        while (lo&lt;hi){            mid = (lo+hi)/2;//中间位置            if (array[mid] == a){                return mid + 1;            }else if (array[mid]&lt;a){                lo = mid + 1;            }else {                hi = mid -1;            }        }        return -1;    }</code></pre><h1 id="冒泡排序算法"><a href="#冒泡排序算法" class="headerlink" title="冒泡排序算法"></a>冒泡排序算法</h1><p>(1)比较前后相邻的二个数据,如果前面数据大于后面的数据,就将这二个数据交换。<br>(2)这样对数组的第 0 个数据到 N-1 个数据进行一次遍历后,最大的一个数据就“沉”到数组第N-1 个位置。<br>(3)N=N-1,如果 N 不为 0 就重复前面二步,否则排序完成。</p><pre><code class="java">    /**     * 冒泡查找     * @param a     * @param n     */    public static void bubbleSort(int []a,int n){        int i,j;        for (i = 0; i &lt; n; i++) {            for (j = 0; j &lt; n - i; j++) {                if (a[j-1]&gt;a[j]){                    int temp;                    temp = a[j-1];                    a[j-1] = a[j];                    a[j] = temp;                }            }        }    }</code></pre><h1 id="插入排序算法"><a href="#插入排序算法" class="headerlink" title="插入排序算法"></a>插入排序算法</h1><p>通过构建有序序列,对于未排序数据,在已排序序列中从后向前扫描,找到相应的位置并插入。插入排序非常类似于整扑克牌。在开始摸牌时,左手是空的,牌面朝下放在桌上。接着,一次从桌上摸起一张牌,并将它插入到左手一把牌中的正确位置上。为了找到这张牌的正确位置,要将它与手中已有的牌从右到左地进行比较。无论什么时候,左手中的牌都是排好序的。如果输入数组已经是排好序的话,插入排序出现最佳情况,其运行时间是输入规模的一个线性函数。如果输入数组是逆序排列的,将出现最坏情况。平均情况与最坏情况一样,其时间代价是(n2)。</p><p><img src="/resource/img/insert-soft.png" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="java">    /**     * 插入排序     * @param arr     */    public void insertSort(int arr[]) {        for (int i = 0; i &lt; arr.length; i++) {            //插入的数            int insertVal = arr[i];            //被插入的位置(准备和前一个数比较)            int index = i - 1;            //如果插入的数比被插入的数小            while (index&gt;=0&amp;insertVal&lt;arr[index]){                //将把arr[index] 向后移动                arr[index+1] = arr[index];                //让index向前移动                index--;            }            //把插入的数放入合适的位置            arr[index+1] = insertVal;        }    }</code></pre><h1 id="快速排序算法"><a href="#快速排序算法" class="headerlink" title="快速排序算法"></a>快速排序算法</h1><p>快速排序的原理:选择一个关键值作为基准值。比基准值小的都在左边序列(一般是无序的),比基准值大的都在右边(一般是无序的)。一般选择序列的第一个元素。</p><p>一次循环:从后往前比较,用基准值和最后一个值比较,如果比基准值小的交换位置,如果没有继续比较下一个,直到找到第一个比基准值小的值才交换。找到这个值之后,又从前往后开始比较,如果有比基准值大的,交换位置,如果没有继续比较下一个,直到找到第一个比基准值大的值才交换。直到从前往后的比较索引&gt;从后往前比较的索引,结束第一次循环,此时,对于基准值来说,左右两边就是有序的了。</p><p><img src="/resource/img/quick-soft.png" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="java">    /**     * 快速排序     * @param a     * @param low     * @param hight     */    public void quickSort(int[] a,int low,int hight) {        int start = low;        int end = hight;        int key = a[low];        while (end&gt;start){            //从后往前比较            while (end&gt;start&amp;&amp; a[end] &gt;= key){                //如果没有比关键值小的,比较下一个,直到有比关键值小的交换位置,然后又从前往后比较                end --;                if (a[end] &lt;= key){                    int temp = a[end];                    a[end] = a[start];                    a[start] = temp;                }                while (end&gt;start&amp;&amp;a[start] &lt;= key){                    //如果没有比关键值大的,比较下一个,直到有比关键值大的交换位置                    start++;                    if (a[start]&gt;= key){                        int temp = a[start];                        a[start] = a[end];                        a[end] = temp;                    }                    //此时第一次循环比较结束,关键值的位置已经确定了。左边的值都比关键值小,右边的值都比关键值大,但是两边的顺序还有可能是不一样的,进行下面的递归调用                }                //递归                if (start&gt;low)quickSort(a,low,start-1);//左边序列。第一个索引位置到关键值索引-1                if (start&lt;low)quickSort(a,end+1,hight);//右边序列。从关键值索引+1 到最后一个            }        }    }</code></pre><h1 id="希尔排序算法"><a href="#希尔排序算法" class="headerlink" title="希尔排序算法"></a>希尔排序算法</h1><p>基本思想:先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序,待整个序列中的记录“基本有序”时,再对全体记录进行依次直接插入排序。</p><p>1.操作方法:选择一个增量序列 t1,t2,…,tk,其中 ti&gt;tj,tk=1;</p><ol start="2"><li><p>按增量序列个数 k,对序列进行 k 趟排序;</p></li><li><p>每趟排序,根据对应的增量 ti,将待排序列分割成若干长度为 m 的子序列,分别对各子表进行直接插入排序。仅增量因子为 1 时,整个序列作为一个表来处理,表长度即为整个序列的长度。</p></li></ol><p><img src="/resource/img/xier-soft.png" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="java">    /**     * 希尔排序     * @param a     */    public void shellSort(int[] a){        int dk = a.length/2;        while (dk&gt;=1){            shellInsertSort(a,dk);            dk = dk / 2;        }    }    /**     *     * @param a     * @param dk     */    private void shellInsertSort(int[] a,int dk) {        for (int i = dk;i&lt;a.length;i++){            if (a[i]&lt;a[i-dk]){                int j;                int x = a[i];//x为待插入元素                a[i] = a[i-dk];                for (j = i - dk; j&gt;=0&amp;&amp;x&lt;a[j];j=j-dk){                    //通过循环,逐个后移一位找到要插入的位置。                    a[j+dk] = a[j];                }                a[j+dk] = x;//插入            }        }    }</code></pre><h1 id="归并排序算法"><a href="#归并排序算法" class="headerlink" title="归并排序算法"></a>归并排序算法</h1><p>归并(Merge)排序法是将两个(或两个以上)有序表合并成一个新的有序表,即把待排序序列分为若干个子序列,每个子序列是有序的。然后再把有序子序列合并为整体有序序列。</p><p><img src="/resource/img/merge-sort.png" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="java">    /**     * 归并排序     * @param data     */    public static void mergeSort(int[] data) {        sort(data, 0, data.length - 1);    }    public static void sort(int[] data, int left, int right) {        if (left &gt;= right)            return;        // 找出中间索引        int center = (left + right) / 2;        // 对左边数组进行递归        sort(data, left, center);        // 对右边数组进行递归        sort(data, center + 1, right);        // 合并        merge(data, left, center, right);        print(data);    }    /**     * 将两个数组进行归并,归并前面 2 个数组已有序,归并后依然有序     * @param data   数组对象     * @param left   左数组的第一个元素的索引     * @param center 左数组的最后一个元素的索引,center+1 是右数组第一个元素的索引     * @param right  右数组最后一个元素的索引     */    public static void merge(int[] data, int left, int center, int right) {        // 临时数组        int[] tmpArr = new int[data.length];        // 右数组第一个元素索引        int mid = center + 1;        // third 记录临时数组的索引        int third = left;        // 缓存左数组第一个元素的索引        int tmp = left;        while (left &lt;= center &amp;&amp; mid &lt;= right) {        // 从两个数组中取出最小的放入临时数组            if (data[left] &lt;= data[mid]) {                tmpArr[third++] = data[left++];            } else {                tmpArr[third++] = data[mid++];            }        }        // 剩余部分依次放入临时数组(实际上两个 while 只会执行其中一个)        while (mid &lt;= right) {            tmpArr[third++] = data[mid++];        }        while (left &lt;= center) {            tmpArr[third++] = data[left++];        }        // 将临时数组中的内容拷贝回原数组中        // (原 left-right 范围的内容被复制回原数组)        while (tmp &lt;= right) {            data[tmp] = tmpArr[tmp++];        }    }    public static void print(int[] data) {        for (int i = 0; i &lt; data.length; i++) {            System.out.print(data[i] + &quot;\t&quot;);        }        System.out.println();    }</code></pre><h1 id="桶排序算法"><a href="#桶排序算法" class="headerlink" title="桶排序算法"></a>桶排序算法</h1><p>桶排序的基本思想是: 把数组 arr 划分为 n 个大小相同子区间(桶),每个子区间各自排序,最后合并 。计数排序是桶排序的一种特殊情况,可以把计数排序当成每个桶里只有一个元素的情况。</p><p>1.找出待排序数组中的最大值 max、最小值 min</p><p>2.我们使用 动态数组 ArrayList 作为桶,桶里放的元素也用 ArrayList 存储。桶的数量为(max-min)/arr.length+1</p><p>3.遍历数组 arr,计算每个元素 arr[i] 放的桶</p><p>4.每个桶各自排序</p><pre><code class="java">    /**     * 桶排序     * @param arr     */    public static void bucketSort(int[] arr){        int max = Integer.MIN_VALUE;        int min = Integer.MAX_VALUE;        for(int i = 0; i &lt; arr.length; i++){            max = Math.max(max, arr[i]);            min = Math.min(min, arr[i]);        }        //创建桶        int bucketNum = (max - min) / arr.length + 1;        ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketNum);        for(int i = 0; i &lt; bucketNum; i++){            bucketArr.add(new ArrayList&lt;Integer&gt;());        }        //将每个元素放入桶        for(int i = 0; i &lt; arr.length; i++){            int num = (arr[i] - min) / (arr.length);            bucketArr.get(num).add(arr[i]);        }        //对每个桶进行排序        for(int i = 0; i &lt; bucketArr.size(); i++){            Collections.sort(bucketArr.get(i));        }    }</code></pre><h1 id="基数排序算法"><a href="#基数排序算法" class="headerlink" title="基数排序算法"></a>基数排序算法</h1><p>将所有待比较数值(正整数)统一为同样的数位长度,数位较短的数前面补零。然后,从最低位开始,依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序列。</p><pre><code class="java">public void radixSort(int a[]) {        sort(a);        for (int i = 0; i &lt; a.length; i++) {            System.out.println(a[i]);        }    }    public void sort(int[] array) {        //首先确定排序的趟数;        int max = array[0];        for (int i = 1; i &lt; array.length; i++) {            if (array[i] &gt; max) {                max = array[i];            }        }        int time = 0;        //判断位数;        while (max &gt; 0) {            max /= 10;            time++;        }        //建立 10 个队列;        List&lt;ArrayList&gt; queue = new ArrayList&lt;ArrayList&gt;();        for (int i = 0; i &lt; 10; i++) {            ArrayList&lt;Integer&gt; queue1 = new ArrayList&lt;Integer&gt;();            queue.add(queue1);        }        //进行 time 次分配和收集;        for (int i = 0; i &lt; time; i++) {        //分配数组元素;            for (int j = 0; j &lt; array.length; j++) {        //得到数字的第 time+1 位数;                int x = array[j] % (int) Math.pow(10, i + 1) / (int) Math.pow(10, i);                ArrayList&lt;Integer&gt; queue2 = queue.get(x);                queue2.add(array[j]);                queue.set(x, queue2);            }            int count = 0;//元素计数器;            //收集队列元素;            for (int k = 0; k &lt; 10; k++) {                while (queue.get(k).size() &gt; 0) {                    ArrayList&lt;Integer&gt; queue3 = queue.get(k);                    array[count] = queue3.get(0);                    queue3.remove(0);                    count++;                }            }        }    }</code></pre><h1 id="剪枝算法"><a href="#剪枝算法" class="headerlink" title="剪枝算法"></a>剪枝算法</h1><p>在搜索算法中优化中,剪枝,就是通过某种判断,避免一些不必要的遍历过程,形象的说,就是剪去了搜索树中的某些“枝条”,故称剪枝。应用剪枝优化的核心问题是设计剪枝判断方法,即确定哪些枝条应当舍弃,哪些枝条应当保留的方法。</p><h1 id="回溯算法"><a href="#回溯算法" class="headerlink" title="回溯算法"></a>回溯算法</h1><p>回溯算法实际上一个类似枚举的搜索尝试过程,主要是在搜索尝试过程中寻找问题的解,当发现已不满足求解条件时,就“回溯”返回,尝试别的路径。</p><h1 id="最短路径算法"><a href="#最短路径算法" class="headerlink" title="最短路径算法"></a>最短路径算法</h1><p>从某顶点出发,沿图的边到达另一顶点所经过的路径中,各边上权值之和最小的一条路径叫做最短路径。解决最短路的问题有以下算法,Dijkstra 算法,Bellman-Ford 算法,Floyd 算法和 SPFA算法等。</p><h1 id="最大子数组算法"><a href="#最大子数组算法" class="headerlink" title="最大子数组算法"></a>最大子数组算法</h1><h1 id="最长公共子序算法"><a href="#最长公共子序算法" class="headerlink" title="最长公共子序算法"></a>最长公共子序算法</h1><h1 id="最小生成树算法"><a href="#最小生成树算法" class="headerlink" title="最小生成树算法"></a>最小生成树算法</h1><p>现在假设有一个很实际的问题:我们要在 n 个城市中建立一个通信网络,则连通这 n 个城市需要布置 n-1 一条通信线路,这个时候我们需要考虑如何在成本最低的情况下建立这个通信网?于是我们就可以引入连通图来解决我们遇到的问题,n 个城市就是图上的 n 个顶点,然后,边表示两个城市的通信线路,每条边上的权重就是我们搭建这条线路所需要的成本,所以现在我们有 n 个顶点的连通网可以建立不同的生成树,每一颗生成树都可以作为一个通信网,当我们构造这个连通网所花的成本最小时,搭建该连通网的生成树,就称为最小生成树。</p><p>构造最小生成树有很多算法,但是他们都是利用了最小生成树的同一种性质:MST 性质(假设N=(V,{E})是一个连通网,U 是顶点集 V 的一个非空子集,如果(u,v)是一条具有最小权值的边,其中 u 属于 U,v 属于 V-U,则必定存在一颗包含边(u,v)的最小生成树),下面就介绍两种使用 MST 性质生成最小生成树的算法:普里姆算法和克鲁斯卡尔算法。</p><p><img src="/resource/img/min-tree.png" srcset="/img/loading.gif" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>基础算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一致性算法</title>
    <link href="/2020/09/06/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/"/>
    <url>/2020/09/06/%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="Paxos"><a href="#Paxos" class="headerlink" title="Paxos"></a>Paxos</h1><p>Paxos 算法解决的问题是一个分布式系统如何就某个值(决议)达成一致。一个典型的场景是,在一个分布式数据库系统中,如果各节点的初始状态一致,每个节点执行相同的操作序列,那么他们最后能得到一个一致的状态。为保证每个节点执行相同的命令序列,需要在每一条指令上执行一个“一致性算法”以保证每个节点看到的指令一致。zookeeper 使用的 zab 算法是该算法的一个实现。 在 Paxos 算法中,有三种角色:Proposer,Acceptor,Learners</p><p>Paxos 三种角色:Proposer,Acceptor,Learners</p><p>Proposer :<br>只要 Proposer 发的提案被半数以上 Acceptor 接受,Proposer 就认为该提案里的 value 被选定了。</p><p>Acceptor :<br>只要 Acceptor 接受了某个提案,Acceptor 就认为该提案里的 value 被选定了。</p><p>Learner :<br>Acceptor 告诉 Learner 哪个 value 被选定,Learner 就认为那个 value 被选定。</p><p>Paxos 算法分为两个阶段。具体如下:</p><p>阶段一(准 leader 确定 ):<br>(a) Proposer 选择一个提案编号 N,然后向半数以上的 Acceptor 发送编号为 N 的 Prepare 请求。<br>(b) 如果一个 Acceptor 收到一个编号为 N 的 Prepare 请求,且 N 大于该 Acceptor 已经响应过的所有 Prepare 请求的编号,那么它就会将它已经接受过的编号最大的提案(如果有的话)作为响应反馈给 Proposer,同时该 Acceptor 承诺不再接受任何编号小于 N 的提案。</p><p>阶段二( leader 确认):<br>(a) 如果 Proposer 收到半数以上 Acceptor 对其发出的编号为 N 的 Prepare 请求的响应,那么它就会发送一个针对[N,V]提案的 Accept 请求给半数以上的 Acceptor。注意:V 就是收到的响应中编号最大的提案的 value,如果响应中不包含任何提案,那么 V 就由 Proposer 自己决定。<br>(b) 如果 Acceptor 收到一个针对编号为 N 的提案的 Accept 请求,只要该 Acceptor 没有对编号大于 N 的 Prepare 请求做出过响应,它就接受该提案。</p><h1 id="Zab"><a href="#Zab" class="headerlink" title="Zab"></a>Zab</h1><p>ZAB( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议)协议包括两种基本的模式:崩溃恢复和消息广播</p><p>1.当整个服务框架在启动过程中,或是当 Leader 服务器出现网络中断崩溃退出与重启等异常情况时,ZAB 就会进入恢复模式并选举产生新的 Leader 服务器。<br>2.当选举产生了新的 Leader 服务器,同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后,ZAB 协议就会退出崩溃恢复模式,进入消息广播模式。<br>3.当有新的服务器加入到集群中去,如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播,那么新加入的服务器会自动进入数据恢复模式,找到 Leader 服务器,并与其进行数据同步,然后一起参与到消息广播流程中去。</p><p>以上其实大致经历了三个步骤:</p><ol><li>崩溃恢复:主要就是 Leader 选举过程</li><li>数据同步: Leader 服务器与其他服务器进行数据同步</li><li>消息广播: Leader 服务器将数据发送给其他服务器</li></ol><p>说明:zookeeper 章节对该协议有详细描述。</p><h1 id="Raft"><a href="#Raft" class="headerlink" title="Raft"></a>Raft</h1><p>与 Paxos 不同 Raft 强调的是易懂(Understandability),Raft 和 Paxos 一样只要保证 n/2+1 节点正常就能够提供服务;raft 把算法流程分为三个子问题:选举(Leader election)、日志复制(Log replication)、安全性(Safety)三个子问题。</p><h2 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h2><p>Raft 把集群中的节点分为三种状态:Leader、 Follower 、Candidate,理所当然每种状态负责的任务也是不一样的,Raft 运行时提供服务的时候只存在 Leader 与 Follower 两种状态;</p><p>Leader (领导者 - 日志管理)<br>负责日志的同步管理,处理来自客户端的请求,与 Follower 保持这 heartBeat 的联系;</p><p>Follower (追随者 - 日志同步)<br>刚启动时所有节点为 Follower 状态,响应 Leader 的日志同步请求,响应 Candidate 的请求,</p><p>把请求到 Follower 的事务转发给 Leader;<br>Candidate (候选者 - 负责选票)<br>负责选举投票,Raft 刚启动时由一个节点从 Follower 转为 Candidate 发起选举,选举出Leader 后从 Candidate 转为 Leader 状态;</p><h2 id="Term-任期"><a href="#Term-任期" class="headerlink" title="Term(任期)"></a>Term(任期)</h2><p>在 Raft 中使用了一个可以理解为周期(第几届、任期)的概念,用 Term 作为一个周期,每个 Term 都是一个连续递增的编号,每一轮选举都是一个 Term 周期,在一个 Term 中只能产生一个 Leader;当某节点收到的请求中 Term 比当前 Term 小时则拒绝该请求。</p><h1 id="选举-Election"><a href="#选举-Election" class="headerlink" title="选举(Election)"></a>选举(Election)</h1><p>选举定时器</p><p>Raft 的选举由定时器来触发,每个节点的选举定时器时间都是不一样的,开始时状态都为Follower 某个节点定时器触发选举后 Term 递增,状态由 Follower 转为 Candidate,向其他节点发起 RequestVote RPC 请求,这时候有三种可能的情况发生:</p><p>1:该 RequestVote 请求接收到 n/2+1(过半数)个节点的投票,从 Candidate 转为 Leader,向其他节点发送 heartBeat 以保持 Leader 的正常运转。</p><p>2:在此期间如果收到其他节点发送过来的 AppendEntries RPC 请求,如该节点的 Term 大则当前节点转为 Follower,否则保持 Candidate 拒绝该请求。</p><p>3:Election timeout 发生则 Term 递增,重新发起选举在一个 Term 期间每个节点只能投票一次,所以当有多个 Candidate 存在时就会出现每个Candidate 发起的选举都存在接收到的投票数都不过半的问题,这时每个 Candidate 都将 Term递增、重启定时器并重新发起选举,由于每个节点中定时器的时间都是随机的,所以就不会多次存在有多个 Candidate 同时发起投票的问题。</p><blockquote><p>在 Raft 中当接收到客户端的日志(事务请求)后先把该日志追加到本地的 Log 中,然后通过heartbeat 把该 Entry 同步给其他 Follower,Follower 接收到日志后记录日志然后向 Leader 发送ACK,当 Leader 收到大多数(n/2+1)Follower 的 ACK 信息后将该日志设置为已提交并追加到本地磁盘中,通知客户端并在下个 heartbeat 中 Leader 将通知所有的 Follower 将该日志存储在自己的本地磁盘中。</p></blockquote><h2 id="安全性-Safety"><a href="#安全性-Safety" class="headerlink" title="安全性(Safety)"></a>安全性(Safety)</h2><p>安全性是用于保证每个节点都执行相同序列的安全机制如当某个 Follower 在当前 Leader commit Log 时变得不可用了,稍后可能该 Follower 又会倍选举为 Leader,这时新 Leader 可能会用新的 Log 覆盖先前已 committed 的 Log,这就是导致节点执行不同序列;Safety 就是用于保证选举出来的 Leader 一定包含先前 commited Log 的机制;</p><p>选举安全性(Election Safety):每个 Term 只能选举出一个 Leader</p><p>Leader 完整性(Leader Completeness):这里所说的完整性是指 Leader 日志的完整性,</p><p>Raft 在选举阶段就使用 Term 的判断用于保证完整性:当请求投票的该 Candidate 的 Term 较大或 Term 相同 Index 更大则投票,该节点将容易变成 leader。</p><h2 id="raft-协议和-zab-协议区别"><a href="#raft-协议和-zab-协议区别" class="headerlink" title="raft 协议和 zab 协议区别"></a>raft 协议和 zab 协议区别</h2><h3 id="相同点"><a href="#相同点" class="headerlink" title="相同点"></a>相同点</h3><p>采用 quorum 来确定整个系统的一致性,这个 quorum 一般实现是集群中半数以上的服务器,zookeeper 里还提供了带权重的 quorum 实现.都由 leader 来发起写操作.都采用心跳检测存活性</p><p>leader election 都采用先到先得的投票方式</p><h3 id="不同点"><a href="#不同点" class="headerlink" title="不同点"></a>不同点</h3><p>zab 用的是 epoch 和 count 的组合来唯一表示一个值, 而 raft 用的是 term 和 index<br>zab 的 follower 在投票给一个 leader 之前必须和 leader 的日志达成一致,而 raft 的 follower<br>则简单地说是谁的 term 高就投票给谁<br>raft 协议的心跳是从 leader 到 follower, 而 zab 协议则相反<br>raft 协议数据只有单向地从 leader 到 follower(成为 leader 的条件之一就是拥有最新的 log),而 zab 协议在 discovery 阶段, 一个 prospective leader 需要将自己的 log 更新为 quorum 里面最新的 log,然后才好在 synchronization 阶段将 quorum 里的其他机器的 log 都同步到一致.</p><h3 id="NWR"><a href="#NWR" class="headerlink" title="NWR"></a>NWR</h3><p>N :在分布式存储系统中,有多少份备份数据<br>W :代表一次成功的更新操作要求至少有 w 份数据写入成功<br>R : 代表一次成功的读数据操作要求至少有 R 份数据成功读取<br>NWR 值的不同组合会产生不同的一致性效果,当 W+R&gt;N 的时候,整个系统对于客户端来讲能保证强一致性。而如果 R+W&lt;=N,则无法保证数据的强一致性。以常见的 N=3、W=2、R=2 为例:<br>N=3,表示,任何一个对象都必须有三个副本( Replica),W=2 表示,对数据的修改操作(Write)只需要在 3 个 Replica 中的 2 个上面完成就返回,R=2 表示,从三个对象中要读取到 2个数据对象,才能返回。</p><p><img src="/resource/img/nwr.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Gossip"><a href="#Gossip" class="headerlink" title="Gossip"></a>Gossip</h1><p>Gossip 算法又被称为反熵(Anti-Entropy),熵是物理学上的一个概念,代表杂乱无章,而反熵就是在杂乱无章中寻求一致,这充分说明了 Gossip 的特点:在一个有界网络中,每个节点都随机地与其他节点通信,经过一番杂乱无章的通信,最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点,也可能仅知道几个邻居节点,只要这些节可以通过网络连通,最终他们的状态都是一致的,当然这也是疫情传播的特点。</p><h1 id="一致性-Hash"><a href="#一致性-Hash" class="headerlink" title="一致性 Hash"></a>一致性 Hash</h1><p>一 致 性 哈 希 算 法 (Consistent Hashing Algorithm) 是 一 种 分 布 式 算 法 , 常 用 于 负 载 均 衡 。<br>Memcached client 也选择这种算法,解决将 key-value 均匀分配到众多 Memcached server 上的问题。它可以取代传统的取模操作,解决了取模操作无法应对增删 Memcached Server 的问题(增删 server 会导致同一个 key,在 get 操作时分配不到数据真正存储的 server,命中率会急剧下降)。</p><p>一致性 Hash 特性<br>平衡性(Balance):平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去,这样可以使得<br>所有的缓冲空间都得到利用。<br>单调性(Monotonicity):单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中,<br>又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到新的缓<br>冲中去,而不会被映射到旧的缓冲集合中的其他缓冲区。容易看到,上面的简单求余算法<br>hash(object)%N 难以满足单调性要求。<br>平滑性(Smoothness):平滑性是指缓存服务器的数目平滑改变和缓存对象的平滑改变是一致<br>的。<br>20.1.6.2.<br>一致性 Hash 原理</p><ol><li>建构环形 hash 空间:</li><li>考虑通常的 hash 算法都是将 value 映射到一个 32 为的 key 值,也即是 0~2^32-1 次方的<br>数值空间;我们可以将这个空间想象成一个首( 0 )尾( 2^32-1 )相接的圆环。</li><li>把需要缓存的内容 ( 对象 ) 映射到 hash 空间</li><li>接下来考虑 4 个对象 object1~object4 ,通过 hash 函数计算出的 hash 值 key 在环上的分<br>布</li><li>把服务器 ( 节点 ) 映射到 hash 空间</li><li>Consistent hashing 的基本思想就是将对象和 cache 都映射到同一个 hash 数值空间中,并<br>且使用相同的 hash 算法。一般的方法可以使用 服务器(节点) 机器的 IP 地址或者机器名作为<br>hash 输入。</li><li>把对象映射到服务节点</li><li>现在服务节点和对象都已经通过同一个 hash 算法映射到 hash 数值空间中了,首先确定对象<br>hash 值在环上的位置,从此位置沿环顺时针“行走”,第一台遇到的服务器就是其应该定位<br>到的服务器。</li></ol><p><img src="/resource/img/con-hash.png" srcset="/img/loading.gif" alt="avatar"><br>考察 cache 的变动<br>5.<br>通过 hash 然后求余的方法带来的最大问题就在于不能满足单调性,当 cache 有所变动时,<br>cache 会失效。<br>5.1 移除 cache:考虑假设 cache B 挂掉了,根据上面讲到的映射方法,这时受影响的将仅是<br>那些沿 cache B 逆时针遍历直到下一个 cache ( cache C )之间的对象。<br>5.2 添加 cache:再考虑添加一台新的 cache D 的情况,这时受影响的将仅是那些沿 cache<br>D 逆时针遍历直到下一个 cache 之间的对象,将这些对象重新映射到 cache D 上即可。<br>虚拟节点<br>hash 算法并不是保证绝对的平衡,如果 cache 较少的话,对象并不能被均匀的映射到 cache 上,<br>为了解决这种情况, consistent hashing 引入了“虚拟节点”的概念,它可以如下定义:<br>虚拟节点( virtual node )是实际节点在 hash 空间的复制品( replica ),一实际个节点对应了<br>若干个“虚拟节点”,这个对应个数也成为“复制个数”,“虚拟节点”在 hash 空间中以 hash<br>值排列。<br>仍以仅部署 cache A 和 cache C 的情况为例。现在我们引入虚拟节点,并设置“复制个数”为 2 ,<br>这就意味着一共会存在 4 个“虚拟节点”, cache A1, cache A2 代表了 cache A; cache C1,<br>cache C2 代表了 cache C 。此时,对象到“虚拟节点”的映射关系为:<br>objec1-&gt;cache A2 ; objec2-&gt;cache A1 ; objec3-&gt;cache C1 ; objec4-&gt;cache C2 ;<br>因此对象 object1 和 object2 都被映射到了 cache A 上,而 object3 和 object4 映射到了 cache<br>C 上;平衡性有了很大提高。<br>引入“虚拟节点”后,映射关系就从 { 对象 -&gt; 节点 } 转换到了 { 对象 -&gt; 虚拟节点 } 。查询物体所<br>在 cache 时的映射关系如下图 所示。</p><p><img src="/resource/img/hash-cache.png" srcset="/img/loading.gif" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>一致性算法</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Load Balancing</title>
    <link href="/2020/08/26/Load-Balancing/"/>
    <url>/2020/08/26/Load-Balancing/</url>
    
    <content type="html"><![CDATA[<h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><blockquote><p>负载均衡 建立在现有网络结构之上,它提供了一种廉价有效透明的方法扩展 网络设备 和 服务器 的带宽、增加 吞吐量 、加强网络数据处理能力、提高网络的灵活性和可用性。</p></blockquote><h2 id="四层负载均衡-vs-七层负载均衡"><a href="#四层负载均衡-vs-七层负载均衡" class="headerlink" title="四层负载均衡 vs 七层负载均衡"></a>四层负载均衡 vs 七层负载均衡</h2><p><img src="/resource/img/4-layer-vs-7-layer.png" srcset="/img/loading.gif" alt="avatar"></p><p>四层负载均衡(目标地址和端口交换)<br>主要通过报文中的目标地址和端口,再加上负载均衡设备设置的服务器选择方式,决定最终选择的内部服务器。</p><p>以常见的 TCP 为例,负载均衡设备在接收到第一个来自客户端的 SYN 请求时,即通过上述方式选择一个最佳的服务器,并对报文中目标 IP 地址进行修改(改为后端服务器 IP),直接转发给该服务器。TCP 的连接建立,即三次握手是客户端和服务器直接建立的,负载均衡设备只是起到一个类似路由器的转发动作。在某些部署情况下,为保证服务器回包可以正确返回给负载均衡设备,在转发报文的同时可能还会对报文原来的源地址进行修改。实现四层负载均衡的软件有:</p><ul><li>F5 :硬件负载均衡器,功能很好,但是成本很高。</li><li>lvs :重量级的四层负载软件。</li><li>nginx :轻量级的四层负载软件,带缓存功能,正则表达式较灵活。</li><li>haproxy :模拟四层转发,较灵活。</li></ul><h1 id="七层负载均衡-内容交换"><a href="#七层负载均衡-内容交换" class="headerlink" title="七层负载均衡(内容交换)"></a>七层负载均衡(内容交换)</h1><blockquote><p>所谓七层负载均衡,也称为“内容交换”,也就是主要通过报文中的真正有意义的应用层内容,再加上负载均衡设备设置的服务器选择方式,决定最终选择的内部服务器。<br>七层应用负载的好处,是使得整个网络更智能化。例如访问一个网站的用户流量,可以通过七层的方式,将对图片类的请求转发到特定的图片服务器并可以使用缓存技术;将对文字类的请求可<br>以转发到特定的文字服务器并可以使用压缩技术。</p></blockquote><p>实现七层负载均衡的软件有:</p><ul><li>haproxy :天生负载均衡技能,全面支持七层代理,会话保持,标记,路径转移;</li><li>nginx :只在 http 协议和 mail 协议上功能比较好,性能与 haproxy 差不多;</li><li>apache :功能较差</li><li>Mysql proxy :功能尚可。</li></ul><h1 id="负载均衡算法-策略"><a href="#负载均衡算法-策略" class="headerlink" title="负载均衡算法/策略"></a>负载均衡算法/策略</h1><h2 id="轮循均衡-Round-Robin"><a href="#轮循均衡-Round-Robin" class="headerlink" title="轮循均衡(Round Robin)"></a>轮循均衡(Round Robin)</h2><blockquote><p>每一次来自网络的请求轮流分配给内部中的服务器,从 1 至 N 然后重新开始。此种均衡算法适合于服务器组中的所有服务器都有相同的软硬件配置并且平均服务请求相对均衡的情况。</p></blockquote><h2 id="权重轮循均衡-Weighted-Round-Robin"><a href="#权重轮循均衡-Weighted-Round-Robin" class="headerlink" title="权重轮循均衡(Weighted Round Robin)"></a>权重轮循均衡(Weighted Round Robin)</h2><blockquote><p>根据服务器的不同处理能力,给每个服务器分配不同的权值,使其能够接受相应权值数的服务请求。例如:服务器 A 的权值被设计成 1,B 的权值是 3,C 的权值是 6,则服务器 A、B、C 将分别接受到 10%、30%、60%的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率,避免低性能的服务器负载过重。</p></blockquote><h2 id="随机均衡-Random"><a href="#随机均衡-Random" class="headerlink" title="随机均衡(Random)"></a>随机均衡(Random)</h2><blockquote><p>把来自网络的请求随机分配给内部中的多个服务器。</p></blockquote><h2 id="权重随机均衡-Weighted-Random"><a href="#权重随机均衡-Weighted-Random" class="headerlink" title="权重随机均衡(Weighted Random)"></a>权重随机均衡(Weighted Random)</h2><blockquote><p>此种均衡算法类似于权重轮循算法,不过在处理请求分担时是个随机选择的过程。</p></blockquote><h2 id="响应速度均衡-Response-Time-探测时间"><a href="#响应速度均衡-Response-Time-探测时间" class="headerlink" title="响应速度均衡(Response Time 探测时间)"></a>响应速度均衡(Response Time 探测时间)</h2><blockquote><p>负载均衡设备对内部各服务器发出一个探测请求(例如 Ping),然后根据内部中各服务器对探测请求的最快响应时间来决定哪一台服务器来响应客户端的服务请求。此种均衡算法能较好的反映服务器的当前运行状态,但这最快响应时间仅仅指的是负载均衡设备与服务器间的最快响应时间,而不是客户端与服务器间的最快响应时间。</p></blockquote><h2 id="最少连接数均衡-Least-Connection"><a href="#最少连接数均衡-Least-Connection" class="headerlink" title="最少连接数均衡(Least Connection)"></a>最少连接数均衡(Least Connection)</h2><blockquote><p>最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录,记录当前该服务器正在处理的连接数量,当有新的服务连接请求时,将把当前请求分配给连接数最少的服务器,使均衡更加符合实际情况,负载更加均衡。此种均衡算法适合长时处理的请求服务,如 FTP。</p></blockquote><h2 id="处理能力均衡-CPU、内存"><a href="#处理能力均衡-CPU、内存" class="headerlink" title="处理能力均衡(CPU、内存)"></a>处理能力均衡(CPU、内存)</h2><blockquote><p>此种均衡算法将把服务请求分配给内部中处理负荷(根据服务器 CPU 型号、CPU 数量、内存大小及当前连接数等换算而成)最轻的服务器,由于考虑到了内部服务器的处理能力及当前网络运行状况,所以此种均衡算法相对来说更加精确,尤其适合运用到第七层(应用层)负载均衡的情况下。</p></blockquote><h2 id="DNS-响应均衡-Flash-DNS"><a href="#DNS-响应均衡-Flash-DNS" class="headerlink" title="DNS 响应均衡(Flash DNS)"></a>DNS 响应均衡(Flash DNS)</h2><blockquote><p>在此均衡算法下,分处在不同地理位置的负载均衡设备收到同一个客户端的域名解析请求,并在同一时间内把此域名解析成各自相对应服务器的 IP 地址并返回给客户端,则客户端将以最先收到的域名解析 IP 地址来继续请求服务,而忽略其它的 IP 地址响应。在种均衡策略适合应用在全局负载均衡的情况下,对本地负载均衡是没有意义的。</p></blockquote><h2 id="哈希算法"><a href="#哈希算法" class="headerlink" title="哈希算法"></a>哈希算法</h2><blockquote><p>一致性哈希一致性 Hash,相同参数的请求总是发到同一提供者。当某一台提供者挂时,原本发往该提供者的请求,基于虚拟节点,平摊到其它提供者,不会引起剧烈变动。</p></blockquote><h2 id="IP-地址散列-保证客户端服务器对应关系稳定"><a href="#IP-地址散列-保证客户端服务器对应关系稳定" class="headerlink" title="IP 地址散列(保证客户端服务器对应关系稳定)"></a>IP 地址散列(保证客户端服务器对应关系稳定)</h2><blockquote><p>通过管理发送方 IP 和目的地 IP 地址的散列,将来自同一发送方的分组(或发送至同一目的地的分组)统一转发到相同服务器的算法。当客户端有一系列业务需要处理而必须和一个服务器反复通信时,该算法能够以流(会话)为单位,保证来自相同客户端的通信能够一直在同一服务器中进行处理。</p></blockquote><h2 id="URL-散列"><a href="#URL-散列" class="headerlink" title="URL 散列"></a>URL 散列</h2><blockquote><p>通过管理客户端请求 URL 信息的散列,将发送至相同 URL 的请求转发至同一服务器的算法。</p></blockquote><h1 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a>LVS</h1><h2 id="LVS-原理"><a href="#LVS-原理" class="headerlink" title="LVS 原理"></a>LVS 原理</h2><h3 id="IPVS"><a href="#IPVS" class="headerlink" title="IPVS"></a>IPVS</h3><p>LVS 的 IP 负载均衡技术是通过 IPVS 模块来实现的,IPVS 是 LVS 集群系统的核心软件,它的主要作用是:安装在 Director Server 上,同时在 Director Server 上虚拟出一个 IP 地址,用户必须通过这个虚拟的 IP 地址访问服务器。这个虚拟 IP 一般称为 LVS 的 VIP,即 Virtual IP。访问的请求首先经过 VIP 到达负载调度器,然后由负载调度器从 Real Server 列表中选取一个服务节点响应用户的请求。 在用户的请求到达负载调度器后,调度器如何将请求发送到提供服务的 Real Server 节点,而 Real Server 节点如何返回数据给用户,是 IPVS 实现的重点技术。</p><blockquote><p>ipvs : 工作于内核空间,主要用于使用户定义的策略生效</p></blockquote><blockquote><p>ipvsadm : 工作于用户空间,主要用于用户定义和管理集群服务的工具</p></blockquote><p><img src="/resource/img/lvs.png" srcset="/img/loading.gif" alt="avatar"></p><p>ipvs 工作于内核空间的 INPUT 链上,当收到用户请求某集群服务时,经过 PREROUTING 链,经检查本机路由表,送往 INPUT 链;在进入 netfilter 的 INPUT 链时,ipvs 强行将请求报文通过ipvsadm 定义的集群服务策略的路径改为 FORWORD 链,将报文转发至后端真实提供服务的主机。</p><p>LVS NAT 模式</p><p><img src="/resource/img/lvs-nat.png" srcset="/img/loading.gif" alt="avatar"></p><p>1.客户端将请求发往前端的负载均衡器,请求报文源地址是 CIP(客户端 IP),后面统称为 CIP),目标地址为 VIP(负载均衡器前端地址,后面统称为 VIP)。<br>2.负载均衡器收到报文后,发现请求的是在规则里面存在的地址,那么它将客户端请求报文的目标地址改为了后端服务器的 RIP 地址并将报文根据算法发送出去。<br>3.报文送到 Real Server 后,由于报文的目标地址是自己,所以会响应该请求,并将响应报文返还给 LVS。<br>4.然后 lvs 将此报文的源地址修改为本机并发送给客户端。</p><p>[注意]:在 NAT 模式中,Real Server 的网关必须指向 LVS,否则报文无法送达客户端</p><h4 id="特点"><a href="#特点" class="headerlink" title="特点:"></a>特点:</h4><p>1、NAT 技术将请求的报文和响应的报文都需要通过 LB 进行地址改写,因此网站访问量比较大的时候 LB 负载均衡调度器有比较大的瓶颈,一般要求最多之能 10-20 台节点<br>2、只需要在 LB 上配置一个公网 IP 地址就可以了。<br>3、每台内部的 realserver 服务器的网关地址必须是调度器 LB 的内网地址。<br>4、NAT 模式支持对 IP 地址和端口进行转换。即用户请求的端口和真实服务器的端口可以不一致。</p><h4 id="优点"><a href="#优点" class="headerlink" title="优点:"></a>优点:</h4><p>集群中的物理服务器可以使用任何支持 TCP/IP 操作系统,只有负载均衡器需要一个合法的 IP 地址。</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点:"></a>缺点:</h4><p>扩展性有限。当服务器节点(普通 PC 服务器)增长过多时,负载均衡器将成为整个系统的瓶颈,因为所有的请求包和应答包的流向都经过负载均衡器。当服务器节点过多时,大量的数据包都交汇在负载均衡器那,速度就会变慢!</p><h2 id="LVS-DR-模式-局域网改写-mac-地址"><a href="#LVS-DR-模式-局域网改写-mac-地址" class="headerlink" title="LVS DR 模式(局域网改写 mac 地址)"></a>LVS DR 模式(局域网改写 mac 地址)</h2><p><img src="/resource/img/lvs-dr.png" srcset="/img/loading.gif" alt="avatar"></p><p>1.客户端将请求发往前端的负载均衡器,请求报文源地址是 CIP,目标地址为 VIP。<br>2.负载均衡器收到报文后,发现请求的是在规则里面存在的地址,那么它将客户端请求报文的源MAC 地址改为自己 DIP 的 MAC 地址,目标 MAC 改为了 RIP 的 MAC 地址,并将此包发送给 RS。<br>3.RS 发现请求报文中的目的 MAC 是自己,就会将次报文接收下来,处理完请求报文后,将响应报文通过 lo 接口送给 eth0 网卡直接发送给客户端。<br>注意:需要设置 lo 接口的 VIP 不能响应本地网络内的 arp 请求。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结:"></a>总结:</h4><p>1、通过在调度器 LB 上修改数据包的目的 MAC 地址实现转发。注意源地址仍然是 CIP,目的地址仍然是 VIP 地址。<br>2、请求的报文经过调度器,而 RS 响应处理后的报文无需经过调度器 LB,因此并发访问量大时使用效率很高(和 NAT 模式比)<br>3、因为 DR 模式是通过 MAC 地址改写机制实现转发,因此所有 RS 节点和调度器 LB 只能在一个局域网里面<br>4、RS 主机需要绑定 VIP 地址在 LO 接口(掩码 32 位)上,并且需要配置 ARP 抑制。<br>5、RS 节点的默认网关不需要配置成 LB,而是直接配置为上级路由的网关,能让 RS 直接出网就可以。<br>6、由于 DR 模式的调度器仅做 MAC 地址的改写,所以调度器 LB 就不能改写目标端口,那么 RS服务器就得使用和 VIP 相同的端口提供服务。<br>7、直接对外的业务比如 WEB 等,RS 的 IP 最好是使用公网 IP。对外的服务,比如数据库等最好使用内网 IP。</p><h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点:"></a>优点:</h4><p>和 TUN(隧道模式)一样,负载均衡器也只是分发请求,应答包通过单独的路由方法返回给客户端。与 VS-TUN 相比,VS-DR 这种实现方式不需要隧道结构,因此可以使用大多数操作系统做为物理服务器。DR 模 式 的 效 率 很 高 , 但 是 配 置 稍 微 复 杂 一 点 , 因 此 对 于 访 问 量 不 是 特 别 大 的 公 司 可 以 用haproxy/nginx 取代。日 1000-2000W PV 或者并发请求 1 万一下都可以考虑用 haproxy/nginx。</p><h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点:"></a>缺点:</h4><p>所有 RS 节点和调度器 LB 只能在一个局域网里面</p><h2 id="LVS-TUN-模式-IP-封装、跨网段"><a href="#LVS-TUN-模式-IP-封装、跨网段" class="headerlink" title="LVS TUN 模式(IP 封装、跨网段)"></a>LVS TUN 模式(IP 封装、跨网段)</h2><p><img src="/resource/img/lvs-tun.png" srcset="/img/loading.gif" alt="avatar"></p><p>1.客户端将请求发往前端的负载均衡器,请求报文源地址是 CIP,目标地址为 VIP。<br>2.负载均衡器收到报文后,发现请求的是在规则里面存在的地址,那么它将在客户端请求报文的首部再封装一层 IP 报文,将源地址改为 DIP,目标地址改为 RIP,并将此包发送给 RS。<br>3.RS 收到请求报文后,会首先拆开第一层封装,然后发现里面还有一层 IP 首部的目标地址是自己lo 接口上的 VIP,所以会处理次请求报文,并将响应报文通过 lo 接口送给 eth0 网卡直接发送给客户端。</p><p>注意:需要设置 lo 接口的 VIP 不能在共网上出现。</p><h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结:"></a>总结:</h4><p>1.TUNNEL 模式必须在所有的 realserver 机器上面绑定 VIP 的 IP 地址<br>2.TUNNEL 模式的 vip ——&gt;realserver 的包通信通过 TUNNEL 模式,不管是内网和外网都能通信,所以不需要 lvs vip 跟 realserver 在同一个网段内。<br>3.TUNNEL 模式 realserver 会把 packet 直接发给 client 不会给 lvs 了<br>4.TUNNEL 模式走的隧道模式,所以运维起来比较难,所以一般不用。</p><h5 id="优点-2"><a href="#优点-2" class="headerlink" title="优点:"></a>优点:</h5><p>负载均衡器只负责将请求包分发给后端节点服务器,而 RS 将应答包直接发给用户。所以,减少了负载均衡器的大量数据流动,负载均衡器不再是系统的瓶颈,就能处理很巨大的请求量,这种方式,一台负载均衡器能够为很多 RS 进行分发。而且跑在公网上就能进行不同地域的分发。</p><h5 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点:"></a>缺点:</h5><p>隧 道 模 式 的 RS 节 点 需 要 合 法 IP , 这 种 方 式 需 要 所 有 的 服 务 器 支 持 ” IP Tunneling ” (IPEncapsulation)协议,服务器可能只局限在部分 Linux 系统上。</p><h1 id="LVS-FULLNAT-模式"><a href="#LVS-FULLNAT-模式" class="headerlink" title="LVS FULLNAT 模式"></a>LVS FULLNAT 模式</h1><p>无论是 DR 还是 NAT 模式,不可避免的都有一个问题:LVS 和 RS 必须在同一个 VLAN 下,否则LVS 无法作为 RS 的网关。这引发的两个问题是:<br>1、同一个 VLAN 的限制导致运维不方便,跨 VLAN 的 RS 无法接入。<br>2、LVS 的水平扩展受到制约。当 RS 水平扩容时,总有一天其上的单点 LVS 会成为瓶颈。</p><p>Full-NAT 由此而生,解决的是 LVS 和 RS 跨 VLAN 的问题,而跨 VLAN 问题解决后,LVS 和 RS不再存在 VLAN 上的从属关系,可以做到多个 LVS 对应多个 RS,解决水平扩容的问题。<br>Full-NAT 相比 NAT 的主要改进是,在 SNAT/DNAT 的基础上,加上另一种转换,转换过程如下:</p><p><img src="/resource/img/lvs-full-nat.png" srcset="/img/loading.gif" alt="avatar"></p><p>1.在包从 LVS 转到 RS 的过程中,源地址从客户端 IP 被替换成了 LVS 的内网 IP。内网 IP 之间可以通过多个交换机跨 VLAN 通信。目标地址从 VIP 修改为 RS IP.<br>2.当 RS 处理完接受到的包,处理完成后返回时,将目标地址修改为 LVS ip,原地址修改为 RSIP,最终将这个包返回给 LVS 的内网 IP,这一步也不受限于 VLAN。<br>3.LVS 收到包后,在 NAT 模式修改源地址的基础上,再把 RS 发来的包中的目标地址从 LVS 内网 IP 改为客户端的 IP,并将原地址修改为 VIP。</p><p>Full-NAT 主要的思想是把网关和其下机器的通信,改为了普通的网络通信,从而解决了跨 VLAN 的问题。采用这种方式,LVS 和 RS 的部署在 VLAN 上将不再有任何限制,大大提高了运维部署的便利性。</p><h3 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h3><ol><li>FULL NAT 模式不需要 LBIP 和 realserver ip 在同一个网段;</li><li>full nat 因为要更新 sorce ip 所以性能正常比 nat 模式下降 10%</li></ol><h1 id="Keepalive"><a href="#Keepalive" class="headerlink" title="Keepalive"></a>Keepalive</h1><p>keepalive 起初是为 LVS 设计的,专门用来监控 lvs 各个服务节点的状态,后来加入了 vrrp 的功能,因此除了 lvs,也可以作为其他服务(nginx,haproxy)的高可用软件。VRRP 是 virtualrouter redundancy protocal(虚拟路由器冗余协议)的缩写。VRRP 的出现就是为了解决静态路由出现的单点故障,它能够保证网络可以不间断的稳定的运行。所以 keepalive 一方面具有 LVScluster node healthcheck 功能,另一方面也具有 LVS director failover。</p><h2 id="Nginx-反向代理负载均衡"><a href="#Nginx-反向代理负载均衡" class="headerlink" title="Nginx 反向代理负载均衡"></a>Nginx 反向代理负载均衡</h2><p>普通的负载均衡软件,如 LVS,其实现的功能只是对请求数据包的转发、传递,从负载均衡下的节点服务器来看,接收到的请求还是来自访问负载均衡器的客户端的真实用户;而反向代理就不一样了,反向代理服务器在接收访问用户请求后,会代理用户 重新发起请求代理下的节点服务器,最后把数据返回给客户端用户。在节点服务器看来,访问的节点服务器的客户端用户就是反向代理服务器,而非真实的网站访问用户。</p><h2 id="upstream-module-和健康检测"><a href="#upstream-module-和健康检测" class="headerlink" title="upstream_module 和健康检测"></a>upstream_module 和健康检测</h2><p>ngx_http_upstream_module 是负载均衡模块,可以实现网站的负载均衡功能即节点的健康检查,upstream 模块允许 Nginx 定义一组或多组节点服务器组,使用时可通过 proxy_pass 代理方式把网站的请求发送到事先定义好的对应 Upstream 组 的名字上。</p><p><img src="/resource/img/nginx-table.png" srcset="/img/loading.gif" alt="avatar"></p><p>proxy_pass 请求转发<br>proxy_pass 指令属于 ngx_http_proxy_module 模块,此模块可以将请求转发到另一台服务器,在实际的反向代理工作中,会通过 location 功能匹配指定的 URI,然后把接收到服务匹配 URI 的<br>请求通过 proyx_pass 抛给定义好的 upstream 节点池。</p><pre><code class="jshelllanguage">location /download/ {    proxy_pass http://download/vedio/;}//这是前端代理节点的设置</code></pre><p><img src="/resource/img/proxy-model-param.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="HAProxy"><a href="#HAProxy" class="headerlink" title="HAProxy"></a>HAProxy</h1>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>负载均衡</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>设计模式</title>
    <link href="/2020/08/26/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"/>
    <url>/2020/08/26/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<ul><li>设计原则</li><li>工厂方法模式</li><li>抽象工厂模式</li><li>单例模式</li><li>建造者模式</li><li>原型模式</li><li>适配器模式</li><li>装饰器模式</li><li>代理模式</li><li>外观模式</li><li>桥接模式</li><li>组合模式</li><li>享元模式</li><li>策略模式</li><li>模板方法模式</li><li>观察者模式</li><li>迭代子模式</li><li>责任链模式</li><li>命令模式</li><li>备忘录模式</li><li>状态模式</li><li>访问者模式</li><li>中介者模式</li><li>解释器模式</li></ul>]]></content>
    
    
    <categories>
      
      <category>编程思想</category>
      
    </categories>
    
    
    <tags>
      
      <tag>设计模式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Cassandra数据库</title>
    <link href="/2020/08/26/Cassandra%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <url>/2020/08/26/Cassandra%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><blockquote><p>Apache Cassandra 是高度可扩展的,高性能的分布式 NoSQL 数据库。 Cassandra 旨在处理许多商品服务器上的大量数据,提供高可用性而无需担心单点故障。Cassandra 具有能够处理大量数据的分布式架构。 数据放置在具有多个复制因子的不同机器上,以获得高可用性,而无需担心单点故障。</p></blockquote><h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h2><p>Key Space(对应 SQL 数据库中的 database)</p><p>1.一个 Key Space 中可包含若干个 CF,如同 SQL 数据库中一个 database 可包含多个 table</p><p>Key(对应 SQL 数据库中的主键)</p><p>2.在 Cassandra 中,每一行数据记录是以 key/value 的形式存储的,其中 key 是唯一标识。</p><p>column(对应 SQL 数据库中的列)</p><p>3.Cassandra 中每个 key/value 对中的 value 又称为 column,它是一个三元组,即:name,value 和 timestamp,其中 name 需要是唯一的。super column(SQL 数据库不支持)</p><p>4.cassandra 允许 key/value 中的 value 是一个 map(key/value_list),即某个 column 有多个子列。Standard Column Family(相对应 SQL 数据库中的 table)</p><p>5.每个 CF 由一系列 row 组成,每个 row 包含一个 key 以及其对应的若干 column。</p><p>Super Column Family(SQL 数据库不支持)</p><p>6.每个 SCF 由一系列 row 组成,每个 row 包含一个 key 以及其对应的若干 super column。</p><p>Cassandra 一致 Hash 和虚拟节点</p><h2 id="一致性-Hash-多米诺-down-机"><a href="#一致性-Hash-多米诺-down-机" class="headerlink" title="一致性 Hash(多米诺 down 机)"></a>一致性 Hash(多米诺 down 机)</h2><p>为每个节点分配一个 token,根据这个 token 值来决定节点在集群中的位置以及这个节点所存储的数据范围。</p><h2 id="虚拟节点-down-机多节点托管"><a href="#虚拟节点-down-机多节点托管" class="headerlink" title="虚拟节点(down 机多节点托管)"></a>虚拟节点(down 机多节点托管)</h2><p>由于这种方式会造成数据分布不均的问题,在 Cassandra1.2 以后采用了虚拟节点的思想:不需要为每个节点分配 token,把圆环分成更多部分,让每个节点负责多个部分的数据,这样一个节点移除后,它所负责的多个 token 会托管给多个节点处理,这种思想解决了数据分布不均的问题。</p><p><img src="/resource/img/Cassandra-node.png" srcset="/img/loading.gif" alt="avatar"></p><p>如图所示,上面部分是标准一致性哈希,每个节点负责圆环中连续的一段,如果 Node2 突然down 掉,Node2 负责的数据托管给 Node1,即 Node1 负责 EFAB 四段,如果 Node1 里面有<br>很多热点用户产生的数据导致 Node1 已经有点撑不住了,恰巧 B 也是热点用户产生的数据,这样一来 Node1 可能会接着 down 机,Node1down 机,Node6 还 hold 住吗?<br>下面部分是虚拟节点实现,每个节点不再负责连续部分,且圆环被分为更多的部分。如果 Node2突然 down 掉,Node2 负责的数据不全是托管给 Node1,而是托管给多个节点。而且也保持了一<br>致性哈希的特点。</p><h1 id="Gossip-协议"><a href="#Gossip-协议" class="headerlink" title="Gossip 协议"></a>Gossip 协议</h1><p>Gossip 算法如其名,灵感来自办公室八卦,只要一个人八卦一下,在有限的时间内所有的人都会知道该八卦的信息,这种方式也与病毒传播类似,因此 Gossip 有众多的别名“闲话算法”、“疫情传播算法”、“病毒感染算法”、“谣言传播算法”。 Gossip 的特点:在一个有界网络中,每个节点都随机地与其他节点通信,经过一番杂乱无章的通信,最终所有节点的状态都会达成一致。因为 Gossip 不要求节点知道所有其他节点,因此又具有去中心化的特点,节点之间完全对等,不需要任何的中心节点。实际上 Gossip 可以用于众多能接受“最终一致性”的领域:失败检测、路由同步、Pub/Sub、动态负载均衡。</p><h2 id="Gossip-节点的通信方式及收敛性"><a href="#Gossip-节点的通信方式及收敛性" class="headerlink" title="Gossip 节点的通信方式及收敛性"></a>Gossip 节点的通信方式及收敛性</h2><p>Gossip 两个节点( A 、 B )之间存在三种通信方式( push 、 pull 、 push&amp;pull )</p><p>1.push: A 节点将数据(key,value,version)及对应的版本号推送给 B 节点,B 节点更新 A 中比自己新的数据。<br>2.pull:A 仅将数据 key,version 推送给 B,B 将本地比 A 新的数据(Key,value,version)推送给 A,A 更新本地。<br>3.push/pull:与 pull 类似,只是多了一步,A 再将本地比 B 新的数据推送给 B,B 更新本地。</p><p>如果把两个节点数据同步一次定义为一个周期,则在一个周期内,push 需通信 1 次,pull 需 2 次,push/pull 则需 3 次,从效果上来讲,push/pull 最好,理论上一个周期内可以使两个节点完全一致。直观上也感觉,push/pull 的收敛速度是最快的。</p><h3 id="gossip-的协议和-seed-list-防止集群分列"><a href="#gossip-的协议和-seed-list-防止集群分列" class="headerlink" title="gossip 的协议和 seed list (防止集群分列)"></a>gossip 的协议和 seed list (防止集群分列)</h3><p>cassandra 使用称为 gossip 的协议来发现加入 C 集群中的其他节点的位置和状态信息。gossip 进程每秒都在进行,并与至多三个节点交换状态信息。节点交换他们自己和所知道的信息,于是所有的节点很快就能学习到整个集群中的其他节点的信息。gossip 信息有一个相关的版本号,于是在一次 gossip 信息交换中,旧的信息会被新的信息覆盖重写。要阻止分区进行 gossip 交流,那么在集群中的所有节点中使用相同的 seed list,种子节点的指定除了启动起 gossip 进程外,没有其他的目的。种子节点不是一个单点故障,他们在集群操作中也没有其他的特殊目的,除了引导节点以外</p><h1 id="数据复制"><a href="#数据复制" class="headerlink" title="数据复制"></a>数据复制</h1><p>Partitioners(计算 primary key token 的 hash 函数)</p><p>在 Cassandra 中,table 的每行由唯一的 primarykey 标识,partitioner 实际上为一 hash 函数用以计算 primary key 的 token。Cassandra 依据这个 token 值在集群中放置对应的行</p><h3 id="两种可用的复制策略"><a href="#两种可用的复制策略" class="headerlink" title="两种可用的复制策略:"></a>两种可用的复制策略:</h3><p>SimpleStrategy :仅用于单数据中心,将第一个 replica 放在由 partitioner 确定的节点中,其余的 replicas 放在上述节点顺时针方向的后续节点中。<br>NetworkTopologyStrategy :可用于较复杂的多数据中心。</p><p>可以指定在每个数据中心分别存储多少份 replicas。<br>复制策略在创建 keyspace 时指定,如</p><pre><code>CREATE KEYSPACE Excelsior WITH REPLICATION = { &#39;class&#39; :&#39;SimpleStrategy&#39;,&#39;replication_factor&#39; : 3 };CREATE KEYSPACE Excalibur WITH REPLICATION = {&#39;class&#39; :&#39;NetworkTopologyStrategy&#39;,&#39;dc1&#39; : 3, &#39;dc2&#39; : 2};</code></pre><h1 id="数据写请求和协调者"><a href="#数据写请求和协调者" class="headerlink" title="数据写请求和协调者"></a>数据写请求和协调者</h1><h3 id="协调者-coordinator"><a href="#协调者-coordinator" class="headerlink" title="协调者(coordinator)"></a>协调者(coordinator)</h3><p>协调者(coordinator)将 write 请求发送到拥有对应 row 的所有 replica 节点,只要节点可用便获取并执行写请求。写一致性级别(write consistency level)确定要有多少个 replica 节点必须返回成功的确认信息。成功意味着数据被正确写入了 commit log 和 memtable。</p><p><img src="/resource/img/cassandra-coordinator.png" srcset="/img/loading.gif" alt="avatar"></p><p>其中 dc1、dc2 这些数据中心名称要与 snitch 中配置的名称一致.上面的拓扑策略表示在 dc1 配置3 个副本,在 dc2 配置 2 个副本</p><h2 id="数据读请求和后台修复"><a href="#数据读请求和后台修复" class="headerlink" title="数据读请求和后台修复"></a>数据读请求和后台修复</h2><ol><li>协调者首先与一致性级别确定的所有 replica 联系,被联系的节点返回请求的数据。</li><li>若多个节点被联系,则来自各 replica 的 row 会在内存中作比较,若不一致,则协调者使用含最新数据的 replica 向 client 返回结果。那么比较操作过程中只需要传递时间戳就可以,因为要比较的只是哪个副本数据是最新的。</li><li>协调者在后台联系和比较来自其余拥有对应 row 的 replica 的数据,若不一致,会向过时的replica 发写请求用最新的数据进行更新 read repair。</li></ol><p><img src="/resource/img/cassandra-coordinator-2.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="数据存储-CommitLog、MemTable、SSTable"><a href="#数据存储-CommitLog、MemTable、SSTable" class="headerlink" title="数据存储( CommitLog、MemTable、SSTable )"></a>数据存储( CommitLog、MemTable、SSTable )</h1><p>写请求分别到 CommitLog 和 MemTable, 并且 MemTable 的数据会刷写到磁盘 SSTable 上. 除了写数据,还有索引也会保存到磁盘上.先将数据写到磁盘中的 commitlog,同时追加到中内存中的数据结构 memtable 。这个时候就会返回客户端状态,memtable内容超出指定容量后会被放进将被刷入磁盘的队列<br>(memtable_flush_queue_size 配置队列长度)。若将被刷入磁盘的数据超出了队列长度,将内存数据刷进磁盘中的 SSTable,之后 commit log 被清空。<br>SSTable 文件构成(BloomFilter、index、data、static)<br>SSTable 文件有 fileer(判断数据 key 是否存在,这里使用了 BloomFilter 提高效率),index(寻找对应 column 值所在 data 文件位置)文件,data(存储真实数据)文件,static(存储和统计column 和 row 大小)文件。</p><h2 id="二级索引-对要索引的-value-摘要-生成-RowKey"><a href="#二级索引-对要索引的-value-摘要-生成-RowKey" class="headerlink" title="二级索引(对要索引的 value 摘要,生成 RowKey)"></a>二级索引(对要索引的 value 摘要,生成 RowKey)</h2><p>在 Cassandra 中,数据都是以 Key-value 的形式保存的。</p><p><img src="/resource/img/cassandra-columfamily.png" srcset="/img/loading.gif" alt="avatar"></p><p>KeysIndex 所创建的二级索引也被保存在一张 ColumnFamily 中。在插入数据时,对需要进行索引的 value 进行摘要,生成独一无二的 key,将其作为 RowKey 保存在索引的 ColumnFamily 中;同时在 RowKey 上添加一个 Column,将插入数据的 RowKey 作为 name 域的值,value 域则赋空值,timestamp 域则赋为插入数据的时间戳。</p><p>如果有相同的 value 被索引了,则会在索引 ColumnFamily 中相同的 RowKey 后再添加新的Column。如果有新的 value 被索引,则会在索引 ColumnFamily 中添加新的 RowKey 以及对应新的 Column。</p><p>当对 value 进行查询时,只需计算该 value 的 RowKey,在索引 ColumnFamily 中的查找该RowKey,对其 Columns 进行遍历就能得到该 value 所有数据的 RowKey。</p><h1 id="数据读写"><a href="#数据读写" class="headerlink" title="数据读写"></a>数据读写</h1><p>数据写入和更新(数据追加)</p><p>Cassandra 的设计思路与这些系统不同,无论是 insert 还是 remove 操作,都是在已有的数据后面进行追加,而不修改已有的数据。这种设计称为 Log structured 存储,顾名思义就是系统中的<br>数据是以日志的形式存在的,所以只会将新的数据追加到已有数据的后面。Log structured 存储系统有两个主要优点:<code>数据的写和删除效率极高</code>传统的存储系统需要更新元信息和数据,因此磁盘的磁头需要反复移动,这是一个比较耗时的操作,而 Log structured 的系统则是顺序写,可以充分利用文件系统的 cache,所以效率很高。</p><p><code>错误恢复简单</code></p><p>由于数据本身就是以日志形式保存,老的数据不会被覆盖,所以在设计 journal 的时候不需要考虑 undo,简化了错误恢复。</p><p><code>读的复杂度高</code></p><p>但是,Log structured 的存储系统也引入了一个重要的问题:读的复杂度和性能。理论上说,读操作需要从后往前扫描数据,以找到某个记录的最新版本。相比传统的存储系统,这是比较耗时的。</p><p><a href="https://blog.csdn.net/fs1360472174/article/details/55005335" target="_blank" rel="noopener">参考</a></p><h3 id="数据删除-column-的墓碑"><a href="#数据删除-column-的墓碑" class="headerlink" title="数据删除(column 的墓碑)"></a>数据删除(column 的墓碑)</h3><p>如果一次删除操作在一个节点上失败了(总共 3 个节点,副本为 3, RF=3).整个删除操作仍然被认为成功的(因为有两个节点应答成功,使用 CL.QUORUM 一致性)。接下来如果读发生在该节点上就会变的不明确,因为结果返回是空,还是返回数据,没有办法确定哪一种是正确的。</p><p>Cassandra 总是认为返回数据是对的,那就会发生删除的数据又出现了的事情,这些数据可以叫”僵尸”,并且他们的表现是不可预见的。</p><h1 id="墓碑"><a href="#墓碑" class="headerlink" title="墓碑"></a>墓碑</h1><p>删除一个 column 其实只是插入一个关于这个 column 的墓碑(tombstone),并不直接删除原有的 column。该墓碑被作为对该 CF 的一次修改记录在 Memtable 和 SSTable 中。墓碑的内容是删除请求被执行的时间,该时间是接受客户端请求的存储节点在执行该请求时的本地时间(local delete time),称为本地删除时间。需要注意区分本地删除时间和时间戳,每个 CF 修改记录都有一个时间戳,这个时间戳可以理解为该 column 的修改时间,是由客户端给定的。</p><h2 id="垃圾回收-compaction"><a href="#垃圾回收-compaction" class="headerlink" title="垃圾回收 compaction"></a>垃圾回收 compaction</h2><p>由于被删除的 column 并不会立即被从磁盘中删除,所以系统占用的磁盘空间会越来越大,这就需要有一种垃圾回收的机制,定期删除被标记了墓碑的 column。垃圾回收是在 compaction 的过程中完成的。</p><h2 id="数据读取-memtable-SStables"><a href="#数据读取-memtable-SStables" class="headerlink" title="数据读取( memtable+SStables )"></a>数据读取( memtable+SStables )</h2><p>为了满足读 cassandra 读取的数据是 memtable 中的数据和 SStables 中数据的合并结果。读取SSTables 中的数据就是查找到具体的哪些的 SSTables 以及数据在这些 SSTables 中的偏移量(SSTables 是按主键排序后的数据块)。首先如果 row cache enable 了话,会检测缓存。缓存命中直接返回数据,没有则查找 Bloom filter,查找可能的 SSTable。然后有一层 Partition key cache,找 partition key 的位置。如果有根据找到的 partition 去压缩偏移量映射表找具体的数据块。如果缓存没有,则要经过 Partition summary,Partition index 去找 partition key。然后经过压缩偏移量映射表找具体的数据块。</p><ol><li>检查 memtable</li><li>如果 enabled 了,检查 row cache</li><li>检查 Bloom filter</li><li>如果 enable 了,检查 partition key 缓存</li><li>如果在 partition key 缓存中找到了 partition key,直接去 compression offset 命中,如果没有,检查 partition summary</li><li>根据 compression offset map 找到数据位置</li><li>从磁盘的 SSTable 中取出数据</li></ol><p><img src="/resource/img/cassandra-row-cache.png" srcset="/img/loading.gif" alt="avatar"></p><p>行缓存和键缓存请求流程图</p><p><img src="/resource/img/cassandra-key-cache.png" srcset="/img/loading.gif" alt="avatar"></p><p>MemTable:如果 memtable 有目标分区数据,这个数据会被读出来并且和从 SSTables 中读出来的数据进行合并。SSTable 的数据访问如下面所示的步骤。Row Cache ( SSTables 中频繁被访问的数据)在 Cassandra2.2+,它们被存储在堆外内存,使用全新的实现避免造成垃圾回收对 JVM 造成压力。存在在 row cache 的子集数据可以在特定的一段时间内配置一定大小的内存。row cache 使用LRU(least-recently-userd)进行回收在申请内存。存储在 row cache 中的数据是 SSTables 中频繁被访问的数据。存储到 row cache 中后,数据就可以被后续的查询访问。row cache 不是写更新。如果写某行了,这行的缓存就会失效,并且不会被继续缓存,直到这行被读到。类似的,如果一个 partition 更新了,整个 partition 的 cache 都会被移除,但目标的数据在 row cache 中找不到,就会去检查 Bloom filter。</p><h2 id="Bloom-Filter-查找数据可能对应的-SSTable"><a href="#Bloom-Filter-查找数据可能对应的-SSTable" class="headerlink" title="Bloom Filter (查找数据可能对应的 SSTable )"></a>Bloom Filter (查找数据可能对应的 SSTable )</h2><blockquote><p>首先,Cassandra 检查 Bloom filter 去发现哪个 SSTables 中有可能有请求的分区数据。Bloomfilter 是存储在堆外内存。每个 SSTable 都有一个关联的 Bloom filter。一个 Bloom filter 可以建立一个 SSTable 没有包含的特定的分区数据。同样也可以找到分区数据存在 SSTable 中的可能性。它可以加速查找 partition key 的查找过程。然而,因为 Bloom filter 是一个概率函数,所以可能会得到错误的结果,并不是所有的 SSTables 都可以被 Bloom filter 识别出是否有数据。如果Bloom filter 不能够查找到 SSTable,Cassandra 会检查 partition key cache。Bloom filter 大小增长很适宜,每 10 亿数据 1~2GB。在极端情况下,可以一个分区一行。都可以很轻松的将数十亿的 entries 存储在单个机器上。Bloom filter 是可以调节的,如果你愿意用内存来换取性能。</p></blockquote><h2 id="Partition-Key-Cache-查找数据可能对应的-Partition-key"><a href="#Partition-Key-Cache-查找数据可能对应的-Partition-key" class="headerlink" title="Partition Key Cache (查找数据可能对应的 Partition key )"></a>Partition Key Cache (查找数据可能对应的 Partition key )</h2><blockquote><p>partition key 缓存如果开启了,将 partition index 存储在堆外内存。key cache 使用一小块可配置大小的内存。在读的过程中,每个”hit”保存一个检索。如果在 key cache 中找到了 partitionkey。就直接到 compression offset map 中招对应的块。partition key cache 热启动后工作的更好,相比较冷启动,有很大的性能提升。如果一个节点上的内存非常受限制,可能的话,需要限制保存在 key cache 中的 partition key 数目。如果一个在 key cache 中没有找到 partition key。就会去 partition summary 中去找。partition key cache 大小是可以配置的,意义就是存储在 keycache 中的 partition keys 数目。</p></blockquote><h2 id="Partition-Summary-内存中存储一些-partition-index-的样本"><a href="#Partition-Summary-内存中存储一些-partition-index-的样本" class="headerlink" title="Partition Summary (内存中存储一些 partition index 的样本)"></a>Partition Summary (内存中存储一些 partition index 的样本)</h2><blockquote><p>partition summary 是存储在堆外内存的结构,存储一些 partition index 的样本。如果一个partition index 包含所有的 partition keys。鉴于一个 partition summary 从每 X 个 keys 中取样,然后将每 X 个 key map 到 index 文件中。例如,如果一个 partition summary 设置了 20keys进行取样。它就会存储 SSTable file 开始的一个 key,20th 个 key,以此类推。尽管并不知道artition key 的具体位置,partition summary 可以缩短找到 partition 数据位置。当找到了partition key 值可能的范围后,就会去找 partition index。通过配置取样频率,你可以用内存来换取性能,当 partition summary 包含的数据越多,使用的内存越多。可以通过表定义的 indexinterval 属性来改变样本频率。固定大小的内存可以通过 index_summary_capacity_in_mb 属性来设置,默认是堆大小的 5%。</p></blockquote><h2 id="Partition-Index-磁盘中"><a href="#Partition-Index-磁盘中" class="headerlink" title="Partition Index (磁盘中)"></a>Partition Index (磁盘中)</h2><blockquote><p>partition index 驻扎在磁盘中,索引所有 partition keys 和偏移量的映射。如果 partitionsummary 已经查到 partition keys 的范围,现在的检索就是根据这个范围值来检索目标 partitionkey。需要进行单次检索和顺序读。根据找到的信息。然后去 compression offset map 中去找磁盘中有这个数据的块。如果 partition index 必须要被检索,则需要检索两次磁盘去找到目标数据。Compression offset map (磁盘中)compression offset map 存储磁盘数据准确位置的指针。存储在堆外内存,可以被 partition keycache 或者 partition index 访问。一旦 compression offset map 识别出来磁盘中的数据位置,就会从正确的 SStable(s)中取出数据。查询就会收到结果集。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Cassandra</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MongoDb</title>
    <link href="/2020/08/26/MongoDb/"/>
    <url>/2020/08/26/MongoDb/</url>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>MongoDB 是由 C++语言编写的,是一个基于分布式文件存储的开源数据库系统。在高负载的情况下,添加更多的节点,可以保证服务器性能。MongoDB 旨在为 WEB 应用提供可扩展的高性能数据存储解决方案。<br>MongoDB 将数据存储为一个文档,数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档,数组及文档数组。</p><p><img src="/resource/img/column-based.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li><p>MongoDB 是一个面向文档存储的数据库,操作起来比较简单和容易。</p></li><li><p>你可以在 MongoDB 记录中设置任何属性的索引 (如:FirstName=”Sameer”,Address=”8 Gandhi Road”)来实现更快的排序。</p></li><li><p>你可以通过本地或者网络创建数据镜像,这使得 MongoDB 有更强的扩展性。</p></li><li><p>如果负载的增加(需要更多的存储空间和更强的处理能力) ,它可以分布在计算机网络中的其他节点上这就是所谓的分片。</p></li><li><p>Mongo 支持丰富的查询表达式。查询指令使用 JSON 形式的标记,可轻易查询文档中内嵌的对象及数组。</p></li><li><p>MongoDb 使用 update()命令可以实现替换完成的文档(数据)或者一些指定的数据字段 。</p></li><li><p>Mongodb 中的 Map/reduce 主要是用来对数据进行批量处理和聚合操作。</p></li><li><p>Map 和 Reduce。Map 函数调用 emit(key,value)遍历集合中所有的记录,将 key 与 value 传给 Reduce 函数进行处理。</p></li><li><p>Map 函数和 Reduce 函数是使用 Javascript 编写的,并可以通过 db.runCommand 或 mapreduce 命令来执行 MapReduce 操作。</p></li><li><p>GridFS 是 MongoDB 中的一个内置功能,可以用于存放大量小文件。</p></li><li><p>MongoDB 允许在服务端执行脚本,可以用 Javascript 编写某个函数,直接在服务端执行,也可以把函数的定义存储在服务端,下次直接调用即可。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MongoDb</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hbase</title>
    <link href="/2020/08/19/Hbase/"/>
    <url>/2020/08/19/Hbase/</url>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>base 是分布式、面向列的开源数据库(其实准确的说是面向列族)。HDFS 为 Hbase 提供可靠的底层数据存储服务,MapReduce 为 Hbase 提供高性能的计算能力,Zookeeper 为 Hbase 提供稳定服务和 Failover 机制,因此我们说 Hbase 是一个通过大量廉价的机器解决海量数据的高速存储和读取的分布式数据库解决方案。</p><h1 id="列式存储"><a href="#列式存储" class="headerlink" title="列式存储"></a>列式存储</h1><p>列方式所带来的重要好处之一就是,由于查询中的选择规则是通过列来定义的,因此整个数据库是自动索引化的。</p><p><img src="/resource/img/column-based.png" srcset="/img/loading.gif" alt="avatar"></p><p>这里的列式存储其实说的是列族存储,Hbase 是根据列族来存储数据的。列族下面可以有非常多的列,列族在创建表的时候就必须指定。为了加深对 Hbase 列族的理解,下面是一个简单的关系型数据库的表和 Hbase 数据库的表:</p><p><img src="/resource/img/hbase-table.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Hbase-核心概念"><a href="#Hbase-核心概念" class="headerlink" title="Hbase 核心概念"></a>Hbase 核心概念</h1><h2 id="Column-Family-列族"><a href="#Column-Family-列族" class="headerlink" title="Column Family 列族"></a>Column Family 列族</h2><p>Column Family 又叫列族,Hbase 通过列族划分数据的存储,列族下面可以包含任意多的列,实现灵活的数据存取。Hbase 表的创建的时候就必须指定列族。就像关系型数据库创建的时候必须指定具体的列是一样的。Hbase 的列族不是越多越好,官方推荐的是列族最好小于或者等于 3。我们使用的场景一般是 1 个列族。</p><h2 id="Rowkey-Rowkey-查询-Rowkey-范围扫描-全表扫描"><a href="#Rowkey-Rowkey-查询-Rowkey-范围扫描-全表扫描" class="headerlink" title="Rowkey( Rowkey 查询,Rowkey 范围扫描,全表扫描)"></a>Rowkey( Rowkey 查询,Rowkey 范围扫描,全表扫描)</h2><p>Rowkey 的概念和 mysql 中的主键是完全一样的,Hbase 使用 Rowkey 来唯一的区分某一行的数据。Hbase 只支持 3 中查询方式:基于 Rowkey 的单行查询,基于 Rowkey 的范围扫描,全表扫描。</p><h2 id="Region-分区"><a href="#Region-分区" class="headerlink" title="Region 分区"></a>Region 分区</h2><p>Region:Region 的概念和关系型数据库的分区或者分片差不多。Hbase 会将一个大表的数据基于 Rowkey 的不同范围分配到不通的 Region 中,每个 Region 负责一定范围的数据访问和存储。这样即使是一张巨大的表,由于被切割到不通的 region,访问起来的时延也很低。</p><h2 id="TimeStamp-多版本"><a href="#TimeStamp-多版本" class="headerlink" title="TimeStamp 多版本"></a>TimeStamp 多版本</h2><p>TimeStamp 是实现 Hbase 多版本的关键。在 Hbase 中使用不同的 timestame 来标识相同rowkey 行对应的不通版本的数据。在写入数据的时候,如果用户没有指定对应的timestamp,Hbase 会自动添加一个 timestamp,timestamp 和服务器时间保持一致。在Hbase 中,相同 rowkey 的数据按照 timestamp 倒序排列。默认查询的是最新的版本,用户可同指定 timestamp 的值来读取旧版本的数据。</p><h1 id="Hbase-核心架构"><a href="#Hbase-核心架构" class="headerlink" title="Hbase 核心架构"></a>Hbase 核心架构</h1><p>Hbase 是由 Client、Zookeeper、Master、HRegionServer、HDFS 等几个组建组成。</p><p><img src="/resource/img/hbase-core.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="Client"><a href="#Client" class="headerlink" title="Client:"></a>Client:</h3><p>Client 包含了访问 Hbase 的接口,另外 Client 还维护了对应的 cache 来加速 Hbase 的访问,比如 cache 的.META.元数据的信息。</p><h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper:"></a>Zookeeper:</h3><p>Hbase 通过 Zookeeper 来做 master 的高可用、RegionServer 的监控、元数据的入口以及集群配置的维护等工作。具体工作如下:</p><p>1.通过 Zoopkeeper 来保证集群中只有 1 个 master 在运行,如果 master 异常,会通过竞争机制产生新的 master 提供服务<br>2.通过 Zoopkeeper 来监控 RegionServer 的状态,当 RegionSevrer 有异常的时候,通过回调的形式通知 Master RegionServer 上下限的信息<br>3.通过 Zoopkeeper 存储元数据的统一入口地址。</p><h3 id="Hmaster"><a href="#Hmaster" class="headerlink" title="Hmaster"></a>Hmaster</h3><p>master 节点的主要职责如下:</p><ol><li>为 RegionServer 分配 Region</li><li>维护整个集群的负载均衡</li><li>维护集群的元数据信息发现失效的 Region,并将失效的 Region 分配到正常RegionServer 上当 RegionSever 失效的时候,协调对应 Hlog 的拆分</li></ol><h3 id="HregionServer"><a href="#HregionServer" class="headerlink" title="HregionServer"></a>HregionServer</h3><p>HregionServer 直接对接用户的读写请求,是真正的“干活”的节点。它的功能概括如下:</p><p>1.管理 master 为其分配的 Region</p><ol start="2"><li><p>处理来自客户端的读写请求</p></li><li><p>负责和底层 HDFS 的交互,存储数据到 HDFS</p></li><li><p>负责 Region 变大以后的拆分</p></li><li><p>负责 Storefile 的合并工作</p></li></ol><h3 id="Region-寻址方式-通过-zookeeper-META"><a href="#Region-寻址方式-通过-zookeeper-META" class="headerlink" title="Region 寻址方式(通过 zookeeper .META)"></a>Region 寻址方式(通过 zookeeper .META)</h3><p>第 1 步:Client 请求 ZK 获取.META.所在的 RegionServer 的地址。<br>第 2 步:Client 请求.META.所在的 RegionServer 获取访问数据所在的 RegionServer 地址,client 会将.META.的相关信息 cache 下来,以便下一次快速访问。<br>第 3 步:Client 请求数据所在的 RegionServer,获取所需要的数据。</p><p><img src="/resource/img/hbase-region.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h3><p>HDFS 为 Hbase 提供最终的底层数据存储服务,同时为 Hbase 提供高可用(Hlog 存储在HDFS)的支持。</p><h1 id="Hbase-的写逻辑"><a href="#Hbase-的写逻辑" class="headerlink" title="Hbase 的写逻辑"></a>Hbase 的写逻辑</h1><blockquote><p>Hbase 的写入流程</p></blockquote><p><img src="/resource/img/hbase-write.png" srcset="/img/loading.gif" alt="avatar"></p><p>从上图可以看出氛围 3 步骤:</p><p>获取 RegionServer</p><blockquote><p>第 1 步:Client 获取数据写入的 Region 所在的 RegionServer</p></blockquote><p>请求写 Hlog</p><blockquote><p>第 2 步:请求写 Hlog, Hlog 存储在 HDFS,当 RegionServer 出现异常,需要使用 Hlog 来</p></blockquote><p>恢复数据。</p><p>请求写 MemStore</p><blockquote><p>第 3 步:请求写 MemStore,只有当写 Hlog 和写 MemStore 都成功了才算请求写入完成。</p></blockquote><p>MemStore 后续会逐渐刷到 HDFS 中。</p><h1 id="MemStore-刷盘"><a href="#MemStore-刷盘" class="headerlink" title="MemStore 刷盘"></a>MemStore 刷盘</h1><p>为了提高 Hbase 的写入性能,当写请求写入 MemStore 后,不会立即刷盘。而是会等到一定的时候进行刷盘的操作。具体是哪些场景会触发刷盘的操作呢?总结成如下的几个场景:</p><h3 id="全局内存控制"><a href="#全局内存控制" class="headerlink" title="全局内存控制"></a>全局内存控制</h3><p>1.这个全局的参数是控制内存整体的使用情况,当所有 memstore 占整个 heap 的最大比例的时候,会触发刷盘的操作。这个参数是hbase.regionserver.global.memstore.upperLimit,默认为整个 heap 内存的 40%。但这并不意味着全局内存触发的刷盘操作会将所有的 MemStore 都进行输盘,而是通过另外一个参数 hbase.regionserver.global.memstore.lowerLimit 来控制,默认是整个heap 内存的 35%。当 flush 到所有 memstore 占整个 heap 内存的比率为 35%的时候,就停止刷盘。这么做主要是为了减少刷盘对业务带来的影响,实现平滑系统负载的目的。</p><h3 id="MemStore-达到上限"><a href="#MemStore-达到上限" class="headerlink" title="MemStore 达到上限"></a>MemStore 达到上限</h3><p>2.当 MemStore 的大小达到 hbase.hregion.memstore.flush.size 大小的时候会触发刷盘,默认 128M 大小</p><h3 id="RegionServer-的-Hlog-数量达到上限"><a href="#RegionServer-的-Hlog-数量达到上限" class="headerlink" title="RegionServer 的 Hlog 数量达到上限"></a>RegionServer 的 Hlog 数量达到上限</h3><p>3.前面说到 Hlog 为了保证 Hbase 数据的一致性,那么如果 Hlog 太多的话,会导致故障恢复的时间太长,因此 Hbase 会对 Hlog 的最大个数做限制。当达到 Hlog 的最大个数的时候,会强制刷盘。这个参数是 hase.regionserver.max.logs,默认是 32 个。</p><h3 id="手工触发"><a href="#手工触发" class="headerlink" title="手工触发"></a>手工触发</h3><p>4.可以通过 hbase shell 或者 java api 手工触发 flush 的操作。</p><h3 id="关闭-RegionServer-触发"><a href="#关闭-RegionServer-触发" class="headerlink" title="关闭 RegionServer 触发"></a>关闭 RegionServer 触发</h3><p>5.在正常关闭 RegionServer 会触发刷盘的操作,全部数据刷盘后就不需要再使用 Hlog 恢复数据。</p><h3 id="Region-使用-HLOG-恢复完数据后触发"><a href="#Region-使用-HLOG-恢复完数据后触发" class="headerlink" title="Region 使用 HLOG 恢复完数据后触发"></a>Region 使用 HLOG 恢复完数据后触发</h3><p>6.当 RegionServer 出现故障的时候,其上面的 Region 会迁移到其他正常的RegionServer 上,在恢复完 Region 的数据后,会触发刷盘,当刷盘完成后才会提供给业务访问。</p><h1 id="HBase-vs-Cassandra"><a href="#HBase-vs-Cassandra" class="headerlink" title="HBase vs Cassandra"></a>HBase vs Cassandra</h1><p><img src="/resource/img/hbase-vs-cassandra-1.png" srcset="/img/loading.gif" alt="avatar"></p><p><img src="/resource/img/hbase-vs-cassandra-2.png" srcset="/img/loading.gif" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hbase</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RabbitMQ</title>
    <link href="/2020/08/18/RabbitMQ/"/>
    <url>/2020/08/18/RabbitMQ/</url>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>RabbitMQ 是一个由 Erlang 语言开发的 AMQP 的开源实现。</p><p>AMQP :Advanced Message Queue,高级消息队列协议。它是应用层协议的一个开放标准,为面向消息的中间件设计,基于此协议的客户端与消息中间件可传递消息,并不受产品、开发语言等条件的限制。</p><p>RabbitMQ 最初起源于金融系统,用于在分布式系统中存储转发消息,在易用性、扩展性、高可用性等方面表现不俗。具体特点包括:</p><p>1.可靠性(Reliability):RabbitMQ 使用一些机制来保证可靠性,如持久化、传输确认、发布确认。</p><p>2.灵活的路由(Flexible Routing):在消息进入队列之前,通过 Exchange 来路由消息的。对于典型的路由功能,RabbitMQ 已经提供了一些内置的 Exchange 来实现。针对更复杂的路由功能,可以将多个 Exchange 绑定在一起,也通过插件机制实现自己的 Exchange 。</p><ol start="3"><li><p>消息集群(Clustering):多个 RabbitMQ 服务器可以组成一个集群,形成一个逻辑 Broker 。</p></li><li><p>高可用(Highly Available Queues):队列可以在集群中的机器上进行镜像,使得在部分节点出问题的情况下队列仍然可用。</p></li></ol><p>5.多种协议(Multi-protocol):RabbitMQ 支持多种消息队列协议,比如 STOMP、MQTT等等。</p><p>6.多语言客户端(Many Clients):RabbitMQ 几乎支持所有常用语言,比如 Java、.NET、Ruby 等等。</p><p>7.管理界面(Management UI):RabbitMQ 提供了一个易用的用户界面,使得用户可以监控和管理消息 Broker 的许多方面。</p><p>8.跟踪机制(Tracing):如果消息异常,RabbitMQ 提供了消息跟踪机制,使用者可以找出发生了什么。</p><p>9.插件机制(Plugin System):RabbitMQ 提供了许多插件,来从多方面进行扩展,也可以编写自己的插件。</p><h1 id="RabbitMQ-架构"><a href="#RabbitMQ-架构" class="headerlink" title="RabbitMQ 架构"></a>RabbitMQ 架构</h1><p> <img src="/resource/img/rabbitmq-sturts.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Message"><a href="#Message" class="headerlink" title="Message"></a>Message</h1><p> 消息,消息是不具名的,它由消息头和消息体组成。消息体是不透明的,而消息头则由一系列的可选属性组成,这些属性包括 routing-key(路由键)、priority(相对于其他消息的优先权)、delivery-mode(指出该消息可能需要持久性存储)等。</p><h1 id="Publisher"><a href="#Publisher" class="headerlink" title="Publisher"></a>Publisher</h1><p> 1.消息的生产者,也是一个向交换器发布消息的客户端应用程序。</p><h1 id="Exchange-将消息路由给队列"><a href="#Exchange-将消息路由给队列" class="headerlink" title="Exchange(将消息路由给队列 )"></a>Exchange(将消息路由给队列 )</h1><p> 2.交换器,用来接收生产者发送的消息并将这些消息路由给服务器中的队列。</p><h1 id="Binding-消息队列和交换器之间的关联"><a href="#Binding-消息队列和交换器之间的关联" class="headerlink" title="Binding(消息队列和交换器之间的关联)"></a>Binding(消息队列和交换器之间的关联)</h1><ol start="3"><li>绑定,用于消息队列和交换器之间的关联。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则,所以可以将交换器理解成一个由绑定构成的路由表。</li></ol><h1 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h1><p> 4.消息队列,用来保存消息直到发送给消费者。它是消息的容器,也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面,等待消费者连接到这个队列将其取走。</p><h1 id="Connection"><a href="#Connection" class="headerlink" title="Connection"></a>Connection</h1><p> 5.网络连接,比如一个 TCP 连接。</p><h1 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h1><p> 6.信道,多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的 TCP 连接内地虚拟连接,AMQP 命令都是通过信道发出去的,不管是发布消息、订阅队列还是接收消息,这些动作都是通过信道完成。因为对于操作系统来说建立和销毁 TCP 都是非常昂贵的开销,所以引入了信道的概念,以复用一条 TCP 连接。</p><h1 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h1><p> 7.消息的消费者,表示一个从消息队列中取得消息的客户端应用程序。</p><h1 id="Virtual-Host"><a href="#Virtual-Host" class="headerlink" title="Virtual Host"></a>Virtual Host</h1><p> 8.虚拟主机,表示一批交换器、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。</p><h1 id="Broker"><a href="#Broker" class="headerlink" title="Broker"></a>Broker</h1><p> 9.表示消息队列服务器实体。</p><h1 id="Exchange-类型"><a href="#Exchange-类型" class="headerlink" title="Exchange 类型"></a>Exchange 类型</h1><p> Exchange 分发消息时根据类型的不同分发策略有区别,目前共四种类型:direct、fanout、topic、headers 。headers 匹配 AMQP 消息的 header 而不是路由键,此外 headers 交换器和direct 交换器完全一致,但性能差很多,目前几乎用不到了,所以直接看另外三种类型:</p><h1 id="Direct-键-routing-key-分布"><a href="#Direct-键-routing-key-分布" class="headerlink" title="Direct 键(routing key)分布:"></a>Direct 键(routing key)分布:</h1><p> 1.Direct:消息中的路由键(routing key)如果和 Binding 中的 binding key 一致,交换器就将消息发到对应的队列中。它是完全匹配、单播的模式。</p><p>  <img src="/resource/img/direct-exchange.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Fanout-广播分发"><a href="#Fanout-广播分发" class="headerlink" title="Fanout(广播分发)"></a>Fanout(广播分发)</h1><p> 2.Fanout:每个发到 fanout 类型交换器的消息都会分到所有绑定的队列上去。很像子网广播,每台子网内的主机都获得了一份复制的消息。fanout 类型转发消息是最快的。</p><p>  <img src="/resource/img/fanout-exchange.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="topic-交换器-模式匹配"><a href="#topic-交换器-模式匹配" class="headerlink" title="topic 交换器(模式匹配)"></a>topic 交换器(模式匹配)</h1><p> 3.topic 交换器:topic 交换器通过模式匹配分配消息的路由键属性,将路由键和某个模式进行匹配,此时队列需要绑定到一个模式上。它将路由键和绑定键的字符串切分成单词,这些单词之间用点隔开。它同样也会识别两个通配符:符号“#”和符号“”。#匹配 0 个或多个单词,匹配不多不少一个单词。</p><p>  <img src="/resource/img/topic-exchange.png" srcset="/img/loading.gif" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rabbitmq</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kafka</title>
    <link href="/2020/08/12/Kafka/"/>
    <url>/2020/08/12/Kafka/</url>
    
    <content type="html"><![CDATA[<h1 id="Kafka-概念"><a href="#Kafka-概念" class="headerlink" title="Kafka 概念"></a>Kafka 概念</h1><p>Kafka 是一种高吞吐量、分布式、基于发布/订阅的消息系统,最初由 LinkedIn 公司开发,使用Scala 语言编写,目前是 Apache 的开源项目。</p><ol><li><p>broker:Kafka 服务器,负责消息存储和转发</p></li><li><p>topic:消息类别,Kafka 按照 topic 来分类消息</p></li><li><p>partition:topic 的分区,一个 topic 可以包含多个 partition,topic 消息保存在各个partition 上</p></li><li><p>offset:消息在日志中的位置,可以理解是消息在 partition 上的偏移量,也是代表该消息的唯一序号</p></li><li><p>Producer:消息生产者</p></li><li><p>Consumer:消息消费者</p></li><li><p>Consumer Group:消费者分组,每个 Consumer 必须属于一个 group</p></li><li><p>Zookeeper:保存着集群 broker、topic、partition 等 meta 数据;另外,还负责 broker 故障发现,partition leader 选举,负载均衡等功能</p></li></ol><p> <img src="/resource/img/kafka.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Kafka-数据存储设计"><a href="#Kafka-数据存储设计" class="headerlink" title="Kafka 数据存储设计"></a>Kafka 数据存储设计</h1><h2 id="partition-的数据文件-offset-MessageSize-data"><a href="#partition-的数据文件-offset-MessageSize-data" class="headerlink" title="partition 的数据文件( offset,MessageSize,data )"></a>partition 的数据文件( offset,MessageSize,data )</h2><p>partition 中的每条 Message 包含了以下三个属性:offset,MessageSize,data,其中 offset 表示 Message 在这个 partition 中的偏移量,offset 不是该 Message 在 partition 数据文件中的实</p><p>际存储位置,而是逻辑上一个值,它唯一确定了 partition 中的一条 Message,可以认为 offset 是partition 中 Message 的 id;MessageSize 表示消息内容 data 的大小;data 为 Message 的具体内容。</p><h2 id="数据文件分段-segment-顺序读写、分段命令、二分查找"><a href="#数据文件分段-segment-顺序读写、分段命令、二分查找" class="headerlink" title="数据文件分段 segment(顺序读写、分段命令、二分查找)"></a>数据文件分段 segment(顺序读写、分段命令、二分查找)</h2><p>partition 物理上由多个 segment 文件组成,每个 segment 大小相等,顺序读写。每个 segment数据文件以该段中最小的 offset 命名,文件扩展名为.log。这样在查找指定 offset 的 Message 的时候,用二分查找就可以定位到该 Message 在哪个 segment 数据文件中。</p><h2 id="数据文件索引-分段索引、稀疏存储"><a href="#数据文件索引-分段索引、稀疏存储" class="headerlink" title="数据文件索引(分段索引、稀疏存储)"></a>数据文件索引(分段索引、稀疏存储)</h2><p>Kafka 为每个分段后的数据文件建立了索引文件,文件名与数据文件的名字是一样的,只是文件扩展名为.index。index 文件中并没有为数据文件中的每条 Message 建立索引,而是采用了稀疏存储的方式,每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间,从而可以将索引文件保留在内存中。</p><p><img src="/resource/img/kafka-data-file-index.png" srcset="/img/loading.gif" alt="avatar"></p><p>生产者设计</p><p>负载均衡(partition 会均衡分布到不同 broker 上)</p><p>由于消息 topic 由多个 partition 组成,且 partition 会均衡分布到不同 broker 上,因此,为了有效利用 broker 集群的性能,提高消息的吞吐量,producer 可以通过随机或者 hash 等方式,将消息平均发送到多个 partition 上,以实现负载均衡。</p><p><img src="/resource/img/kafka-loadblance.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="批量发送"><a href="#批量发送" class="headerlink" title="批量发送"></a>批量发送</h2><p>是提高消息吞吐量重要的方式,Producer 端可以在内存中合并多条消息后,以一次请求的方式发送了批量的消息给 broker,从而大大减少 broker 存储消息的 IO 操作次数。但也一定程度上影响了消息的实时性,相当于以时延代价,换取更好的吞吐量。</p><h2 id="压缩-GZIP-或-Snappy"><a href="#压缩-GZIP-或-Snappy" class="headerlink" title="压缩( GZIP 或 Snappy )"></a>压缩( GZIP 或 Snappy )</h2><p>Producer 端可以通过 GZIP 或 Snappy 格式对消息集合进行压缩。Producer 端进行压缩之后,在Consumer 端需进行解压。压缩的好处就是减少传输的数据量,减轻对网络传输的压力,在对大数据处理上,瓶颈往往体现在网络上而不是 CPU(压缩和解压会耗掉部分 CPU 资源)。</p><p><img src="/resource/img/kafka-gzip.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="Consumer-Group"><a href="#Consumer-Group" class="headerlink" title="Consumer Group"></a>Consumer Group</h2><p>同一 Consumer Group 中的多个 Consumer 实例,不同时消费同一个 partition,等效于队列模式。partition 内消息是有序的,Consumer 通过 pull 方式消费消息。Kafka 不删除已消费的消息对于 partition,顺序读写磁盘数据,以时间复杂度 O(1)方式提供消息持久化能力。</p>]]></content>
    
    
    <categories>
      
      <category>框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>kafka</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Zookeeper</title>
    <link href="/2020/08/12/Zookeeper/"/>
    <url>/2020/08/12/Zookeeper/</url>
    
    <content type="html"><![CDATA[<h1 id="Zookeeper-概念"><a href="#Zookeeper-概念" class="headerlink" title="Zookeeper 概念"></a>Zookeeper 概念</h1><p>Zookeeper 是一个分布式协调服务,可用于服务发现,分布式锁,分布式领导选举,配置管理等。<br>Zookeeper 提供了一个类似于 Linux 文件系统的树形结构(可认为是轻量级的内存文件系统,但只适合存少量信息,完全不适合存储大量文件或者大文件),同时提供了对于每个节点的监控与通知机制。</p><h1 id="Zookeeper-角色"><a href="#Zookeeper-角色" class="headerlink" title="Zookeeper 角色"></a>Zookeeper 角色</h1><p>Zookeeper 集群是一个基于主从复制的高可用集群,每个服务器承担如下三种角色中的一种</p><p>Leader</p><p>1.一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader,它会发起并维护与各 Follwer及 Observer 间的心跳。<br>2.所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。只要有超过半数节点(不包括 observeer 节点)写入成功,该写请求就会被提交(类 2PC 协议)。</p><p>Follower</p><ol><li>一个 Zookeeper 集群可能同时存在多个 Follower,它会响应 Leader 的心跳,</li><li>Follower 可直接处理并返回客户端的读请求,同时会将写请求转发给 Leader 处理,</li><li>并且负责在 Leader 处理写请求时对请求进行投票。</li></ol><p>Observer</p><p>角色与 Follower 类似,但是无投票权。Zookeeper 需保证高可用和强一致性,为了支持更多的客户端,需要增加更多 Server;Server 增多,投票阶段延迟增大,影响性能;引入 Observer,Observer 不参与投票; Observers 接受客户端的连接,并将写请求转发给 leader 节点; 加入更多 Observer 节点,提高伸缩性,同时不影响吞吐率。</p><p><img src="/resource/img/elk.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="ZAB-协议"><a href="#ZAB-协议" class="headerlink" title="ZAB 协议"></a>ZAB 协议</h1><h2 id="事务编号-Zxid-事务请求计数器-epoch"><a href="#事务编号-Zxid-事务请求计数器-epoch" class="headerlink" title="事务编号 Zxid (事务请求计数器 + epoch )"></a>事务编号 Zxid (事务请求计数器 + epoch )</h2><p>在 ZAB ( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议) 协议的事务编号 Zxid设计中,Zxid 是一个 64 位的数字,其中低 32 位是一个简单的单调递增的计数器,针对客户端每一个事务请求,计数器加 1;而高 32 位则代表 Leader 周期 epoch 的编号,每个当选产生一个新<br>的 Leader 服务器,就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID,并从中读取epoch 值,然后加 1,以此作为新的 epoch,并将低 32 位从 0 开始计数。<br>Zxid(Transaction id)类似于 RDBMS 中的事务 ID,用于标识一次更新操作的 Proposal(提议)ID。为了保证顺序性,该 zkid 必须单调递增。</p><h2 id="epoch"><a href="#epoch" class="headerlink" title="epoch"></a>epoch</h2><p>epoch:可以理解为当前集群所处的年代或者周期,每个 leader 就像皇帝,都有自己的年号,所以每次改朝换代,leader 变更之后,都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后,也没有人听他的了,因为 follower 只听从当前年代的 leader 的命令。<br>Zab 协议有两种模式 - 恢复模式(选主)、广播模式(同步)<br>Zab 协议有两种模式,它们分别是恢复模式(选主)和广播模式(同步)。当服务启动或者在领导者崩溃后,Zab 就进入了恢复模式,当领导者被选举出来,且大多数 Server 完成了和 leader 的状态同步以后,恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。</p><h2 id="ZAB-协议-4-阶段"><a href="#ZAB-协议-4-阶段" class="headerlink" title="ZAB 协议 4 阶段"></a>ZAB 协议 4 阶段</h2><h3 id="Leader-election-选举阶段-选出准-Leader"><a href="#Leader-election-选举阶段-选出准-Leader" class="headerlink" title="Leader election (选举阶段 - 选出准 Leader )"></a>Leader election (选举阶段 - 选出准 Leader )</h3><p>1.Leader election(选举阶段):节点在一开始都处于选举阶段,只要有一个节点得到超半数节点的票数,它就可以当选准 leader。只有到达 广播阶段(broadcast) 准 leader 才会成为真正的 leader。这一阶段的目的是就是为了选出一个准 leader,然后进入下一个阶段。</p><h2 id="Discovery-发现阶段-接受提议、生成-epoch-、接受-epoch"><a href="#Discovery-发现阶段-接受提议、生成-epoch-、接受-epoch" class="headerlink" title="Discovery (发现阶段 - 接受提议、生成 epoch 、接受 epoch )"></a>Discovery (发现阶段 - 接受提议、生成 epoch 、接受 epoch )</h2><p>2.Discovery(发现阶段):在这个阶段,followers 跟准 leader 进行通信,同步 followers最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议,并且准 leader 生成新的 epoch,让 followers 接受,更新它们的 accepted Epoch一个 follower 只会连接一个 leader,如果有一个节点 f 认为另一个 follower p 是 leader,f在尝试连接 p 时会被拒绝,f 被拒绝之后,就会进入重新选举阶段。</p><h2 id="Synchronization-同步阶段-同步-follower-副本"><a href="#Synchronization-同步阶段-同步-follower-副本" class="headerlink" title="Synchronization (同步阶段 - 同步 follower 副本)"></a>Synchronization (同步阶段 - 同步 follower 副本)</h2><p>3.Synchronization(同步阶段):同步阶段主要是利用 leader 前一阶段获得的最新提议历史,同步集群中所有的副本。只有当 大多数节点都同步完成,准 leader 才会成为真正的 leader。follower 只会接收 zxid 比自己的 lastZxid 大的提议。</p><h2 id="Broadcast-广播阶段-leader-消息广播"><a href="#Broadcast-广播阶段-leader-消息广播" class="headerlink" title="Broadcast (广播阶段 -leader 消息广播)"></a>Broadcast (广播阶段 -leader 消息广播)</h2><p>4.Broadcast(广播阶段):到了这个阶段,Zookeeper 集群才能正式对外提供事务服务,并且 leader 可以进行消息广播。同时如果有新的节点加入,还需要对新节点进行同步。<br>ZAB 提交事务并不像 2PC 一样需要全部 follower 都 ACK,只需要得到超过半数的节点的 ACK 就可以了。</p><h2 id="ZAB-协议-JAVA-实现-FLE-发现阶段和同步合并为-Recovery-Phase-恢复阶段"><a href="#ZAB-协议-JAVA-实现-FLE-发现阶段和同步合并为-Recovery-Phase-恢复阶段" class="headerlink" title="ZAB 协议 JAVA 实现( FLE-发现阶段和同步合并为 Recovery Phase(恢复阶段) )"></a>ZAB 协议 JAVA 实现( FLE-发现阶段和同步合并为 Recovery Phase(恢复阶段) )</h2><p>协议的 Java 版本实现跟上面的定义有些不同,选举阶段使用的是 Fast Leader Election(FLE),<br>它包含了 选举的发现职责。因为 FLE 会选举拥有最新提议历史的节点作为 leader,这样就省去了<br>发现最新提议的步骤。实际的实现将 发现阶段 和 同步合并为 Recovery Phase(恢复阶段)。所<br>以,ZAB 的实现只有三个阶段:Fast Leader Election;Recovery Phase;Broadcast Phase。</p><h1 id="投票机制"><a href="#投票机制" class="headerlink" title="投票机制"></a>投票机制</h1><p>每个 sever 首先给自己投票,然后用自己的选票和其他 sever 选票对比,权重大的胜出,使用权重较大的更新自身选票箱。具体选举过程如下:</p><ol><li><p>每个 Server 启动以后都询问其它的 Server 它要投票给谁。对于其他 server 的询问,server 每次根据自己的状态都回复自己推荐的 leader 的 id 和上一次处理事务的 zxid(系统启动时每个 server 都会推荐自己)</p></li><li><p>收到所有 Server 回复以后,就计算出 zxid 最大的哪个 Server,并将这个 Server 相关信息设置成下一次要投票的 Server。</p></li><li><p>计算这过程中获得票数最多的的 sever 为获胜者,如果获胜者的票数超过半数,则改server 被选为 leader。否则,继续这个过程,直到 leader 被选举出来</p></li><li><p>leader 就会开始等待 server 连接</p></li><li><p>Follower 连接 leader,将最大的 zxid 发送给 leader</p></li><li><p>Leader 根据 follower 的 zxid 确定同步点,至此选举阶段完成。</p></li><li><p>选举阶段完成 Leader 同步后通知 follower 已经成为 uptodate 状态</p></li><li><p>Follower 收到 uptodate 消息后,又可以重新接受 client 的请求进行服务了</p></li></ol><p>目前有 5 台服务器,每台服务器均没有数据,它们的编号分别是 1,2,3,4,5,按编号依次启动,它们的选择举过程如下:</p><ol><li><p>服务器 1 启动,给自己投票,然后发投票信息,由于其它机器还没有启动所以它收不到反馈信息,服务器 1 的状态一直属于 Looking。</p></li><li><p>服务器 2 启动,给自己投票,同时与之前启动的服务器 1 交换结果,由于服务器 2 的编号大所以服务器 2 胜出,但此时投票数没有大于半数,所以两个服务器的状态依然是LOOKING。</p></li><li><p>服务器 3 启动,给自己投票,同时与之前启动的服务器 1,2 交换信息,由于服务器 3 的编号最大所以服务器 3 胜出,此时投票数正好大于半数,所以服务器 3 成为领导者,服务器1,2 成为小弟。</p></li><li><p>服务器 4 启动,给自己投票,同时与之前启动的服务器 1,2,3 交换信息,尽管服务器 4 的编号大,但之前服务器 3 已经胜出,所以服务器 4 只能成为小弟。</p></li><li><p>服务器 5 启动,后面的逻辑同服务器 4 成为小弟。</p></li></ol><h1 id="Zookeeper-工作原理-原子广播"><a href="#Zookeeper-工作原理-原子广播" class="headerlink" title="Zookeeper 工作原理(原子广播)"></a>Zookeeper 工作原理(原子广播)</h1><ol><li><p>Zookeeper 的核心是原子广播,这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式,它们分别是恢复模式和广播模式。</p></li><li><p>当服务启动或者在领导者崩溃后,Zab 就进入了恢复模式,当领导者被选举出来,且大多数 server 的完成了和 leader 的状态同步以后,恢复模式就结束了。</p></li><li><p>状态同步保证了 leader 和 server 具有相同的系统状态</p></li><li><p>一旦 leader 已经和多数的 follower 进行了状态同步后,他就可以开始广播消息了,即进入广播状态。这时候当一个 server 加入 zookeeper 服务中,它会在恢复模式下启动,发现 leader,并和 leader 进行状态同步。待到同步结束,它也参与消息广播。Zookeeper服务一直维持在 Broadcast 状态,直到 leader 崩溃了或者 leader 失去了大部分的followers 支持。</p></li></ol><p>5.广播模式需要保证 proposal 被按顺序处理,因此 zk 采用了递增的事务 id 号(zxid)来保证。所有的提议(proposal)都在被提出的时候加上了 zxid。</p><ol start="6"><li><p>实现中 zxid 是一个 64 为的数字,它高 32 位是 epoch 用来标识 leader 关系是否改变,每次一个 leader 被选出来,它都会有一个新的 epoch。低 32 位是个递增计数。</p></li><li><p>当 leader 崩溃或者 leader 失去大多数的 follower,这时候 zk 进入恢复模式,恢复模式需要重新选举出一个新的 leader,让所有的 server 都恢复到一个正确的状态。</p></li></ol><h1 id="Znode-有四种形式的目录节点"><a href="#Znode-有四种形式的目录节点" class="headerlink" title="Znode 有四种形式的目录节点"></a>Znode 有四种形式的目录节点</h1><ol><li><p>PERSISTENT:持久的节点。</p></li><li><p>EPHEMERAL:暂时的节点。</p></li><li><p>PERSISTENT_SEQUENTIAL:持久化顺序编号目录节点。</p></li><li><p>EPHEMERAL_SEQUENTIAL:暂时化顺序编号目录节点。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>zookeeper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>日志管理</title>
    <link href="/2020/08/12/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/"/>
    <url>/2020/08/12/%E6%97%A5%E5%BF%97%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="Slf4j"><a href="#Slf4j" class="headerlink" title="Slf4j"></a>Slf4j</h1><p>slf4j 的全称是 Simple Loging Facade For Java,即它仅仅是一个为 Java 程序提供日志输出的统一接<br>口,并不是一个具体的日志实现方案,就比如 JDBC 一样,只是一种规则而已。所以单独的 slf4j 是不<br>能工作的,必须搭配其他具体的日志实现方案,比如 apache 的 org.apache.log4j.Logger,jdk 自带<br>的 java.util.logging.Logger 等。</p><h1 id="Log4j"><a href="#Log4j" class="headerlink" title="Log4j"></a>Log4j</h1><p>Log4j 是 Apache 的一个开源项目,通过使用 Log4j,我们可以控制日志信息输送的目的地是控制台、<br>文件、GUI 组件,甚至是套接口服务器、NT 的事件记录器、UNIX Syslog 守护进程等;我们也可以控<br>制每一条日志的输出格式;通过定义每一条日志信息的级别,我们能够更加细致地控制日志的生成过程。<br>Log4j 由三个重要的组成构成:日志记录器(Loggers),输出端(Appenders)和日志格式化器(Layout)。<br>1.Logger:控制要启用或禁用哪些日志记录语句,并对日志信息进行级别限制<br>2.Appenders : 指定了日志将打印到控制台还是文件中<br>3.Layout : 控制日志信息的显示格式<br>Log4j 中将要输出的 Log 信息定义了 5 种级别,依次为 DEBUG、INFO、WARN、ERROR 和 FATAL,<br>当输出时,只有级别高过配置中规定的 级别的信息才能真正的输出,这样就很方便的来配置不同情况<br>下要输出的内容,而不需要更改代码。</p><h1 id="LogBack"><a href="#LogBack" class="headerlink" title="LogBack"></a>LogBack</h1><p>简单地说,Logback 是一个 Java 领域的日志框架。它被认为是 Log4J 的继承人。<br>Logback 主要由三个模块组成:logback-core,logback-classic。logback-access<br>logback-core 是其它模块的基础设施,其它模块基于它构建,显然,logback-core 提供了一些关键的<br>通用机制。<br>logback-classic 的地位和作用等同于 Log4J,它也被认为是 Log4J 的一个改进版,并且它实现了简单<br>日志门面 SLF4J;<br>logback-access 主要作为一个与 Servlet 容器交互的模块,比如说 tomcat 或者 jetty,提供一些与<br>HTTP 访问相关的功能。</p><h2 id="Logback-优点"><a href="#Logback-优点" class="headerlink" title="Logback 优点"></a>Logback 优点</h2><p>同样的代码路径,Logback 执行更快更充分的测试原生实现了 SLF4J API(Log4J 还需要有一个中间转换层)内容更丰富的文档支持 XML 或者 Groovy 方式配置配置文件自动热加载</p><p>从 IO 错误中优雅恢复自动删除日志归档自动压缩日志成为归档文件支持 Prudent 模式,使多个 JVM 进程能记录同一个日志文件支持配置文件中加入条件判断来适应不同的环境更强大的过滤器支持 SiftingAppender(可筛选 Appender)异常栈信息带有包信息</p><h1 id="ELK"><a href="#ELK" class="headerlink" title="ELK"></a>ELK</h1><p>ELK 是软件集合 Elasticsearch、Logstash、Kibana 的简称,由这三个软件及其相关的组件可以打造大规模日志实时处理系统。<br>Elasticsearch 是一个基于 Lucene 的、支持全文索引的分布式存储和索引引擎,主要负责将日志索引并存储起来,方便业务方检索查询。<br>Logstash 是一个日志收集、过滤、转发的中间件,主要负责将各条业务线的各类日志统一收集、过滤后,转发给 Elasticsearch 进行下一步处理。<br>Kibana 是一个可视化工具,主要负责查询 Elasticsearch 的数据并以可视化的方式展现给业务方,比如各类饼图、直方图、区域图等。</p><p><img src="/resource/img/elk.png" srcset="/img/loading.gif" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>日志</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Log4j</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络协议</title>
    <link href="/2020/08/12/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"/>
    <url>/2020/08/12/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="网络-7-层架构"><a href="#网络-7-层架构" class="headerlink" title="网络 7 层架构"></a>网络 7 层架构</h1><h2 id="7-层模型主要包括"><a href="#7-层模型主要包括" class="headerlink" title="7 层模型主要包括:"></a>7 层模型主要包括:</h2><p>1.物理层:主要定义物理设备标准,如网线的接口类型、光纤的接口类型、各种传输介质的传输速率等。它的主要作用是传输比特流(就是由 1、0 转化为电流强弱来进行传输,到达目的地后在转化为1、0,也就是我们常说的模数转换与数模转换)。这一层的数据叫做比特。</p><p>2.数据链路层:主要将从物理层接收的数据进行 MAC 地址(网卡的地址)的封装与解封装。常把这一层的数据叫做帧。在这一层工作的设备是交换机,数据通过交换机来传输。</p><p>3.网络层:主要将从下层接收到的数据进行 IP 地址(例 192.168.0.1)的封装与解封装。在这一层工作的设备是路由器,常把这一层的数据叫做数据包。</p><p>4.传输层:定义了一些传输数据的协议和端口号(WWW 端口 80 等),如:TCP(传输控制协议,传输效率低,可靠性强,用于传输可靠性要求高,数据量大的数据),UDP(用户数据报协议,与 TCP 特性恰恰相反,用于传输可靠性要求不高,数据量小的数据,如 QQ 聊天数据就是通过这种方式传输的)。 主要是将从下层接收的数据进行分段进行传输,到达目的地址后在进行重组。常常把这一层数据叫做段。</p><p>5.会话层:通过传输层(端口号:传输端口与接收端口)建立数据传输的通路。主要在你的系统之间发起会话或或者接受会话请求(设备之间需要互相认识可以是 IP 也可以是 MAC 或者是主机名)</p><p>6.表示层:主要是进行对接收的数据进行解释、加密与解密、压缩与解压缩等(也就是把计算机能够识别的东西转换成人能够能识别的东西(如图片、声音等))</p><p>7.应用层 主要是一些终端的应用,比如说 FTP(各种文件下载),WEB(IE 浏览),QQ 之类的(你就把它理解成我们在电脑屏幕上可以看到的东西.就 是终端应用)。</p><p><img src="/resource/img/seven-network-protocol.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="TCP-IP-原理"><a href="#TCP-IP-原理" class="headerlink" title="TCP/IP 原理"></a>TCP/IP 原理</h1><p>TCP/IP 协议不是 TCP 和 IP 这两个协议的合称,而是指因特网整个 TCP/IP 协议族。从协议分层模型方面来讲,TCP/IP 由四个层次组成:网络接口层、网络层、传输层、应用层。</p><p><img src="/resource/img/tcp-ip.png" srcset="/img/loading.gif" alt="avatar"></p><p>1.网络访问层(Network Access Layer)</p><blockquote><p>网络访问层(Network Access Layer)在 TCP/IP 参考模型中并没有详细描述,只是指出主机必须使用某种协议与网络相连。</p></blockquote><p>2.网络层(Internet Layer)</p><blockquote><p>网络层(Internet Layer)是整个体系结构的关键部分,其功能是使主机可以把分组发往任何网络,并使分组独立地传向目标。这些分组可能经由不同的网络,到达的顺序和发送的顺序也可能不同。高层如果需要顺序收发,那么就必须自行处理对分组的排序。互联网层使用因特网协议(IP,Internet Protocol)。</p></blockquote><p>3.传输层(Tramsport Layer-TCP/UDP)</p><blockquote><p>传输层(Tramsport Layer)使源端和目的端机器上的对等实体可以进行会话。在这一层定义了两个端到端的协议:传输控制协议(TCP,Transmission Control Protocol)和用户数据报协议(UDP,User Datagram Protocol)。TCP 是面向连接的协议,它提供可靠的报文传输和对上层应用的连接服务。为此,除了基本的数据传输外,它还有可靠性保证、流量控制、多路复用、优先权和安全性控制等功能。UDP 是面向无连接的不可靠传输的协议,主要用于不需要 TCP 的排序和流量控制等功能的应用程序。</p></blockquote><p>4.应用层(Application Layer)</p><blockquote><p>应用层(Application Layer)包含所有的高层协议,包括:虚拟终端协议(TELNET,TELecommunications NETwork)、文件传输协议(FTP,File Transfer Protocol)、电子邮件传输协议(SMTP,Simple Mail Transfer Protocol)、域名服务(DNS,Domain NameService)、网上新闻传输协议(NNTP,Net News Transfer Protocol)和超文本传送协议(HTTP,HyperText Transfer Protocol)等。</p></blockquote><h1 id="TCP-三次握手-四次挥手"><a href="#TCP-三次握手-四次挥手" class="headerlink" title="TCP 三次握手/四次挥手"></a>TCP 三次握手/四次挥手</h1><blockquote><p>TCP 在传输之前会进行三次沟通,一般称为“三次握手”,传完数据断开的时候要进行四次沟通,一般称为“四次挥手”。</p></blockquote><h1 id="数据包说明"><a href="#数据包说明" class="headerlink" title="数据包说明"></a>数据包说明</h1><ol><li>源端口号( 16 位):它(连同源主机 IP 地址)标识源主机的一个应用进程。</li><li>目的端口号( 16 位):它(连同目的主机 IP 地址)标识目的主机的一个应用进程。这两个值加上 IP 报头中的源主机 IP 地址和目的主机 IP 地址唯一确定一个 TCP 连接。</li><li>顺序号 seq( 32 位):用来标识从 TCP 源端向 TCP 目的端发送的数据字节流,它表示在这个报文段中的第一个数据字节的顺序号。如果将字节流看作在两个应用程序间的单向流动,则TCP 用顺序号对每个字节进行计数。序号是 32bit 的无符号数,序号到达 2 的 32 次方 - 1 后又从 0 开始。当建立一个新的连接时, SYN 标志变 1 ,顺序号字段包含由这个主机选择的该连接的初始顺序号 ISN ( Initial Sequence Number )。</li><li>确认号 ack( 32 位):包含发送确认的一端所期望收到的下一个顺序号。因此,确认序号应当是上次已成功收到数据字节顺序号加 1 。只有 ACK 标志为 1 时确认序号字段才有效。 TCP 为应用层提供全双工服务,这意味数据能在两个方向上独立地进行传输。因此,连接的每一端必须保持每个方向上的传输数据顺序号。</li><li>TCP 报头长度( 4 位):给出报头中 32bit 字的数目,它实际上指明数据从哪里开始。需要这个值是因为任选字段的长度是可变的。这个字段占 4bit ,因此 TCP 最多有 60 字节的首部。然而,没有任选字段,正常的长度是 20 字节。</li><li>保留位( 6 位):保留给将来使用,目前必须置为 0 。</li><li>控制位( control flags , 6 位):在 TCP 报头中有 6 个标志比特,它们中的多个可同时被设置为 1 。</li></ol><p>依次为:</p><blockquote><p>URG :为 1 表示紧急指针有效,为 0 则忽略紧急指针值。<br>ACK :为 1 表示确认号有效,为 0 表示报文中不包含确认信息,忽略确认号字段。<br>PSH :为 1 表示是带有 PUSH 标志的数据,指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。<br>RST :用于复位由于主机崩溃或其他原因而出现错误的连接。它还可以用于拒绝非法的报文段和拒绝连接请求。一般情况下,如果收到一个 RST 为 1 的报文,那么一定发生了某些问题。<br>SYN :同步序号,为 1 表示连接请求,用于建立连接和使顺序号同步( synchronize )。<br>FIN :用于释放连接,为 1 表示发送方已经没有数据发送了,即关闭本方数据流。</p></blockquote><p>8.窗口大小( 16 位):数据字节数,表示从确认号开始,本报文的源方可以接收的字节数,即源方接收窗口大小。窗口大小是一个 16bit 字段,因而窗口大小最大为 65535 字节。<br>9.校验和( 16 位):此校验和是对整个的 TCP 报文段,包括 TCP 头部和 TCP 数据,以 16 位字进行计算所得。这是一个强制性的字段,一定是由发送端计算和存储,并由接收端进行验证。<br>10. 紧急指针( 16 位):只有当 URG 标志置 1 时紧急指针才有效。TCP 的紧急方式是发送端向另一端发送紧急数据的一种方式。</p><ol start="11"><li>选项:最常见的可选字段是最长报文大小,又称为 MSS(Maximum Segment Size) 。每个连接方通常都在通信的第一个报文段(为建立连接而设置 SYN 标志的那个段)中指明这个选项,它指明本端所能接收的最大长度的报文段。选项长度不一定是 32 位字的整数倍,所以要加填充位,使得报头长度成为整字数。</li><li>数据: TCP 报文段中的数据部分是可选的。在一个连接建立和一个连接终止时,双方交换的报文段仅有 TCP 首部。如果一方没有数据要发送,也使用没有任何数据的首部来确认收到的数据。在处理超时的许多情况中,也会发送不带任何数据的报文段。</li></ol><p><img src="/resource/img/three-hand.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="三次握手"><a href="#三次握手" class="headerlink" title="三次握手"></a>三次握手</h1><p>第一次握手:主机 A 发送位码为 syn=1,随机产生 seq number=1234567 的数据包到服务器,主机 B由 SYN=1 知道,A 要求建立联机;<br>第二次握手: 主 机 B 收 到 请 求 后 要 确 认 联 机 信 息 , 向 A 发 送 ack number=( 主 机 A 的seq+1),syn=1,ack=1,随机产生 seq=7654321 的包<br>第三次握手:主机 A 收到后检查 ack number 是否正确,即第一次发送的 seq number+1,以及位码ack 是否为 1,若正确,主机 A 会再发送 ack number=(主机 B 的 seq+1),ack=1,主机 B 收到后确认seq 值与 ack=1 则连接建立成功。</p><p><img src="/resource/img/three-hand-1.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="四次挥手"><a href="#四次挥手" class="headerlink" title="四次挥手"></a>四次挥手</h1><p>TCP 建立连接要进行三次握手,而断开连接要进行四次。这是由于 TCP 的半关闭造成的。因为 TCP 连接是全双工的(即数据可在两个方向上同时传递)所以进行关闭时每个方向上都要单独进行关闭。这个单方向的关闭就叫半关闭。当一方完成它的数据发送任务,就发送一个 FIN 来向另一方通告将要终止这个方向的连接。</p><p>1) 关闭客户端到服务器的连接:首先客户端 A 发送一个 FIN,用来关闭客户到服务器的数据传送,然后等待服务器的确认。其中终止标志位 FIN=1,序列号 seq=u<br>2) 服务器收到这个 FIN,它发回一个 ACK,确认号 ack 为收到的序号加 1。<br>3) 关闭服务器到客户端的连接:也是发送一个 FIN 给客户端。<br>4) 客户段收到 FIN 后,并发回一个 ACK 报文确认,并将确认序号 seq 设置为收到序号加 1。首先进行关闭的一方将执行主动关闭,而另一方执行被动关闭。</p><p><img src="/resource/img/four-hand.png" srcset="/img/loading.gif" alt="avatar"></p><p>主机 A 发送 FIN 后,进入终止等待状态, 服务器 B 收到主机 A 连接释放报文段后,就立即给主机 A 发送确认,然后服务器 B 就进入 close-wait 状态,此时 TCP 服务器进程就通知高层应用进程,因而从 A 到 B 的连接就释放了。此时是“半关闭”状态。即 A 不可以发送给B,但是 B 可以发送给 A。此时,若 B 没有数据报要发送给 A 了,其应用进程就通知 TCP 释放连接,然后发送给 A 连接释放报文段,并等待确认。A 发送确认后,进入 time-wait,注意,此时 TCP 连接还没有释放掉,然后经过时间等待计时器设置的 2MSL 后,A 才进入到close 状态。</p><h1 id="HTTP-原理"><a href="#HTTP-原理" class="headerlink" title="HTTP 原理"></a>HTTP 原理</h1><p>HTTP 是一个无状态的协议。无状态是指客户机(Web 浏览器)和服务器之间不需要建立持久的连接,这意味着当一个客户端向服务器端发出请求,然后服务器返回响应(response),连接就被关闭了,在服务器端不保留连接的有关信息.HTTP 遵循请求(Request)/应答(Response)模型。客户机(浏览器)向服务器发送请求,服务器处理请求并返回适当的应答。所有 HTTP 连接都被构造成一套请求和应答。</p><h1 id="传输流程"><a href="#传输流程" class="headerlink" title="传输流程"></a>传输流程</h1><p>1 :地址解析</p><p>如用客户端浏览器请求这个页面:<a href="http://localhost.com:8080/index.htm" target="_blank" rel="noopener">http://localhost.com:8080/index.htm</a> 从中分解出协议名、主机名、端口、对象路径等部分,对于我们的这个地址,解析得到的结果如下:</p><p>协议名:http<br>主机名:localhost.com<br>端口:8080<br>对象路径:/index.htm</p><p>在这一步,需要域名系统 DNS 解析域名 localhost.com,得主机的 IP 地址。</p><p>2 :封装 HTTP 请求数据包把以上部分结合本机自己的信息,封装成一个 HTTP 请求数据包</p><p>3 :封装成 TCP 包并建立连接封装成 TCP 包,建立 TCP 连接(TCP 的三次握手)</p><p>4 :客户机发送请求命<br>4)客户机发送请求命令:建立连接后,客户机发送一个请求给服务器,请求方式的格式为:统一资源标识符(URL)、协议版本号,后边是 MIME 信息包括请求修饰符、客户机信息和可内容。</p><p>5 :服务器响应服务器接到请求后,给予相应的响应信息,其格式为一个状态行,包括信息的协议版本号、一个成功或错误的代码,后边是 MIME 信息包括服务器信息、实体信息和可能的内容。</p><p>6 :服务器关闭 TCP 连接服务器关闭 TCP 连接:一般情况下,一旦 Web 服务器向浏览器发送了请求数据,它就要关闭 TCP 连接,然后如果浏览器或者服务器在其头信息加入了这行代码 Connection:keep-alive,TCP 连接在发送后将仍然保持打开状态,于是,浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间,还节约了网络带宽。</p><p><img src="/resource/img/tcp-layer.png" srcset="/img/loading.gif" alt="avatar"></p><table border="1px" class="reference"><caption>HTTP状态码列表</caption><tbody><tr><th>状态码</th><th>状态码英文名称</th><th>中文描述</th></tr><tr><td>100</td><td>Continue</td><td>继续。<a href="http://www.dreamdu.com/webbuild/client_vs_server/" target="_blank" rel="noopener">客户端</a>应继续其请求</td></tr><tr><td>101</td><td>Switching Protocols</td><td>切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议</td></tr><tr><td colspan="3"></td></tr><tr><td>200</td><td>OK</td><td>请求成功。一般用于GET与POST请求</td></tr><tr><td>201</td><td>Created</td><td>已创建。成功请求并创建了新的资源</td></tr><tr><td>202</td><td>Accepted</td><td>已接受。已经接受请求，但未处理完成</td></tr><tr><td>203</td><td>Non-Authoritative Information</td><td>非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本</td></tr><tr><td>204</td><td>No Content</td><td>无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档</td></tr><tr><td>205</td><td>Reset Content</td><td>重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域</td></tr><tr><td>206</td><td>Partial Content</td><td>部分内容。服务器成功处理了部分GET请求</td></tr><tr><td colspan="3"></td></tr><tr><td>300</td><td>Multiple Choices</td><td>多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择</td></tr><tr><td>301</td><td>Moved Permanently</td><td>永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替</td></tr><tr><td>302</td><td>Found</td><td>临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI</td></tr><tr><td>303</td><td>See Other</td><td>查看其它地址。与301类似。使用GET和POST请求查看</td></tr><tr><td>304</td><td>Not Modified</td><td>未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源</td></tr><tr><td>305</td><td>Use Proxy</td><td>使用代理。所请求的资源必须通过代理访问</td></tr><tr><td>306</td><td>Unused</td><td>已经被废弃的HTTP状态码</td></tr><tr><td>307</td><td>Temporary Redirect</td><td>临时重定向。与302类似。使用GET请求重定向</td></tr><tr><td colspan="3"></td></tr><tr><td>400</td><td>Bad Request</td><td>客户端请求的语法错误，服务器无法理解</td></tr><tr><td>401</td><td>Unauthorized</td><td>请求要求用户的身份认证</td></tr><tr><td>402</td><td>Payment Required</td><td>保留，将来使用</td></tr><tr><td>403</td><td>Forbidden</td><td>服务器理解请求客户端的请求，但是拒绝执行此请求</td></tr><tr><td>404</td><td>Not Found</td><td>服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置"您所请求的资源无法找到"的个性页面</td></tr><tr><td>405</td><td>Method Not Allowed</td><td>客户端请求中的方法被禁止</td></tr><tr><td>406</td><td>Not Acceptable</td><td>服务器无法根据客户端请求的内容特性完成请求</td></tr><tr><td>407</td><td>Proxy Authentication Required</td><td>请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权</td></tr><tr><td>408</td><td>Request Time-out</td><td>服务器等待客户端发送的请求时间过长，超时</td></tr><tr><td>409</td><td>Conflict</td><td>服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突</td></tr><tr><td>410</td><td>Gone</td><td>客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置</td></tr><tr><td>411</td><td>Length Required</td><td>服务器无法处理客户端发送的不带Content-Length的请求信息</td></tr><tr><td>412</td><td>Precondition Failed</td><td>客户端请求信息的先决条件错误</td></tr><tr><td>413</td><td>Request Entity Too Large</td><td>由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息</td></tr><tr><td>414</td><td>Request-URI Too Large</td><td>请求的URI过长（URI通常为网址），服务器无法处理</td></tr><tr><td>415</td><td>Unsupported Media Type</td><td>服务器无法处理请求附带的媒体格式</td></tr><tr><td>416</td><td>Requested range not satisfiable</td><td>客户端请求的范围无效</td></tr><tr><td>417</td><td>Expectation Failed</td><td>服务器无法满足Expect的请求头信息</td></tr><tr><td colspan="3"></td></tr><tr><td>500</td><td>Internal Server Error</td><td>服务器内部错误，无法完成请求</td></tr><tr><td>501</td><td>Not Implemented</td><td>服务器不支持请求的功能，无法完成请求</td></tr><tr><td>502</td><td>Bad Gateway</td><td>作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应</td></tr><tr><td>503</td><td>Service Unavailable</td><td>由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中</td></tr><tr><td>504</td><td>Gateway Time-out</td><td>充当网关或代理的服务器，未及时从远端服务器获取请求</td></tr><tr><td>505</td><td>HTTP Version not supported</td><td>服务器不支持请求的HTTP协议的版本，无法完成处理</td></tr></tbody></table><h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><p>HTTPS(全称:Hypertext Transfer Protocol over Secure Socket Layer),是以安全为目标的</p><p>HTTP 通道,简单讲是 HTTP 的安全版。即 HTTP 下加入 SSL 层,HTTPS 的安全基础是 SSL。</p><p>其所用的端口号是 443。 过程大致如下:</p><h2 id="建立连接获取证书"><a href="#建立连接获取证书" class="headerlink" title="建立连接获取证书"></a>建立连接获取证书</h2><p>1) SSL 客户端通过 TCP 和服务器建立连接之后(443 端口),并且在一般的 tcp 连接协商(握手)过程中请求证书。即客户端发出一个消息给服务器,这个消息里面包含了自己可实现的算法列表和其它一些需要的消息,SSL 的服务器端会回应一个数据包,这里面确定了这次通信所需要的算法,然后服务器向客户端返回证书。(证书里面包含了服务器信息:域名。申请证书的公司,公共秘钥)。证书验证<br>2) Client 在收到服务器返回的证书后,判断签发这个证书的公共签发机构,并使用这个机构的公共秘钥确认签名是否有效,客户端还会确保证书中列出的域名就是它正在连接的域名。数据加密和传输<br>3) 如果确认证书有效,那么生成对称秘钥并使用服务器的公共秘钥进行加密。然后发送给服务器,服务器使用它的私钥对它进行解密,这样两台计算机可以开始进行对称加密进行通信。</p><p><img src="/resource/img/https.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="CDN-原理"><a href="#CDN-原理" class="headerlink" title="CDN 原理"></a>CDN 原理</h1><p>CND 一般包含分发服务系统、负载均衡系统和管理系统</p><h2 id="分发服务系统"><a href="#分发服务系统" class="headerlink" title="分发服务系统"></a>分发服务系统</h2><p>其基本的工作单元就是各个 Cache 服务器。负责直接响应用户请求,将内容快速分发到用户;同时还负责内容更新,保证和源站内容的同步。</p><p>根据内容类型和服务种类的不同,分发服务系统分为多个子服务系统,如:网页加速服务、流媒体加速服务、应用加速服务等。每个子服务系统都是一个分布式的服务集群,由功能类似、地域接近的分布部署的 Cache 集群组成。在承担内容同步、更新和响应用户请求之外,分发服务系统还需要向上层的管理调度系统反馈各个Cache 设备的健康状况、响应情况、内容缓存状况等,以便管理调度系统能够根据设定的策略决定由哪个 Cache 设备来响应用户的请求。</p><h1 id="负载均衡系统"><a href="#负载均衡系统" class="headerlink" title="负载均衡系统:"></a>负载均衡系统:</h1><p>负载均衡系统是整个 CDN 系统的中枢。负责对所有的用户请求进行调度,确定提供给用户的最终访问地址。<br>使用分级实现。最基本的两极调度体系包括全局负载均衡(GSLB)和本地负载均衡(SLB)。<br>GSLB 根据用户地址和用户请求的内容,主要根据就近性原则,确定向用户服务的节点。一般通过 DNS解析或者应用层重定向(Http 3XX 重定向)的方式实现。<br>SLB 主要负责节点内部的负载均衡。当用户请求从 GSLB 调度到 SLB 时,SLB 会根据节点内各个Cache 设备的工作状况和内容分布情况等对用户请求重定向。SLB 的实现有四层调度(LVS)、七层调度(Nginx)和链路负载调度等。</p><h1 id="管理系统"><a href="#管理系统" class="headerlink" title="管理系统:"></a>管理系统:</h1><p>分为运营管理和网络管理子系统。<br>网络管理系统实现对 CDN 系统的设备管理、拓扑管理、链路监控和故障管理,为管理员提供对全网资源的可视化的集中管理,通常用 web 方式实现。<br>运营管理是对 CDN 系统的业务管理,负责处理业务层面的与外界系统交互所必须的一些收集、整理、交付工作。包括用户管理、产品管理、计费管理、统计分析等。</p><p><img src="/resource/img/system.png" srcset="/img/loading.gif" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>网络协议</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>React 快速入门</title>
    <link href="/2020/08/12/React-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/"/>
    <url>/2020/08/12/React-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><ul><li>React is a JavaScript library - one of the most popular ones, with over 100,000 stars on GitHub.</li><li>React is not a framework (unlike Angular, which is more opinionated).</li><li>React is an open-source project created by Facebook.</li><li>React is used to build user interfaces (UI) on the front end.</li><li>React is the view layer of an MVC application (Model View Controller)<blockquote><p> One of the most important aspects of React is the fact that you can create components, which are like custom, reusable HTML elements, to quickly and efficiently build user interfaces. React also streamlines how data is stored and handled, using state and props.</p></blockquote></li></ul><h1 id="JSX简介"><a href="#JSX简介" class="headerlink" title="JSX简介"></a>JSX简介</h1><p><code>const element = &lt;h1&gt;Hello, world!&lt;/h1&gt;;</code></p><p>这个有趣的标签语法既不是字符串也不是 HTML。</p><p>它被称为 JSX，是一个 JavaScript 的语法扩展。我们建议在 React 中配合使用 JSX，JSX 可以很好地描述 UI 应该呈现出它应有交互的本质形式。JSX 可能会使人联想到模版语言，但它具有 JavaScript 的全部功能。</p><h2 id="为什么使用-JSX？"><a href="#为什么使用-JSX？" class="headerlink" title="为什么使用 JSX？"></a>为什么使用 JSX？</h2><p>React 认为渲染逻辑本质上与其他 UI 逻辑内在耦合，比如，在 UI 中需要绑定处理事件、在某些时刻状态发生变化时需要通知到 UI，以及需要在 UI 中展示准备好的数据。</p><p>React 并没有采用将标记与逻辑进行分离到不同文件这种人为地分离方式，而是通过将二者共同存放在称之为“组件”的松散耦合单元之中，来实现关注点分离。我们将在后面章节中深入学习组件。如果你还没有适应在 JS 中使用标记语言，这个会议讨论应该可以说服你。</p><p>React 不强制要求使用 JSX，但是大多数人发现，在 JavaScript 代码中将 JSX 和 UI 放在一起时，会在视觉上有辅助作用。它还可以使 React 显示更多有用的错误和警告消息。</p><p>搞清楚这个问题后，我们就开始学习 JSX 吧！</p><h2 id="在-JSX-中嵌入表达式"><a href="#在-JSX-中嵌入表达式" class="headerlink" title="在 JSX 中嵌入表达式"></a>在 JSX 中嵌入表达式</h2><p>在下面的例子中，我们声明了一个名为 name 的变量，然后在 JSX 中使用它，并将它包裹在大括号中：</p><pre><code>const name = &#39;Josh Perez&#39;;const element = &lt;h1&gt;Hello, {name}&lt;/h1&gt;;ReactDOM.render(  element,  document.getElementById(&#39;root&#39;));</code></pre><p>在 JSX 语法中</p><h1 id="元素渲染"><a href="#元素渲染" class="headerlink" title="元素渲染"></a>元素渲染</h1><h1 id="组件-amp-Props"><a href="#组件-amp-Props" class="headerlink" title="组件 &amp; Props"></a>组件 &amp; Props</h1><h1 id="State-amp-生命周期"><a href="#State-amp-生命周期" class="headerlink" title="State &amp; 生命周期"></a>State &amp; 生命周期</h1><h1 id="事件处理"><a href="#事件处理" class="headerlink" title="事件处理"></a>事件处理</h1><h1 id="条件渲染"><a href="#条件渲染" class="headerlink" title="条件渲染"></a>条件渲染</h1><h1 id="列表-amp-Key"><a href="#列表-amp-Key" class="headerlink" title="列表 &amp; Key"></a>列表 &amp; Key</h1><h1 id="表单"><a href="#表单" class="headerlink" title="表单"></a>表单</h1><h1 id="状态提升"><a href="#状态提升" class="headerlink" title="状态提升"></a>状态提升</h1><h1 id="组合-vs-继承"><a href="#组合-vs-继承" class="headerlink" title="组合 vs 继承"></a>组合 vs 继承</h1><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.taniarascia.com/" target="_blank" rel="noopener">官网</a></p><p><a href="https://www.taniarascia.com/getting-started-with-react/" target="_blank" rel="noopener">快速开始</a></p>]]></content>
    
    
    <categories>
      
      <category>React</category>
      
    </categories>
    
    
    <tags>
      
      <tag>React</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Netty 与 RPC</title>
    <link href="/2020/08/10/Netty-%E4%B8%8E-RPC/"/>
    <url>/2020/08/10/Netty-%E4%B8%8E-RPC/</url>
    
    <content type="html"><![CDATA[<h1 id="Netty-原理"><a href="#Netty-原理" class="headerlink" title="Netty 原理"></a>Netty 原理</h1><blockquote><p>Netty 是一个高性能、异步事件驱动的 NIO 框架,基于 JAVA NIO 提供的 API 实现。它提供了对<br>TCP、UDP 和文件传输的支持,作为一个异步 NIO 框架,Netty 的所有 IO 操作都是异步非阻塞<br>的,通过 Future-Listener 机制,用户可以方便的主动获取或者通过通知机制获得 IO 操作结果。<br>8.1.2. Netty 高性能<br>在 IO 编程过程中,当需要同时处理多个客户端接入请求时,可以利用多线程或者 IO 多路复用技术<br>进行处理。IO 多路复用技术通过把多个 IO 的阻塞复用到同一个 select 的阻塞上,从而使得系统在<br>单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型比,I/O 多路复用的<br>最大优势是系统开销小,系统不需要创建新的额外进程或者线程,也不需要维护这些进程和线程<br>的运行,降低了系统的维护工作量,节省了系统资源。<br>与 Socket 类和 ServerSocket 类相对应,NIO 也提供了 SocketChannel 和 ServerSocketChannel<br>两种不同的套接字通道实现。</p></blockquote><h1 id="多路复用通讯方式"><a href="#多路复用通讯方式" class="headerlink" title="多路复用通讯方式"></a>多路复用通讯方式</h1><p>Netty 架构按照 Reactor 模式设计和实现,它的服务端通信序列图如下:</p><p><img src="/resource/img/netty-reactor.png" srcset="/img/loading.gif" alt="avatar"></p><p>客户端通信</p><p><img src="/resource/img/netty-reactor-client.png" srcset="/img/loading.gif" alt="avatar"></p><p>Netty 的 IO 线程 NioEventLoop 由于聚合了多路复用器 Selector,可以同时并发处理成百上千个客户端 Channel,由于读写操作都是非阻塞的,这就可以充分提升 IO 线程的运行效率,避免由于频繁 IO 阻塞导致的线程挂起。</p><h1 id="异步通讯-NIO"><a href="#异步通讯-NIO" class="headerlink" title="异步通讯 NIO"></a>异步通讯 NIO</h1><p>由于 Netty 采用了异步通信模式,一个 IO 线程可以并发处理 N 个客户端连接和读写操作,这从根本上解决了传统同步阻塞 IO 一连接一线程模型,架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。</p><p>零拷贝(DIRECT BUFFERS 使用堆外直接内存)</p><p>1.</p><blockquote><p>Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS,使用堆外直接内存进行 Socket 读写,不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存(HEAP BUFFERS)进行 Socket 读写,JVM 会将堆内存 Buffer 拷贝一份到直接内存中,然后才写入 Socket 中。相比于堆外直接内存,消息在发送过程中多了一次缓冲区的内存拷贝。</p></blockquote><p>2.</p><blockquote><p>Netty 提供了组合 Buffer 对象,可以聚合多个 ByteBuffer 对象,用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作,避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的Buffer。</p></blockquote><p>3.</p><blockquote><p>Netty 的文件传输采用了 transferTo 方法,它可以直接将文件缓冲区的数据发送到目标 Channel,避免了传统通过循环 write 方式导致的内存拷贝问题</p></blockquote><h2 id="内存池-基于内存池的缓冲区重用机制"><a href="#内存池-基于内存池的缓冲区重用机制" class="headerlink" title="内存池(基于内存池的缓冲区重用机制)"></a>内存池(基于内存池的缓冲区重用机制)</h2><p>随着 JVM 虚拟机和 JIT 即时编译技术的发展,对象的分配和回收是个非常轻量级的工作。但是对于缓冲区 Buffer,情况却稍有不同,特别是对于堆外直接内存的分配和回收,是一件耗时的操作。为了尽量重用缓冲区,Netty 提供了基于内存池的缓冲区重用机制。</p><h2 id="高效的-Reactor-线程模型"><a href="#高效的-Reactor-线程模型" class="headerlink" title="高效的 Reactor 线程模型"></a>高效的 Reactor 线程模型</h2><p>常用的 Reactor 线程模型有三种,Reactor 单线程模型, Reactor 多线程模型, 主从 Reactor 多线程模型。</p><h3 id="Reactor-单线程模型"><a href="#Reactor-单线程模型" class="headerlink" title="Reactor 单线程模型"></a>Reactor 单线程模型</h3><blockquote><p>Reactor 单线程模型,指的是所有的 IO 操作都在同一个 NIO 线程上面完成,NIO 线程的职责如下:</p></blockquote><p>1) 作为 NIO 服务端,接收客户端的 TCP 连接;<br>2) 作为 NIO 客户端,向服务端发起 TCP 连接;<br>3) 读取通信对端的请求或者应答消息;<br>4) 向通信对端发送消息请求或者应答消息。</p><p><img src="/resource/img/reactor-more-thread.png" srcset="/img/loading.gif" alt="avatar"></p><p>由于 Reactor 模式使用的是异步非阻塞 IO,所有的 IO 操作都不会导致阻塞,理论上一个线程可以独立处理所有 IO 相关的操作。从架构层面看,一个 NIO 线程确实可以完成其承担的职责。例如,通过Acceptor 接收客户端的 TCP 连接请求消息,链路建立成功之后,通过 Dispatch 将对应的 ByteBuffer派发到指定的 Handler 上进行消息解码。用户 Handler 可以通过 NIO 线程将消息发送给客户端。</p><h3 id="Reactor-多线程模型"><a href="#Reactor-多线程模型" class="headerlink" title="Reactor 多线程模型"></a>Reactor 多线程模型</h3><p>Rector 多线程模型与单线程模型最大的区别就是有一组 NIO 线程处理 IO 操作。 有专门一个NIO 线程-Acceptor 线程用于监听服务端,接收客户端的 TCP 连接请求; 网络 IO 操作-读、写等由一个 NIO 线程池负责,线程池可以采用标准的 JDK 线程池实现,它包含一个任务队列和 N个可用的线程,由这些 NIO 线程负责消息的读取、解码、编码和发送;</p><p><img src="/resource/img/master-slave-reactor-thread.png" srcset="/img/loading.gif" alt="avatar"></p><p>主从 Reactor 多线程模型</p><p><img src="/resource/img/master-slave-reactor-thread-2.png" srcset="/img/loading.gif" alt="avatar"></p><blockquote><p>服务端用于接收客户端连接的不再是个 1 个单独的 NIO 线程,而是一个独立的 NIO 线程池。<br>Acceptor 接收到客户端 TCP 连接请求处理完成后(可能包含接入认证等),将新创建的SocketChannel 注册到 IO 线程池(sub reactor 线程池)的某个 IO 线程上,由它负责SocketChannel 的读写和编解码工作。Acceptor 线程池仅仅只用于客户端的登陆、握手和安全认证,一旦链路建立成功,就将链路注册到后端 subReactor 线程池的 IO 线程上,由 IO 线程负责后续的 IO 操作。</p></blockquote><h3 id="无锁设计、线程绑定"><a href="#无锁设计、线程绑定" class="headerlink" title="无锁设计、线程绑定"></a>无锁设计、线程绑定</h3><p>Netty 采用了串行无锁化设计,在 IO 线程内部进行串行操作,避免多线程竞争导致的性能下降。<br>表面上看,串行化设计似乎 CPU 利用率不高,并发程度不够。但是,通过调整 NIO 线程池的线程参数,可以同时启动多个串行化的线程并行运行,这种局部无锁化的串行线程设计相比一个队列-多个工作线程模型性能更优。<br>Netty 的 NioEventLoop 读取到消息之后,直接调用 ChannelPipeline 的fireChannelRead(Object msg),只要用户不主动切换线程,一直会由 NioEventLoop 调用到用户的 Handler,期间不进行线程切换,这种串行化处理方式避免了多线程操作导致的锁的竞争,从性能角度看是最优的。</p><p><img src="/resource/img/no-block-thread.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="高性能的序列化框架"><a href="#高性能的序列化框架" class="headerlink" title="高性能的序列化框架"></a>高性能的序列化框架</h3><p>Netty 默认提供了对 Google Protobuf 的支持,通过扩展 Netty 的编解码接口,用户可以实现其它的高性能序列化框架,例如 Thrift 的压缩二进制编解码框架。</p><p>1.SO_RCVBUF 和 SO_SNDBUF:通常建议值为 128K 或者 256K。小包封大包,防止网络阻塞</p><p>2.SO_TCPNODELAY:NAGLE 算法通过将缓冲区内的小封包自动相连,组成较大的封包,阻止大量小封包的发送阻塞网络,从而提高网络应用效率。但是对于时延敏感的应用场景需要关闭该优化算法。软中断 Hash 值和 CPU 绑定</p><p>3.软中断:开启 RPS 后可以实现软中断,提升网络吞吐量。RPS 根据数据包的源地址,目的地址以及目的和源端口,计算出一个 hash 值,然后根据这个 hash 值来选择软中断运行的 cpu,从上层来看,也就是说将每个连接和 cpu 绑定,并通过这个 hash 值,来均衡软中断在多个 cpu 上,提升网络并行处理性能。</p><h1 id="Netty-RPC-实现"><a href="#Netty-RPC-实现" class="headerlink" title="Netty RPC 实现"></a>Netty RPC 实现</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>RPC,即 Remote Procedure Call(远程过程调用),调用远程计算机上的服务,就像调用本地服务一样。RPC 可以很好的解耦系统,如 WebService 就是一种基于 Http 协议的 RPC。这个 RPC 整体框架</p><p>如下:</p><p><img src="/resource/img/netty-rpc.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="关键技术"><a href="#关键技术" class="headerlink" title="关键技术"></a>关键技术</h2><p>1  服务发布与订阅:服务端使用 Zookeeper 注册服务地址,客户端从 Zookeeper 获取可用的服务地址。<br>2. 通信:使用 Netty 作为通信框架。<br>3. Spring:使用 Spring 配置服务,加载 Bean,扫描注解。<br>4. 动态代理:客户端使用代理模式透明化服务调用。<br>5. 消息编解码:使用 Protostuff 序列化和反序列化消息。</p><p>1.核心流程服务消费方(client)调用以本地调用方式调用服务;<br>2. client stub 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体;<br>3. client stub 找到服务地址,并将消息发送到服务端;<br>4. server stub 收到消息后进行解码;<br>5. server stub 根据解码结果调用本地的服务;<br>6. 本地服务执行并将结果返回给 server stub;<br>7. server stub 将返回结果打包成消息并发送至消费方;<br>8. client stub 接收到消息,并进行解码;<br>9. 服务消费方得到最终结果。</p><blockquote><p>RPC 的目标就是要 2~8 这些步骤都封装起来,让用户对这些细节透明。JAVA 一般使用动态代理方式实现远程调用。</p></blockquote><p><img src="/resource/img/rpc-proxy.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="消息编解码"><a href="#消息编解码" class="headerlink" title="消息编解码"></a>消息编解码</h2><p>息数据结构(接口名称 + 方法名 + 参数类型和参数值 + 超时时间 + requestID )<br>客户端的请求消息结构一般需要包括以下内容:</p><p>1.接口名称:在我们的例子里接口名是“HelloWorldService”,如果不传,服务端就不知道调用哪个接口了;<br>2. 方法名:一个接口内可能有很多方法,如果不传方法名服务端也就不知道调用哪个方法;<br>3. 参数类型和参数值:参数类型有很多,比如有 bool、int、long、double、string、map、list,甚至如 struct(class);以及相应的参数值;<br>4. 超时时间:<br>5. requestID,标识唯一请求 id,在下面一节会详细描述 requestID 的用处。<br>6. 服务端返回的消息 : 一般包括以下内容。返回值+状态 code+requestID</p><h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><p>目前互联网公司广泛使用 Protobuf、Thrift、Avro 等成熟的序列化解决方案来搭建 RPC 框架,这些都是久经考验的解决方案。</p><h2 id="通讯过程"><a href="#通讯过程" class="headerlink" title="通讯过程"></a>通讯过程</h2><p>核心问题 ( 线程暂停、消息乱序 )<br>如果使用 netty 的话,一般会用 channel.writeAndFlush()方法来发送消息二进制串,这个方法调用后对于整个远程调用(从发出请求到接收到结果)来说是一个异步的,即对于当前线程来说,将请求发送出来后,线程就可以往后执行了,至于服务端的结果,是服务端处理完成后,再以消息的形式发送给客户端的。于是这里出现以下两个问题:</p><ol><li>怎么让当前线程“暂停”,等结果回来后,再向后执行?</li><li>如果有多个线程同时进行远程方法调用,这时建立在 client server 之间的 socket 连接上会有很多双方发送的消息传递,前后顺序也可能是随机的,server 处理完结果后,将结果消息发送给 client,client 收到很多消息,怎么知道哪个消息结果是原先哪个线程调用的?如下图所示,线程 A 和线程 B 同时向 client socket 发送请求 requestA 和 requestB,socket 先后将 requestB 和 requestA 发送至 server,而 server 可能将 responseB 先返回, 尽管 requestB 请 求 到达 时 间 更晚 。 我 们需 要 一种 机 制 保证 responseA 丢给ThreadA,responseB 丢给 ThreadB。</li></ol><p><img src="/resource/img/rpc-proxy.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="通讯流程"><a href="#通讯流程" class="headerlink" title="通讯流程"></a>通讯流程</h2><p>requestID 生成 -AtomicLong</p><p>1.client 线程每次通过 socket 调用一次远程接口前,生成一个唯一的 ID,即 requestID(requestID 必需保证在一个 Socket 连接里面是唯一的),一般常常使用 AtomicLong从 0 开始累计数字生成唯一 ID;存放回调对象 callback 到全局 ConcurrentHashMap</p><p>2.将 处 理 结 果 的 回 调 对 象 callback , 存 放 到 全 局 ConcurrentHashMap 里 面put(requestID, callback);synchronized 获取回调对象 callback 的锁并自旋 wait</p><p>3.当线程调用 channel.writeAndFlush()发送消息后,紧接着执行 callback 的 get()方法试图获取远程返回的结果。在 get()内部,则使用 synchronized 获取回调对象 callback 的锁,再先检测是否已经获取到结果,如果没有,然后调用 callback 的 wait()方法,释放callback 上的锁,让当前线程处于等待状态。监听消息的线程收到消息,找到 callback 上的锁并唤醒</p><p>4.服务端接收到请求并处理后,将 response 结果(此结果中包含了前面的 requestID)发送给客户端,客户端 socket 连接上专门监听消息的线程收到消息,分析结果,取到requestID , 再 从 前 面 的 ConcurrentHashMap 里 面 get(requestID) , 从 而 找 到callback 对象,再用 synchronized 获取 callback 上的锁,将方法调用结果设置到callback 对象里,再调用 callback.notifyAll()唤醒前面处于等待状态的线程。</p><pre><code class="java">    public Object get() {        synchronized (this) { // 旋锁            while (true) { // 是否有结果了                If (!isDone){                    wait(); //没结果释放锁,让当前线程处于等待状态                }else{//获取数据并处理                }            }        }    }    private void setDone(Response res) {        this.res = res;        isDone = true;        synchronized (this) { //获取锁,因为前面 wait()已经释放了 callback 的锁了            notifyAll(); // 唤醒处于等待的线程        }    }</code></pre><h2 id="RMI-实现方式"><a href="#RMI-实现方式" class="headerlink" title="RMI 实现方式"></a>RMI 实现方式</h2><p>Java 远程方法调用,即 Java RMI(Java Remote Method Invocation)是 Java 编程语言里,一种用于实现远程过程调用的应用程序编程接口。它使客户机上运行的程序可以调用远程服务器上的对象。远程方法调用特性使 Java 编程人员能够在网络环境中分布操作。RMI 全部的宗旨就是尽可能简化远程接口对象的使用。</p><h3 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h3><ol><li>编写远程服务接口,该接口必须继承 java.rmi.Remote 接口,方法必须抛出java.rmi.RemoteException 异常;</li><li>编写远程接口实现类,该实现类必须继承 java.rmi.server.UnicastRemoteObject 类;</li><li>运行 RMI 编译器(rmic),创建客户端 stub 类和服务端 skeleton 类;</li><li>启动一个 RMI 注册表,以便驻留这些服务;</li><li>在 RMI 注册表中注册服务;</li><li>客户端查找远程对象,并调用远程方法;</li></ol><pre><code class="java">//1:创建远程接口,继承 java.rmi.Remote 接口    public interface GreetService extends java.rmi.Remote {        String sayHello(String name) throws RemoteException;    }//2:实现远程接口,继承 java.rmi.server.UnicastRemoteObject 类    public class GreetServiceImpl extends java.rmi.server.UnicastRemoteObject            implements GreetService {        private static final long serialVersionUID = 3434060152387200042L;        public GreetServiceImpl() throws RemoteException {            super();        }        @Override        public String sayHello(String name) throws RemoteException {            return &quot;Hello &quot; + name;        }    }//3:生成 Stub 和 Skeleton;//4:执行 rmiregistry 命令注册服务//5:启动服务LocateRegistry.createRegistry(1098);Naming.bind(&quot;rmi://10.108.1.138:1098/GreetService&quot;, new GreetServiceImpl());//6.客户端调用GreetService greetService=(GreetService)Naming.lookup(&quot;rmi://10.108.1.138:1098/GreetService&quot;);System.out.println(greetService.sayHello(&quot;Jobs&quot;));</code></pre><h1 id="Protocol-Buffer"><a href="#Protocol-Buffer" class="headerlink" title="Protocol Buffer"></a>Protocol Buffer</h1><blockquote><p>protocol buffer 是 google 的一个开源项目,它是用于结构化数据串行化的灵活、高效、自动的方法,例如 XML,不过它比 xml 更小、更快、也更简单。你可以定义自己的数据结构,然后使用代码生成器生成的代码来读写这个数据结构。你甚至可以在无需重新部署程序的情况下更新数据结构。</p></blockquote><p><img src="/resource/img/protocol-buffer.png" srcset="/img/loading.gif" alt="avatar"></p><p>Protocol Buffer 的序列化 &amp; 反序列化简单 &amp; 速度快的原因是:</p><ol><li>编码 / 解码 方式简单(只需要简单的数学运算 = 位移等等)</li><li>采用 Protocol Buffer 自身的框架代码 和 编译器 共同完成</li></ol><p>Protocol Buffer 的数据压缩效果好(即序列化后的数据量体积小)的原因是:</p><ol><li>a. 采用了独特的编码方式,如 Varint、Zigzag 编码方式等等</li><li>b. 采用 T - L - V 的数据存储方式:减少了分隔符的使用 &amp; 数据存储得紧凑</li></ol><h1 id="Thrift"><a href="#Thrift" class="headerlink" title="Thrift"></a>Thrift</h1><p>Apache Thrift 是 Facebook 实现的一种高效的、支持多种编程语言的远程服务调用的框架。本文将从Java 开发人员角度详细介绍 Apache Thrift 的架构、开发和部署,并且针对不同的传输协议和服务类型给出相应的 Java 实例,同时详细介绍 Thrift 异步客户端的实现,最后提出使用 Thrift 需要注意的事项。<br>目前流行的服务调用方式有很多种,例如基于 SOAP 消息格式的 Web Service,基于 JSON 消息格式的 RESTful 服务等。其中所用到的数据传输方式包括 XML,JSON 等,然而 XML 相对体积太大,传输效率低,JSON 体积较小,新颖,但还不够完善。本文将介绍由 Facebook 开发的远程服务调用框架<br>Apache Thrift,它采用接口描述语言定义并创建服务,支持可扩展的跨语言服务开发,所包含的代码生成引擎可以在多种语言中,如 <code>C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa,Smalltalk</code> 等创建高效的、无缝的服务,其传输数据采用二进制格式,相对 XML 和 JSON 体积更小,<br>对于高并发、大数据量和多语言的环境更有优势。本文将详细介绍 Thrift 的使用,并且提供丰富的实例代码加以解释说明,帮助使用者快速构建服务。</p><h2 id="为什么要-Thrift"><a href="#为什么要-Thrift" class="headerlink" title="为什么要 Thrift:"></a>为什么要 Thrift:</h2><p>1、多语言开发的需要 2、性能问题</p><p><img src="/resource/img/thrift.png" srcset="/img/loading.gif" alt="avatar"></p>]]></content>
    
    
    <categories>
      
      <category>框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>netty</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>微服务</title>
    <link href="/2020/07/30/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"/>
    <url>/2020/07/30/%E5%BE%AE%E6%9C%8D%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="服务注册发现"><a href="#服务注册发现" class="headerlink" title="服务注册发现"></a>服务注册发现</h1><p>服务注册就是维护一个登记簿,它管理系统内所有的服务地址。当新的服务启动后,它会向登记<br>簿交待自己的地址信息。服务的依赖方直接向登记簿要 Service Provider 地址就行了。当下用于服<br>务注册的工具非常多 ZooKeeper,Consul,Etcd, 还有 Netflix 家的 eureka 等。服务注册有两种<br>形式:客户端注册和第三方注册。</p><h1 id="客户端注册-zookeeper"><a href="#客户端注册-zookeeper" class="headerlink" title="客户端注册(zookeeper)"></a>客户端注册(zookeeper)</h1><p>客户端注册是服务自身要负责注册与注销的工作。当服务启动后向注册中心注册自身,当服务下<br>线时注销自己。期间还需要和注册中心保持心跳。心跳不一定要客户端来做,也可以由注册中心<br>负责(这个过程叫探活)。这种方式的缺点是注册工作与服务耦合在一起,不同语言都要实现一<br>套注册逻辑。</p><p><img src="/resource/img/service-discovery.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="第三方注册-独立的服务-Registrar"><a href="#第三方注册-独立的服务-Registrar" class="headerlink" title="第三方注册( 独立的服务 Registrar )"></a>第三方注册( 独立的服务 Registrar )</h3><p>第三方注册由一个独立的服务 Registrar 负责注册与注销。当服务启动后以某种方式通知 Registrar,<br>然后 Registrar 负责向注册中心发起注册工作。同时注册中心要维护与服务之间的心跳,当服务不<br>可用时,向注册中心注销服务。这种方式的缺点是 Registrar 必须是一个高可用的系统,否则注册<br>工作没法进展。</p><p><img src="/resource/img/simple-register.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="客户端发现"><a href="#客户端发现" class="headerlink" title="客户端发现"></a>客户端发现</h3><p>客户端发现是指客户端负责查询可用服务地址,以及负载均衡的工作。这种方式最方便直接,而<br>且也方便做负载均衡。再者一旦发现某个服务不可用立即换另外一个,非常直接。缺点也在于多<br>语言时的重复工作,每个语言实现相同的逻辑。</p><p><img src="/resource/img/client-discovery.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="服务端发现"><a href="#服务端发现" class="headerlink" title="服务端发现"></a>服务端发现</h3><p>服务端发现需要额外的 Router 服务,请求先打到 Router,然后 Router 负责查询服务与负载均衡。<br>这种方式虽然没有客户端发现的缺点,但是它的缺点是保证 Router 的高可用。</p><p><img src="/resource/img/server-discovery.png" srcset="/img/loading.gif" alt="avatar"></p><p>7.1.1.5. Consul<br>7.1.1.6. Eureka<br>7.1.1.7. SmartStack<br>7.1.1.8. Etcd</p><h2 id="Api-网关"><a href="#Api-网关" class="headerlink" title="Api 网关"></a>Api 网关</h2><p>API Gateway 是一个服务器,也可以说是进入系统的唯一节点。这跟面向对象设计模式中的<br>Facade 模式很像。API Gateway 封装内部系统的架构,并且提供 API 给各个客户端。它还可能有<br>其他功能,如授权、监控、负载均衡、缓存、请求分片和管理、静态响应处理等。下图展示了一<br>个适应当前架构的 API Gateway。</p><p><img src="/resource/img/gateway.png" srcset="/img/loading.gif" alt="avatar"></p><p><code>API Gateway 负责请求转发、合成和协议转换。</code>所有来自客户端的请求都要先经过 API Gateway,然后路由这些请求到对应的微服务。API Gateway 将经常通过调用多个微服务来处理一个请求以及聚合多个服务的结果。它可以在 web 协议与内部使用的非 Web 友好型协议间进行转换,如HTTP 协议、WebSocket 协议。</p><p>请求转发</p><blockquote><p>服务转发主要是对客户端的请求安装微服务的负载转发到不同的服务上</p></blockquote><p>响应合并</p><blockquote><p>把业务上需要调用多个服务接口才能完成的工作合并成一次调用对外统一提供服务。</p></blockquote><p>协议转换</p><blockquote><p>重点是支持 SOAP,JMS,Rest 间的协议转换。</p></blockquote><p>数据转换</p><blockquote><p>重点是支持 XML 和 Json 之间的报文格式转换能力(可选)</p></blockquote><p>安全认证</p><blockquote><ol><li>基于 Token 的客户端访问控制和安全策略</li><li>传输数据和报文加密,到服务端解密,需要在客户端有独立的 SDK 代理包</li><li>基于 Https 的传输加密,客户端和服务端数字证书支持</li><li>基于 OAuth2.0 的服务安全认证(授权码,客户端,密码模式等)</li></ol></blockquote><h1 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a>配置中心</h1><p>配置中心一般用作系统的参数配置,它需要满足如下几个要求:高效获取、实时感知、分布式访问。</p><h2 id="zookeeper-配置中心"><a href="#zookeeper-配置中心" class="headerlink" title="zookeeper 配置中心"></a>zookeeper 配置中心</h2><p>实现的架构图如下所示,采取数据加载到内存方式解决高效获取的问题,借助 zookeeper 的节点监听机制来实现实时感知。</p><p><img src="/resource/img/zookeeper.png" srcset="/img/loading.gif" alt="avatar"></p><p>配置中心数据分类<br><img src="/resource/img/config-center-data-type.png" srcset="/img/loading.gif" alt="avatar"></p><p>事件调度(kafka)</p><blockquote><p>消息服务和事件的统一调度,常用用 kafka ,activemq 等。</p></blockquote><p>服务跟踪( starter-sleuth )</p><blockquote><p>随着微服务数量不断增长,需要跟踪一个请求从一个微服务到下一个微服务的传播过程, SpringCloud Sleuth 正是解决这个问题,它在日志中引入唯一 ID,以保证微服务调用之间的一致性,这样你就能跟踪某个请求是如何从一个微服务传递到下一个。</p></blockquote><p>1.<br>为了实现请求跟踪,当请求发送到分布式系统的入口端点时,只需要服务跟踪框架为该请求<br>创建一个唯一的跟踪标识,同时在分布式系统内部流转的时候,框架始终保持传递该唯一标<br>识,直到返回给请求方为止,这个唯一标识就是前文中提到的 Trace ID。通过 Trace ID 的记<br>录,我们就能将所有请求过程日志关联起来。<br>2.<br>为了统计各处理单元的时间延迟,当请求达到各个服务组件时,或是处理逻辑到达某个状态<br>时,也通过一个唯一标识来标记它的开始、具体过程以及结束,该标识就是我们前文中提到<br>的 Span ID,对于每个 Span 来说,它必须有开始和结束两个节点,通过记录开始 Span 和结<br>束 Span 的时间戳,就能统计出该 Span 的时间延迟,除了时间戳记录之外,它还可以包含一<br>些其他元数据,比如:事件名称、请求信息等。<br>3.<br>在快速入门示例中,我们轻松实现了日志级别的跟踪信息接入,这完全归功于 spring-cloud-<br>starter-sleuth 组件的实现。在 Spring Boot 应用中,通过在工程中引入 spring-cloud-<br>starter-sleuth 依赖之后, 它会自动的为当前应用构建起各通信通道的跟踪机制,比如:<br>通过诸如 RabbitMQ、Kafka(或者其他任何 Spring Cloud Stream 绑定器实现的消息<br>中间件)传递的请求。<br>通过 Zuul 代理传递的请求。<br>通过 RestTemplate 发起的请求。</p><h1 id="服务熔断-Hystrix"><a href="#服务熔断-Hystrix" class="headerlink" title="服务熔断(Hystrix)"></a>服务熔断(Hystrix)</h1><p>在微服务架构中通常会有多个服务层调用,基础服务的故障可能会导致级联故障,进而造成整个<br>系统不可用的情况,这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不<br>可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。</p><p>熔断器的原理很简单,如同电力过载保护器。它可以实现快速失败,如果它在一段时间内侦测到<br>许多类似的错误,会强迫其以后的多个调用快速失败,不再访问远程服务器,从而防止应用程序<br>不断地尝试执行可能会失败的操作,使得应用程序继续执行而不用等待修正错误,或者浪费 CPU<br>时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正,如果已经<br>修正,应用程序会再次尝试调用操作。</p><p><img src="/resource/img/config.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="Hystrix-断路器机制"><a href="#Hystrix-断路器机制" class="headerlink" title="Hystrix 断路器机制"></a>Hystrix 断路器机制</h2><p>断路器很好理解, 当 Hystrix Command 请求后端服务失败数量超过一定比例(默认 50%), 断路器会<br>切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态<br>一段时间后(默认 5 秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况,<br>如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix 的断路器<br>就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效<br>请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力。</p><h2 id="API-管理"><a href="#API-管理" class="headerlink" title="API 管理"></a>API 管理</h2><p>SwaggerAPI 管理工具。</p>]]></content>
    
    
    <categories>
      
      <category>微服务</category>
      
    </categories>
    
    
    <tags>
      
      <tag>微服务</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Spring 原理</title>
    <link href="/2020/07/27/Spring-%E5%8E%9F%E7%90%86/"/>
    <url>/2020/07/27/Spring-%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="Spring-原理"><a href="#Spring-原理" class="headerlink" title="Spring 原理"></a>Spring 原理</h1><blockquote><p>它是一个全面的、企业应用开发一站式的解决方案,贯穿表现层、业务层、持久层。但是 Spring仍然可以和其他的框架无缝整合。</p></blockquote><h1 id="Spring-特点"><a href="#Spring-特点" class="headerlink" title="Spring 特点"></a>Spring 特点</h1><ul><li>轻量级<blockquote><p>从大小与开销两方面而言Spring都是轻量的，完整的Spring框架可以在一个大小只有1M多的JAR文件里发布，并且Spring所需的处理开销也是微不足道的。<br>此外Spring是非入侵式的：典型的Spring应用的对象不依赖Spring的特定类</p></blockquote></li><li>控制反转<blockquote><p>Spring通过一种称为控制反转IOC的技术促进了低耦合。当应用了IOC一个对象依赖的其他对象会通过被动的方式传递进来，而不是这个对象自己创建或者查找依赖对象。</p></blockquote></li><li>面向切面<blockquote><p>Spring支持面向切面的编程，并且把应用业务逻辑和系统服务分开</p></blockquote></li><li>容器<blockquote><p>Spring包含并管理应用对象的配置和生命周期，在这个意义上是一种容器，你可以配置你的每个bean如何被创建—–基于一个可配置的原型，你的bean可以创建一个单独的实例或者每次需要时都生成一个新的实例—以及他们是如何关联的。</p></blockquote></li><li>框架集合<blockquote><p>Spring可以将简单的组件配置，组合成为复杂的应用，在Spring中应用对象被声明式的组合，典型的是在一个XML文件里，Spring也提供了很多基础功能(事物管理，持久化框架集成等)，将应用逻辑的开发留给开发者。</p></blockquote></li></ul><h1 id="Spring-核心组件"><a href="#Spring-核心组件" class="headerlink" title="Spring 核心组件"></a>Spring 核心组件</h1><p><img src="/resource/img/spring-core.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-常用模块"><a href="#Spring-常用模块" class="headerlink" title="Spring 常用模块"></a>Spring 常用模块</h1><p><img src="/resource/img/spring-model.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-主要包"><a href="#Spring-主要包" class="headerlink" title="Spring 主要包"></a>Spring 主要包</h1><p><img src="/resource/img/spring-package.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-常用注解"><a href="#Spring-常用注解" class="headerlink" title="Spring 常用注解"></a>Spring 常用注解</h1><blockquote><p>bean 注入与装配的的方式有很多种,可以通过 xml,get set 方式,构造函数或者注解等。简单易用的方式就是使用 Spring 的注解了,Spring 提供了大量的注解方式。</p></blockquote><p><img src="/resource/img/spring-annotation.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-第三方结合"><a href="#Spring-第三方结合" class="headerlink" title="Spring 第三方结合"></a>Spring 第三方结合</h1><p><img src="/resource/img/spring-another.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-IOC-原理"><a href="#Spring-IOC-原理" class="headerlink" title="Spring IOC 原理"></a>Spring IOC 原理</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><blockquote><p>Spring 通过一个配置文件描述 Bean 及 Bean 之间的依赖关系,利用 Java 语言的反射功能实例化<br> Bean 并建立 Bean 之间的依赖关系。 Spring 的 IoC 容器在完成这些底层工作的基础上,还提供<br> 了 Bean 实例缓存、生命周期管理、 Bean 实例代理、事件发布、资源装载等高级服务。</p></blockquote><h2 id="Spring-容器高层视图"><a href="#Spring-容器高层视图" class="headerlink" title="Spring 容器高层视图"></a>Spring 容器高层视图</h2><blockquote><p>Spring 启动时读取应用程序提供的 Bean 配置信息,并在 Spring 容器中生成一份相应的 Bean 配<br>置注册表,然后根据这张注册表实例化 Bean,装配好 Bean 之间的依赖关系,为上层应用提供准<br>备就绪的运行环境。其中 Bean 缓存池为 HashMap 实现</p></blockquote><p><img src="/resource/img/spring-ioc.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="IOC-容器实现"><a href="#IOC-容器实现" class="headerlink" title="IOC 容器实现"></a>IOC 容器实现</h1><h2 id="BeanFactory-框架基础设施"><a href="#BeanFactory-框架基础设施" class="headerlink" title="BeanFactory- 框架基础设施"></a>BeanFactory- 框架基础设施</h2><blockquote><p>BeanFactory 是 Spring 框架的基础设施,面向 Spring 本身;ApplicationContext 面向使用<br>Spring 框架的开发者,几乎所有的应用场合我们都直接使用 ApplicationContext 而非底层<br>的 BeanFactory。</p></blockquote><p><img src="/resource/img/spring-ioc-beanfactory.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="1-BeanDefinitionRegistry-注册表"><a href="#1-BeanDefinitionRegistry-注册表" class="headerlink" title="1.BeanDefinitionRegistry 注册表"></a>1.BeanDefinitionRegistry 注册表</h3><p>Spring 配置文件中每一个节点元素在 Spring 容器里都通过一个 BeanDefinition 对象表示,<br>它 描 述 了 Bean 的 配 置 信 息 。 而 BeanDefinitionRegistry 接 口 提 供 了 向 容 器 手 工 注 册<br>BeanDefinition 对象的方法。</p><h3 id="2-BeanFactory-顶层接口"><a href="#2-BeanFactory-顶层接口" class="headerlink" title="2.BeanFactory 顶层接口"></a>2.BeanFactory 顶层接口</h3><p>位于类结构树的顶端 ,它最主要的方法就是 getBean(String beanName),该方法从容器中<br>返回特定名称的 Bean,BeanFactory 的功能通过其他的接口得到不断扩展:</p><h3 id="3-ListableBeanFactory"><a href="#3-ListableBeanFactory" class="headerlink" title="3.ListableBeanFactory"></a>3.ListableBeanFactory</h3><p>该接口定义了访问容器中 Bean 基本信息的若干方法,如查看 Bean 的个数、获取某一类型<br>Bean 的配置名、查看容器中是否包括某一 Bean 等方法;</p><h3 id="4-HierarchicalBeanFactory-父子级联"><a href="#4-HierarchicalBeanFactory-父子级联" class="headerlink" title="4.HierarchicalBeanFactory 父子级联"></a>4.HierarchicalBeanFactory 父子级联</h3><p>父子级联 IoC 容器的接口,子容器可以通过接口方法访问父容器; 通过<br>HierarchicalBeanFactory 接口, Spring 的 IoC 容器可以建立父子层级关联的容器体系,子<br>容器可以访问父容器中的 Bean,但父容器不能访问子容器的 Bean。Spring 使用父子容器实<br>现了很多功能,比如在 Spring MVC 中,展现层 Bean 位于一个子容器中,而业务层和持久<br>层的 Bean 位于父容器中。这样,展现层 Bean 就可以引用业务层和持久层的 Bean,而业务<br>层和持久层的 Bean 则看不到展现层的 Bean。</p><h3 id="5-ConfigurableBeanFactory"><a href="#5-ConfigurableBeanFactory" class="headerlink" title="5.ConfigurableBeanFactory"></a>5.ConfigurableBeanFactory</h3><p>是一个重要的接口,增强了 IoC 容器的可定制性,它定义了设置类装载器、属性编辑器、容<br>器初始化后置处理器等方法;</p><h3 id="AutowireCapableBeanFactory-自动装配"><a href="#AutowireCapableBeanFactory-自动装配" class="headerlink" title="AutowireCapableBeanFactory 自动装配"></a>AutowireCapableBeanFactory 自动装配</h3><p>6.定义了将容器中的 Bean 按某种规则(如按名字匹配、按类型匹配等)进行自动装配的方法;SingletonBeanRegistry 运行期间注册单例 Bean</p><p>7.定义了允许在运行期间向容器注册单实例 Bean 的方法;对于单实例( singleton)的 Bean<br>来说,BeanFactory 会缓存 Bean 实例,所以第二次使用 getBean() 获取 Bean 时将直接从<br>IoC 容器的缓存中获取 Bean 实例。Spring 在 DefaultSingletonBeanRegistry 类中提供了一<br>个用于缓存单实例 Bean 的缓存器,它是一个用 HashMap 实现的缓存器,单实例的 Bean 以<br>beanName 为键保存在这个 HashMap 中。<br>依赖日志框框</p><p>8.在初始化 BeanFactory 时,必须为其提供一种日志框架,比如使用 Log4J, 即在类路径下提供 Log4J 配置文件,这样启动 Spring 容器才不会报错。</p><h2 id="ApplicationContext-面向开发应用"><a href="#ApplicationContext-面向开发应用" class="headerlink" title="ApplicationContext 面向开发应用"></a>ApplicationContext 面向开发应用</h2><p>ApplicationContext 由 BeanFactory 派 生 而 来 , 提 供 了 更 多 面 向 实 际 应 用 的 功 能 。<br>ApplicationContext 继承了 HierarchicalBeanFactory 和 ListableBeanFactory 接口,在此基础上,还通过多个其他的接口扩展了 BeanFactory 的功能:</p><p><img src="/resource/img/beanfactory.png" srcset="/img/loading.gif" alt="avatar"></p><ol><li>ClassPathXmlApplicationContext:默认从类路径加载配置文件</li><li>FileSystemXmlApplicationContext:默认从文件系统中装载配置文件</li><li>ApplicationEventPublisher:让容器拥有发布应用上下文事件的功能,包括容器启动事件、关闭事件等。</li><li>MessageSource:为应用提供 i18n 国际化消息访问的功能;</li><li>ResourcePatternResolver : 所 有 ApplicationContext 实 现 类 都 实 现 了 类 似 于PathMatchingResourcePatternResolver 的功能,可以通过带前缀的 Ant 风格的资源文件路径装载 Spring 的配置文件。</li><li>LifeCycle:该接口是 Spring 2.0 加入的,该接口提供了 start()和 stop()两个方法,主要用于控制异步处理过程。在具体使用时,该接口同时被 ApplicationContext 实现及具体Bean 实现, ApplicationContext 会将 start/stop 的信息传递给容器中所有实现了该接口的 Bean,以达到管理和控制 JMX、任务调度等目的。</li><li>ConfigurableApplicationContext 扩展于 ApplicationContext,它新增加了两个主要的方法: refresh()和 close(),让 ApplicationContext 具有启动、刷新和关闭应用上下文的能力。在应用上下文关闭的情况下调用 refresh()即可启动应用上下文,在已经启动的状态下,调用 refresh()则清除缓存并重新装载配置信息,而调用 close()则可关闭应用上下文。</li></ol><h1 id="WebApplication-体系架构"><a href="#WebApplication-体系架构" class="headerlink" title="WebApplication 体系架构"></a>WebApplication 体系架构</h1><blockquote><p>WebApplicationContext 是专门为 Web 应用准备的,它允许从相对于 Web 根目录的<br>路 径 中 装 载 配 置 文 件 完 成 初 始 化 工 作 。 从 WebApplicationContext 中 可 以 获 得<br>ServletContext 的引用,整个 Web 应用上下文对象将作为属性放置到 ServletContext<br>中,以便 Web 应用环境可以访问 Spring 应用上下文。</p></blockquote><p><img src="/resource/img/spring-web.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-Bean-作用域"><a href="#Spring-Bean-作用域" class="headerlink" title="Spring Bean 作用域"></a>Spring Bean 作用域</h1><p>Spring 3 中为 Bean 定义了 5 中作用域,分别为 <code>singleton(单例)</code>、<code>prototype(原型)</code>、<code>request</code>、<code>session</code> 和 <code>global session</code>,5 种作用域说明如下:</p><h3 id="singleton-单例模式-多线程下不安全"><a href="#singleton-单例模式-多线程下不安全" class="headerlink" title="singleton :单例模式(多线程下不安全)"></a>singleton :单例模式(多线程下不安全)</h3><p>1.singleton:单例模式,Spring IoC 容器中只会存在一个共享的 Bean 实例,无论有多少个Bean 引用它,始终指向同一对象。该模式在多线程下是不安全的。Singleton 作用域是Spring 中的缺省作用域,也可以显示的将 Bean 定义为 singleton 模式,配置为:<br><code>&lt;bean id=&quot;userDao&quot; class=&quot;com.ioc.UserDaoImpl&quot; scope=&quot;singleton&quot;/&gt;</code></p><h3 id="prototype-原型模式每次使用时创建"><a href="#prototype-原型模式每次使用时创建" class="headerlink" title="prototype: 原型模式每次使用时创建"></a>prototype: 原型模式每次使用时创建</h3><p>2.prototype:原型模式,每次通过 Spring 容器获取 prototype 定义的 bean 时,容器都将创建一个新的 Bean 实例,每个 Bean 实例都有自己的属性和状态,而 singleton 全局只有一个对象。根据经验,对有状态的 bean 使用 prototype 作用域,而对无状态的 bean 使用 singleton作用域。</p><h3 id="Request-一次-request-一个实例"><a href="#Request-一次-request-一个实例" class="headerlink" title="Request :一次 request 一个实例"></a>Request :一次 request 一个实例</h3><p>3.request:在一次 Http 请求中,容器会返回该 Bean 的同一实例。而对不同的 Http 请求则会产生新的 Bean,而且该 bean 仅在当前 Http Request 内有效,当前 Http 请求结束,该 bean实例也将会被销毁。<br><code>&lt;bean id=&quot;loginAction&quot; class=&quot;com.cnblogs.Login&quot; scope=&quot;request&quot;/&gt;</code></p><h3 id="session"><a href="#session" class="headerlink" title="session"></a>session</h3><p>4.session:在一次 Http Session 中,容器会返回该 Bean 的同一实例。而对不同的 Session 请求则会创建新的实例,该 bean 实例仅在当前 Session 内有效。同 Http 请求相同,每一次session 请求创建新的实例,而不同的实例之间不共享属性,且实例仅在自己的 session 请求内有效,请求结束,则实例将被销毁。<br><code>&lt;bean id=&quot;userPreference&quot; class=&quot;com.ioc.UserPreference&quot; scope=&quot;session&quot;/&gt;</code></p><h3 id="global-Session"><a href="#global-Session" class="headerlink" title="global Session"></a>global Session</h3><p>5.global Session:在一个全局的 Http Session 中,容器会返回该 Bean 的同一个实例,仅在使用 portlet context 时有效。</p><h1 id="Spring-Bean-生命周期"><a href="#Spring-Bean-生命周期" class="headerlink" title="Spring Bean 生命周期"></a>Spring Bean 生命周期</h1><h3 id="实例化"><a href="#实例化" class="headerlink" title="实例化"></a>实例化</h3><p>1.实例化一个 Bean,也就是我们常说的 new。</p><h3 id="IOC-依赖注入"><a href="#IOC-依赖注入" class="headerlink" title="IOC 依赖注入"></a>IOC 依赖注入</h3><p>2.按照 Spring 上下文对实例化的 Bean 进行配置,也就是 IOC 注入。</p><h3 id="setBeanName-实现"><a href="#setBeanName-实现" class="headerlink" title="setBeanName 实现"></a>setBeanName 实现</h3><p>3.如果这个 Bean 已经实现了 BeanNameAware 接口,会调用它实现的 setBeanName(String)方法,此处传递的就是 Spring 配置文件中 Bean 的 id 值</p><h3 id="BeanFactoryAware-实现"><a href="#BeanFactoryAware-实现" class="headerlink" title="BeanFactoryAware 实现"></a>BeanFactoryAware 实现</h3><p>4.如果这个 Bean 已经实现了 BeanFactoryAware 接口,会调用它实现的 setBeanFactory,setBeanFactory(BeanFactory)传递的是 Spring 工厂自身(可以用这个方式来获取其它 Bean,只需在 Spring 配置文件中配置一个普通的 Bean 就可以)。</p><h3 id="ApplicationContextAware-实现"><a href="#ApplicationContextAware-实现" class="headerlink" title="ApplicationContextAware 实现"></a>ApplicationContextAware 实现</h3><p>5.如果这个 Bean 已经实现了 ApplicationContextAware 接口,会调用setApplicationContext(ApplicationContext)方法,传入 Spring 上下文(同样这个方式也可以实现步骤 4 的内容,但比 4 更好,因为 ApplicationContext 是 BeanFactory 的子接口,有更多的实现方法)</p><h3 id="postProcessBeforeInitialization-接口实现-初始化预处理"><a href="#postProcessBeforeInitialization-接口实现-初始化预处理" class="headerlink" title="postProcessBeforeInitialization 接口实现 - 初始化预处理"></a>postProcessBeforeInitialization 接口实现 - 初始化预处理</h3><p>6.如果这个 Bean 关联了 BeanPostProcessor 接口,将会调用postProcessBeforeInitialization(Object obj, String s)方法,BeanPostProcessor 经常被用作是 Bean 内容的更改,并且由于这个是在 Bean 初始化结束时调用那个的方法,也可以被应用于内存或缓存技术。</p><h3 id="init-method"><a href="#init-method" class="headerlink" title="init-method"></a>init-method</h3><p>7.如果 Bean 在 Spring 配置文件中配置了 init-method 属性会自动调用其配置的初始化方法。</p><h3 id="postProcessAfterInitialization"><a href="#postProcessAfterInitialization" class="headerlink" title="postProcessAfterInitialization"></a>postProcessAfterInitialization</h3><p>8.如果这个 Bean 关联了 BeanPostProcessor 接口,将会调用postProcessAfterInitialization(Object obj, String s)方法。<br>注:以上工作完成以后就可以应用这个 Bean 了,那这个 Bean 是一个 Singleton 的,所以一般情况下我们调用同一个 id 的 Bean 会是在内容地址相同的实例,当然在 Spring 配置文件中也可以配置非 Singleton。</p><h3 id="Destroy-过期自动清理阶段"><a href="#Destroy-过期自动清理阶段" class="headerlink" title="Destroy 过期自动清理阶段"></a>Destroy 过期自动清理阶段</h3><p>9.当 Bean 不再需要时,会经过清理阶段,如果 Bean 实现了 DisposableBean 这个接口,会调用那个其实现的 destroy()方法;</p><h3 id="destroy-method-自配置清理"><a href="#destroy-method-自配置清理" class="headerlink" title="destroy-method 自配置清理"></a>destroy-method 自配置清理</h3><ol start="10"><li>最后,如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性,会自动调用其配置的销毁方法。</li></ol><p><img src="/resource/img/spring-live.png" srcset="/img/loading.gif" alt="avatar"></p><ol start="11"><li>bean 标签有两个重要的属性(init-method 和 destroy-method)。用它们你可以自己定制初始化和注销方法。它们也有相应的注解(@PostConstruct 和@PreDestroy)。</li></ol><p><code>&lt;bean id=&quot;&quot; class=&quot;&quot; init-method=&quot;初始化方法&quot; destroy-method=&quot;销毁方法&quot;&gt;</code></p><h1 id="Spring-依赖注入四种方式"><a href="#Spring-依赖注入四种方式" class="headerlink" title="Spring 依赖注入四种方式"></a>Spring 依赖注入四种方式</h1><h2 id="构造器注入"><a href="#构造器注入" class="headerlink" title="构造器注入"></a>构造器注入</h2><pre><code class="xml">/*带参数,方便利用构造器进行注入*/public CatDaoImpl(String message){    this. message = message;}&lt;bean id=&quot;CatDaoImpl&quot; class=&quot;com.CatDaoImpl&quot;&gt;    &lt;constructor-arg value=&quot; message &quot;&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;</code></pre><h2 id="setter-方法注入"><a href="#setter-方法注入" class="headerlink" title="setter 方法注入"></a>setter 方法注入</h2><pre><code class="java">public class Id {   private int id;   public int getId() {       return id;   }   public void setId(int id) {       this.id = id;    }}</code></pre><pre><code class="xml">   &lt;bean id=&quot;id&quot; class=&quot;com.id &quot;&gt; &lt;property name=&quot;id&quot; value=&quot;123&quot;&gt;&lt;/property&gt; &lt;/bean&gt;</code></pre><h2 id="静态工厂注入"><a href="#静态工厂注入" class="headerlink" title="静态工厂注入"></a>静态工厂注入</h2><blockquote><p>静态工厂顾名思义,就是通过调用静态工厂的方法来获取自己需要的对象,为了让 spring 管理所有对象,我们不能直接通过”工程类.静态方法()”来获取对象,而是依然通过 spring 注入的形式获取:</p></blockquote><pre><code class="java">public class DaoFactory { //静态工厂    public static final FactoryDao getStaticFactoryDaoImpl(){        return new StaticFacotryDaoImpl();    }}public class SpringAction {    private FactoryDao staticFactoryDao; //注入对象    //注入对象的 set 方法    public void setStaticFactoryDao(FactoryDao staticFactoryDao) {        this.staticFactoryDao = staticFactoryDao;    }}//factory-method=&quot;getStaticFactoryDaoImpl&quot;指定调用哪个工厂方法</code></pre><pre><code class="xml">&lt;bean name=&quot;springAction&quot; class=&quot; SpringAction&quot; &gt;&lt;!--使用静态工厂的方法注入对象,对应下面的配置文件--&gt;&lt;property name=&quot;staticFactoryDao&quot; ref=&quot;staticFactoryDao&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--此处获取对象的方式是从工厂类中获取静态方法--&gt;&lt;bean name=&quot;staticFactoryDao&quot; class=&quot;DaoFactory&quot;        factory-method=&quot;getStaticFactoryDaoImpl&quot;&gt;&lt;/bean&gt;</code></pre><h2 id="实例工厂"><a href="#实例工厂" class="headerlink" title="实例工厂"></a>实例工厂</h2><blockquote><p>实例工厂的意思是获取对象实例的方法不是静态的,所以你需要首先 new 工厂类,再调用普通的实例方法:</p></blockquote><pre><code class="java">public class DaoFactory { //实例工厂    public FactoryDao getFactoryDaoImpl(){        return new FactoryDaoImpl();}    }public class SpringAction {    private FactoryDao factoryDao;    //注入对象    public void setFactoryDao(FactoryDao factoryDao) {        this.factoryDao = factoryDao;    }}</code></pre><pre><code class="xml">&lt;bean name=&quot;springAction&quot; class=&quot;SpringAction&quot;&gt;&lt;!--使用实例工厂的方法注入对象,对应下面的配置文件--&gt;&lt;property name=&quot;factoryDao&quot; ref=&quot;factoryDao&quot;&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--此处获取对象的方式是从工厂类中获取实例方法--&gt;&lt;bean name=&quot;daoFactory&quot; class=&quot;com.DaoFactory&quot;&gt;&lt;/bean&gt;&lt;bean name=&quot;factoryDao&quot; factory-bean=&quot;daoFactory&quot;factory-method=&quot;getFactoryDaoImpl&quot;&gt;&lt;/bean&gt;</code></pre><h1 id="5-种不同方式的自动装配"><a href="#5-种不同方式的自动装配" class="headerlink" title="5 种不同方式的自动装配"></a>5 种不同方式的自动装配</h1><p>Spring 装配包括手动装配和自动装配,手动装配是有基于 xml 装配、构造方法、setter 方法等</p><p>自动装配有五种自动装配的方式,可以用来指导 Spring 容器用自动装配方式来进行依赖注入。</p><ol><li>no:默认的方式是不进行自动装配,通过显式设置 ref 属性来进行装配。</li><li>byName:通过参数名 自动装配,Spring 容器在配置文件中发现 bean 的 autowire 属性被设置成 byname,之后容器试图匹配、装配和该 bean 的属性具有相同名字的 bean。</li><li>byType:通过参数类型自动装配,Spring 容器在配置文件中发现 bean 的 autowire 属性被设置成 byType,之后容器试图匹配、装配和该 bean 的属性具有相同类型的 bean。如果有多个 bean 符合条件,则抛出错误。</li><li>constructor:这个方式类似于 byType, 但是要提供给构造器参数,如果没有确定的带参数的构造器参数类型,将会抛出异常。</li><li>autodetect:首先尝试使用 constructor 来自动装配,如果无法工作,则使用 byType 方式。</li></ol><h1 id="Spring-APO-原理"><a href="#Spring-APO-原理" class="headerlink" title="Spring APO 原理"></a>Spring APO 原理</h1><h2 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h2><p>“ 横切”的技术,剖解开封装的对象内部,并将那些影响了多个类的公共行为封装到一个可重用模块,并将其命名为”Aspect”,即切面。所谓”切面”,简单说就是那些与业务无关,却为业务模块所共<br>同调用的逻辑或责任封装起来,便于减少系统的重复代码,降低模块之间的耦合度,并有利于未来的可操作性和可维护性。使用”横切”技术,AOP 把软件系统分为两个部分:核心关注点和横切关注点。业务处理的主要流<br>程是核心关注点,与之关系不大的部分是横切关注点。横切关注点的一个特点是,他们经常发生在核心关注点的多处,而各处基本相似,比如权限认证、日志、事物。AOP 的作用在于分离系统中的各种关注点,将核心关注点和横切关注点分离开来。</p><h2 id="AOP-主要应用场景有"><a href="#AOP-主要应用场景有" class="headerlink" title="AOP 主要应用场景有:"></a>AOP 主要应用场景有:</h2><ol><li>Authentication 权限</li><li>Caching 缓存</li><li>Context passing 内容传递</li><li>Error handling 错误处理</li><li>Lazy loading 懒加载</li><li>Debugging 调试</li><li>logging, tracing, profiling and monitoring 记录跟踪 优化 校准</li><li>Performance optimization 性能优化</li><li>Persistence 持久化</li><li>Resource pooling 资源池</li><li>Synchronization 同步</li><li>Transactions 事务</li></ol><h2 id="AOP-核心概念"><a href="#AOP-核心概念" class="headerlink" title="AOP 核心概念"></a>AOP 核心概念</h2><p>1、切面(aspect):类是对物体特征的抽象,切面就是对横切关注点的抽象<br>2、横切关注点:对哪些方法进行拦截,拦截后怎么处理,这些关注点称之为横切关注点。<br>3、连接点(joinpoint):被拦截到的点,因为 Spring 只支持方法类型的连接点,所以在 Spring中连接点指的就是被拦截到的方法,实际上连接点还可以是字段或者构造器。<br>4、切入点(pointcut):对连接点进行拦截的定义<br>5、通知(advice):所谓通知指的就是指拦截到连接点之后要执行的代码,通知分为前置、后置、异常、最终、环绕通知五类。<br>6、目标对象:代理的目标对象<br>7、织入(weave):将切面应用到目标对象并导致代理对象创建的过程<br>8、引入(introduction):在不修改代码的前提下,引入可以在运行期为类动态地添加一些方法或字段。</p><p><img src="/resource/img/spring-aop.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="AOP-两种代理方式"><a href="#AOP-两种代理方式" class="headerlink" title="AOP 两种代理方式"></a>AOP 两种代理方式</h3><p>Spring 提 供 了 两 种 方 式 来 生 成 代 理 对 象 : JDKProxy 和 Cglib , 具体使用哪种方式生成由AopProxyFactory 根据 AdvisedSupport 对象的配置来决定。默认的策略是如果目标类是接口,则使用 JDK 动态代理技术,否则使用 Cglib 来生成代理。</p><ul><li><p>JDK 动态接口代理</p><blockquote><p>1.JDK 动态代理主要涉及到 java.lang.reflect 包中的两个类:Proxy 和 InvocationHandler。<br>InvocationHandler 是一个接口,通过实现该接口定义横切逻辑,并通过反射机制调用目标类<br>的代码,动态将横切逻辑和业务逻辑编制在一起。Proxy 利用 InvocationHandler 动态创建<br>一个符合某一接口的实例,生成目标类的代理对象。</p></blockquote></li><li><p>CGLib 动态代理</p><blockquote><p>2.:CGLib 全称为 Code Generation Library,是一个强大的高性能,高质量的代码生成类库,<br>可以在运行期扩展 Java 类与实现 Java 接口,CGLib 封装了 asm,可以再运行期动态生成新<br>的 class。和 JDK 动态代理相比较:JDK 创建代理有一个限制,就是只能为接口创建代理实例,<br>而对于没有通过接口定义业务方法的类,则可以通过 CGLib 创建动态代理。</p></blockquote></li></ul><pre><code class="java">@Aspectpublic class TransactionDemo {    @Pointcut(value=&quot;execution(* com.yangxin.core.service.*.*.*(..))&quot;)    public void point(){    }    @Before(value=&quot;point()&quot;)    public void before(){        System.out.println(&quot;transaction begin&quot;);    }    @AfterReturning(value = &quot;point()&quot;)    public void after(){        System.out.println(&quot;transaction commit&quot;);    }    @Around(&quot;point()&quot;)    public void around(ProceedingJoinPoint joinPoint) throws Throwable{        System.out.println(&quot;transaction begin&quot;);        joinPoint.proceed();        System.out.println(&quot;transaction commit&quot;);    }}</code></pre><p><img src="/resource/img/spring-proxy.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-MVC-原理"><a href="#Spring-MVC-原理" class="headerlink" title="Spring MVC 原理"></a>Spring MVC 原理</h1><blockquote><p>Spring 的模型-视图-控制器(MVC)框架是围绕一个 DispatcherServlet 来设计的,这个 Servlet会把请求分发给各个处理器,并支持可配置的处理器映射、视图渲染、本地化、时区与主题渲染等,甚至还能支持文件上传。</p></blockquote><p><img src="/resource/img/spring-mvc.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="Http-请求到-DispatcherServlet"><a href="#Http-请求到-DispatcherServlet" class="headerlink" title="Http 请求到 DispatcherServlet"></a>Http 请求到 DispatcherServlet</h3><p>(1) 客户端请求提交到 DispatcherServlet。</p><h3 id="HandlerMapping-寻找处理器"><a href="#HandlerMapping-寻找处理器" class="headerlink" title="HandlerMapping 寻找处理器"></a>HandlerMapping 寻找处理器</h3><p>(2) 由 DispatcherServlet 控制器查询一个或多个 HandlerMapping,找到处理请求的Controller。</p><h3 id="调用处理器-Controller"><a href="#调用处理器-Controller" class="headerlink" title="调用处理器 Controller"></a>调用处理器 Controller</h3><p>(3) DispatcherServlet 将请求提交到 Controller。<br>Controller 调用业务逻辑处理后,返回 ModelAndView<br>(4)(5)调用业务处理和返回结果:Controller 调用业务逻辑处理后,返回 ModelAndView。</p><h3 id="DispatcherServlet-查询-ModelAndView"><a href="#DispatcherServlet-查询-ModelAndView" class="headerlink" title="DispatcherServlet 查询 ModelAndView"></a>DispatcherServlet 查询 ModelAndView</h3><p>(6)(7)处理视图映射并返回模型: DispatcherServlet 查询一个或多个 ViewResoler 视图解析器,找到 ModelAndView 指定的视图。</p><h3 id="ModelAndView-反馈浏览器-HTTP"><a href="#ModelAndView-反馈浏览器-HTTP" class="headerlink" title="ModelAndView 反馈浏览器 HTTP"></a>ModelAndView 反馈浏览器 HTTP</h3><p>(8) Http 响应:视图负责将结果显示到客户端。</p><p><img src="/resource/img/spring-mvc-anno.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Spring-Boot-原理"><a href="#Spring-Boot-原理" class="headerlink" title="Spring Boot 原理"></a>Spring Boot 原理</h1><p>Spring Boot 是由 Pivotal 团队提供的全新框架,其设计目的是用来简化新 Spring 应用的初始搭建以及开发过程。该框架使用了特定的方式来进行配置,从而使开发人员不再需要定义样板化的配置。通过这种方式,Spring Boot 致力于在蓬勃发展的快速应用开发领域(rapid applicationdevelopment)成为领导者。其特点如下:</p><ol><li>创建独立的 Spring 应用程序</li><li>嵌入的 Tomcat,无需部署 WAR 文件</li><li>简化 Maven 配置</li><li>自动配置 Spring</li><li>提供生产就绪型功能,如指标,健康检查和外部配置</li><li>绝对没有代码生成和对 XML 没有要求配置 [1]</li></ol><h1 id="JPA-原理"><a href="#JPA-原理" class="headerlink" title="JPA 原理"></a>JPA 原理</h1><h3 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h3><p>事务是计算机应用中不可或缺的组件模型,它保证了用户操作的原子性 ( Atomicity )、一致性( Consistency )、隔离性 ( Isolation ) 和持久性 ( Durabilily )。</p><h3 id="本地事务"><a href="#本地事务" class="headerlink" title="本地事务"></a>本地事务</h3><p>紧密依赖于底层资源管理器(例如数据库连接 ),事务处理局限在当前事务资源内。此种事务处理方式不存在对应用服务器的依赖,因而部署灵活却无法支持多数据源的分布式事务。在数据库连接中使用本地事务示例如下:</p><pre><code class="java">    public void transferAccount() {        Connection conn = null;        Statement stmt = null;        try{            conn = getDataSource().getConnection();// 将自动提交设置为 false,若设置为 true 则数据库将会把每一次数据更新认定为一个事务并自动提交            conn.setAutoCommit(false);            stmt = conn.createStatement();// 将 A 账户中的金额减少 500            stmt.execute(&quot;update t_account set amount = amount - 500 where account_id = &#39;A&#39;&quot;);            // 将 B 账户中的金额增加 500            stmt.execute(&quot;update t_account set amount = amount + 500 where account_id = &#39;B&#39;&quot;);// 提交事务            conn.commit();// 事务提交:转账的两步操作同时成功        } catch(SQLException sqle){// 发生异常,回滚在本事务中的操做            conn.rollback();// 事务回滚:转账的两步操作完全撤销            stmt.close();            conn.close();        }    }</code></pre><h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><blockquote><p>Java 事务编程接口(JTA:Java Transaction API)和 Java 事务服务 (JTS;Java Transaction<br>Service) 为 J2EE 平台提供了分布式事务服务。分布式事务(Distributed Transaction)包括事务<br>管 理 器 ( Transaction Manager ) 和 一 个 或 多 个 支 持 XA 协 议 的 资 源 管 理 器 ( Resource<br>Manager )。我们可以将资源管理器看做任意类型的持久化数据存储;事务管理器承担着所有事务<br>参与单元的协调与控制。</p></blockquote><pre><code class="java">    public void transferAccount() {        UserTransaction userTx = null;        Connection connA = null; Statement stmtA = null;        Connection connB = null; Statement stmtB = null;        try{// 获得 Transaction 管理对象            userTx = (UserTransaction)getContext().lookup(&quot;java:comp/UserTransaction&quot;);            connA = getDataSourceA().getConnection();// 从数据库 A 中取得数据库连接            connB = getDataSourceB().getConnection();// 从数据库 B 中取得数据库连接            userTx.begin(); // 启动事务            stmtA = connA.createStatement();// 将 A 账户中的金额减少 500            stmtA.execute(&quot;update t_account set amount = amount - 500 where account_id = &#39;A&#39;&quot;);// 将 B 账户中的金额增加 500            stmtB = connB.createStatement();            stmtB.execute(&quot;update t_account set amount = amount + 500 where account_id = &#39;B&#39;&quot;);            userTx.commit();// 提交事务// 事务提交:转账的两步操作同时成功(数据库 A 和数据库 B 中的数据被同时更新)        } catch(SQLException sqle){// 发生异常,回滚在本事务中的操纵            userTx.rollback();// 事务回滚:数据库 A 和数据库 B 中的数据更新被同时撤销        } catch(Exception ne){ }    }</code></pre><h2 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h2><blockquote><p>两阶段提交主要保证了分布式事务的原子性:即所有结点要么全做要么全不做,所谓的两个阶段是指:第一阶段:准备阶段;第二阶段:提交阶段。</p></blockquote><p><img src="/resource/img/spring-mvc-jps.png" srcset="/img/loading.gif" alt="avatar"></p><p>1 准备阶段<br>事务协调者(事务管理器)给每个参与者(资源管理器)发送 Prepare 消息,每个参与者要么直接返回<br>失败(如权限验证失败),要么在本地执行事务,写本地的 redo 和 undo 日志,但不提交,到达一<br>种“万事俱备,只欠东风”的状态。<br>2 提交阶段:<br>如果协调者收到了参与者的失败消息或者超时,直接给每个参与者发送回滚(Rollback)消息;否则,<br>发送提交(Commit)消息;参与者根据协调者的指令执行提交或者回滚操作,释放所有事务处理过<br>程中使用的锁资源。(注意:必须在最后阶段释放锁资源)将提交分成两阶段进行的目的很明确,就是尽可能晚地提交事务,让事务在提交前尽可能地完成所有能完成的工作。</p><h1 id="Mybatis-缓存"><a href="#Mybatis-缓存" class="headerlink" title="Mybatis 缓存"></a>Mybatis 缓存</h1><blockquote><p>Mybatis 中有一级缓存和二级缓存,默认情况下一级缓存是开启的,而且是不能关闭的。一级缓存<br>是指 SqlSession 级别的缓存,当在同一个 SqlSession 中进行相同的 SQL 语句查询时,第二次以<br>后的查询不会从数据库查询,而是直接从缓存中获取,一级缓存最多缓存 1024 条 SQL。</p></blockquote><blockquote><p>二级缓存<br>是指可以跨 SqlSession 的缓存。是 mapper 级别的缓存,对于 mapper 级别的缓存不同的<br>sqlsession 是可以共享的。</p></blockquote><p><img src="/resource/img/spring-mvc-cache.png" srcset="/img/loading.gif" alt="avatar"></p><p>Mybatis 的一级缓存原理( sqlsession 级别 )<br>第一次发出一个查询 sql,sql 查询结果写入 sqlsession 的一级缓存中,缓存使用的数据结构是一个 map。</p><blockquote><p>key:MapperID+offset+limit+Sql+所有的入参<br>value:用户信息</p></blockquote><p>同一个 sqlsession 再次发出相同的 sql,就从缓存中取出数据。如果两次中间出现 commit 操作(修改、添加、删除),本 sqlsession 中的一级缓存区域全部清空,下次再去缓存中查询不到所以要从数据库查询,从数据库查询到再写入缓存。</p><p>二级缓存原理( mapper 基本 )</p><p>二级缓存的范围是 mapper 级别(mapper 同一个命名空间),mapper 以命名空间为单位创建缓存数据结构,结构是 map。mybatis 的二级缓存是通过 CacheExecutor 实现的。CacheExecutor</p><p>其实是 Executor 的代理对象。所有的查询操作,在 CacheExecutor 中都会先匹配缓存中是否存<br>在,不存在则查询数据库。<br>key:MapperID+offset+limit+Sql+所有的入参<br>具体使用需要配置:</p><ol><li>Mybatis 全局配置中启用二级缓存配置</li><li>在对应的 Mapper.xml 中配置 cache 节点</li><li>在对应的 select 查询节点中添加 useCache=true</li></ol><h1 id="Tomcat-架构"><a href="#Tomcat-架构" class="headerlink" title="Tomcat 架构"></a>Tomcat 架构</h1><p><a href="https://www.cnblogs.com/alimayun/p/10604532.html" target="_blank" rel="noopener">参考资料</a></p>]]></content>
    
    
    <categories>
      
      <category>框架</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>网络安全入门</title>
    <link href="/2020/07/23/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8/"/>
    <url>/2020/07/23/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%85%A5%E9%97%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><ul><li>《黑客初级入门》</li><li>《白帽子讲web安全》</li><li>《从零开始学习黑客技术入门教程(基础)》</li><li>《白帽子讲web安全》</li><li>《web前端黑客技术揭秘》</li><li>《黑客攻防宝典：web实战篇》</li><li>《暗战亮剑:黑客渗透于防御全程实录》</li><li>《backtrack从入门到精通》</li><li>《黑客攻防技术与案例剖析》</li><li>《黑客攻防技术与案例剖析》</li><li>《黑客大曝光第6版》</li><li>《黑客攻防技术宝典-WEB实战篇》</li><li>《黑客攻防技术宝典系统实战篇》</li><li>《黑客WEB脚本攻击与防御技术核心剖析》</li><li>《黑客渗透笔记完整版》</li><li>《Q版缓冲区溢出教程》</li><li>《php漏洞挖掘书籍》</li><li>《Shellcoder编程揭秘》</li><li>《黑客防线2009缓冲区溢出攻击与防范专辑》</li><li>《黑客大曝光：无线网络安全（原书第2版）》</li><li>《LINUX黑客大曝光（第2版）》</li><li>《0day安全软件漏洞分析技术（第一版和第二版）</li><li>《Binary+Hacks+黑客秘笈100选》</li><li>《Windows黑客技术揭秘与攻防1C语言篇》</li><li>《黑武器-linux_BT4无线黑客》</li><li>《黑客入侵网页攻防修炼》</li><li>《backtrack4:assuring security by penetration testing》</li><li>《Web应用安全威胁于防治（基于owasp top 与esapi）</li><li>《backtrack4:利用渗透测试保证系统安全》</li><li>《无线网络黑客攻防》</li><li>《Metasploit渗透测试指南》</li><li>《网络安全进阶笔记》</li><li>《Linux网络安全技术与实现(第2版)》</li><li>《网络安全 王淑江、 等 机械工业出版社 (2007-09出版)》</li><li>《Web系统安全和渗透性测试基础》</li><li>《渗透测试实践指南:必知必会的工具与方法》</li><li>《大中型网络入侵要案直击与防御》</li><li>《Web安全测试》</li><li>《Python灰帽子:黑客与逆向工程师的Python编程之道》</li><li>《SQL Injection Attacks and Defense（SQL注入攻击和防御）》</li><li>《SQL Injection Attacks and Possible Remedies（SQL注入攻击和可能的补救措施）》</li><li>《SQL: PL-SQL, Transact-SQL, SQL Injection, Database Console Commands, Xleratordb, Foreign Key, Navicat, Cursor,…》</li><li>《CEH Certified Ethical Hacker Study Guide [With CDROM]（国家认证的道德黑客学习指南(光盘)》</li><li>《The Shellcoder’s Handbook: Discovering and Exploiting Security Holes(这个Shellcoder手册:发现和利用安全漏洞）》《Sockets, Shellcode, Porting and Coding: Reverse Engineering Exploits and Tool Coding for Security Professionals…（套接字,Shellcode,移植和编码:逆向工程利用和工具编码为安全专家……)》《Metasploit Toolkit for Penetration Testing, Exploit Development, and Vulnerability Research（Metasploit工具包对渗透测试,利用开发和脆弱性研究)》《Buffer Overflow Attacks: Detect, Exploit, Prevent（缓冲区溢出攻击:检测,利用,防止）》</li></ul>]]></content>
    
    
    <categories>
      
      <category>网络安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>网络安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>k8s 入门实践</title>
    <link href="/2020/07/07/k8s-%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/"/>
    <url>/2020/07/07/k8s-%E5%85%A5%E9%97%A8%E5%AE%9E%E8%B7%B5/</url>
    
    <content type="html"><![CDATA[<h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><ul><li>至少2台 2核4G 的服务器 Cent OS 7.6 / 7.7 / 7.8</li></ul><h3 id="服务器信息-CentOS-Linux-release-7-8-2003-Core"><a href="#服务器信息-CentOS-Linux-release-7-8-2003-Core" class="headerlink" title="服务器信息 CentOS Linux release 7.8.2003 (Core)"></a>服务器信息 CentOS Linux release 7.8.2003 (Core)</h3><pre><code>Architecture:          x86_64CPU op-mode(s):        32-bit, 64-bitByte Order:            Little EndianCPU(s):                4On-line CPU(s) list:   0-3Thread(s) per core:    2Core(s) per socket:    2Socket(s):             1NUMA node(s):          1Vendor ID:             GenuineIntelCPU family:            6Model:                 85Model name:            Intel(R) Xeon(R) Gold 6266C CPU @ 3.00GHzStepping:              7CPU MHz:               3000.000BogoMIPS:              6000.00Hypervisor vendor:     KVMVirtualization type:   fullL1d cache:             32KL1i cache:             32KL2 cache:              1024KL3 cache:              30976KNUMA node0 CPU(s):     0-3Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 arat avx512_vnni md_clear spec_ctrl intel_stibp flush_l1d arch_capabilities</code></pre><p>K8s</p><ul><li>kubelet</li></ul><p>Docker 镜像</p><ul><li>etcd</li><li>kube-proxy</li><li>kube-apiserver</li><li>kube-controller-manager</li><li>kube-scheduler</li></ul><h1 id="安装Kubernates"><a href="#安装Kubernates" class="headerlink" title="安装Kubernates"></a>安装Kubernates</h1><ul><li><p>修改 hostname,不能使用localhost</p><pre><code>如果您需要修改 hostname，可执行如下指令：# 修改 hostnamehostnamectl set-hostname your-new-host-name# 查看修改结果hostnamectl status# 设置 hostname 解析echo &quot;127.0.0.1   $(hostname)&quot; &gt;&gt; /etc/hosts</code></pre></li><li><p>检查网络</p></li></ul><pre><code>[root@server-781e6bf7-bce3-4d09-adc8-2a169fdb8719 ~]# ip route showdefault via 192.168.0.1 dev eth0 proto dhcp metric 100 169.254.169.254 via 192.168.0.254 dev eth0 proto dhcp metric 100 172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 172.18.0.0/16 dev br-66ad3449f59f proto kernel scope link src 172.18.0.1 172.19.0.0/16 dev br-3d8dbba954bf proto kernel scope link src 172.19.0.1 192.168.0.0/24 dev eth0 proto kernel scope link src 192.168.0.39 metric 100 [root@server-781e6bf7-bce3-4d09-adc8-2a169fdb8719 ~]# ip address1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000    link/ether fa:16:3e:c1:b5:a5 brd ff:ff:ff:ff:ff:ff    inet 192.168.0.39/24 brd 192.168.0.255 scope global noprefixroute dynamic eth0       valid_lft 53761sec preferred_lft 53761sec    inet6 fe80::f816:3eff:fec1:b5a5/64 scope link        valid_lft forever preferred_lft forever3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default     link/ether 02:42:54:bb:c6:75 brd ff:ff:ff:ff:ff:ff    inet 172.17.0.1/16 scope global docker0       valid_lft forever preferred_lft forever    inet6 fe80::42:54ff:febb:c675/64 scope link        valid_lft forever preferred_lft forever4: br-66ad3449f59f: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default     link/ether 02:42:ee:d9:c2:68 brd ff:ff:ff:ff:ff:ff    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-66ad3449f59f       valid_lft forever preferred_lft forever    inet6 fe80::42:eeff:fed9:c268/64 scope link        valid_lft forever preferred_lft forever5: br-3d8dbba954bf: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default     link/ether 02:42:6c:a5:67:cc brd ff:ff:ff:ff:ff:ff    inet 172.19.0.1/16 brd 172.19.255.255 scope global br-3d8dbba954bf       valid_lft forever preferred_lft forever    inet6 fe80::42:6cff:fea5:67cc/64 scope link        valid_lft forever preferred_lft forever9: veth7dba01e@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br-66ad3449f59f state UP group default     link/ether aa:7c:a6:ae:85:2c brd ff:ff:ff:ff:ff:ff link-netnsid 0    inet6 fe80::a87c:a6ff:feae:852c/64 scope link        valid_lft forever preferred_lft forever15: veth9f52d5f@if14: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br-3d8dbba954bf state UP group default     link/ether e2:bd:35:53:c6:0c brd ff:ff:ff:ff:ff:ff link-netnsid 1    inet6 fe80::e0bd:35ff:fe53:c60c/64 scope link        valid_lft forever preferred_lft forever</code></pre><ul><li><p>安装 Docker</p></li><li><p>安装 nfs-utils</p></li><li><p>安装 kubectl / kubeadm / kubelet</p></li></ul><pre><code># 在 master 节点和 worker 节点都要执行# 最后一个参数 1.18.6 用于指定 kubenetes 版本，支持所有 1.18.x 版本的安装# 腾讯云 docker hub 镜像# export REGISTRY_MIRROR=&quot;https://mirror.ccs.tencentyun.com&quot;# DaoCloud 镜像# export REGISTRY_MIRROR=&quot;http://f1361db2.m.daocloud.io&quot;# 华为云镜像# export REGISTRY_MIRROR=&quot;https://05f073ad3c0010ea0f4bc00b7105ec20.mirror.swr.myhuaweicloud.com&quot;# 阿里云 docker hub 镜像export REGISTRY_MIRROR=https://registry.cn-hangzhou.aliyuncs.comcurl -sSL https://kuboard.cn/install-script/v1.18.x/install_kubelet.sh | sh -s 1.18.6</code></pre><details><summary>脚本内容</summary><pre><code>#!/bin/bash# 在 master 节点和 worker 节点都要执行# 安装 docker# 参考文档如下# https://docs.docker.com/install/linux/docker-ce/centos/ # https://docs.docker.com/install/linux/linux-postinstall/# 卸载旧版本yum remove -y docker \docker-client \docker-client-latest \docker-ce-cli \docker-common \docker-latest \docker-latest-logrotate \docker-logrotate \docker-selinux \docker-engine-selinux \docker-engine# 设置 yum repositoryyum install -y yum-utils \device-mapper-persistent-data \lvm2yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# 安装并启动 dockeryum install -y docker-ce-19.03.8 docker-ce-cli-19.03.8 containerd.iosystemctl enable dockersystemctl start docker# 安装 nfs-utils# 必须先安装 nfs-utils 才能挂载 nfs 网络存储yum install -y nfs-utilsyum install -y wget# 关闭 防火墙systemctl stop firewalldsystemctl disable firewalld# 关闭 SeLinuxsetenforce 0sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config# 关闭 swapswapoff -ayes | cp /etc/fstab /etc/fstab_bakcat /etc/fstab_bak |grep -v swap &gt; /etc/fstab# 修改 /etc/sysctl.conf# 如果有配置，则修改sed -i &quot;s#^net.ipv4.ip_forward.*#net.ipv4.ip_forward=1#g&quot;  /etc/sysctl.confsed -i &quot;s#^net.bridge.bridge-nf-call-ip6tables.*#net.bridge.bridge-nf-call-ip6tables=1#g&quot;  /etc/sysctl.confsed -i &quot;s#^net.bridge.bridge-nf-call-iptables.*#net.bridge.bridge-nf-call-iptables=1#g&quot;  /etc/sysctl.confsed -i &quot;s#^net.ipv6.conf.all.disable_ipv6.*#net.ipv6.conf.all.disable_ipv6=1#g&quot;  /etc/sysctl.confsed -i &quot;s#^net.ipv6.conf.default.disable_ipv6.*#net.ipv6.conf.default.disable_ipv6=1#g&quot;  /etc/sysctl.confsed -i &quot;s#^net.ipv6.conf.lo.disable_ipv6.*#net.ipv6.conf.lo.disable_ipv6=1#g&quot;  /etc/sysctl.confsed -i &quot;s#^net.ipv6.conf.all.forwarding.*#net.ipv6.conf.all.forwarding=1#g&quot;  /etc/sysctl.conf# 可能没有，追加echo &quot;net.ipv4.ip_forward = 1&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.bridge.bridge-nf-call-ip6tables = 1&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.bridge.bridge-nf-call-iptables = 1&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv6.conf.all.disable_ipv6 = 1&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv6.conf.default.disable_ipv6 = 1&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv6.conf.lo.disable_ipv6 = 1&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv6.conf.all.forwarding = 1&quot;  &gt;&gt; /etc/sysctl.conf# 执行命令以应用sysctl -p# 配置K8S的yum源cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF# 卸载旧版本yum remove -y kubelet kubeadm kubectl# 安装kubelet、kubeadm、kubectl# 将 ${1} 替换为 kubernetes 版本号，例如 1.17.2yum install -y kubelet-${1} kubeadm-${1} kubectl-${1}# 修改docker Cgroup Driver为systemd# # 将/usr/lib/systemd/system/docker.service文件中的这一行 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock# # 修改为 ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd# 如果不修改，在添加 worker 节点时可能会碰到如下错误# [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. # Please follow the guide at https://kubernetes.io/docs/setup/cri/sed -i &quot;s#^ExecStart=/usr/bin/dockerd.*#ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --exec-opt native.cgroupdriver=systemd#g&quot; /usr/lib/systemd/system/docker.service# 设置 docker 镜像，提高 docker 镜像下载速度和稳定性# 如果您访问 https://hub.docker.io 速度非常稳定，亦可以跳过这个步骤curl -sSL https://kuboard.cn/install-script/set_mirror.sh | sh -s ${REGISTRY_MIRROR}# 重启 docker，并启动 kubeletsystemctl daemon-reloadsystemctl restart dockersystemctl enable kubelet &amp;&amp; systemctl start kubeletdocker version</code></pre></details><br><ul><li>初始化 master 节点</li></ul><pre><code># 只在 master 节点执行# 替换 x.x.x.x 为 master 节点实际 IP（请使用内网 IP）# export 命令只在当前 shell 会话中有效，开启新的 shell 窗口后，如果要继续安装过程，请重新执行此处的 export 命令export MASTER_IP=x.x.x.x# 替换 apiserver.demo 为 您想要的 dnsNameexport APISERVER_NAME=apiserver.demo# Kubernetes 容器组所在的网段，该网段安装完成后，由 kubernetes 创建，事先并不存在于您的物理网络中export POD_SUBNET=10.100.0.1/16echo &quot;${MASTER_IP}    ${APISERVER_NAME}&quot; &gt;&gt; /etc/hostscurl -sSL https://kuboard.cn/install-script/v1.18.x/init_master.sh | sh -s 1.18.6</code></pre><details>    <summary>脚本代码</summary><pre><code>````#!/bin/bash# 只在 master 节点执行# 脚本出错时终止执行set -eif [ ${#POD_SUBNET} -eq 0 ] || [ ${#APISERVER_NAME} -eq 0 ]; then  echo -e &quot;\033[31;1m请确保您已经设置了环境变量 POD_SUBNET 和 APISERVER_NAME \033[0m&quot;  echo 当前POD_SUBNET=$POD_SUBNET  echo 当前APISERVER_NAME=$APISERVER_NAME  exit 1fi# 查看完整配置选项 https://godoc.org/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2rm -f ./kubeadm-config.yamlcat &lt;&lt;EOF &gt; ./kubeadm-config.yamlapiVersion: kubeadm.k8s.io/v1beta2kind: ClusterConfigurationkubernetesVersion: v${1}imageRepository: registry.aliyuncs.com/k8sxiocontrolPlaneEndpoint: &quot;${APISERVER_NAME}:6443&quot;networking:  serviceSubnet: &quot;10.96.0.0/16&quot;  podSubnet: &quot;${POD_SUBNET}&quot;  dnsDomain: &quot;cluster.local&quot;EOF# kubeadm init# 根据您服务器网速的情况，您需要等候 3 - 10 分钟kubeadm init --config=kubeadm-config.yaml --upload-certs# 配置 kubectlrm -rf /root/.kube/mkdir /root/.kube/cp -i /etc/kubernetes/admin.conf /root/.kube/config# 安装 calico 网络插件# 参考文档 https://docs.projectcalico.org/v3.13/getting-started/kubernetes/self-managed-onprem/onpremisesecho &quot;安装calico-3.13.1&quot;rm -f calico-3.13.1.yamlwget https://kuboard.cn/install-script/calico/calico-3.13.1.yamlkubectl apply -f calico-3.13.1.yaml````</code></pre></details><br><ul><li>检查 master 初始化结果</li></ul><pre><code># 只在 master 节点执行# 执行如下命令，等待 3-10 分钟，直到所有的容器组处于 Running 状态watch kubectl get pod -n kube-system -o wide# 查看 master 节点初始化结果kubectl get nodes -o wide</code></pre><p>成功</p><pre><code>Every 2.0s: kubectl get pod -n kube-system -o wide                                                                                                                                                                                               Tue Jul 28 17:31:56 2020NAME                                       READY   STATUS     RESTARTS   AGE    IP             NODE     NOMINATED NODE   READINESS GATEScalico-kube-controllers-5b8b769fcd-dw2fq   0/1     Pending    0          99s    &lt;none&gt;         &lt;none&gt;   &lt;none&gt;           &lt;none&gt;calico-node-gcw6r                          0/1     Init:0/3   0          99s    192.168.0.39   mikey    &lt;none&gt;           &lt;none&gt;coredns-66db54ff7f-2f9qn                   0/1     Pending    0          99s    &lt;none&gt;         &lt;none&gt;   &lt;none&gt;           &lt;none&gt;coredns-66db54ff7f-csm5w                   0/1     Pending    0          99s    &lt;none&gt;         &lt;none&gt;   &lt;none&gt;           &lt;none&gt;etcd-mikey                                 1/1     Running    0          108s   192.168.0.39   mikey    &lt;none&gt;           &lt;none&gt;kube-apiserver-mikey                       1/1     Running    0          108s   192.168.0.39   mikey    &lt;none&gt;           &lt;none&gt;kube-controller-manager-mikey              1/1     Running    0          108s   192.168.0.39   mikey    &lt;none&gt;           &lt;none&gt;kube-proxy-xhmgq                           1/1     Running    0          99s    192.168.0.39   mikey    &lt;none&gt;           &lt;none&gt;kube-scheduler-mikey                       1/1     Running    0          108s   192.168.0.39   mikey    &lt;none&gt;           &lt;none&gt;</code></pre><pre><code>[root@server-781e6bf7-bce3-4d09-adc8-2a169fdb8719 ~]# kubectl get nodes -o wideNAME    STATUS     ROLES    AGE     VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION                CONTAINER-RUNTIMEmikey   NotReady   master   2m18s   v1.18.6   192.168.0.39   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-1062.12.1.el7.x86_64   docker://19.3.8</code></pre><ul><li>初始化 worker节点<blockquote><p>获得 join命令参数在 master 节点上执行</p></blockquote></li></ul><p><code>kubeadm token create --print-join-command</code></p><p>可获取kubeadm join 命令及参数，如下所示</p><p>kubeadm token create 命令的输出</p><blockquote><p>kubeadm join apiserver.demo:6443 –token mpfjma.4vjjg8flqihor4vt     –discovery-token-ca-cert-hash sha256:6f7a8e40a810323672de5eee6f4d19aa2dbdb38411845a1bf5dd63485c43d303</p></blockquote><p><code>该 token 的有效时间为 2 个小时，2小时内，您可以使用此 token 初始化任意数量的 worker 节点</code></p><ul><li>初始化worker</li></ul><p>针对所有的 worker 节点执行</p><pre><code># 只在 worker 节点执行# 替换 x.x.x.x 为 master 节点的内网 IPexport MASTER_IP=x.x.x.x# 替换 apiserver.demo 为初始化 master 节点时所使用的 APISERVER_NAMEexport APISERVER_NAME=apiserver.demoecho &quot;${MASTER_IP}    ${APISERVER_NAME}&quot; &gt;&gt; /etc/hosts# 替换为 master 节点上 kubeadm token create 命令的输出kubeadm join apiserver.demo:6443 --token mpfjma.4vjjg8flqihor4vt     --discovery-token-ca-cert-hash sha256:031a838dcdb8a66e0a5ddb826a2ada6065d3f68d5ddfa97226270a0e56861160</code></pre><p>出现问题<code>kubeadm reset</code>进行重置</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://kuboard.cn/install/install-k8s.html#%E6%96%87%E6%A1%A3%E7%89%B9%E7%82%B9" target="_blank" rel="noopener">单节点安装</a></p><p><a href="https://kuboard.cn/learning/k8s-bg/what-is-k8s.html#%E5%9B%9E%E9%A1%BE" target="_blank" rel="noopener">Kubernates 教学</a></p>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernates</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java 基础</title>
    <link href="/2020/07/07/Java-%E5%9F%BA%E7%A1%80/"/>
    <url>/2020/07/07/Java-%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="JAVA-异常分类及处理"><a href="#JAVA-异常分类及处理" class="headerlink" title="JAVA 异常分类及处理"></a>JAVA 异常分类及处理</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><blockquote><p>如果某个方法不能按照正常的途径完成任务,就可以通过另一种路径退出方法。在这种情况下<br> 会抛出一个封装了错误信息的对象。此时,这个方法会立刻退出同时不返回任何值。另外,调用<br> 这个方法的其他代码也无法继续执行,异常处理机制会将代码执行交给异常处理器。</p></blockquote><p><img src="/resource/img/exception.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="异常分类"><a href="#异常分类" class="headerlink" title="异常分类"></a>异常分类</h2><blockquote><p>Throwable 是 Java 语言中所有错误或异常的超类。下一层分为 Error 和 Exception</p></blockquote><h3 id="Error"><a href="#Error" class="headerlink" title="Error"></a>Error</h3><blockquote><p>Error 类是指 java 运行时系统的内部错误和资源耗尽错误。应用程序不会抛出该类对象。如果出现了这样的错误,除了告知用户,剩下的就是尽力使程序安全的终止。</p></blockquote><h3 id="Exception-RuntimeException、CheckedException"><a href="#Exception-RuntimeException、CheckedException" class="headerlink" title="Exception(RuntimeException、CheckedException)"></a>Exception(RuntimeException、CheckedException)</h3><blockquote><p>Exception 又 有 两 个 分 支 , 一 个 是 运 行 时 异 常 RuntimeException , 一 个 是CheckedException。</p></blockquote><h3 id="RuntimeException"><a href="#RuntimeException" class="headerlink" title="RuntimeException"></a>RuntimeException</h3><blockquote><p>如 : <code>NullPointerException</code> 、 <code>ClassCastException</code> ; 一 个 是 检 查 异 常<br>CheckedException,如 I/O 错误导致的 <code>IOException</code>、<code>SQLException</code>。 RuntimeException 是<br>那些可能在 Java 虚拟机正常运行期间抛出的异常的超类。 如果出现 RuntimeException,那么一定是程序员的错误.</p></blockquote><h3 id="检查异常-CheckedException"><a href="#检查异常-CheckedException" class="headerlink" title="检查异常 CheckedException:"></a>检查异常 CheckedException:</h3><blockquote><p>一般是外部错误,这种异常都发生在编译阶段,Java 编译器会强<br>制程序去捕获此类异常,即会出现要求你把这段可能出现异常的程序进行 try catch,该类异常一<br>般包括几个方面:</p></blockquote><ol><li>试图在文件尾部读取数据</li><li>试图打开一个错误格式的 URL</li><li>试图根据给定的字符串查找 class 对象,而这个字符串表示的类并不存在</li></ol><h3 id="异常的处理方式"><a href="#异常的处理方式" class="headerlink" title="异常的处理方式"></a>异常的处理方式</h3><p>遇到问题不进行具体处理,而是继续抛给调用者 (throw,throws)  </p><pre><code class="java">public static void main(String[] args) {    String s = &quot;abc&quot;;        if(s.equals(&quot;abc&quot;)) {            throw new NumberFormatException();        } else {            System.out.println(s);    }}int div(int a,int b) throws Exception{    return a/b;}</code></pre><p>try catch 捕获异常针对性处理方式<br>Throw 和 throws 的区别:<br>位置不同:</p><blockquote><p>throws 用在函数上,后面跟的是异常类,可以跟多个;而 throw 用在函数内,后面跟的是异常对象。</p></blockquote><p>功能不同:  </p><blockquote><p>throws 用来声明异常,让调用者只知道该功能可能出现的问题,可以给出预先的处理方式;throw 抛出具体的问题对象,执行到 throw,功能就已经结束了,跳转到调用者,并将具体的问题对象抛给调用者。也就是说 throw 语句独立存在时,下面不要定义其他语句,因为执行不到。</p></blockquote><blockquote><p>throws 表示出现异常的一种可能性,并不一定会发生这些异常;throw 则是抛出了异常,<br> 执行 throw 则一定抛出了某种异常对象。</p></blockquote><blockquote><p>两者都是消极处理异常的方式,只是抛出或者可能抛出异常,但是不会由函数去处理异<br> 常,真正的处理异常由函数的上层调用处理。</p></blockquote><h1 id="JAVA-反射"><a href="#JAVA-反射" class="headerlink" title="JAVA 反射"></a>JAVA 反射</h1><h2 id="动态语言"><a href="#动态语言" class="headerlink" title="动态语言"></a>动态语言</h2><blockquote><p>动态语言,是指程序在运行时可以改变其结构:新的函数可以引进,已有的函数可以被删除等结<br> 构上的变化。比如常见的 JavaScript 就是动态语言,除此之外 Ruby,Python 等也属于动态语言,<br> 而 C、C++则不属于动态语言。从反射角度说 JAVA 属于半动态语言。</p></blockquote><p><img src="/resource/img/reflex.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="反射机制概念-运行状态中知道类所有的属性和方法"><a href="#反射机制概念-运行状态中知道类所有的属性和方法" class="headerlink" title="反射机制概念 (运行状态中知道类所有的属性和方法)"></a>反射机制概念 (运行状态中知道类所有的属性和方法)</h2><blockquote><p>在 Java 中的反射机制是指在运行状态中,对于任意一个类都能够知道这个类所有的属性和方法;<br>并且对于任意一个对象,都能够调用它的任意一个方法;这种动态获取信息以及动态调用对象方<br>法的功能成为 Java 语言的反射机制。</p></blockquote><h3 id="反射的应用场合"><a href="#反射的应用场合" class="headerlink" title="反射的应用场合"></a>反射的应用场合</h3><p>编译时类型和运行时类型  </p><p>在 Java 程序中许多对象在运行是都会出现两种类型:编译时类型和运行时类型。 编译时的类型由<br>声明对象时实用的类型来决定,运行时的类型由实际赋值给对象的类型决定 。如:<br><code>Person p=new Student();</code><br>其中编译时类型为 Person,运行时类型为 Student。</p><p>的编译时类型无法获取具体方法  </p><blockquote><p>程序在运行时还可能接收到外部传入的对象,该对象的编译时类型为 Object,但是程序有需要调用<br> 该对象的运行时类型的方法。为了解决这些问题,程序需要在运行时发现对象和类的真实信息。<br> 然而,如果编译时根本无法预知该对象和类属于哪些类,程序只能依靠运行时信息来发现该对象<br> 和类的真实信息,此时就必须使用到反射了。</p></blockquote><p>Java 反射 API<br>反射 API 用来生成 JVM 中的类、接口或则对象的信息。  </p><blockquote><ol><li>Class 类:反射的核心类,可以获取类的属性,方法等信息。</li><li>Field 类:Java.lang.reflec 包中的类,表示类的成员变量,可以用来获取和设置类之中的属性值。</li><li>Method 类: Java.lang.reflec 包中的类,表示类的方法,它可以用来获取类中的方法信息或者执行方法。</li><li>Constructor 类: Java.lang.reflec 包中的类,表示类的构造方法。</li></ol></blockquote><h4 id="反射使用步骤-获取-Class-对象、调用对象方法"><a href="#反射使用步骤-获取-Class-对象、调用对象方法" class="headerlink" title="反射使用步骤(获取 Class 对象、调用对象方法)"></a>反射使用步骤(获取 Class 对象、调用对象方法)</h4><blockquote><ol><li>反射使用步骤(获取 Class 对象、调用对象方法)获取想要操作的类的 Class 对象,他是反射的核心,通过 Class 对象我们可以任意调用类的方法</li><li>调用 Class 类中的方法,既就是反射的使用阶段</li><li>使用反射 API 来操作这些信息</li></ol></blockquote><p>获取 Class 对象的 3 种方法<br>调用某个对象的 getClass()方法  </p><pre><code class="java">Person p=new Person();Class clazz=p.getClass();</code></pre><p>调用某个类的 class 属性来获取该类对应的 Class 对象  </p><pre><code class="java">Class clazz=Person.class;</code></pre><p>使用 Class 类中的 forName()静态方法(最安全/性能最好)  </p><pre><code class="java">Class clazz=Class.forName(&quot;类的全路径&quot;); (最常用)</code></pre><p>当我们获得了想要操作的类的 Class 对象后,可以通过 Class 类中的方法获取并查看该类中的方法和属性。</p><pre><code class="java">//获取 Person 类的 Class 对象Class clazz=Class.forName(&quot;reflection.Person&quot;);//获取 Person 类的所有方法信息Method[] method=clazz.getDeclaredMethods();for(Method m:method){    System.out.println(m.toString());}//获取 Person 类的所有成员属性信息Field[] field=clazz.getDeclaredFields();for(Field f:field){    System.out.println(f.toString());}//获取 Person 类的所有构造方法信息Constructor[] constructor=clazz.getDeclaredConstructors();for(Constructor c:constructor){    System.out.println(c.toString());}</code></pre><h4 id="创建对象的两种方法"><a href="#创建对象的两种方法" class="headerlink" title="创建对象的两种方法"></a>创建对象的两种方法</h4><p>Class 对象的 newInstance()  </p><pre><code class="java">使用 Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例,但是这种方法要求该 Class 对象对应的类有默认的空构造器。</code></pre><p>调用 Constructor 对象的 newInstance()  </p><pre><code class="java">先使用 Class 对象获取指定的 Constructor 对象,再调用 Constructor 对象的 newInstance()方法来创建 Class 对象对应类的实例,通过这种方法可以选定构造方法创建实例。</code></pre><pre><code class="java">//获取 Person 类的 Class 对象Class clazz=Class.forName(&quot;reflection.Person&quot;);//使用.newInstane 方法创建对象Person p=(Person) clazz.newInstance();//获取构造方法并创建对象Constructor c=clazz.getDeclaredConstructor(String.class,String.class,int.class);//创建对象并设置属性Person p1=(Person) c.newInstance(&quot;李四&quot;,&quot;男&quot;,20);</code></pre><h1 id="JAVA-注解"><a href="#JAVA-注解" class="headerlink" title="JAVA 注解"></a>JAVA 注解</h1><h2 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h2><blockquote><p>A nnotation(注解)是 Java 提供的一种对元程序中元素关联信息和元数据(metadata)的途径<br> 和方法。Annatation(注解)是一个接口,程序可以通过反射来获取指定程序中元素的 Annotation<br> 对象,然后通过该 Annotation 对象来获取注解中的元数据信息。</p></blockquote><h2 id="四种标准元注解"><a href="#四种标准元注解" class="headerlink" title="四种标准元注解"></a>四种标准元注解</h2><blockquote><p>元注解的作用是负责注解其他注解。 Java5.0 定义了 4 个标准的 meta-annotation 类型,它们被<br> 用来提供对其它 annotation 类型作说明。</p></blockquote><p>@Target 修饰的对象范围  </p><blockquote><p>@Target 说明了 Annotation 所修饰的对象范围: Annotation 可被用于 packages、types(类、<br> 接口、枚举、Annotation 类型)、类型成员(方法、构造方法、成员变量、枚举值)、方法参数<br> 和本地变量(如循环变量、catch 参数)。在 Annotation 类型的声明中使用了 target 可更加明晰<br> 其修饰的目标</p></blockquote><p>@Retention 定义 被保留的时间长短  </p><blockquote><p>Retention 定义了该 Annotation 被保留的时间长短:表示需要在什么级别保存注解信息,用于描<br> 述注解的生命周期(即:被描述的注解在什么范围内有效),取值(RetentionPoicy)由:</p></blockquote><ul><li>SOURCE:在源文件中有效(即源文件保留)</li><li>CLASS:在 class 文件中有效(即 class 保留)</li><li>RUNTIME:在运行时有效(即运行时保留)</li></ul><p>@Documented 描述-javadoc  </p><blockquote><p>@ Documented 用于描述其它类型的 annotation 应该被作为被标注的程序成员的公共 API,因此可以被例如 javadoc 此类的工具文档化。</p></blockquote><p>@Inherited 阐述了某个被标注的类型是被继承的  </p><blockquote><p>@Inherited 元注解是一个标记注解,@Inherited 阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited 修饰的 annotation 类型被用于一个 class,则这个 annotation 将被用于该class 的子类。</p></blockquote><p><img src="/resource/img/annotation.png" srcset="/img/loading.gif" alt="avatar"></p><p>注解处理器  </p><blockquote><p>如果没有用来读取注解的方法和工作,那么注解也就不会比注释更有用处了。使用注解的过程中,很重要的一部分就是创建于使用注解处理器。Java SE5 扩展了反射机制的 API,以帮助程序员快速的构造自定义注解处理器。下面实现一个注解处理器。</p></blockquote><pre><code class="java">/1:*** 定义注解*/@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface FruitProvider {    /**供应商编号*/    public int id() default -1;    /*** 供应商名称*/    public String name() default &quot;&quot;;    /** * 供应商地址*/    public String address() default &quot;&quot;;}//2:注解使用public class Apple {    @FruitProvider(id = 1, name = &quot;陕西红富士集团&quot;, address = &quot;陕西省西安市延安路&quot;)    private String appleProvider;    public void setAppleProvider(String appleProvider) {        this.appleProvider = appleProvider;    }    public String getAppleProvider() {        return appleProvider;    }}/3:*********** 注解处理器 ***************/public class FruitInfoUtil {    public static void getFruitInfo(Class&lt;?&gt; clazz) {        String strFruitProvicer = &quot;供应商信息:&quot;;        Field[] fields = clazz.getDeclaredFields();//通过反射获取处理注解        for (Field field : fields) {            if (field.isAnnotationPresent(FruitProvider.class)) {                FruitProvider fruitProvider = (FruitProvider) field.getAnnotation(FruitProvider.class);//注解信息的处理地方                strFruitProvicer = &quot; 供应商编号:&quot; + fruitProvider.id() + &quot; 供应商名称:&quot;                        + fruitProvider.name() + &quot; 供应商地址:&quot;+ fruitProvider.address();                System.out.println(strFruitProvicer);            }        }    }}public class FruitRun {    public static void main(String[] args) {        FruitInfoUtil.getFruitInfo(Apple.class);/***********输出结果***************/// 供应商编号:1 供应商名称:陕西红富士集团 供应商地址:陕西省西安市延    }}</code></pre><h1 id="JAVA-内部类"><a href="#JAVA-内部类" class="headerlink" title="JAVA 内部类"></a>JAVA 内部类</h1><blockquote><p>Java 类中不仅可以定义变量和方法,还可以定义类,这样定义在类内部的类就被称为内部类。根据定义的方式不同,内部类分为静态内部类,成员内部类,局部内部类,匿名内部类四种。</p></blockquote><p>静态内部类  </p><blockquote><p>定义在类内部的静态类,就是静态内部类。</p></blockquote><pre><code class="java">public class Out {    private static int a;    private int b;    public static class Inner {        public void print() {            System.out.println(a);            }    }}</code></pre><ol><li>静态内部类可以访问外部类所有的静态变量和方法,即使是 private 的也一样。</li><li>静态内部类和一般类一致,可以定义静态变量、方法,构造方法等。</li><li>其它类使用静态内部类需要使用“外部类.静态内部类”方式,如下所示:Out.Inner inner = new Out.Inner();inner.print();</li><li>Java 集合类 HashMap 内部就有一个静态内部类 Entry。Entry 是 HashMap 存放元素的抽象,HashMap 内部维护 Entry 数组用了存放元素,但是 Entry 对使用者是透明的。像这种和外部类关系密切的,且不依赖外部类实例的,都可以使用静态内部类。</li></ol><p>成员内部类  </p><blockquote><p>定义在类内部的非静态类,就是成员内部类。成员内部类不能定义静态方法和变量(final 修饰的除外)。这是因为成员内部类是非静态的,类初始化的时候先初始化静态成员,如果允许成员内部类定义静态变量,那么成员内部类的静态变量初始化顺序是有歧义的。</p></blockquote><pre><code class="java">public class Out {  private static int a;  private int b;  public class Inner {    public void print() {      System.out.println(a);      System.out.println(b);    }  }}</code></pre><p>局部内部类(定义在方法中的类)  </p><blockquote><p>定义在方法中的类,就是局部类。如果一个类只在某个方法中使用,则可以考虑使用局部类。</p></blockquote><pre><code class="java">public class Out {    private static int a;    private int b;    public void test(final int c) {        final int d = 1;        class Inner {            public void print() {                System.out.println(c);            }        }    }}</code></pre><p>匿名内部类(要继承一个父类或者实现一个接口、直接使用 new 来生成一个对象的引用) </p><blockquote><p>匿名内部类我们必须要继承一个父类或者实现一个接口,当然也仅能只继承一个父类或者实现一<br> 个接口。同时它也是没有 class 关键字,这是因为匿名内部类是直接使用 new 来生成一个对象的引<br> 用。</p></blockquote><pre><code class="java">public abstract class Bird {    private String name;    public String getName() {        return name;    }    public void setName(String name) {        this.name = name;    }    public abstract int fly();}public class Test {    public void test(Bird bird){        System.out.println(bird.getName() + &quot;能够飞 &quot; + bird.fly() + &quot;米&quot;);    }    public static void main(String[] args) {        Test test = new Test();        test.test(new Bird() {            public int fly() {                return 10000;            }            public String getName() {                return &quot;大雁&quot;;            }        });    }}</code></pre><h1 id="JAVA-泛型"><a href="#JAVA-泛型" class="headerlink" title="JAVA 泛型"></a>JAVA 泛型</h1><blockquote><p>泛型提供了编译时类型安全检测机制,该机制允许程序员在编译时检测到非法的类型。泛型的本<br> 质是参数化类型,也就是说所操作的数据类型被指定为一个参数。比如我们要写一个排序方法,<br> 能够对整型数组、字符串数组甚至其他任何类型的数组进行排序,我们就可以使用 Java 泛型。</p></blockquote><h2 id="泛型方法"><a href="#泛型方法" class="headerlink" title="泛型方法()"></a>泛型方法(<E>)</h2><blockquote><p>你可以写一个泛型方法,该方法在调用时可以接收不同类型的参数。根据传递给泛型方法的参数<br> 类型,编译器适当地处理每一个方法调用。</p></blockquote><pre><code class="java">// 泛型方法 printArraypublic static &lt; E &gt; void printArray( E[] inputArray ){    for ( E element : inputArray ){        System.out.printf( &quot;%s &quot;, element );    }}</code></pre><ol><li>&lt;? extends T&gt;表示该通配符所代表的类型是 T 类型的子类。</li><li>&lt;? super T&gt;表示该通配符所代表的类型是 T 类型的父类。</li></ol><h2 id="泛型类"><a href="#泛型类" class="headerlink" title="泛型类"></a>泛型类<T></h2><blockquote><p>泛型类的声明和非泛型类的声明类似,除了在类名后面添加了类型参数声明部分。和泛型方法一<br> 样,泛型类的类型参数声明部分也包含一个或多个类型参数,参数间用逗号隔开。一个泛型参数,<br> 也被称为一个类型变量,是用于指定一个泛型类型名称的标识符。因为他们接受一个或多个参数,<br> 这些类被称为参数化的类或参数化的类型。</p></blockquote><pre><code class="java">public class Box&lt;T&gt; {    private T t;    public void add(T t) {        this.t = t;        }    public T get() {        return t;    }</code></pre><h2 id="类型通配符"><a href="#类型通配符" class="headerlink" title="类型通配符?"></a>类型通配符?</h2><blockquote><p>类型通配符一般是使用 ? 代替具体的类型参数。例如<br> List&lt;?&gt; 在 逻 辑 上 是<br> List<String>,List<Integer> 等所有 List&lt;具体类型实参&gt;的父类。</p></blockquote><p>类型擦除  </p><blockquote><p>Java 中的泛型基本上都是在编译器这个层次来实现的。在生成的 Java 字节代码中是不包含泛<br> 型中的类型信息的。使用泛型的时候加上的类型参数,会被编译器在编译的时候去掉。这个<br> 过程就称为类型擦除。如在代码中定义的 List<Object>和 List<String>等类型,在编译之后<br> 都会变成 List。JVM 看到的只是 List,而由泛型附加的类型信息对 JVM 来说是不可见的。<br> 类型擦除的基本过程也比较简单,首先是找到用来替换类型参数的具体类。这个具体类一般<br> 是 Object。如果指定了类型参数的上界的话,则使用这个上界。把代码中的类型参数都替换<br> 成具体的类。</p></blockquote><h1 id="JAVA-序列化-创建可复用的-Java-对象"><a href="#JAVA-序列化-创建可复用的-Java-对象" class="headerlink" title="JAVA 序列化 ( 创建可复用的 Java 对象 )"></a>JAVA 序列化 ( 创建可复用的 Java 对象 )</h1><p>保存(持久化)对象及其状态到内存或者磁盘 </p><blockquote><p>Java 平台允许我们在内存中创建可复用的 Java 对象,但一般情况下,只有当 JVM 处于运行时,<br> 这些对象才可能存在,即,这些对象的生命周期不会比 JVM 的生命周期更长。但在现实应用中,<br> 就可能要求在 JVM 停止运行之后能够保存(持久化)指定的对象,并在将来重新读取被保存的对象。<br> Java 对象序列化就能够帮助我们实现该功能。</p></blockquote><p>序列化对象以字节数组保持-静态成员不保存  </p><blockquote><p>使用 Java 对象序列化,在保存对象时,会把其状态保存为一组字节,在未来,再将这些字节组装<br> 成对象。必须注意地是,对象序列化保存的是对象的”状态”,即它的成员变量。由此可知,对<br> 象序列化不会关注类中的静态变量。</p></blockquote><p>序列化用户远程对象传输  </p><blockquote><p>除了在持久化对象时会用到对象序列化之外,当使用 RMI(远程方法调用),或在网络中传递对象时,<br> 都会用到对象序列化。Java 序列化 API 为处理对象序列化提供了一个标准机制,该 API 简单易用。</p></blockquote><p>Serializable 实现序列化  </p><blockquote><p>在 Java 中,只要一个类实现了 java.io.Serializable 接口,那么它就可以被序列化。</p></blockquote><p>ObjectOutputStream 和 ObjectInputStream 对对象进行序列化及反序列化  </p><blockquote><p>通过 ObjectOutputStream 和 ObjectInputStream 对对象进行序列化及反序列化。</p></blockquote><p>writeObject 和 readObject 自定义序列化策略  </p><blockquote><p>在类中增加 writeObject 和 readObject 方法可以实现自定义序列化策略。</p></blockquote><p>序列化 ID  </p><blockquote><p>虚拟机是否允许反序列化,不仅取决于类路径和功能代码是否一致,一个非常重要的一点是两个<br> 类的序列化 ID 是否一致(就是 private static final long serialVersionUID)</p></blockquote><h3 id="序列化并不保存静态变量"><a href="#序列化并不保存静态变量" class="headerlink" title="序列化并不保存静态变量"></a>序列化并不保存静态变量</h3><p>序列化子父类说明  </p><blockquote></blockquote><p>Transient 关键字阻止该变量被序列化到文件中  </p><blockquote><p>1.在变量声明前加上 Transient 关键字,可以阻止该变量被序列化到文件中,在被反序列<br> 化后,transient 变量的值被设为初始值,如 int 型的是 0,对象型的是 null。</p></blockquote><blockquote><p>2.服务器端给客户端发送序列化对象数据,对象中有一些数据是敏感的,比如密码字符串<br> 等,希望对该密码字段在序列化时,进行加密,而客户端如果拥有解密的密钥,只有在<br> 客户端进行反序列化时,才可以对密码进行读取,这样可以一定程度保证序列化对象的<br> 数据安全。</p></blockquote><h1 id="JAVA-复制"><a href="#JAVA-复制" class="headerlink" title="JAVA 复制"></a>JAVA 复制</h1><blockquote><p>将一个对象的引用复制给另外一个对象,一共有三种方式。第一种方式是直接赋值,第二种方式<br> 是浅拷贝,第三种是深拷贝。所以大家知道了哈,这三种概念实际上都是为了拷贝对象。</p></blockquote><p>直接赋值复制  </p><blockquote><p>直接赋值。在 Java 中,A a1 = a2,我们需要理解的是这实际上复制的是引用,也就是<br> 说 a1 和 a2 指向的是同一个对象。因此,当 a1 变化的时候,a2 里面的成员变量也会跟<br> 着变化。</p></blockquote><p>浅复制(复制引用但不复制引用的对象)  </p><blockquote><p>创建一个新对象,然后将当前对象的非静态字段复制到该新对象,如果字段是值类型的,<br> 那么对该字段执行复制;如果该字段是引用类型的话,则复制引用但不复制引用的对象。<br> 因此,原始对象及其副本引用同一个对象。</p></blockquote><pre><code class="java">class Resume implements Cloneable{    public Object clone() {        try {            return (Resume)super.clone();        } catch (Exception e) {            e.printStackTrace();            return null;        }    }}</code></pre><p>深复制(复制对象和其应用对象)  </p><blockquote><p>深拷贝不仅复制对象本身，而且复制对象包含的引用指向的所有对象</p></blockquote><pre><code class="java">class Student implements Cloneable {    String name;    int age;    Professor p;    Student(String name, int age, Professor p) {        this.name = name;        this.age = age;        this.p = p;    }    public Object clone() {        Student o = null;        try {            o = (Student) super.clone();        } catch (CloneNotSupportedException e) {            System.out.println(e.toString());        }        o.p = (Professor) p.clone();        return o;    }}</code></pre><p>序列化(深 clone 一中实现) </p><blockquote><p>在 Java 语言里深复制一个对象,常常可以先使对象实现 Serializable 接口,然后把对象(实际上只是对象的一个拷贝)写到一个流里,再从流里读出来,便可以重建对象。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ubuntu开发环境配置</title>
    <link href="/2020/06/25/Ubuntu%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <url>/2020/06/25/Ubuntu%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h1><p><a href="https://ubuntu.com/download/desktop" target="_blank" rel="noopener">镜像下载地址</a></p><blockquote><p>下载后制作成启动盘就可以安装系统了</p></blockquote><h1 id="挂载磁盘"><a href="#挂载磁盘" class="headerlink" title="挂载磁盘"></a>挂载磁盘</h1><blockquote></blockquote><h1 id="常用软件安装"><a href="#常用软件安装" class="headerlink" title="常用软件安装"></a>常用软件安装</h1><h3 id="JetBrains-系列"><a href="#JetBrains-系列" class="headerlink" title="JetBrains 系列"></a>JetBrains 系列</h3><ul><li><a href="">Android Studio</a></li><li><a href="">CLion</a></li><li><a href="">DataGrip</a></li><li><a href="">Intelli IDEA</a></li><li><a href="">GoLand</a></li><li><a href="">Pycharm</a></li><li><a href="">WebStorm</a></li></ul><h3 id="浏览器"><a href="#浏览器" class="headerlink" title="浏览器"></a>浏览器</h3><ul><li><a href="">Chrome</a></li><li><a href="">Chromium</a></li><li><a href="">Firefox</a></li></ul><h3 id="开发工具"><a href="#开发工具" class="headerlink" title="开发工具"></a>开发工具</h3><ul><li><a href="">Redis Desktop Manager</a></li><li><a href="">Sublime Text</a></li><li><a href="https://sunlogin.oray.com/" target="_blank" rel="noopener">Sunlogin Client</a></li><li><a href="">Teamview</a></li><li><a href="">Xmind ZEN</a></li><li><a href="https://www.wps.cn/product/wpslinux" target="_blank" rel="noopener">WPS</a></li><li><a href="https://github.com/nashaofu/dingtalk" target="_blank" rel="noopener">DingTalk</a></li></ul><h3 id="其他软件"><a href="#其他软件" class="headerlink" title="其他软件"></a>其他软件</h3><ul><li><a href="https://github.com/kinget007/electron-ssr" target="_blank" rel="noopener">electron-ssr</a></li><li><a href="">FileZilla</a></li><li><a href="https://github.com/getlantern/lantern" target="_blank" rel="noopener">lantern</a></li><li><a href="">Remmina</a></li><li><a href="">VirtualBox</a></li><li><a href="">网易云音乐</a></li><li><a href="">shougou输入法</a></li><li><a href="">SimpleScreenRecorder</a></li></ul><h3 id="社交软件"><a href="#社交软件" class="headerlink" title="社交软件"></a>社交软件</h3><ul><li><a href="https://gitee.com/wszqkzqk/deepin-wine-for-ubuntu" target="_blank" rel="noopener">QQ</a></li><li><a href="https://gitee.com/wszqkzqk/deepin-wine-for-ubuntu" target="_blank" rel="noopener">Wechat</a></li><li><a href="https://gitee.com/wszqkzqk/deepin-wine-for-ubuntu" target="_blank" rel="noopener">TIM</a>  </li></ul><p>解决非中文系统中文乱码问题</p><pre><code class="jshelllanguage">在/opt/deepinwine/tools/run.sh 和 run_v2.sh 中将 WINE_CMD 那一行修改为 WINE_CMD=&quot;LC_ALL=zh_CN.UTF-8 deepin-wine&quot;</code></pre><h1 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h1><ul><li>JDK</li><li>Golang</li><li>Docker</li><li>Nodejs</li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Ubuntu</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MySQL底层实现机制</title>
    <link href="/2020/06/08/MySQL%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/"/>
    <url>/2020/06/08/MySQL%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ul><li>数据库中最常见的慢查询优化方式是什么？</li><li>为什么加索引能优化查询？</li><li>你知道哪些数据结构可以提高查询速度？</li><li>那这些数据结构既然都能优化查询速度，MySQL为什么选择B+TREE</li><li></li></ul><h1 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>数据库存储引擎是数据库底层软件组织,数据库管理系统(DBMS)使用数据引擎进行创建、查询、更新和删除数据。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能,使用不同的存储引擎,还可以 获得特定的功能。现在许多不同的数据库管理系统都支持多种不同的数据引擎。存储引擎主要有: 1. MyIsam , 2. InnoDB, 3. Memory, 4. Archive, 5. Federated 。</p><h2 id="InnoDB-B-树"><a href="#InnoDB-B-树" class="headerlink" title="InnoDB( B+树 )"></a>InnoDB( B+树 )</h2><p>InnoDB 底层存储结构为 B+树, B 树的每个节点对应 innodb 的一个 page,page 大小是固定的,一般设为 16k。其中非叶子节点只有键值,叶子节点包含完成数据。</p><p><img src="/resource/img/innodb.png" srcset="/img/loading.gif" alt="avatar"></p><p>适用场景:<br>1)经常更新的表,适合处理多重并发的更新请求。<br>2)支持事务。<br>3)可以从灾难中恢复(通过 bin-log 日志等)。<br>4)外键约束。只有他支持外键。<br>5)支持自动增加列属性 auto_increment。</p><h2 id="TokuDB-Fractal-Tree-节点带数据"><a href="#TokuDB-Fractal-Tree-节点带数据" class="headerlink" title="TokuDB( Fractal Tree-节点带数据 )"></a>TokuDB( Fractal Tree-节点带数据 )</h2><p>TokuDB 底层存储结构为 <code>Fractal Tree</code>,<code>Fractal Tree</code> 的结构与 B+树有些类似, 在 Fractal Tree中,每一个 child 指针除了需要指向一个 child 节点外,还会带有一个 Message Buffer ,这个Message Buffer 是一个 FIFO 的队列,用来缓存更新操作。</p><p>例如,一次插入操作只需要落在某节点的 Message Buffer 就可以马上返回了,并不需要搜索到叶子节点。这些缓存的更新会在查询时或后台异步合并应用到对应的节点中。TokuDB 在线添加索引,不影响读写操作, 非常快的写入性能, Fractal-tree 在事务实现上有优势。 他主要适用于访问频率不高的数据或历史数据归档。</p><h2 id="MyIASM"><a href="#MyIASM" class="headerlink" title="MyIASM"></a>MyIASM</h2><p>MyIASM 是 MySQL 默认的引擎,但是它没有提供对数据库事务的支持,也不支持行级锁和外键,因此当 INSERT(插入)或 UPDATE(更新)数据时即写操作需要锁定整个表,效率便会低一些。<br>ISAM 执行读取操作的速度很快,而且不占用大量的内存和存储资源。在设计之初就预想数据组织成有固定长度的记录,按顺序存储的。—ISAM 是一种静态索引结构。缺点是它不 支持事务处理。</p><h2 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h2><p>Memory(也叫 HEAP)堆内存:使用存在内存中的内容来创建表。每个 MEMORY 表只实际对应一个磁盘文件。MEMORY 类型的表访问非常得快,因为它的数据是放在内存中的,并且默认使用HASH 索引。但是一旦服务关闭,表中的数据就会丢失掉。 Memory 同时支持散列索引和 B 树索引,B 树索引可以使用部分查询和通配查询,也可以使用&lt;,&gt;和&gt;=等操作符方便数据挖掘,散列索引相等的比较快但是对于范围的比较慢很多。</p><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><blockquote><p>索引(Index)是帮助 MySQL 高效获取数据的数据结构。常见的查询算法,<code>顺序查找</code>,<code>二分查找</code>,<code>二叉排序树查找</code>,<code>哈希散列法</code>,<code>分块查找</code>,<code>平衡多路搜索树 B 树(B-tree)</code></p></blockquote><h2 id="常见索引原则有"><a href="#常见索引原则有" class="headerlink" title="常见索引原则有"></a>常见索引原则有</h2><ol><li>选择唯一性索引</li><li>唯一性索引的值是唯一的,可以更快速的通过该索引来确定某条记录。</li><li>为经常需要排序、分组和联合操作的字段建立索引:<br>3 .为常作为查询条件的字段建立索引。<br>4 .限制索引的数目:<br>越多的索引,会使更新表变得很浪费时间。<br>尽量使用数据量少的索引</li><li>如果索引的值很长,那么查询的速度会受到影响。<br>尽量使用前缀来索引</li><li>如果索引字段的值很长,最好使用值的前缀来索引。<br>7 .删除不再使用或者很少使用的索引<br>8 . 最左前缀匹配原则,非常重要的原则。<br>10 . 尽量选择区分度高的列作为索引<br>区分度的公式是表示字段不重复的比例<br>11 . 索引列不能参与计算,保持列“干净”:带函数的查询不参与索引。<br>12 . 尽量的扩展索引,不要新建索引。</li></ol><h2 id="数据库三范式"><a href="#数据库三范式" class="headerlink" title="数据库三范式"></a>数据库三范式</h2><p>范式是具有最小冗余的表结构。范式具体如下:</p><p>第一范式(1st NF -列都是不可再分)<br>第一范式的目标是确保每列的原子性:如果每列都是不可再分的最小数据单元(也称为最小的原子单元),则满足第一范式(1NF)</p><p><img src="/resource/img/1st-nf.png" srcset="/img/loading.gif" alt="avatar"></p><p>首先满足第一范式,并且表中非主键列不存在对主键的部分依赖。 第二范式要求每个表只描述一件事情。</p><p><img src="/resource/img/2st-nf.png" srcset="/img/loading.gif" alt="avatar"></p><p>第三范式(3rd NF- 不存在对非主键列的传递依赖)<br>第三范式定义是,满足第二范式,并且表中的列不存在对非主键列的传递依赖。除了主键订单编号外,顾客姓名依赖于非主键顾客编号。</p><p><img src="/resource/img/3st-nf.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="数据库是事务"><a href="#数据库是事务" class="headerlink" title="数据库是事务"></a>数据库是事务</h2><blockquote><p>事务(TRANSACTION)是作为单个逻辑工作单元执行的一系列操作,这些操作作为一个整体一起向系统提交,要么都执行、要么都不执行 。事务是一个不可分割的工作逻辑单元事务必须具备以下四个属性,简称 ACID 属性:</p></blockquote><h3 id="原子性-Atomicity"><a href="#原子性-Atomicity" class="headerlink" title="原子性( Atomicity )"></a>原子性( Atomicity )</h3><p>1.事务是一个完整的操作。事务的各步操作是不可分的(原子的);要么都执行,要么都不执行。</p><h3 id="一致性-Consistency"><a href="#一致性-Consistency" class="headerlink" title="一致性( Consistency )"></a>一致性( Consistency )</h3><p>2.当事务完成时,数据必须处于一致状态</p><p>隔离性( Isolation )</p><p>3.对数据进行修改的所有并发事务是彼此隔离的,这表明事务必须是独立的,它不应以任何方式依赖于或影响其他事务。</p><p>永久性( Durability )</p><p>4.事务完成后,它对数据库的修改被永久保持,事务日志能够保持事务的永久性。</p><h1 id="存储过程-特定功能的-SQL-语句集"><a href="#存储过程-特定功能的-SQL-语句集" class="headerlink" title="存储过程(特定功能的 SQL 语句集)"></a>存储过程(特定功能的 SQL 语句集)</h1><blockquote><p>一组为了完成特定功能的 SQL 语句集,存储在数据库中,经过第一次编译后再次调用不需要再次编译,用户通过指定存储过程的名字并给出参数(如果该存储过程带有参数)来执行它。存储过程是数据库中的一个重要对象。</p></blockquote><p>存储过程优化思路:</p><ol><li>尽量利用一些 sql 语句来替代一些小循环,例如聚合函数,求平均函数等。</li><li>中间结果存放于临时表,加索引。</li><li>少使用游标。sql 是个集合语言,对于集合运算具有较高性能。而 cursors 是过程运算。比如对一个 100 万行的数据进行查询。游标需要读表 100 万次,而不使用游标则只需要少量几次读取。</li><li>事务越短越好。sqlserver 支持并发操作。如果事务过多过长,或者隔离级别过高,都会造成并发操作的阻塞,死锁。导致查询极慢,cpu 占用率极地。</li><li>使用 try-catch 处理错误异常。</li><li>查找语句尽量不要放在循环内。</li></ol><h1 id="触发器-一段能自动执行的程序"><a href="#触发器-一段能自动执行的程序" class="headerlink" title="触发器(一段能自动执行的程序)"></a>触发器(一段能自动执行的程序)</h1><blockquote><p>触发器是一段能自动执行的程序,是一种特殊的存储过程,触发器和普通的存储过程的区别是:<br>触发器是当对某一个表进行操作时触发。诸如:update、insert、delete 这些操作的时候,系统<br>会自动调用执行该表上对应的触发器。SQL Server 2005 中触发器可以分为两类:DML 触发器和<br>DDL 触发器,其中 DDL 触发器它们会影响多种数据定义语言语句而激发,这些语句有 create、alter、drop 语句。</p></blockquote><h1 id="数据库并发策略"><a href="#数据库并发策略" class="headerlink" title="数据库并发策略"></a>数据库并发策略</h1><p>并发控制一般采用三种方法,分别是乐观锁和悲观锁以及时间戳。</p><h1 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h1><p>乐观锁认为一个用户读数据的时候,别人不会去写自己所读的数据;悲观锁就刚好相反,觉得自己读数据库的时候,别人可能刚好在写自己刚读的数据,其实就是持一种比较保守的态度;时间戳就是不加锁,通过时间戳来控制并发出现的问题。</p><h1 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h1><p>悲观锁就是在读取数据的时候,为了不让别人修改自己读取的数据,就会先对自己读取的数据加锁,只有自己把数据读完了,才允许别人修改那部分数据,或者反过来说,就是自己修改某条数据的时候,不允许别人读取该数据,只有等自己的整个事务提交了,才释放自己加上的锁,才允许其他用户访问那部分数据。</p><h1 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h1><p>时间戳就是在数据库表中单独加一列时间戳,比如“TimeStamp”,每次读出来的时候,把该字段也读出来,当写回去的时候,把该字段加 1,提交之前 ,跟数据库的该字段比较一次,如果比数据库的值大的话,就允许保存,否则不允许保存,这种处理方法虽然不使用数据库系统提供的锁机制,但是这种方法可以大大提高数据库处理的并发量,以上悲观锁所说的加“锁”,其实分为几种锁,分别是:排它锁(写锁)和共享锁(读锁)。</p><h1 id="数据库锁"><a href="#数据库锁" class="headerlink" title="数据库锁"></a>数据库锁</h1><h2 id="行级锁"><a href="#行级锁" class="headerlink" title="行级锁"></a>行级锁</h2><p>行级锁是一种排他锁,防止其他事务修改此行;在使用以下语句时,Oracle 会自动应用行级锁:</p><ol><li>INSERT、UPDATE、DELETE、SELECT … FOR UPDATE [OF columns] [WAIT n | NOWAIT];</li><li>SELECT … FOR UPDATE 语句允许用户一次锁定多条记录进行更新</li><li>使用 COMMIT 或 ROLLBACK 语句释放锁。</li></ol><h2 id="表级锁"><a href="#表级锁" class="headerlink" title="表级锁"></a>表级锁</h2><blockquote><p>表示对当前操作的整张表加锁,它实现简单,资源消耗较少,被大部分 MySQL 引擎支持。最常使用的 MYISAM 与 INNODB 都支持表级锁定。表级锁定分为表共享读锁(共享锁)与表独占写锁(排他锁)。</p></blockquote><h2 id="页级锁"><a href="#页级锁" class="headerlink" title="页级锁"></a>页级锁</h2><blockquote><p>页级锁是 MySQL 中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快,但冲突多,行级冲突少,但速度慢。所以取了折衷的页级,一次锁定相邻的一组记录。BDB 支持页级锁</p></blockquote><p>1.基于 Redis 分布式锁</p><ol><li><p>获取锁的时候,使用 setnx(SETNX key val:当且仅当 key 不存在时,set 一个 key为 val 的字符串,返回 1;若 key 存在,则什么都不做,返回 0)加锁,锁的 value值为一个随机生成的 UUID,在释放锁的时候进行判断。并使用 expire 命令为锁添加一个超时时间,超过该时间则自动释放锁。</p></li><li><p>获取锁的时候调用 setnx,如果返回 0,则该锁正在被别人使用,返回 1 则成功获取锁。 还设置一个获取的超时时间,若超过这个时间则放弃获取锁。</p></li><li><p>释放锁的时候,通过 UUID 判断是不是该锁,若是该锁,则执行 delete 进行锁释放。</p></li></ol><h2 id="分区分表"><a href="#分区分表" class="headerlink" title="分区分表"></a>分区分表</h2><p>分库分表有垂直切分和水平切分两种。</p><h3 id="垂直切分-按照功能模块"><a href="#垂直切分-按照功能模块" class="headerlink" title="垂直切分 ( 按照功能模块 )"></a>垂直切分 ( 按照功能模块 )</h3><p>将表按照功能模块、关系密切程度划分出来,部署到不同的库上。例如,我们会建立定义数据库 workDB、商品数据库 payDB、用户数据库 userDB、日志数据库 logDB 等,分别用于存储项目数据定义表、商品定义表、用户数据表、日志数据表等。</p><p><img src="/resource/img/vertical-partitioning.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="水平切分-按照规则划分存储"><a href="#水平切分-按照规则划分存储" class="headerlink" title="水平切分 ( 按照规则划分存储 )"></a>水平切分 ( 按照规则划分存储 )</h3><p>当一个表中的数据量过大时,我们可以把该表的数据按照某种规则,例如 userID 散列,进行划分,然后存储到多个结构相同的表,和不同的库上。</p><p><img src="/resource/img/horizontal-partitioning.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="两阶段提交协议"><a href="#两阶段提交协议" class="headerlink" title="两阶段提交协议"></a>两阶段提交协议</h3><p>分布式事务是指会涉及到操作多个数据库的事务,在分布式系统中,各个节点之间在物理上相互独立,通过网络进行沟通和协调。</p><p>XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范(即接口函数),交易中间件<br>用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。<br>二阶段提交(Two-phaseCommit)是指,在计算机网络以及数据库领域内,为了使基于分布式系统<br>架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。通常,二阶段提<br>交也被称为是一种协议(Protocol))。在分布式系统中,每个节点虽然可以知晓自己的操作时成功<br>或者失败,却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时,为了保持事<br>务的 ACID 特性,需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并<br>最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此,<br>二阶段提交的算法思路可以概括为:参与者将操作成败通知协调者,再由协调者根据所有参与者<br>的反馈情报决定各参与者是否要提交操作还是中止操作。</p><ul><li><p>准备阶段</p><blockquote><p>事务协调者(事务管理器)给每个参与者(资源管理器)发送 Prepare 消息,每个参与者要么直接返回<br>失败(如权限验证失败),要么在本地执行事务,写本地的 redo 和 undo 日志,但不提交,到达一<br>种“万事俱备,只欠东风”的状态。</p></blockquote></li><li><p>提交阶段</p><blockquote><p>如果协调者收到了参与者的失败消息或者超时,直接给每个参与者发送回滚(Rollback)消息;否则,<br>发送提交(Commit)消息;参与者根据协调者的指令执行提交或者回滚操作,释放所有事务处理过<br>程中使用的锁资源。(注意:必须在最后阶段释放锁资源)</p></blockquote></li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>同步阻塞问题<br>1、 执行过程中,所有参与节点都是事务阻塞型的。</p><p>单点故障<br>2、 由于协调者的重要性,一旦协调者发生故障。参与者会一直阻塞下去。</p><p>数据不一致(脑裂问题)<br>3、 在二阶段提交的阶段二中,当协调者向参与者发送 commit 请求之后,发生了局部网络异常或者在发送 commit 请求过程中协调者发生了故障,导致只有一部分参与者接受到了commit 请求。于是整个分布式系统便出现了数据部一致性的现象(脑裂现象)。</p><p>二阶段无法解决的问题(数据状态不确定)<br>4、 协调者再发出 commit 消息之后宕机,而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者,这条事务的状态也是不确定的,没人知道事务是否被已经提交。</p><p>三阶段提交协议</p><p>三 阶 段 提 交 ( Three-phase commit ) , 也 叫 三 阶 段 提 交 协 议 ( Three-phase commit protocol),是二阶段提交(2PC)的改进版本。</p><p>与两阶段提交不同的是,三阶段提交有两个改动点。</p><p>1、引入超时机制。同时在协调者和参与者中都引入超时机制。<br>2、在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。也就是说,除了引入超时机制之外,3PC 把 2PC 的准备阶段再次一分为二,这样三阶段提交就有 CanCommit、PreCommit、DoCommit 三个阶段。</p><h2 id="CanCommit-阶段"><a href="#CanCommit-阶段" class="headerlink" title="CanCommit 阶段"></a>CanCommit 阶段</h2><p>协调者向参与者发送 commit 请求,参与者如果可以提交就返回 Yes 响应,否则返回 No 响应。</p><h2 id="PreCommit-阶段"><a href="#PreCommit-阶段" class="headerlink" title="PreCommit 阶段"></a>PreCommit 阶段</h2><p>协调者根据参与者的反应情况来决定是否可以继续进行,有以下两种可能。假如协调者从所有的参与者获得的反馈都是 Yes 响应,那么就会执行事务的预执行假如有任何一个参与者向协调者发送了 No 响应,或者等待超时之后,协调者都没有接到参与者的响应,那么就执行事务的中断。</p><h2 id="doCommit-阶段"><a href="#doCommit-阶段" class="headerlink" title="doCommit 阶段"></a>doCommit 阶段</h2><p>该阶段进行真正的事务提交,主要包含 1.协调这发送提交请求 2.参与者提交事务 3.参与者响应反馈( 事务提交完之后,向协调者发送 Ack 响应。)4.协调者确定完成事务。</p><h2 id="柔性事务"><a href="#柔性事务" class="headerlink" title="柔性事务"></a>柔性事务</h2><blockquote><p>在电商领域等互联网场景下,传统的事务在数据库性能和处理能力上都暴露出了瓶颈。在分布式领域基于 CAP 理论以及 BASE 理论,有人就提出了 柔性事务 的概念。CAP(一致性、可用性、分区容忍性)理论大家都理解很多次了,这里不再叙述。说一下 BASE 理论,它是在 CAP 理论的基础之上的延伸。包括 基本可用(Basically Available)、柔性状态(Soft State)、最终一致性(Eventual Consistency)。</p></blockquote><p>通常所说的柔性事务分为:两阶段型、补偿型、异步确保型、最大努力通知型几种。</p><p>两阶段型<br>1、 就是分布式事务两阶段提交,对应技术上的 XA、JTA/JTS。这是分布式环境下事务处理的</p><p>典型模式。<br>补偿型<br>2、 TCC 型事务(Try/Confirm/Cancel)可以归为补偿型。</p><p>WS-BusinessActivity 提供了一种基于补偿的 long-running 的事务处理模型。服务器 A 发起事务,服务器 B 参与事务,服务器 A 的事务如果执行顺利,那么事务 A 就先行提交,如果事务 B 也执行顺利,则事务 B 也提交,整个事务就算完成。但是如果事务 B 执行失败,事务 B 本身回滚,这时事务 A 已经被提交,所以需要执行一个补偿操作,将已经提交的事务 A 执行的操作作反操作,恢复到未执行前事务 A 的状态。这样的 SAGA 事务模型,是牺牲了一定的隔离性和一致性的,但是提高了 long-running 事务的可用性。</p><p><img src="/resource/img/soft-transcation.png" srcset="/img/loading.gif" alt="avatar"></p><p>异步确保型<br>3、 通过将一系列同步的事务操作变为基于消息执行的异步操作, 避免了分布式事务中的同步阻塞操作的影响。</p><p><img src="/resource/img/async-sure.png" srcset="/img/loading.gif" alt="avatar"></p><p>最大努力通知型(多次尝试)<br>4、 这是分布式事务中要求最低的一种, 也可以通过消息中间件实现, 与前面异步确保型操作不同的一点是, 在消息由 MQ Server 投递到消费者之后, 允许在达到最大重试次数之后正常结束事务。</p><h1 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h1><p>CAP 原则又称 CAP 定理,指的是在一个分布式系统中, Consistency(一致性)、 Availability(可用性)、Partition tolerance(分区容错性),三者不可得兼。</p><h2 id="一致性-C"><a href="#一致性-C" class="headerlink" title="一致性(C):"></a>一致性(C):</h2><p>1.在分布式系统中的所有数据备份,在同一时刻是否同样的值。(等同于所有节点访问同一份最新的数据副本)</p><h2 id="可用性-A"><a href="#可用性-A" class="headerlink" title="可用性(A):"></a>可用性(A):</h2><p>2.在集群中一部分节点故障后,集群整体是否还能响应客户端的读写请求。(对数据更新具备高可用性)</p><h2 id="分区容忍性-P"><a href="#分区容忍性-P" class="headerlink" title="分区容忍性(P) :"></a>分区容忍性(P) :</h2><p>3.以实际效果而言,分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性,就意味着发生了分区的情况,必须就当前操作在 C 和 A 之间做出选择。</p><h1 id="资料"><a href="#资料" class="headerlink" title="资料"></a>资料</h1><ul><li><p><a href="https://www.bilibili.com/video/BV1Ez411B7X2/" target="_blank" rel="noopener">视频</a></p></li><li><p><a href="https://my.oschina.net/u/585635/blog/4547089" target="_blank" rel="noopener">Mysql Explain 详解</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>RDB</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java面试问题汇总</title>
    <link href="/2020/05/31/Java%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/"/>
    <url>/2020/05/31/Java%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="美团面试题"><a href="#美团面试题" class="headerlink" title="美团面试题"></a>美团面试题</h1><ul><li><p>请解释一下对象的创建过程？（半初始化）</p><blockquote><p>申请一块内存，给它赋值默认值（8大类型都有自己的默认值，此时为半初始化状态），然后调用构造方法，赋初始值，然后建立关联线程上锁需要两遍检查，DCL= double check lock，开始的时候判断是否为空，加锁，进去后再判断实例是否为空，然后再进行执行，检查两遍。</p></blockquote><p>Volatile ：保持线程可见性，禁止指令重排序(谁先请求的，就先返回谁，然后再进行下一个指令。)</p></li><li><p>加问DCL与volatile问题？（指令重排序）</p><blockquote><p>Double Check Lock<br>如果没有禁止指令重排，第一个线程来了会进行版初始化状态，让t不为空，第二个线程来了判断t不为空，直接使用半初始化状态的值，出现不同的异常状态。因此要加上volatile，禁止指令重排序(对内存区域加了volatile，对这个内存限制)。[订单更新的时候会有更新]</p></blockquote></li><li><p>对象在内存中的存储布局？（对象与数组的存储不同）</p><pre><code class="text">普通对象和数组不同。普通对象有四项：占用16个字节markword(标记用，放锁状态年龄 hashcode等)、 8个字节类型指针classpointer(指向属于哪个类型 a.class)、4个字节实例数据instance data(存放实例数据int a = new int[0],存放a)、对齐padding(前面三个内容的位数不是8的倍数(读一块内容的时候，整块读最快)，则补上) 4个字节，JOL能将能将对象打印出来，打印布局。数组对象有5项：markword(标记用，放锁状态年龄 hashcode等)、 8个字节类型指针classpointer(指向属于哪个类型 a.class)、4个字节数组长度实例数据instance data(存放实例数据int a = new int[0],存放a)、对齐padding(前面三个内容的位数不是8的倍数(读一块内容的时候，整块读最快)，则补上) 4个字节，</code></pre></li><li><p>对象头具体包括什么？（markword klasspointer）synchronized锁信息？</p><blockquote><p>最主要的内容：锁的信息。有一个锁升级的过程。<br>New— 偏向锁——自旋锁（无锁 lock-free 轻量级锁）— 重量级锁<br>偏向锁：贴标签<br>自旋锁：取消偏向锁，多个线程进行CAS竞争(先读出来，然后修改，再回去对比一下，如果值还是原来的，则贴上标签，加锁成功。)，   ABA问题，加个版本。自旋次数超过ncpu内存的一半，在jvm中进行抢占，则升级为重量级锁。<br>重量级锁：将线程放到队列里面，按照顺序执行</p></blockquote></li><li><p>对象怎么定位？（直接间接）</p><blockquote><p>在JVM中怎么指向对象。<br>1.句柄两次引用，效率低，唯一好处：垃圾回收的比较方便。<br>T在堆中通过实例数据指针倒找对象，通过类型数据指针在方法区找到t.class。<br>2.直接指针，平时常用<br>T指向堆中的类型数据指针，在方法区中找到t.class.</p></blockquote></li><li><p>对象怎么分配？（栈上－线程本地－Eden－Old）</p><blockquote><p>Start — new (优先在栈上分配，栈上分配的好处：方法没了之后，栈及没有了，不需要对栈内存进行gc回收。需要满足1.逃逸分析，2.标量替换。)—- 栈上空间够用，直接end，如果不够用，如果很大，看看老年代，可能会fullgec；如果不大，线程本次分配TLAB，年轻代分配里面分配内存，<br>栈上比堆上快一倍。(java 优化，参照c语言的struct，struck在栈上分配)<br>1.栈上分配：不会有逸出，没有别的线程访问(没有别的方法使用)。直接使用成员两边替换这个对象。满足以上两个条件则可以进行栈上分配。<br>e.g. User对象，有两个成员变量 id 和name，小内容的东西直接放在栈上，别的方法不会调用这个user对象；直接使用id和name代替user对象，直接放到栈上。<br>Gc回收一次，年龄加一，到达一定年龄则进行回收。age是4位，最大表示15.</p></blockquote></li><li><p>Object obj = new Object() 在内存中占用多少字节？</p><blockquote><p>在java中空对象占八个字节,对象的引用占四个字节。<br>普通对象指针 o 占用4个字节，正常占用8个字节，但是开启了压缩，所以是4个。<br>Object对象占用：16字节，如果有压缩的话，padding是4，如果没有压缩的话，padding是0，指针占用8个字节了。默认压缩。<br>4字节寻址的最大空间：指向的最大数字2*<em>4</em>8-1，32g<br>堆内存超过一定值，访问不到所有对象，压缩自动不起作用了，就算你自己扩展内存为48个g，结果发现对象跟32g一样，内存自动膨胀了。</p></blockquote></li><li><p>为什么hotspot不使用C++对象来代表java对象？</p><blockquote><p>C++对象具有虚函数表，如果使用C++对象代表Java对象它所占的空间就会较大</p></blockquote></li><li><p>Class对象是在堆区还是方法区？</p><blockquote><p>在方法区(跟HotSpot版本有关系)</p></blockquote></li></ul><blockquote><p>JDK1.7:Method Area (接口)　-&gt;　Perm Generation(实现)<br>JDK1.8:Method Area (接口)　-&gt;　MetaSpace(实现)</p></blockquote><p><a href="https://docs.oracle.com/javase/specs/jvms/se6/html/VMSpecTOC.doc.html" target="_blank" rel="noopener">Java虚拟机规范</a></p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>基础</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JAVA 多线程并发</title>
    <link href="/2020/05/30/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91/"/>
    <url>/2020/05/30/JAVA-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%B9%B6%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h1 id="Java-并发知识库"><a href="#Java-并发知识库" class="headerlink" title="Java 并发知识库"></a>Java 并发知识库</h1><p><img src="/resource/img/thread.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Java线程实现-创建方式"><a href="#Java线程实现-创建方式" class="headerlink" title="Java线程实现/创建方式"></a>Java线程实现/创建方式</h1><h2 id="继承Thread"><a href="#继承Thread" class="headerlink" title="继承Thread"></a>继承Thread</h2><blockquote><p>Thread类本质上是实现了<code>Runnable</code>接口的一个实例，代表一个线程的实例。启动线程的唯一方法就是通过<code>Thread</code>类的<code>start</code>实例方法。start方法是一个native方法，它将启动一个新的线程，并执行run()方法。</p></blockquote><pre><code class="java">public class MyThread extends Thread {    public void run() {        System.out.println(&quot;MyThread.run()&quot;);    }}MyThread myThread = new MyThread();myThread.start();</code></pre><h2 id="实现Runnable接口"><a href="#实现Runnable接口" class="headerlink" title="实现Runnable接口"></a>实现Runnable接口</h2><blockquote><p>实现Runnable接口</p></blockquote><p>如果自己的类已经extends另一个类，就无法直接extends Thread此时，可以实现一个Runnable接口。</p><pre><code class="java">public class MyThread extends OtherClass implements Runnable {    public void run () {        System.out.println(&quot;MyThread.run()&quot;);    }}//启动 MyThread,需要首先实例化一个 Thread,并传入自己的 MyThread 实例:MyThread myThread = new MyThread();Thread thread = new Thread(myThread);thread.start();//事实上,当传入一个 Runnable target 参数给 Thread 后,Thread 的 run()方法就会调用target.run()public void run() {    if (target != null) {        target.run();    }}</code></pre><h2 id="执行器方式"><a href="#执行器方式" class="headerlink" title="执行器方式"></a>执行器方式</h2><blockquote><p>有返回值的任务必须实现 Callable 接口,类似的,无返回值的任务必须 Runnable 接口。执行Callable 任务后,可以获取一个 Future 的对象,在该对象上调用 get 就可以获取到 Callable 任务返回的 Object 了,再结合线程池接口 ExecutorService 就可以实现传说中有返回结果的多线程了。</p></blockquote><pre><code class="java">//创建一个线程池ExecutorService pool = Executors.newFixedThreadPool(taskSize);// 创建多个有返回值的任务List&lt;Future&gt; list = new ArrayList&lt;Future&gt;();for (int i = 0; i &lt; taskSize; i++) {Callable c = new MyCallable(i + &quot; &quot;);// 执行任务并获取 Future 对象Future f = pool.submit(c);list.add(f);}// 关闭线程池pool.shutdown();// 获取所有并发任务的运行结果for (Future f : list) {// 从 Future 对象上获取任务的返回值,并输出到控制台System.out.println(&quot;res:&quot; + f.get().toString());}</code></pre><h2 id="线程池方式"><a href="#线程池方式" class="headerlink" title="线程池方式"></a>线程池方式</h2><blockquote><p>线程和数据库连接这些资源都是非常宝贵的资源。那么每次需要的时候创建,不需要的时候销毁,是非常浪费资源的。那么我们就可以使用缓存的策略,也就是使用线程池。</p></blockquote><pre><code class="java">// 创建线程池ExecutorService threadPool = Executors.newFixedThreadPool(10);while(true) {    threadPool.execute(new Runnable() { // 提交多个线程任务,并执行        @Override        public void run() {            System.out.println(Thread.currentThread().getName() + &quot; is running ..&quot;);        try {            Thread.sleep(3000);        } catch (InterruptedException e) {            e.printStackTrace();        }       }    });}</code></pre><h3 id="4种线程池"><a href="#4种线程池" class="headerlink" title="4种线程池"></a>4种线程池</h3><blockquote><p>Java 里面线程池的顶级接口是 Executor,但是严格意义上讲 Executor 并不是一个线程池,而只是一个执行线程的工具。真正的线程池接口是 ExecutorService。</p></blockquote><p><img src="/resource/img/threadpool.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li>NewCachedThreadPool<blockquote><p>创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用他们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能<br><code>调用 execute 将重用以前构造的线程(如果线程可用)。如果现有线程没有可用的,则创建一个新线程并添加到池中。终止并从缓存中移除那些已有 60 秒钟未被使用的线程。</code>因此,长时间保持空闲的线程池不会使用任何资源。</p></blockquote></li></ul><ul><li>newFixedThreadPool</li></ul><blockquote><p>创建一个可重用固定线程数的线程池,以共享的无界队列方式来运行这些线程。在任意点,在大<br> 多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务,<br> 则在有可用线程之前,附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何<br> 线程终止,那么一个新线程将代替它执行后续的任务(如果需要)。在某个线程被显式地关闭之<br> 前,池中的线程将一直存在。</p></blockquote><ul><li>newScheduledThreadPool</li></ul><blockquote><p>创建一个线程池,它可安排在给定延迟后运行命令或者定期地执行。</p></blockquote><pre><code class="java">public class ThreadPool {    public static void main(String[] args) {        ScheduledExecutorService scheduledThreadPool= Executors.newScheduledThreadPool(3);        scheduledThreadPool.schedule(new Runnable(){            @Override            public void run() {                System.out.println(&quot;延迟三秒&quot;);            }        }, 3, TimeUnit.SECONDS);        scheduledThreadPool.scheduleAtFixedRate(new Runnable(){            @Override            public void run() {                System.out.println(&quot;延迟 1 秒后每三秒执行一次&quot;);            }        },1,3,TimeUnit.SECONDS);    }}</code></pre><ul><li>newSingleThreadExecutor</li></ul><blockquote><p>Executors.newSingleThreadExecutor()返回一个线程池(这个线程池只有一个线程),这个线程池可以在线程死后(或发生异常时)重新启动一个线程来替代原来的线程继续执行下去!</p></blockquote><h1 id="线程生命周期-状态"><a href="#线程生命周期-状态" class="headerlink" title="线程生命周期(状态)"></a>线程生命周期(状态)</h1><blockquote><p>当线程被创建并启动以后,它既不是一启动就进入了执行状态,也不是一直处于执行状态。在线程的生命周期中,它要经过新建(New)、就绪(Runnable)、运行(Running)、阻塞(Blocked)和死亡(Dead)5 种状态。尤其是当线程启动以后,它不可能一直”霸占”着 CPU 独自运行,所以 CPU 需要在多条线程之间切换,于是线程状态也会多次在运行、阻塞之间切换</p></blockquote><ul><li><p>新建状态(NEW)<br>当程序使用 new 关键字创建了一个线程之后,该线程就处于新建状态,此时仅由 JVM 为其分配<br>内存,并初始化其成员变量的值</p></li><li><p>就绪状态(RUNNABLE):<br>当线程对象调用了 start()方法之后,该线程处于就绪状态。Java 虚拟机会为其创建方法调用栈和<br>程序计数器,等待调度运行。</p></li><li><p>运行状态(RUNNING):<br>如果处于就绪状态的线程获得了 CPU,开始执行 run()方法的线程执行体,则该线程处于运行状<br>态。</p></li><li><p>阻塞状态(BLOCKED):<br>阻塞状态是指线程因为某种原因放弃了 cpu 使用权,也即让出了 cpu timeslice,暂时停止运行。<br>直到线程进入可运行(runnable)状态,才有机会再次获得 cpu timeslice 转到运行(running)状<br>态。阻塞的情况分三种:</p><ul><li>等待阻塞( o.wait-&gt; 等待对列):<br>   运行(running)的线程执行 o.wait()方法,JVM 会把该线程放入等待队列(waitting queue)中。</li><li>同步阻塞 (lock-&gt; 锁池 )<br>   运行(running)的线程在获取对象的同步锁时,若该同步锁被别的线程占用,则 JVM 会把该线</li><li>程放入锁池(lock pool)中。</li></ul><p>其他阻塞 (sleep/join)</p><pre><code> - 运行(running)的线程执行 Thread.sleep(long ms)或 t.join()方法,或者发出了 I/O 请求时,JVM 会把该线程置为阻塞状态。当 sleep()状态超时、join()等待线程终止或者超时、或者 I/O处理完毕时,线程重新转入可运行(runnable)状态。</code></pre></li><li><p>线程死亡(DEAD)<br>线程会以下面三种方式结束,结束后就是死亡状态。</p><p><em>正常结束</em>  </p><blockquote><p>1.run()或 call()方法执行完成,线程正常结束。</p></blockquote><p><em>异常结束</em></p><blockquote><p>2.线程抛出一个未捕获的 Exception 或 Error。</p></blockquote><p><em>调用 stop</em></p><blockquote><p>3.直接调用该线程的 stop()方法来结束该线程—该方法通常容易导致死锁,不推荐使用。</p></blockquote></li></ul><p><img src="/resource/img/QQ%E5%9B%BE%E7%89%8720200610172044.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="终止线程-4-种方式"><a href="#终止线程-4-种方式" class="headerlink" title="终止线程 4 种方式"></a>终止线程 4 种方式</h2><ul><li><p>正常运行结束</p><blockquote><p>程序运行结束,线程自动结束。</p></blockquote></li><li><p>使用退出标志退出线程</p><blockquote><p>一般 run()方法执行完,线程就会正常结束,然而,常常有些线程是伺服线程。它们需要长时间的运行,只有在外部某些条件满足的情况下,才能关闭这些线程。使用一个变量来控制循环,例如:最直接的方法就是设一个 boolean 类型的标志,并通过设置这个标志为 true 或 false 来控制 while<br>循环是否退出,代码示例:</p></blockquote><pre><code class="java">public class ThreadSafe extends Thread { public volatile boolean exit = false; public void run() {     while (!exit){         //do something     } }}</code></pre></li></ul><p>定义了一个退出标志 exit,当 exit 为 true 时,while 循环退出,exit 的默认值为 false.在定义 exit<br>时,使用了一个 Java 关键字 volatile,这个关键字的目的是使 exit 同步,也就是说在同一时刻只<br>能由一个线程来修改 exit 的值。</p><ul><li>Interrupt 方法结束线程<blockquote><p>使用 interrupt()方法来中断线程有两种情况:</p></blockquote></li></ul><p> 1.线程处于阻塞状态:如使用了 sleep,同步锁的 wait,socket 中的 receiver,accept 等方法时,<br> 会使线程处于阻塞状态。当调用线程的 interrupt()方法时,会抛出 InterruptException 异常。<br> 阻塞中的那个方法抛出这个异常,通过代码捕获该异常,然后 break 跳出循环状态,从而让<br> 我们有机会结束这个线程的执行。通常很多人认为只要调用 interrupt 方法线程就会结束,实<br> 际上是错的, 一定要先捕获 InterruptedException 异常之后通过 break 来跳出循环,才能正<br> 常结束 run 方法。</p><p> 2.线程未处于阻塞状态:使用 isInterrupted()判断线程的中断标志来退出循环。当使用<br> interrupt()方法时,中断标志就会置 true,和使用自定义的标志来控制循环是一样的道理。</p><pre><code class="java">public class ThreadSafe extends Thread {    public void run() {        while (!isInterrupted()){ //非阻塞过程中通过判断中断标志来退出            try{                Thread.sleep(5*1000);//阻塞过程捕获中断异常来退出            }catch(InterruptedException e){                e.printStackTrace();                break;//捕获到异常之后,执行 break 跳出循环            }        }    }}</code></pre><ul><li><p>stop 方法终止线程(线程不安全)</p><blockquote><p>程序中可以直接使用 thread.stop()来强行终止线程,但是 stop 方法是很危险的,就象突然关<br>闭计算机电源,而不是按正常程序关机一样,可能会产生不可预料的结果,不安全主要是:<br>thread.stop()调用之后,创建子线程的线程就会抛出 ThreadDeatherror 的错误,并且会释放子<br>线程所持有的所有锁。一般任何进行加锁的代码块,都是为了保护数据的一致性,如果在<code>调用thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)</code>,那么被保护数据就有可能呈<br>现不一致性,其他线程在使用这些被破坏的数据时,有可能导致一些很奇怪的应用程序错误。因<br>此,并不推荐使用 stop 方法来终止线程。</p></blockquote></li></ul><h2 id="sleep-与-wait-区别"><a href="#sleep-与-wait-区别" class="headerlink" title="sleep 与 wait 区别"></a>sleep 与 wait 区别</h2><p> 1.对于 sleep()方法,我们首先要知道该方法是属于 Thread 类中的。而 wait()方法,则是属于Object 类中的。<br> 2.sleep()方法导致了程序暂停执行指定的时间,让出 cpu 该其他线程,但是他的监控状态依然保持者,当指定的时间到了又会自动恢复运行状态。<br> 3. 在调用 sleep()方法的过程中,线程不会释放对象锁。<br> 4. 而当调用 wait()方法的时候,线程会放弃对象锁,进入等待此对象的等待锁定池,只有针对此对象调用 notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态。  </p><h2 id="start-与-run-区别"><a href="#start-与-run-区别" class="headerlink" title="start 与 run 区别"></a>start 与 run 区别</h2><p> 1.start()方法来启动线程,真正实现了多线程运行。这时无需等待 run 方法体代码执行完毕,可以直接继续执行下面的代码。<br> 2.通过调用 Thread 类的 start()方法来启动一个线程, 这时此线程是处于就绪状态, 并没有运行。<br> 3.方法 run()称为线程体,它包含了要执行的这个线程的内容,线程就进入了运行状态,开始运行 run 函数当中的代码。 Run 方法运行结束, 此线程终止。然后 CPU 再调度其它线程。</p><h2 id="JAVA-后台线程"><a href="#JAVA-后台线程" class="headerlink" title="JAVA 后台线程"></a>JAVA 后台线程</h2><p>1.定义:守护线程–也称“服务线程”,他是后台线程,它有一个特性,即为用户线程 提供 公共服务,在没有用户线程可服务时会自动离开。  </p><p>2.优先级:守护线程的优先级比较低,用于为系统中的其它对象和线程提供服务。  </p><p>3.设置:通过 setDaemon(true)来设置线程为“守护线程”;将一个用户线程设置为守护线程的方式是在 线程对象创建 之前 用线程对象的 setDaemon 方法。  </p><p>4.在 Daemon 线程中产生的新线程也是 Daemon 的。</p><p>5.线程则是 JVM 级别的,以 Tomcat 为例,如果你在 Web 应用中启动一个线程,这个线程的生命周期并不会和 Web 应用程序保持同步。也就是说,即使你停止了 Web 应用,这个线程依旧是活跃的。  </p><p>6.example: 垃圾回收线程就是一个经典的守护线程,当我们的程序中不再有任何运行的 Thread,程序就不会再产生垃圾,垃圾回收器也就无事可做,所以当垃圾回收线程是 JVM 上仅剩的线程时,垃圾回收线程会自动离开。它始终在低级别的状态中运行,用于实时监控和管理系统中的可回收资源。</p><p>7.生命周期:守护进程(Daemon)是运行在后台的一种特殊进程。它独立于控制终端并且周期性地执行某种任务或等待处理某些发生的事件。也就是说守护线程不依赖于终端,但是依赖于系统,与系统“同生共死”。当 JVM 中所有的线程都是守护线程的时候,JVM 就可以退出了;如果还有一个或以上的非守护线程则 JVM 不会退出。  </p><h1 id="JAVA-锁"><a href="#JAVA-锁" class="headerlink" title="JAVA 锁"></a>JAVA 锁</h1><h2 id="乐观锁"><a href="#乐观锁" class="headerlink" title="乐观锁"></a>乐观锁</h2><blockquote><p>乐观锁是一种乐观思想,即认为读多写少,遇到并发写的可能性低,每次去拿数据的时候都认为别人不会修改,所以不会上锁,但是在更新的时候会判断一下在此期间别人有没有去更新这个数据,<br>采取在写时先读出当前版本号,然后加锁操作(比较跟上一次的版本号,如果一样则更新),如果失败则要重复读-比较-写的操作。java 中的乐观锁基本都是通过 CAS 操作实现的,CAS 是一种更新的原子操作,<br>比较当前值跟传入值是否一样,一样则更新,否则失败。</p></blockquote><h2 id="悲观锁"><a href="#悲观锁" class="headerlink" title="悲观锁"></a>悲观锁</h2><blockquote><p>悲观锁是就是悲观思想,即认为写多,遇到并发写的可能性高,每次去拿数据的时候都认为别人<br> 会修改,所以每次在读写数据的时候都会上锁,这样别人想读写这个数据就会 block 直到拿到锁。<br> java 中的悲观锁就是 Synchronized,AQS 框架下的锁则是先尝试 cas 乐观锁去获取锁,获取不到,<br> 才会转换为悲观锁,如 RetreenLock。</p></blockquote><h2 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h2><blockquote><p>自旋锁原理非常简单,如果持有锁的线程能在很短时间内释放锁资源,那么那些等待竞争锁<br> 的线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态,它们只需要等一等(自旋),<br> 等持有锁的线程释放锁后即可立即获取锁,这样就避免用户线程和内核的切换的消耗。<br> 线程自旋是需要消耗 cup 的,说白了就是让 cup 在做无用功,如果一直获取不到锁,那线程<br> 也不能一直占用 cup 自旋做无用功,所以需要设定一个自旋等待的最大时间。<br> 如果持有锁的线程执行的时间超过自旋等待的最大时间扔没有释放锁,就会导致其它争用锁<br> 的线程在最大等待时间内还是获取不到锁,这时争用线程会停止自旋进入阻塞状态。</p></blockquote><p> 自旋锁的优缺点</p><blockquote><p>自旋锁尽可能的减少线程的阻塞,这对于锁的竞争不激烈,且占用锁时间非常短的代码块来<br> 说性能能大幅度的提升,因为自旋的消耗会小于线程阻塞挂起再唤醒的操作的消耗,这些操作会<br> 导致线程发生两次上下文切换!<br> 但是如果锁的竞争激烈,或者持有锁的线程需要长时间占用锁执行同步块,这时候就不适合<br> 使用自旋锁了,因为自旋锁在获取锁前一直都是占用 cpu 做无用功,占着 XX 不 XX,同时有大量<br> 线程在竞争一个锁,会导致获取锁的时间很长,线程自旋的消耗大于线程阻塞挂起操作的消耗,<br> 其它需要 cup 的线程又不能获取到 cpu,造成 cpu 的浪费。所以这种情况下我们要关闭自旋锁;</p></blockquote><p> 自旋锁时间阈值 ( 1.6 引入了适应性自旋锁)</p><blockquote><p>自旋锁的目的是为了占着 CPU 的资源不释放,等到获取到锁立即进行处理。但是如何去选择<br> 自旋的执行时间呢?如果自旋执行时间太长,会有大量的线程处于自旋状态占用 CPU 资源,进而<br> 会影响整体系统的性能。因此自旋的周期选的额外重要!JVM 对于自旋周期的选择,jdk1.5 这个限度是一定的写死的,在 1.6 引入了适应性自旋锁,适应<br> 性自旋锁意味着自旋的时间不在是固定的了,而是由前一次在同一个锁上的自旋时间以及锁的拥<br> 有者的状态来决定,基本认为一个线程上下文切换的时间是最佳的一个时间,同时 JVM 还针对当<br> 前 CPU 的负荷情况做了较多的优化,如果平均负载小于 CPUs 则一直自旋,如果有超过(CPUs/2)<br> 个线程正在自旋,则后来线程直接阻塞,如果正在自旋的线程发现 Owner 发生了变化则延迟自旋<br> 时间(自旋计数)或进入阻塞,如果 CPU 处于节电模式则停止自旋,自旋时间的最坏情况是 CPU<br> 的存储延迟(CPU A 存储了一个数据,到 CPU B 得知这个数据直接的时间差),自旋时会适当放<br> 弃线程优先级之间的差异。<br> 自旋锁的开启<br> JDK1.6 中-XX:+UseSpinning 开启;<br> <code>-XX:PreBlockSpin=10</code> 为自旋次数;<br> JDK1.7 后,去掉此参数,由 jvm 控制;</p></blockquote><h3 id="Synchronized-同步锁"><a href="#Synchronized-同步锁" class="headerlink" title="Synchronized 同步锁"></a>Synchronized 同步锁</h3><p>synchronized 它可以把任意一个非 NULL 的对象当作锁。他属于独占式的悲观锁,同时属于可重入锁。</p><p><strong>Synchronized 作用范围</strong><br>1.作用于方法时,锁住的是对象的实例(this);<br>2.当作用于静态方法时,锁住的是 Class 实例,又因为 Class 的相关数据存储在永久带 PermGen(jdk1.8 则是 metaspace),永久带是全局共享的,因此静态方法锁相当于类的一个全局锁,会锁所有调用该方法的线程;<br>3.synchronized 作用于一个对象实例时,锁住的是所有以该对象为锁的代码块。它有多个队列,当多个线程一起访问某个对象监视器的时候,对象监视器会将这些线程存储在不同的容器中。</p><p><strong>Synchronized 核心组件</strong></p><p>1) Wait Set:哪些调用 wait 方法被阻塞的线程被放置在这里;<br>2) Contention List:竞争队列,所有请求锁的线程首先被放在这个竞争队列中;<br>3) Entry List:Contention List 中那些有资格成为候选资源的线程被移动到 Entry List 中;<br>4) OnDeck:任意时刻,最多只有一个线程正在竞争锁资源,该线程被成为 OnDeck;<br>5) Owner:当前已经获取到所资源的线程被称为 Owner;<br>6) !Owner:当前释放锁的线程。</p><p><strong>Synchronized 实现</strong></p><p><img src="/resource/img/synchronized.png" srcset="/img/loading.gif" alt="avatar"></p><blockquote><p>1.JVM 每次从队列的尾部取出一个数据用于锁竞争候选者(OnDeck),但是并发情况下,<br>ContentionList 会被大量的并发线程进行 CAS 访问,为了降低对尾部元素的竞争,JVM 会将<br>一部分线程移动到 EntryList 中作为候选竞争线程。</p></blockquote><blockquote><p>2.Owner 线程会在 unlock 时,将 ContentionList 中的部分线程迁移到 EntryList 中,并指定<br>EntryList 中的某个线程为 OnDeck 线程(一般是最先进去的那个线程)。</p></blockquote><blockquote><p>3.Owner 线程并不直接把锁传递给 OnDeck 线程,而是把锁竞争的权利交给 OnDeck,<br>OnDeck 需要重新竞争锁。这样虽然牺牲了一些公平性,但是能极大的提升系统的吞吐量,在<br>JVM 中,也把这种选择行为称之为“竞争切换”。</p></blockquote><blockquote><p>4.OnDeck 线程获取到锁资源后会变为 Owner 线程,而没有得到锁资源的仍然停留在 EntryList<br>中。如果 Owner 线程被 wait 方法阻塞,则转移到 WaitSet 队列中,直到某个时刻通过 notify<br>或者 notifyAll 唤醒,会重新进去 EntryList 中。</p></blockquote><blockquote><p>5.处于 ContentionList、EntryList、WaitSet 中的线程都处于阻塞状态,该阻塞是由操作系统<br>来完成的(Linux 内核下采用 pthread_mutex_lock 内核函数实现的)。</p></blockquote><blockquote><p>6.Synchronized 是非公平锁。 Synchronized 在线程进入 ContentionList 时,等待的线程会先<br>尝试自旋获取锁,如果获取不到就进入 ContentionList,这明显对于已经进入队列的线程是<br>不公平的,还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁<br>资源。<a href="https://blog.csdn.net/zqz_zqz/article/details/70233767" target="_blank" rel="noopener">参考</a></p></blockquote><blockquote><p>7.每个对象都有个 monitor 对象,加锁就是在竞争 monitor 对象,代码块加锁是在前后分别加<br>上 monitorenter 和 monitorexit 指令来实现的,方法加锁是通过一个标记位来判断的</p></blockquote><blockquote><p>8.synchronized 是一个重量级操作,需要调用操作系统相关接口,性能是低效的,有可能给线程加锁消耗的时间比有用操作消耗的时间更多。</p></blockquote><blockquote><p>9.Java1.6,synchronized 进行了很多的优化,有适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等,效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中,均对该关键字的实现机理做<br>了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位,不需要经过操作系统加锁。</p></blockquote><blockquote><p>10.锁可以从偏向锁升级到轻量级锁,再升级到重量级锁。这种升级过程叫做锁膨胀;</p></blockquote><blockquote><p>11.JDK 1.6 中默认是开启偏向锁和轻量级锁,可以通过<code>-XX:-UseBiasedLocking</code> 来禁用偏向锁。</p></blockquote><h1 id="ReentrantLock"><a href="#ReentrantLock" class="headerlink" title="ReentrantLock"></a>ReentrantLock</h1><blockquote><p>ReentantLock 继承接口 Lock 并实现了接口中定义的方法,他是一种可重入锁,除了能完成 synchronized 所能完成的所有工作外,还提供了诸如可响应中断锁、可轮询锁请求、定时锁等避免多线程死锁的方法。</p></blockquote><h3 id="Lock-接口的主要方法"><a href="#Lock-接口的主要方法" class="headerlink" title="Lock 接口的主要方法"></a>Lock 接口的主要方法</h3><pre><code class="text">void lock(): 执行此方法时, 如果锁处于空闲状态, 当前线程将获取到锁. 相反, 如果锁已经被其他线程持有, 将禁用当前线程, 直到当前线程获取到锁.boolean tryLock():如果锁可用, 则获取锁, 并立即返回 true, 否则返回 false. 该方法和lock()的区别在于, tryLock()只是&quot;试图&quot;获取锁, 如果锁不可用, 不会导致当前线程被禁用,当前线程仍然继续往下执行代码. 而 lock()方法则是一定要获取到锁, 如果锁不可用, 就一直等待, 在未获得锁之前,当前线程并不继续向下执行.void unlock():执行此方法时, 当前线程将释放持有的锁. 锁只能由持有者释放, 如果线程并不持有锁, 却执行该方法, 可能导致异常的发生.Condition newCondition():条件对象,获取等待通知组件。该组件和当前的锁绑定,当前线程只有获取了锁,才能调用该组件的 await()方法,而调用后,当前线程将缩放锁。getHoldCount() :查询当前线程保持此锁的次数,也就是执行此线程执行 lock 方法的次数。getQueueLength():返回正等待获取此锁的线程估计数,比如启动 10 个线程,1 个线程获得锁,此时返回的是 9getWaitQueueLength:(Condition condition)返回等待与此锁相关的给定条件的线程估计数。比如 10 个线程,用同一个 condition 对象,并且此时这 10 个线程都执行了condition 对象的 await 方法,那么此时执行此方法返回 10hasWaiters(Condition condition) : 查 询 是 否 有 线 程 等 待 与 此 锁 有 关 的 给 定 条 件(condition),对于指定 contidion 对象,有多少线程执行了 condition.await 方法hasQueuedThread(Thread thread):查询给定线程是否等待获取此锁hasQueuedThreads():是否有线程等待此锁isFair():该锁是否公平锁isHeldByCurrentThread(): 当前线程是否保持锁锁定,线程的执行 lock 方法的前后分别是 false 和 trueisLock():此锁是否有任意线程占用lockInterruptibly():如果当前线程未被中断,获取锁tryLock():尝试获得锁,仅在调用时锁未被线程占用,获得锁tryLock(long timeout TimeUnit unit):如果锁在给定等待时间内没有被另一个线程保持,则获取该锁。</code></pre><h1 id="非公平锁"><a href="#非公平锁" class="headerlink" title="非公平锁"></a>非公平锁</h1><p>JVM 按随机、就近原则分配锁的机制则称为不公平锁,ReentrantLock 在构造函数中提供了是否公平锁的初始化方式,默认为非公平锁。非公平锁实际执行的效率要远远超出公平锁,除非程序有特殊需要,否则最常用非公平锁的分配机制。</p><h1 id="公平锁"><a href="#公平锁" class="headerlink" title="公平锁"></a>公平锁</h1><p>公平锁指的是锁的分配机制是公平的,通常先对锁提出获取请求的线程会先被分配到锁,ReentrantLock 在构造函数中提供了是否公平锁的初始化方式来定义公平锁。</p><h1 id="ReentrantLock-与-synchronized"><a href="#ReentrantLock-与-synchronized" class="headerlink" title="ReentrantLock 与 synchronized"></a>ReentrantLock 与 synchronized</h1><p>1.ReentrantLock 通过方法 lock()与 unlock()来进行加锁与解锁操作,与 synchronized 会被 JVM 自动解锁机制不同,ReentrantLock 加锁后需要手动进行解锁。为了避免程序出现异常而无法正常解锁的情况,使用 ReentrantLock 必须在 finally 控制块中进行解锁操作。<br>2.ReentrantLock 相比 synchronized 的优势是可中断、公平锁、多个锁。这种情况下需要使用 ReentrantLock。</p><p>ReentrantLock 实现</p><pre><code class="java">public class MyService {    private Lock lock = new ReentrantLock();    //Lock lock=new ReentrantLock(true);//公平锁    //Lock lock=new ReentrantLock(false);//非公平锁    private Condition condition = lock.newCondition();//创建 Condition    public void testMethod() {        try {            lock.lock();//lock 加锁            //1:wait 方法等待:            //System.out.println(&quot;开始 wait&quot;);            condition.await();            //通过创建 Condition 对象来使线程 wait,必须先执行 lock.lock 方法获得锁            //:2:signal 方法唤醒            condition.signal();//condition 对象的 signal 方法可以唤醒 wait 线程            for (int i = 0; i &lt; 5; i++) {                System.out.println(&quot;ThreadName=&quot; + Thread.currentThread().getName() + (&quot; &quot; + (i + 1)));            }        } catch (InterruptedException e) {            e.printStackTrace();        } finally {            lock.unlock();        }    }}</code></pre><h2 id="Condition-类和-Object-类锁方法区别区别"><a href="#Condition-类和-Object-类锁方法区别区别" class="headerlink" title="Condition 类和 Object 类锁方法区别区别"></a>Condition 类和 Object 类锁方法区别区别</h2><ol><li>Condition 类的 awiat 方法和 Object 类的 wait 方法等效</li><li>Condition 类的 signal 方法和 Object 类的 notify 方法等效</li><li>Condition 类的 signalAll 方法和 Object 类的 notifyAll 方法等效</li><li>ReentrantLock 类可以唤醒指定条件的线程,而 object 的唤醒是随机的</li></ol><h2 id="tryLock-和-lock-和-lockInterruptibly-的区别"><a href="#tryLock-和-lock-和-lockInterruptibly-的区别" class="headerlink" title="tryLock 和 lock 和 lockInterruptibly 的区别"></a>tryLock 和 lock 和 lockInterruptibly 的区别</h2><p>1.tryLock 能获得锁就返回 true,不能就立即返回 false,tryLock(long timeout,TimeUnitunit),可以增加时间限制,如果超过该时间段还没获得锁,返回 false<br>2. lock 能获得锁就返回 true,不能的话一直等待获得锁<br>3. lock 和 lockInterruptibly,如果两个线程分别执行这两个方法,但此时中断这两个线程,lock 不会抛出异常,而 lockInterruptibly 会抛出异常。</p><h1 id="Semaphore-信号量"><a href="#Semaphore-信号量" class="headerlink" title="Semaphore 信号量"></a>Semaphore 信号量</h1><p>Semaphore 是一种基于计数的信号量。它可以设定一个阈值,基于此,多个线程竞争获取许可信号,做完自己的申请后归还,超过阈值后,线程申请许可信号将会被阻塞。Semaphore 可以用来构建一些对象池,资源池之类的,比如数据库连接池实现互斥锁(计数器为 1 )<br>我们也可以创建计数为 1 的 Semaphore,将其作为一种类似互斥锁的机制,这也叫二元信号量,表示两种互斥状态。<br>代码实现<br>它的用法如下:</p><pre><code class="java">// 创建一个计数阈值为 5 的信号量对象// 只能 5 个线程同时访问Semaphore semp = new Semaphore(5);try {    // 申请许可    semp.acquire();        try {            // 业务逻辑        } catch (Exception e) {            } finally {            // 释放许可            semp.release();        }    } catch (InterruptedException e) {}</code></pre><h2 id="Semaphore-与-ReentrantLock"><a href="#Semaphore-与-ReentrantLock" class="headerlink" title="Semaphore 与 ReentrantLock"></a>Semaphore 与 ReentrantLock</h2><p>Semaphore 基本能完成 ReentrantLock 的所有工作,使用方法也与之类似,通过 acquire()与<br>release()方法来获得和释放临界资源。经实测,Semaphone.acquire()方法默认为可响应中断锁,<br>与 ReentrantLock.lockInterruptibly()作用效果一致,也就是说在等待临界资源的过程中可以被<br>Thread.interrupt()方法中断。</p><p>此外,Semaphore 也实现了<code>可轮询的锁请求与定时锁的功能</code>,除了方法名 tryAcquire 与 tryLock<br>不同,其使用方法与 ReentrantLock 几乎一致。Semaphore 也提供了公平与非公平锁的机制,也<br>可在构造函数中进行设定。<br>Semaphore 的锁释放操作也由手动进行,因此与 ReentrantLock 一样,为避免线程因抛出异常而<br>无法正常释放锁的情况发生,释放锁的操作也必须在 finally 代码块中完成。</p><h3 id="AtomicInteger"><a href="#AtomicInteger" class="headerlink" title="AtomicInteger"></a>AtomicInteger</h3><p>首 先 说 明 , 此 处 AtomicInteger , 一 个 提 供 原 子 操 作 的 Integer 的 类 , 常 见 的 还 有<br><code>AtomicBoolean</code>、<code>AtomicInteger</code>、<code>AtomicLong</code>、<code>AtomicReference</code> 等,他们的实现原理相同,<br>区别在与运算对象类型的不同。令人兴奋地,还可以通过 AtomicReference<V>将一个对象的所<br>有操作转化成原子操作。</p><p>我们知道,在多线程程序中,诸如++i 或 i++等运算不具有原子性,是不安全的线程操作之一。<br>通常我们会使用 synchronized 将该操作变成一个原子操作,但 JVM 为此类操作特意提供了一些<br>同步类,使得使用更方便,且使程序运行效率变得更高。通过相关资料显示,通常 AtomicInteger<br>的性能是 ReentantLock 的好几倍。</p><h3 id="可重入锁-递归锁"><a href="#可重入锁-递归锁" class="headerlink" title="可重入锁(递归锁)"></a>可重入锁(递归锁)</h3><p>本文里面讲的是广义上的可重入锁,而不是单指 JAVA 下的 <code>ReentrantLock</code>。可重入锁,也叫<br>做递归锁,指的是同一线程 外层函数获得锁之后 ,内层递归函数仍然有获取该锁的代码,但不受<br>影响。在 JAVA 环境下 <code>ReentrantLock</code> 和 <code>synchronized</code> 都是 可重入锁。</p><h2 id="公平锁与非公平锁"><a href="#公平锁与非公平锁" class="headerlink" title="公平锁与非公平锁"></a>公平锁与非公平锁</h2><p>公平锁( Fair )<br>加锁前检查是否有排队等待的线程,优先排队等待的线程,先来先得<br>非公平锁( Nonfair )<br>加锁时不考虑排队等待问题,直接尝试获取锁,获取不到自动到队尾等待</p><ol><li>非公平锁性能比公平锁高 5~10 倍,因为公平锁需要在多核的情况下维护一个队列</li><li>Java 中的 synchronized 是非公平锁,ReentrantLock 默认的 lock()方法采用的是非公平锁。</li></ol><h3 id="ReadWriteLock-读写锁"><a href="#ReadWriteLock-读写锁" class="headerlink" title="ReadWriteLock 读写锁"></a>ReadWriteLock 读写锁</h3><p>为了提高性能,Java 提供了读写锁,在读的地方使用读锁,在写的地方使用写锁,灵活控制,如<br>果没有写锁的情况下,读是无阻塞的,在一定程度上提高了程序的执行效率。读写锁分为读锁和写<br>锁,多个读锁不互斥,读锁与写锁互斥,这是由 jvm 自己控制的,你只要上好相应的锁即可。<br>读锁<br>如果你的代码只读数据,可以很多人同时读,但不能同时写,那就上读锁<br>写锁<br>如果你的代码修改数据,只能有一个人在写,且不能同时读取,那就上写锁。总之,读的时候上<br>读锁,写的时候上写锁!<br>Java 中 读 写 锁 有 个 接 口 java.util.concurrent.locks.ReadWriteLock , 也 有 具 体 的 实 现</p><h3 id="ReentrantReadWriteLock"><a href="#ReentrantReadWriteLock" class="headerlink" title="ReentrantReadWriteLock"></a>ReentrantReadWriteLock</h3><h2 id="共享锁和独占锁"><a href="#共享锁和独占锁" class="headerlink" title="共享锁和独占锁"></a>共享锁和独占锁</h2><p>java 并发包提供的加锁模式分为独占锁和共享锁。<br>独占锁</p><blockquote><p>独占锁模式下,每次只能有一个线程能持有锁,ReentrantLock 就是以独占方式实现的互斥锁。<br>独占锁是一种悲观保守的加锁策略,它避免了读/读冲突,如果某个只读线程获取锁,则其他读线<br>程都只能等待,这种情况下就限制了不必要的并发性,因为读操作并不会影响数据的一致性。</p></blockquote><p>共享锁</p><blockquote><p>共享锁则允许多个线程同时获取锁,并发访问 共享资源,如:ReadWriteLock。共享锁则是一种<br>乐观锁,它放宽了加锁策略,允许多个执行读操作的线程同时访问共享资源。</p></blockquote><p>1.AQS 的内部类 Node 定义了两个常量 SHARED 和 EXCLUSIVE,他们分别标识 AQS 队列中等待线程的锁获取模式。<br>2.java 的并发包中提供了 ReadWriteLock,读-写锁。它允许一个资源可以被多个读操作访问,或者被一个 写操作访问,但两者不能同时进行。</p><h3 id="重量级锁-Mutex-Lock"><a href="#重量级锁-Mutex-Lock" class="headerlink" title="重量级锁( Mutex Lock )"></a>重量级锁( Mutex Lock )</h3><p>Synchronized 是通过对象内部的一个叫做监视器锁(monitor)来实现的。但是监视器锁本质又是依赖于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到核心态,这个成本非常高,状态之间的转换需要相对比较长的时间,这就是为什么<br>Synchronized 效率低的原因。因此,这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为“重量级锁”。JDK 中对 Synchronized 做的种种优化,其核心都是为了减少这种重量级锁的使用。<br>JDK1.6 以后,为了减少获得锁和释放锁所带来的性能消耗,提高性能,引入了“轻量级锁”和“偏向锁”。</p><h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>锁的状态总共有四种:无锁状态、偏向锁、轻量级锁和重量级锁。</p><p><strong>锁升级</strong><br>随着锁的竞争,锁可以从偏向锁升级到轻量级锁,再升级的重量级锁(但是锁的升级是单向的,<br>也就是说只能从低到高升级,不会出现锁的降级)。</p><p>  “轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是,首先需要强调一点的是,<br>轻量级锁并不是用来代替重量级锁的,它的本意是在没有多线程竞争的前提下,减少传统的重量<br>级锁使用产生的性能消耗。在解释轻量级锁的执行过程之前,先明白一点,轻量级锁所适应的场<br>景是线程交替执行同步块的情况,如果存在同一时间访问同一锁的情况,就会导致轻量级锁膨胀<br>为重量级锁。</p><h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><blockquote><p>Hotspot 的作者经过以往的研究发现大多数情况下锁不仅不存在多线程竞争,而且总是由同一线<br>程多次获得。偏向锁的目的是在某个线程获得锁之后,消除这个线程锁重入(CAS)的开销,看起<br>来让这个线程得到了偏护。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级<br>锁执行路径,因为轻量级锁的获取及释放依赖多次 CAS 原子指令,而偏向锁只需要在置换<br>ThreadID 的时候依赖一次 CAS 原子指令(由于一旦出现多线程竞争的情况就必须撤销偏向锁,所<br>以偏向锁的撤销操作的性能损耗必须小于节省下来的 CAS 原子指令的性能消耗)。上面说过,轻<br>量级锁是为了在线程交替执行同步块时提高性能,而偏向锁则是在只有一个线程执行同步块时进<br>一步提高性能。</p></blockquote><h3 id="分段锁"><a href="#分段锁" class="headerlink" title="分段锁"></a>分段锁</h3><blockquote><p>分段锁也并非一种实际的锁,而是一种思想 ConcurrentHashMap 是学习分段锁的最好实践</p></blockquote><h3 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h3><ul><li><p>减少锁持有时间  </p><blockquote><p>只用在有线程安全要求的程序上加锁</p></blockquote></li><li><p>减小锁粒度</p><blockquote><p>将大对象(这个对象可能会被很多线程访问),拆成小对象,大大增加并行度,降低锁竞争。<br>降低了锁的竞争,偏向锁,轻量级锁成功率才会提高。最最典型的减小锁粒度的案例就是<br>ConcurrentHashMap。</p></blockquote></li><li><p>锁分离</p><blockquote><p>最常见的锁分离就是读写锁 ReadWriteLock,根据功能进行分离成读锁和写锁,这样读读不互<br>斥,读写互斥,写写互斥,即保证了线程安全,又提高了性能,具体也请查看[高并发 Java 五]<br>JDK 并发包 1。读写分离思想可以延伸,只要操作互不影响,锁就可以分离。比如<br>LinkedBlockingQueue 从头部取出,从尾部放数据</p></blockquote></li><li><p>锁粗化</p><blockquote><p>通常情况下,为了保证多线程间的有效并发,会要求每个线程持有锁的时间尽量短,即在使用完<br>公共资源后,应该立即释放锁。但是,凡事都有一个度,如果对同一个锁不停的进行请求、同步<br>和释放,其本身也会消耗系统宝贵的资源,反而不利于性能的优化 。<br>锁消除<br>锁消除是在编译器级别的事情。在即时编译器时,如果发现不可能被共享的对象,则可以消除这<br>些对象的锁操作,多数是因为程序员编码不规范引起。<br><a href="https://www.jianshu.com/p/39628e1180a9" target="_blank" rel="noopener">参考</a></p></blockquote></li></ul><p>4.1.10.</p><ul><li>线程基本方法<br>线程相关的基本方法有 <code>wait,notify,notifyAll,sleep,join,yield</code> 等。</li></ul><p><img src="/resource/img/threadmethods.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="线程等待-wait"><a href="#线程等待-wait" class="headerlink" title="线程等待(wait)"></a>线程等待(wait)</h2><blockquote><p>调用该方法的线程进入 WAITING 状态,只有等待另外线程的通知或被中断才会返回,需要注意的<br>是调用 wait()方法后,会释放对象的锁。因此,wait 方法一般用在同步方法或同步代码块中。<br>4.1.10.2.</p></blockquote><h2 id="线程睡眠-sleep"><a href="#线程睡眠-sleep" class="headerlink" title="线程睡眠(sleep)"></a>线程睡眠(sleep)</h2><p>sleep 导致当前线程休眠,与 wait 方法不同的是 sleep 不会释放当前占有的锁,sleep(long)会导致线程进入 <code>TIMED-WATING</code> 状态,而 wait()方法会导致当前线程进入 <code>WATING</code> 状态</p><h2 id="线程让步-yield"><a href="#线程让步-yield" class="headerlink" title="线程让步(yield)"></a>线程让步(yield)</h2><p>yield 会使当前线程让出 CPU 执行时间片,与其他线程一起重新竞争 CPU 时间片。一般情况下,优先级高的线程有更大的可能性成功竞争得到 CPU 时间片,但这又不是绝对的,有的操作系统对线程优先级并不敏感。</p><h2 id="线程中断-interrupt"><a href="#线程中断-interrupt" class="headerlink" title="线程中断(interrupt)"></a>线程中断(interrupt)</h2><p>中断一个线程,其本意是给这个线程一个通知信号,会影响这个线程内部的一个中断标识位。这个线程本身并不会因此而改变状态(如阻塞,终止等)。</p><p>1.调用 interrupt()方法并不会中断一个正在运行的线程。也就是说处于 Running 状态的线程并不会因为被中断而被终止,仅仅改变了内部维护的中断标识位而已。</p><p>2.若调用 sleep()而使线程处于 TIMED-WATING 状态,这时调用 interrupt()方法,会抛出InterruptedException,从而使线程提前结束 TIMED-WATING 状态。</p><p>3.许多声明抛出 InterruptedException 的方法(如 Thread.sleep(long mills 方法)),抛出异常前,都会清除中断标识位,所以抛出异常后,调用 isInterrupted()方法将会返回 false。</p><p>4.中断状态是线程固有的一个标识位,可以通过此标识位安全的终止线程。比如,你想终止一个线程 thread 的时候,可以调用 thread.interrupt()方法,在线程的 run 方法内部可以根据 thread.isInterrupted()的值来优雅的终止线程。</p><h3 id="Join-等待其他线程终止"><a href="#Join-等待其他线程终止" class="headerlink" title="Join 等待其他线程终止"></a>Join 等待其他线程终止</h3><pre><code>join() 方法,等待其他线程终止,在当前线程中调用一个线程的 join() 方法,则当前线程转为阻塞状态,回到另一个线程结束,当前线程再由阻塞状态变为就绪状态,等待 cpu 的宠幸。</code></pre><h5 id="为什么要用-join-方法"><a href="#为什么要用-join-方法" class="headerlink" title="为什么要用 join()方法?"></a>为什么要用 join()方法?</h5><pre><code>很多情况下,主线程生成并启动了子线程,需要用到子线程返回的结果,也就是需要主线程需要在子线程结束后再结束,这时候就要用到 join() 方法。</code></pre><pre><code class="text">System.out.println(Thread.currentThread().getName() + &quot;线程运行开始!&quot;);Thread6 thread1 = new Thread6();thread1.setName(&quot;线程 B&quot;);thread1.join();System.out.println(&quot;这时 thread1 执行完毕之后才能执行主线程&quot;);</code></pre><h3 id="线程唤醒-notify"><a href="#线程唤醒-notify" class="headerlink" title="线程唤醒(notify)"></a>线程唤醒(notify)</h3><p>Object 类中的 notify() 方法,唤醒在此对象监视器上等待的单个线程,如果所有线程都在此对象上等待,则会选择唤醒其中一个线程,选择是任意的,并在对实现做出决定时发生,线程通过调<br>用其中一个 wait() 方法,在对象的监视器上等待,直到当前的线程放弃此对象上的锁定,才能继续执行被唤醒的线程,被唤醒的线程将以常规方式与在该对象上主动同步的其他所有线程进行竞争。类似的方法还有 notifyAll() ,唤醒再次监视器上等待的所有线程。</p><h4 id="其他方法"><a href="#其他方法" class="headerlink" title="其他方法:"></a>其他方法:</h4><ol><li><code>sleep()</code>:强迫一个线程睡眠N毫秒。</li><li><code>isAlive()</code>: 判断一个线程是否存活。</li><li><code>join()</code>: 等待线程终止。</li><li><code>activeCount()</code>: 程序中活跃的线程数。</li><li><code>enumerate()</code>: 枚举程序中的线程。</li><li><code>currentThread()</code>: 得到当前线程。</li><li><code>isDaemon()</code>: 一个线程是否为守护线程。</li><li><code>setDaemon()</code>: 设置一个线程为守护线程。(用户线程和守护线程的区别在于,是否等待主线程依赖于主线程结束而结束)</li><li><code>setName()</code>: 为线程设置一个名称。</li><li><code>wait()</code>: 强迫一个线程等待。</li><li><code>notify()</code>: 通知一个线程继续运行。</li><li><code>setPriority()</code>: 设置一个线程的优先级。</li><li><code>getPriority()</code>::获得一个线程的优先级。</li></ol><h2 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a>线程上下文切换</h2><blockquote><p>巧妙地利用了时间片轮转的方式, CPU 给每个任务都服务一定的时间,然后把当前任务的状态保存下来,在加载下一任务的状态后,继续服务下一任务,任务的状态保存及再加载, 这段过程就叫做上下文切换。时间片轮转的方式使多个任务在同一颗 CPU 上执行变成了可能。</p></blockquote><p><img src="/resource/img/threadcontentchange.png" srcset="/img/loading.gif" alt="avatar"></p><h4 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h4><p>(有时候也称做任务)是指一个程序运行的实例。在 Linux 系统中,线程就是能并行运行并且与他们的父进程(创建他们的进程)共享同一地址空间(一段内存区域)和其他资源的轻量级的进程。</p><h3 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h3><p>是指某一时间点 CPU 寄存器和程序计数器的内容。</p><h3 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h3><p>是 CPU 内部的数量较少但是速度很快的内存(与之对应的是 CPU 外部相对较慢的 RAM 主内存)。寄存器通过对常用值(通常是运算的中间值)的快速访问来提高计算机程序运行的速度。</p><h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>是一个专用的寄存器,用于表明指令序列中 CPU 正在执行的位置,存的值为正在执行的指令的位置或者下一个将要被执行的指令的位置,具体依赖于特定的系统。</p><h3 id="PCB-“切换桢”"><a href="#PCB-“切换桢”" class="headerlink" title="PCB-“切换桢”"></a>PCB-“切换桢”</h3><p>上下文切换可以认为是内核(操作系统的核心)在 CPU 上对于进程(包括线程)进行切换,上下文切换过程中的信息是保存在进程控制块(PCB, process control block)中的。PCB 还经常被称作“切换桢”(switchframe)。信息会一直保存到 CPU 的内存中,直到他们被再次使用。</p><p>###上下文切换的活动:</p><ol><li>挂起一个进程,将这个进程在 CPU 中的状态(上下文)存储于内存中的某处。</li><li>在内存中检索下一个进程的上下文并将其在 CPU 的寄存器中恢复。</li><li>跳转到程序计数器所指向的位置(即跳转到进程被中断时的代码行),以恢复该进程在程序中。</li></ol><h3 id="引起线程上下文切换的原因"><a href="#引起线程上下文切换的原因" class="headerlink" title="引起线程上下文切换的原因"></a>引起线程上下文切换的原因</h3><ol><li>当前执行任务的时间片用完之后,系统 CPU 正常调度下一个任务;</li><li>当前执行任务碰到 IO 阻塞,调度器将此任务挂起,继续下一任务;</li><li>多个任务抢占锁资源,当前任务没有抢到锁资源,被调度器挂起,继续下一任务;</li><li>用户代码挂起当前任务,让出 CPU 时间;</li><li>硬件中断;</li></ol><h2 id="同步锁与死锁"><a href="#同步锁与死锁" class="headerlink" title="同步锁与死锁"></a>同步锁与死锁</h2><p>同步锁<br>当多个线程同时访问同一个数据时,很容易出现问题。为了避免这种情况出现,我们要保证线程同步互斥,就是指并发执行的多个线程,在同一时间内只允许一个线程访问共享数据。 Java 中可以使用 synchronized 关键字来取得一个对象的同步锁。</p><p>死锁<br>何为死锁,就是多个线程同时被阻塞,它们中的一个或者全部都在等待某个资源被释放。</p><p>线程池原理<br>线程池做的工作主要是控制运行的线程的数量,处理过程中将任务放入队列,然后在线程创建后启动这些任务,如果线程数量超过了最大数量超出数量的线程排队等候,等其它线程执行完毕,再从队列中取出任务来执行。他的主要特点为:线程复用;控制最大并发数;管理线程。</p><h3 id="线程复用"><a href="#线程复用" class="headerlink" title="线程复用"></a>线程复用</h3><p>每一个 Thread 的类都有一个 start 方法。 当调用 start 启动线程时 Java 虚拟机会调用该类的 run方法。 那么该类的 run() 方法中就是调用了 Runnable 对象的 run() 方法。 我们可以继承重写<br>Thread 类,在其 start 方法中添加不断循环调用传递过来的 Runnable 对象。 这就是线程池的实现原理。循环方法中不断获取 Runnable 是用 Queue 实现的,在获取下一个 Runnable 之前可以是阻塞的。</p><h3 id="线程池的组成"><a href="#线程池的组成" class="headerlink" title="线程池的组成"></a>线程池的组成</h3><p>一般的线程池主要分为以下 4 个组成部分:</p><ol><li>线程池管理器:用于创建并管理线程池</li><li>工作线程:线程池中的线程</li><li>任务接口:每个任务必须实现的接口,用于工作线程调度其运行</li><li>任务队列:用于存放待处理的任务,提供一种缓冲机制<br>Java 中 的 线 程 池 是 通 过 Executor 框 架 实 现 的 , 该 框 架 中 用 到 了 Executor , Executors ,ExecutorService,ThreadPoolExecutor ,Callable 和 Future、FutureTask 这几个类。</li></ol><p><img src="/resource/img/threadpoolcon.png" srcset="/img/loading.gif" alt="avatar"><br>ThreadPoolExecutor 的构造方法如下:</p><pre><code class="java">public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime,TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) {    this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,Executors.defaultThreadFactory(), defaultHandler);}</code></pre><ol><li>corePoolSize:指定了线程池中的线程数量。</li><li>maximumPoolSize:指定了线程池中的最大线程数量。</li><li>keepAliveTime:当前线程池数量超过 corePoolSize 时,多余的空闲线程的存活时间,即多次时间内会被销毁。</li><li>unit:keepAliveTime 的单位。</li><li>workQueue:任务队列,被提交但尚未被执行的任务。</li><li>threadFactory:线程工厂,用于创建线程,一般用默认的即可。</li><li>handler:拒绝策略,当任务太多来不及处理,如何拒绝任务。</li></ol><h4 id="拒绝策略"><a href="#拒绝策略" class="headerlink" title="拒绝策略"></a>拒绝策略</h4><p>线程池中的线程已经用完了,无法继续为新任务服务,同时,等待队列也已经排满了,再也<br>塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。<br>JDK 内置的拒绝策略如下:</p><ol><li>AbortPolicy : 直接抛出异常,阻止系统正常运行。</li><li>CallerRunsPolicy : 只要线程池未关闭,该策略直接在调用者线程中,运行当前被丢弃的任务。显然这样做不会真的丢弃任务,但是,任务提交线程的性能极有可能会急剧下降。</li><li>DiscardOldestPolicy : 丢弃最老的一个请求,也就是即将被执行的一个任务,并尝试再次提交当前任务。</li><li>DiscardPolicy : 该策略默默地丢弃无法处理的任务,不予任何处理。如果允许任务丢失,这是最好的一种方案。以上内置拒绝策略均实现了 RejectedExecutionHandler 接口,若以上策略仍无法满足实际需要,完全可以自己扩展 RejectedExecutionHandler 接口。</li></ol><h3 id="Java-线程池工作过程"><a href="#Java-线程池工作过程" class="headerlink" title="Java 线程池工作过程"></a>Java 线程池工作过程</h3><p>1.线程池刚创建时,里面没有一个线程。任务队列是作为参数传进来的。不过,就算队列里面有任务,线程池也不会马上执行它们。<br>2.当调用 execute() 方法添加一个任务时,线程池会做如下判断:</p><blockquote><p>a) 如果正在运行的线程数量小于 corePoolSize,那么马上创建线程运行这个任务;</p></blockquote><blockquote><p>b) 如果正在运行的线程数量大于或等于 corePoolSize,那么将这个任务放入队列;</p></blockquote><blockquote><p>c) 如果这时候队列满了,而且正在运行的线程数量小于 maximumPoolSize,那么还是要创建非核心线程立刻运行这个任务;</p></blockquote><blockquote><p>d)如果队列满了,而且正在运行的线程数量大于或等于 maximumPoolSize,那么线程池会抛出异常 RejectExecutionException。<br>3. 当一个线程完成任务时,它会从队列中取下一个任务来执行。<br>4. 当一个线程无事可做,超过一定的时间(keepAliveTime)时,线程池会判断,如果当前运行的线程数大于 corePoolSize,那么这个线程就被停掉。所以线程池的所有任务完成后,它最终会收缩到 corePoolSize 的大小。</p></blockquote><p><img src="/resource/img/threadwork.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="JAVA-阻塞队列原理"><a href="#JAVA-阻塞队列原理" class="headerlink" title="JAVA 阻塞队列原理"></a>JAVA 阻塞队列原理</h3><blockquote><p>阻塞队列,关键字是阻塞,先理解阻塞的含义,在阻塞队列中,线程阻塞有这样的两种情况:</p></blockquote><p>1.当队列中没有数据的情况下,消费者端的所有线程都会被自动阻塞(挂起),直到有数据放入队列。<br><img src="/resource/img/thread-1.png" srcset="/img/loading.gif" alt="avatar"></p><p>2.当队列中填满数据的情况下,生产者端的所有线程都会被自动阻塞(挂起),直到队列中有空的位置,线程被自动唤醒。<br><img src="/resource/img/thread-2.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="阻塞队列的主要方法"><a href="#阻塞队列的主要方法" class="headerlink" title="阻塞队列的主要方法"></a>阻塞队列的主要方法</h3><p><img src="/resource/img/blockqueue.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li>抛出异常:抛出一个异常;  </li><li>特殊值:返回一个特殊值(null 或 false,视情况而定)</li><li>则塞:在成功操作之前,一直阻塞线程</li><li>超时:放弃前只在最大的时间内阻塞</li></ul><h3 id="插入操作"><a href="#插入操作" class="headerlink" title="插入操作:"></a>插入操作:</h3><p>1:public abstract boolean add(E paramE):将指定元素插入此队列中(如果立即可行且不会违反容量限制),成功时返回 true,如果当前没有可用的空间,则抛出 IllegalStateException。如果该元素是 NULL,则会抛出 NullPointerException 异常。</p><p>2:public abstract boolean offer(E paramE):将指定元素插入此队列中(如果立即可行且不会违反容量限制),成功时返回 true,如果当前没有可用的空间,则返回 false。</p><p>3:public abstract void put(E paramE) throws InterruptedException: 将指定元素插入此队列中,将等待可用的空间(如果有必要)</p><pre><code class="java">public void put(E paramE) throws InterruptedException {    checkNotNull(paramE);    ReentrantLock localReentrantLock = this.lock;    localReentrantLock.lockInterruptibly();    try {        while (this.count == this.items.length)            this.notFull.await();//如果队列满了,则线程阻塞等待            enqueue(paramE);            localReentrantLock.unlock();        } finally {            localReentrantLock.unlock();    }}</code></pre><p>4:offer(E o, long timeout, TimeUnit unit):可以设定等待的时间,如果在指定的时间内,还不能往队列中加入 BlockingQueue,则返回失败。</p><h3 id="获取数据操作"><a href="#获取数据操作" class="headerlink" title="获取数据操作:"></a>获取数据操作:</h3><p>1:poll(time):取走 BlockingQueue 里排在首位的对象,若不能立即取出,则可以等 time 参数规定的时间,取不到时返回 null;</p><p>2:poll(long timeout, TimeUnit unit):从 BlockingQueue 取出一个队首的对象,如果在指定时间内,队列一旦有数据可取,则立即返回队列中的数据。否则直到时间超时还没有数据可取,返回失败。</p><p>3:take():取走 BlockingQueue 里排在首位的对象,若 BlockingQueue 为空,阻断进入等待状态直到 BlockingQueue 有新的数据被加入。</p><p>4.drainTo():一次性从 BlockingQueue 获取所有可用的数据对象(还可以指定获取数据的个数),通过该方法,可以提升获取数据效率;不需要多次分批加锁或释放锁。</p><h3 id="Java中的阻塞队列"><a href="#Java中的阻塞队列" class="headerlink" title="Java中的阻塞队列"></a>Java中的阻塞队列</h3><p><img src="/resource/img/blocking_queue.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li>ArrayBlockingQueue: 由数组结构组成的有界阻塞队列.(公平、非公平)<blockquote><p>用数组实现的有界阻塞队列。此队列按照先进先出(FIFO)的原则对元素进行排序。默认情况下<br>不保证访问者公平的访问队列,所谓公平访问队列是指阻塞的所有生产者线程或消费者线程,当<br>队列可用时,可以按照阻塞的先后顺序访问队列,即先阻塞的生产者线程,可以先往队列里插入<br>元素,先阻塞的消费者线程,可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐<br>量。我们可以使用以下代码创建一个公平的阻塞队列:<code>ArrayBlockingQueue fairQueue = new ArrayBlockingQueue(1000,true);</code></p></blockquote></li></ul><ul><li>LinkedBlockingQueue: 由链表结构组成的有界阻塞队列.(两个独立锁提高并发)<blockquote><p>基于链表的阻塞队列,同 ArrayListBlockingQueue 类似,此队列按照先进先出(FIFO)的原则对<br>元素进行排序。而 LinkedBlockingQueue 之所以能够高效的处理并发数据,还因为其对于生产者<br>端和消费者端分别采用了独立的锁来控制数据同步,这也意味着在高并发的情况下生产者和消费<br>者可以并行地操作队列中的数据,以此来提高整个队列的并发性能。<br>LinkedBlockingQueue 会默认一个类似无限大小的容量(Integer.MAX_VALUE)。</p></blockquote></li></ul><ul><li>PriorityBlockingQueue: 支持优先级排序的无界阻塞队列.(compareTo 排序实现优先)<blockquote><p>是 一 个 支持 优 先级 的 无界 队 列 。默 认 情况 下 元素 采 取 自然 顺 序升 序 排列 。 可 以自 定 义实 现<br>compareTo()方法来指定元素进行排序规则,或者初始化 PriorityBlockingQueue 时,指定构造<br>参数 Comparator 来对元素进行排序。需要注意的是不能保证同优先级元素的顺序。</p></blockquote></li></ul><ul><li>DelayQueue: 使用优先级队列实现的无界阻塞队列.(缓存失效、定时任务 )<blockquote><p>是一个支持延时获取元素的无界阻塞队列。队列使用 PriorityQueue 来实现。队列中的元素必须实<br>现 Delayed 接口,在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才<br>能从队列中提取元素。我们可以将 DelayQueue 运用在以下应用场景:</p></blockquote></li></ul><blockquote><p>1.缓存系统的设计:可以用 DelayQueue 保存缓存元素的有效期,使用一个线程循环查询 DelayQueue,一旦能从 DelayQueue 中获取元素时,表示缓存有效期到了。<br>2.定时任务调度 : 使用 DelayQueue 保存当天将会执行的任务和执行时间,一旦从DelayQueue 中获取到任务就开始执行,从比如 TimerQueue 就是使用 DelayQueue 实现的。</p></blockquote><ul><li>SynchronousQueue: 不存储元素的阻塞队列.(不存储数据、可用于传递数据)<blockquote><p>是一个不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作,否则不能继续添加元素。<br>SynchronousQueue 可以看成是一个传球手,负责把生产者线程处理的数据直接传递给消费者线<br>程。队列本身并不存储任何元素,非常适合于传递性场景,比如在一个线程中使用的数据,传递给<br>另 外 一 个 线 程 使 用 , SynchronousQueue 的 吞 吐 量 高 于 LinkedBlockingQueue 和<br>ArrayBlockingQueue。</p></blockquote></li></ul><ul><li><p>LinkedTransferQueue: 由链表结构组成的无界阻塞队列.</p><blockquote><p>是 一 个 由 链 表 结 构 组 成 的 无 界 阻 塞 TransferQueue 队 列 。 相 对 于 其 他 阻 塞 队 列 ,<br>LinkedTransferQueue 多了 tryTransfer 和 transfer 方法。</p></blockquote><blockquote><p>1.transfer 方法:如果当前有消费者正在等待接收元素(消费者使用 take()方法或带时间限制的<br>poll()方法时),transfer 方法可以把生产者传入的元素立刻 transfer(传输)给消费者。如<br>果没有消费者在等待接收元素,transfer 方法会将元素存放在队列的 tail 节点,并等到该元素<br>被消费者消费了才返回。</p></blockquote><blockquote><p>2.tryTransfer 方法。则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费<br>者等待接收元素,则返回 false。和 transfer 方法的区别是 tryTransfer 方法无论消费者是否<br>接收,方法立即返回。而 transfer 方法是必须等到消费者消费了才返回。<br>对于带有时间限制的 tryTransfer(E e, long timeout, TimeUnit unit)方法,则是试图把生产者传<br>入的元素直接传给消费者,但是如果没有消费者消费该元素则等待指定的时间再返回,如果超时<br>还没消费元素,则返回 false,如果在超时时间内消费了元素,则返回 true。</p></blockquote></li></ul><ul><li>LinkedBlockingDeque: 由链表结构组成的双向阻塞队列.<blockquote><p>是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。<br>双端队列因为多了一个操作队列的入口,在多线程同时入队时,也就减少了一半的竞争。相比其<br>他 的 阻 塞 队 列 , LinkedBlockingDeque 多 了 addFirst , addLast , offerFirst , offerLast ,<br>peekFirst,peekLast 等方法,以 First 单词结尾的方法,表示插入,获取(peek)或移除双端队<br>列的第一个元素。以 Last 单词结尾的方法,表示插入,获取或移除双端队列的最后一个元素。另<br>外插入方法 add 等同于 addLast,移除方法 remove 等效于 removeFirst。但是 take 方法却等同<br>于 takeFirst,不知道是不是 Jdk 的 bug,使用时还是用带有 First 和 Last 后缀的方法更清楚。<br>在初始化 LinkedBlockingDeque 时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在<br>“工作窃取”模式中。</p></blockquote></li></ul><h3 id="CyclicBarrier、CountDownLatch、Semaphore-的用法"><a href="#CyclicBarrier、CountDownLatch、Semaphore-的用法" class="headerlink" title="CyclicBarrier、CountDownLatch、Semaphore 的用法"></a>CyclicBarrier、CountDownLatch、Semaphore 的用法</h3><h4 id="CountDownLatch-线程计数器"><a href="#CountDownLatch-线程计数器" class="headerlink" title="CountDownLatch(线程计数器 )"></a>CountDownLatch(线程计数器 )</h4><blockquote><p>CountDownLatch 类位于 java.util.concurrent 包下,利用它可以实现类似计数器的功能。比如有<br>一个任务 A,它要等待其他 4 个任务执行完毕之后才能执行,此时就可以利用 CountDownLatch<br>来实现这种功能了。</p></blockquote><pre><code class="java">        final CountDownLatch latch = new CountDownLatch(2);        new Thread() {            public void run() {                System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;正在执行&quot;);                Thread.sleep(3000);                System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;执行完毕&quot;);                latch.countDown();            }            ;        }.start();        new Thread() {            public void run() {                System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;正在执行&quot;);                Thread.sleep(3000);                System.out.println(&quot;子线程&quot; + Thread.currentThread().getName() + &quot;执行完毕&quot;);                latch.countDown();            }            ;        }.start();        System.out.println(&quot;等待 2 个子线程执行完毕...&quot;);        latch.await();        System.out.println(&quot;2 个子线程已经执行完毕&quot;);        System.out.println(&quot;继续执行主线程&quot;)</code></pre><h4 id="CyclicBarrier-回环栅栏-等待至-barrier-状态再全部同时执行"><a href="#CyclicBarrier-回环栅栏-等待至-barrier-状态再全部同时执行" class="headerlink" title="CyclicBarrier(回环栅栏-等待至 barrier 状态再全部同时执行)"></a>CyclicBarrier(回环栅栏-等待至 barrier 状态再全部同时执行)</h4><blockquote><p>字面意思回环栅栏,通过它可以实现让一组线程等待至某个状态之后再全部同时执行。叫做回环<br> 是因为当所有等待线程都被释放以后,CyclicBarrier 可以被重用。我们暂且把这个状态就叫做<br> barrier,当调用 await()方法之后,线程就处于 barrier 了。<br> CyclicBarrier 中最重要的方法就是 await 方法,它有 2 个重载版本:</p></blockquote><p> 1.public int await():用来挂起当前线程,直至所有线程都到达 barrier 状态再同时执行后续任务;<br> 2.public int await(long timeout, TimeUnit unit):让这些线程等待至一定的时间,如果还有线程没有到达 barrier 状态就直接让到达 barrier 的线程执行后续任务。</p><pre><code class="java">    public static void main(String[] args) {        int N = 4;        CyclicBarrier barrier = new CyclicBarrier(N);        for(int i=0;i&lt;N;i++)            new Writer(barrier).start();    }    static class Writer extends Thread{        private CyclicBarrier cyclicBarrier;        public Writer(CyclicBarrier cyclicBarrier) {            this.cyclicBarrier = cyclicBarrier;        }        @Override        public void run() {            try {                Thread.sleep(5000);                //以睡眠来模拟线程需要预定写入数据操作                System.out.println(&quot; 线 程 &quot;+Thread.currentThread().getName()+&quot; 写 入 数 据 完 毕,等待其他线程写入完毕&quot;);                cyclicBarrier.await();            } catch (InterruptedException e) {                e.printStackTrace();            }catch( BrokenBarrierException e){                e.printStackTrace();            }            System.out.println(&quot;所有线程写入完毕,继续处理其他任务,比如数据操作&quot;);        }    }</code></pre><h4 id="Semaphore-信号量-控制同时访问的线程个数"><a href="#Semaphore-信号量-控制同时访问的线程个数" class="headerlink" title="Semaphore(信号量-控制同时访问的线程个数)"></a>Semaphore(信号量-控制同时访问的线程个数)</h4><p>Semaphore 翻译成字面意思为 信号量,Semaphore 可以控制同时访问的线程个数,通过<br>acquire() 获取一个许可,如果没有就等待,而 release() 释放一个许可。<br>Semaphore 类中比较重要的几个方法:</p><p>1.public void acquire(): 用来获取一个许可,若无许可能够获得,则会一直等待,直到获得许可。<br>2. public void acquire(int permits):获取 permits 个许可<br>3. public void release() { } :释放许可。注意,在释放许可之前,必须先获获得许可。<br>4. public void release(int permits) { }:释放 permits 个许可 </p><blockquote><p>上面 4 个方法都会被阻塞,如果想立即得到执行结果,可以使用下面几个方法</p></blockquote><p>1.public boolean tryAcquire():尝试获取一个许可,若获取成功,则立即返回 true,若获取失败,则立即返回 false<br>2.public boolean tryAcquire(long timeout, TimeUnit unit):尝试获取一个许可,若在指定的时间内获取成功,则立即返回 true,否则则立即返回 false<br>3.public boolean tryAcquire(int permits):尝试获取 permits 个许可,若获取成功,则立即返回 true,若获取失败,则立即返回 false<br>4.public boolean tryAcquire(int permits, long timeout, TimeUnit unit): 尝试获取 permits个许可,若在指定的时间内获取成功,则立即返回 true,否则则立即返回 false<br>5.还可以通过 availablePermits()方法得到可用的许可数目。例子:若一个工厂有 5 台机器,但是有 8 个工人,一台机器同时只能被一个工人使用,只有使用完了,其他工人才能继续使用。那么我们就可以通过 Semaphore 来实现:</p><pre><code class="java">public class SemaphoreDemo {    public static void main(String[] args) {        int N = 8;        //工人数        Semaphore semaphore = new Semaphore(5); //机器数目        for (int i = 0; i &lt; N; i++) new Worker(i, semaphore).start();    }    static class Worker extends Thread {        private int num;        private Semaphore semaphore;        public Worker(int num, Semaphore semaphore) {            this.num = num;            this.semaphore = semaphore;        }        @Override        public void run() {            try {                semaphore.acquire();                System.out.println(&quot;工人&quot; + this.num + &quot;占用一个机器在生产...&quot;);                Thread.sleep(2000);                System.out.println(&quot;工人&quot; + this.num + &quot;释放出机器&quot;);                semaphore.release();            } catch (InterruptedException e) {                e.printStackTrace();            }        }    }}</code></pre><ul><li>CountDownLatch 和 CyclicBarrier 都能够实现线程之间的等待,只不过它们侧重点不同;CountDownLatch 一般用于某个线程 A 等待若干个其他线程执行完任务之后,它才执行;而 CyclicBarrier 一般用于一组线程互相等待至某个状态,然后这一组线程再同时执行;另外,CountDownLatch 是不能够重用的,而 CyclicBarrier 是可以重用的。</li><li>Semaphore 其实和锁有点类似,它一般用于控制对某组资源的访问权限。</li></ul><h4 id="volatile-关键字的作用-变量可见性、禁止重排序"><a href="#volatile-关键字的作用-变量可见性、禁止重排序" class="headerlink" title="volatile 关键字的作用(变量可见性、禁止重排序)"></a>volatile 关键字的作用(变量可见性、禁止重排序)</h4><blockquote><p>Java 语言提供了一种稍弱的同步机制,即 volatile 变量,用来确保将变量的更新操作通知到其他线程。volatile 变量具备两种特性,volatile 变量不会被缓存在寄存器或者对其他处理器不可见的地方,因此在读取 volatile 类型的变量时总会返回最新写入的值。</p></blockquote><p><strong>变量可见性</strong><br>其一是保证该变量对所有线程可见,这里的可见性指的是当一个线程修改了变量的值,那么新的<br>值对于其他线程是可以立即获取的。<br><strong>禁止重排序</strong><br>volatile 禁止了指令重排。<br><code>比 sychronized 更轻量级的同步锁</code><br>在访问 volatile 变量时不会执行加锁操作,因此也就不会使执行线程阻塞,因此 volatile 变量是一<br>种比 sychronized 关键字更轻量级的同步机制。volatile 适合这种场景:一个变量被多个线程共<br>享,线程直接给这个变量赋值。</p><p><img src="/resource/img/volatile.png" srcset="/img/loading.gif" alt="avatar"></p><blockquote><p>当对非 volatile 变量进行读写的时候,每个线程先从内存拷贝变量到 CPU 缓存中。如果计算机有<br> 多个 CPU,每个线程可能在不同的 CPU 上被处理,这意味着每个线程可以拷贝到不同的 CPU<br> cache 中。而声明变量是 volatile 的,JVM 保证了每次读变量都从内存中读,跳过 CPU cache<br> 这一步。</p></blockquote><p><strong>适用场景</strong><br>值得说明的是对 volatile 变量的单次读/写操作可以保证原子性的,如 long 和 double 类型变量,<br>但是并不能保证 i++这种操作的原子性,因为本质上 i++是读、写两次操作。在某些场景下可以<br>代替 Synchronized。但是,volatile 的不能完全取代 Synchronized 的位置,只有在一些特殊的场景下,<br>才能适用 volatile。总的来说,必须同时满足下面两个条件才能保证在并发环境的线程安全:</p><p>(1)对变量的写操作不依赖于当前值(比如 i++),或者说是单纯的变量赋值(boolean flag = true)。</p><p>(2)该变量没有包含在具有其他变量的不变式中,也就是说,不同的 volatile 变量之间,不能互相依赖。只有在状态真正独立于程序内其他内容时才能使用 volatile。</p><h2 id="如何在两个线程之间共享数据"><a href="#如何在两个线程之间共享数据" class="headerlink" title="如何在两个线程之间共享数据"></a>如何在两个线程之间共享数据</h2><p>Java 里面进行多线程通信的主要方式就是共享内存的方式,共享内存主要的关注点有两个:可见<br>性和有序性原子性。Java 内存模型(JMM)解决了可见性和有序性的问题,而锁解决了原子性的<br>问题,理想情况下我们希望做到“同步”和“互斥”。有以下常规实现方法:</p><p><code>将数据抽象成一个类,并将数据的操作作为这个类的方法</code></p><p>1.将数据抽象成一个类,并将对这个数据的操作作为这个类的方法,这么设计可以和容易做到同步,只要在方法上加”synchronized“</p><pre><code class="java">public class Demo {    public class MyData {        private int j=0;        public synchronized void add(){            j++;            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j 为:&quot;+j);        }        public synchronized void dec(){            j--;            System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j 为:&quot;+j);        }        public int getData(){            return j;        }    }    public class AddRunnable implements Runnable{        MyData data;        public AddRunnable(MyData data){            this.data= data;        }        public void run() {            data.add();        }    }    public class DecRunnable implements Runnable {        MyData data;        public DecRunnable(MyData data){            this.data = data;        }        public void run() {            data.dec();        }    }    public static void main(String[] args) {        MyData data = new MyData();        Runnable add = new AddRunnable(data);        Runnable dec = new DecRunnable(data);        for (int i = 0; i &lt; 2; i++) {            new Thread(add).start();            new Thread(dec).start();        }    }}</code></pre><p>Runnable 对象作为一个类的内部类<br>2.将 Runnable 对象作为一个类的内部类,共享数据作为这个类的成员变量,每个线程对共享数<br>据的操作方法也封装在外部类,以便实现对数据的各个操作的同步和互斥,作为内部类的各<br>个 Runnable 对象调用外部类的这些方法。</p><pre><code class="java">public class MyData {    private int j=0;    public synchronized void add(){        j++;        System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j 为:&quot;+j);    }    public synchronized void dec(){        j--;        System.out.println(&quot;线程&quot;+Thread.currentThread().getName()+&quot;j 为:&quot;+j);    }    public int getData(){        return j;}}public class TestThread {    public static void main(String[] args) {        final MyData data = new MyData();        for(int i=0;i&lt;2;i++){            new Thread(new Runnable(){                public void run() {                    data.add();                }            }).start();            new Thread(new Runnable(){                public void run() {                    data.dec();                }            }).start();        }    }}</code></pre><h3 id="ThreadLocal-作用-线程本地存储"><a href="#ThreadLocal-作用-线程本地存储" class="headerlink" title="ThreadLocal 作用( 线程本地存储 )"></a>ThreadLocal 作用( 线程本地存储 )</h3><p>ThreadLocal,很多地方叫做线程本地变量,也有些地方叫做线程本地存储,ThreadLocal 的作用<br>是提供线程内的局部变量,这种变量在线程的生命周期内起作用,减少同一个线程内多个函数或<br>者组件之间一些公共变量的传递的复杂度。<br>ThreadLocalMap (线程的一个属性)<br>1.每个线程中都有一个自己的 ThreadLocalMap 类对象,可以将线程自己的对象保持到其中,各管各的,线程可以正确的访问到自己的对象。<br>2.将 一 个共 用的 ThreadLocal 静 态实 例作 为 key, 将 不同 对象 的引 用保存 到 不同 线程 的ThreadLocalMap 中,然后在线程执行的各处通过这个静态 ThreadLocal 实例的 get()方法取得自己线程保存的那个对象,避免了将这个对象作为参数传递的麻烦。<br>3.ThreadLocalMap 其实就是线程里面的一个属性,它在 Thread 类中定义<code>ThreadLocal.ThreadLocalMap threadLocals = null;</code></p><p><img src="/resource/img/ThreadLocal.png" srcset="/img/loading.gif" alt="avatar"></p><p><strong>使用场景</strong><br>最常见的 ThreadLocal 使用场景为 用来解决 数据库连接、Session 管理等。</p><pre><code class="java"> private static final ThreadLocal threadSession = new ThreadLocal();    public static Session getSession() throws InfrastructureException {        Session s = (Session) threadSession.get();        try {            if (s == null) {                s = getSessionFactory().openSession();                threadSession.set(s);            }        } catch (HibernateException ex) {            throw new InfrastructureException(ex);        }        return s;    }</code></pre><h3 id="synchronized-和-ReentrantLock-的区别"><a href="#synchronized-和-ReentrantLock-的区别" class="headerlink" title="synchronized 和 ReentrantLock 的区别"></a>synchronized 和 ReentrantLock 的区别</h3><p><strong>两者的共同点:</strong></p><ol><li>都是用来协调多线程对共享对象、变量的访问</li><li>都是可重入锁,同一线程可以多次获得同一个锁</li><li>都保证了可见性和互斥性</li></ol><p><strong>两者的不同点:</strong></p><ol><li>ReentrantLock 显示的获得、释放锁,synchronized 隐式获得释放锁</li><li>ReentrantLock 可响应中断、可轮回,synchronized 是不可以响应中断的,为处理锁的不可用性提供了更高的灵活性</li><li>ReentrantLock 是 API 级别的,synchronized 是 JVM 级别的</li><li>ReentrantLock 可以实现公平锁</li><li>ReentrantLock 通过 Condition 可以绑定多个条件</li><li>底层实现不一样, synchronized 是同步阻塞,使用的是悲观并发策略,lock 是同步非阻塞,采用的是乐观并发策略</li><li>Lock 是一个接口,而 synchronized 是 Java 中的关键字,synchronized 是内置的语言实现。</li><li>synchronized 在发生异常时,会自动释放线程占有的锁,因此不会导致死锁现象发生;而 Lock 在发生异常时,如果没有主动通过 unLock()去释放锁,则很可能造成死锁现象,因此使用 Lock 时需要在 finally 块中释放锁。</li><li>Lock 可以让等待锁的线程响应中断,而 synchronized 却不行,使用 synchronized 时,等待的线程会一直等待下去,不能够响应中断。</li><li>通过 Lock 可以知道有没有成功获取锁,而 synchronized 却无法办到。</li><li>Lock 可以提高多个线程进行读操作的效率,既就是实现读写锁等。</li></ol><h3 id="ConcurrentHashMap-并发"><a href="#ConcurrentHashMap-并发" class="headerlink" title="ConcurrentHashMap 并发"></a>ConcurrentHashMap 并发</h3><p>减小锁粒度</p><blockquote><p>减小锁粒度是指缩小锁定对象的范围,从而减小锁冲突的可能性,从而提高系统的并发能力。减<br>小锁粒度是一种削弱多线程锁竞争的有效手段,这种技术典型的应用是 ConcurrentHashMap(高<br>性能的 HashMap)类的实现。对于 HashMap 而言,最重要的两个方法是 get 与 set 方法,如果我<br>们对整个 HashMap 加锁,可以得到线程安全的对象,但是加锁粒度太大。Segment 的大小也被<br>称为 ConcurrentHashMap 的并发度。</p></blockquote><p>ConcurrentHashMap 分段锁</p><blockquote><p>ConcurrentHashMap,它内部细分了若干个小的 HashMap,称之为段(Segment)。默认情况下<br>一个 ConcurrentHashMap 被进一步细分为 16 个段,既就是锁的并发度。<br>如果需要在 ConcurrentHashMap 中添加一个新的表项,并不是将整个 HashMap 加锁,而是首<br>先根据 hashcode 得到该表项应该存放在哪个段中,然后对该段加锁,并完成 put 操作。在多线程<br>环境中,如果多个线程同时进行 put 操作,只要被加入的表项不存放在同一个段中,则线程间可以<br>做到真正的并行。</p></blockquote><p>ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成</p><blockquote><p>ConcurrentHashMap 是由 Segment 数组结构和 HashEntry 数组结构组成。Segment 是一种可<br>重入锁 ReentrantLock,在 ConcurrentHashMap 里扮演锁的角色,HashEntry 则用于存储键值<br>对数据。一个 ConcurrentHashMap 里包含一个 Segment 数组,Segment 的结构和 HashMap<br>类似,是一种数组和链表结构, 一个 Segment 里包含一个 HashEntry 数组,每个 HashEntry 是<br>一个链表结构的元素, 每个 Segment 守护一个 HashEntry 数组里的元素,当对 HashEntry 数组的<br>数据进行修改时,必须首先获得它对应的 Segment 锁。</p></blockquote><p><img src="/resource/img/ConcurrentHashMap.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="Java-中用到的线程调度"><a href="#Java-中用到的线程调度" class="headerlink" title="Java 中用到的线程调度"></a>Java 中用到的线程调度</h2><p>抢占式调度:  </p><blockquote><p>抢占式调度指的是每条线程执行的时间、线程的切换都由系统控制,系统控制指的是在系统某种<br>运行机制下,可能每条线程都分同样的执行时间片,也可能是某些线程执行的时间片较长,甚至<br>某些线程得不到执行的时间片。在这种机制下,一个线程的堵塞不会导致整个进程堵塞。</p></blockquote><p>协同式调度:  </p><blockquote><p>协同式调度指某一线程执行完后主动通知系统切换到另一线程上执行,这种模式就像接力赛一样,<br>一个人跑完自己的路程就把接力棒交接给下一个人,下个人继续往下跑。线程的执行时间由线程<br>本身控制,线程切换可以预知,不存在多线程同步问题,但它有一个致命弱点:如果一个线程编<br>写有问题,运行到一半就一直堵塞,那么可能导致整个系统崩溃。</p></blockquote><p><img src="/resource/img/threadway.png" srcset="/img/loading.gif" alt="avatar"></p><p>JVM 的线程调度实现(抢占式调度)</p><blockquote><p>java 使用的线程调使用抢占式调度,Java 中线程会按优先级分配 CPU 时间片运行,且优先级越高<br>越优先执行,但优先级高并不代表能独自占用执行时间片,可能是优先级高得到越多的执行时间<br>片,反之,优先级低的分到的执行时间少但不会分配不到执行时间。</p></blockquote><p>线程让出 cpu 的情况:</p><p>1.当前运行线程主动放弃 CPU,JVM 暂时放弃 CPU 操作(基于时间片轮转调度的 JVM 操作系统不会让线程永久放弃 CPU,或者说放弃本次时间片的执行权),例如调用 yield()方法。<br>2. 当前运行线程因为某些原因进入阻塞状态,例如阻塞在 I/O 上。<br>3. 当前运行线程结束,即运行完 run()方法里面的任务。</p><h3 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h3><p>优先调度算法</p><p>1.先来先服务调度算法(FCFS)<br>当在作业调度中采用该算法时,每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业,将它们调入内存,为它们分配资源、创建进程,然后放入就绪队列。在进程调度中采用 FCFS 算法时,则每次调度是从就绪队列中选择一个最先进入该队列的进程,为之分配处理机,使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机,特点是:算法比较简单,可以实现基本上的公平。</p><p>2.短作业(进程)优先调度算法<br>短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业,将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程,将处理机分配给它,使它立即执行并一直执行到完成,或发生某事件而被阻塞放弃处理机时再重新调度。该算法未照顾紧迫型作业。</p><h3 id="高优先权优先调度算法"><a href="#高优先权优先调度算法" class="headerlink" title="高优先权优先调度算法"></a>高优先权优先调度算法</h3><p>为了照顾紧迫型作业,使之在进入系统后便获得优先处理,引入了最高优先权优先(FPF)调度<br>算法。当把该算法用于作业调度时,系统将从后备队列中选择若干个优先权最高的作业装入内存。<br>当用于进程调度时,该算法是把处理机分配给就绪队列中优先权最高的进程。</p><p>1.非抢占式优先权算法<br>在这种方式下,系统一旦把处理机分配给就绪队列中优先权最高的进程后,该进程便一直执行下<br>去,直至完成;或因发生某事件使该进程放弃处理机时。这种调度算法主要用于批处理系统中;<br>也可用于某些对实时性要求不严的实时系统中。</p><p>2.抢占式优先权调度算法<br>在这种方式下,系统同样是把处理机分配给优先权最高的进程,使之执行。但在其执行期间,只<br>要又出现了另一个其优先权更高的进程,进程调度程序就立即停止当前进程(原优先权最高的进程)<br>的执行,重新将处理机分配给新到的优先权最高的进程。显然,这种抢占式的优先权调度算法能<br>更好地满足紧迫作业的要求,故而常用于要求比较严格的实时系统中,以及对性能要求较高的批<br>处理和分时系统中。</p><h3 id="高响应比优先调度算法"><a href="#高响应比优先调度算法" class="headerlink" title="高响应比优先调度算法"></a>高响应比优先调度算法</h3><p>在批处理系统中,短作业优先算法是一种比较好的算法,其主要的不足之处是长作业的运行<br>得不到保证。如果我们能为每个作业引入前面所述的动态优先权,并使作业的优先级随着等待时<br>间的增加而以速率 a 提高,则长作业在等待一定的时间后,必然有机会分配到处理机。该优先权的<br>变化规律可描述为:</p><p><img src="/resource/img/hightresponse.png" srcset="/img/loading.gif" alt="avatar"></p><p>(1) 如果作业的等待时间相同,则要求服务的时间愈短,其优先权愈高,因而该算法有利于短作业。<br>(2) 当要求服务的时间相同时,作业的优先权决定于其等待时间,等待时间愈长,其优先权愈高,因而它实现的是先来先服务。<br>(3) 对于长作业,作业的优先级可以随等待时间的增加而提高,当其等待时间足够长时,其优先级便可升到很高,从而也可获得处理机。简言之,该算法既照顾了短作业,又考虑了作业到达的先后次序,不会使长作业长期得不到服务。因此,该算法实现了一种较好的折衷。当然,在利用该算法时,每要进行调度之前,都须先做响应比的计算,这会增加系统开销。</p><h3 id="基于时间片的轮转调度算法"><a href="#基于时间片的轮转调度算法" class="headerlink" title="基于时间片的轮转调度算法"></a>基于时间片的轮转调度算法</h3><p>1.时间片轮转法<br>在早期的时间片轮转法中,系统将所有的就绪进程按先来先服务的原则排成一个队列,每次调度<br>时,把 CPU 分配给队首进程,并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行<br>的时间片用完时,由一个计时器发出时钟中断请求,调度程序便据此信号来停止该进程的执行,<br>并将它送往就绪队列的末尾;然后,再把处理机分配给就绪队列中新的队首进程,同时也让它执<br>行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处<br>理机执行时间。</p><p>2.多级反馈队列调度算法</p><p>(1) 应设置多个就绪队列,并为各个队列赋予不同的优先级。第一个队列的优先级最高,第二<br>个队列次之,其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各<br>不相同,在优先权愈高的队列中,为每个进程所规定的执行时间片就愈小。例如,第二个队列的<br>时间片要比第一个队列的时间片长一倍,……,第 i+1 个队列的时间片要比第 i 个队列的时间片长<br>一倍。</p><p>(2) 当一个新进程进入内存后,首先将它放入第一队列的末尾,按 FCFS 原则排队等待调度。当<br>轮到该进程执行时,如它能在该时间片内完成,便可准备撤离系统;如果它在一个时间片结束时<br>尚未完成,调度程序便将该进程转入第二队列的末尾,再同样地按 FCFS 原则等待调度执行;如果<br>它在第二队列中运行一个时间片后仍未完成,再依次将它放入第三队列,……,如此下去,当一个<br>长作业(进程)从第一队列依次降到第 n 队列后,在第 n 队列便采取按时间片轮转的方式运行。</p><p>(3) 仅当第一队列空闲时,调度程序才调度第二队列中的进程运行;仅当第 1<del>(i-1)队列均空时,<br>才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时,又有新进程进入优<br>先权较高的队列(第 1</del>(i-1)中的任何一个队列),则此时新进程将抢占正在运行进程的处理机,即<br>由调度程序把正在运行的进程放回到第 i 队列的末尾,把处理机分配给新到的高优先权进程。<br>在多级反馈队列调度算法中,如果规定第一个队列的时间片略大于多数人机交互所需之处理时间<br>时,便能够较好的满足各种类型用户的需要。</p><h1 id="什么是-CAS-比较并交换-乐观锁机制-锁自旋"><a href="#什么是-CAS-比较并交换-乐观锁机制-锁自旋" class="headerlink" title="什么是 CAS( 比较并交换-乐观锁机制-锁自旋 )"></a>什么是 CAS( 比较并交换-乐观锁机制-锁自旋 )</h1><h3 id="概念及特性"><a href="#概念及特性" class="headerlink" title="概念及特性"></a>概念及特性</h3><blockquote><p>CAS(Compare And Swap/Set)比较并交换,CAS 算法的过程是这样:它包含 3 个参数<br>CAS(V,E,N)。V 表示要更新的变量(内存值),E 表示预期值(旧的),N 表示新值。当且仅当 V 值等<br>于 E 值时,才会将 V 的值设为 N,如果 V 值和 E 值不同,则说明已经有其他线程做了更新,则当<br>前线程什么都不做。最后,CAS 返回当前 V 的真实值。<br>CAS 操作是抱着乐观的态度进行的(乐观锁),它总是认为自己可以成功完成操作。当多个线程同时<br>使用 CAS 操作一个变量时,只有一个会胜出,并成功更新,其余均会失败。失败的线程不会被挂<br>起,仅是被告知失败,并且允许再次尝试,当然也允许失败的线程放弃操作。基于这样的原理,<br>CAS 操作即使没有锁,也可以发现其他线程对当前线程的干扰,并进行恰当的处理。</p></blockquote><h3 id="原子包-java-util-concurrent-atomic-锁自旋"><a href="#原子包-java-util-concurrent-atomic-锁自旋" class="headerlink" title="原子包 java.util.concurrent.atomic(锁自旋)"></a>原子包 java.util.concurrent.atomic(锁自旋)</h3><blockquote><p>JDK1.5 的原子包:java.util.concurrent.atomic 这个包里面提供了一组原子类。其基本的特性就<br>是在多线程环境下,当有多个线程同时执行这些类的实例包含的方法时,具有排他性,即当某个<br>线程进入方法,执行其中的指令时,不会被其他线程打断,而别的线程就像自旋锁一样,一直等<br>到该方法执行完成,才由 JVM 从等待队列中选择一个另一个线程进入,这只是一种逻辑上的理解。<br>相对于对于 synchronized 这种阻塞算法,CAS 是非阻塞算法的一种常见实现。由于一般 CPU 切<br>换时间比 CPU 指令集操作更加长, 所以 J.U.C 在性能上有了很大的提升。如下代码:</p></blockquote><pre><code class="java">public class AtomicInteger extends Number implements java.io.Serializable {    private volatile int value;    public final int get() {        return value;    }    public final int getAndIncrement() {        for (;;) { //CAS 自旋,一直尝试,直达成功            int current = get();            int next = current + 1;            if (compareAndSet(current, next))                return current;        }    }    public final boolean compareAndSet(int expect, int update) {        return unsafe.compareAndSwapInt(this, valueOffset, expect, update);    }}</code></pre><p>getAndIncrement 采用了 CAS 操作,每次从内存中读取数据然后将此数据和+1 后的结果进行<br>CAS 操作,如果成功就返回结果,否则重试直到成功为止。而 compareAndSet 利用 JNI 来完成<br>CPU 指令的操作。</p><p><img src="/resource/img/CAS.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="ABA-问题"><a href="#ABA-问题" class="headerlink" title="ABA 问题"></a>ABA 问题</h3><p>CAS 会导致“ABA 问题”。CAS 算法实现一个重要前提需要取出内存中某时刻的数据,而在下时<br>刻比较并替换,那么在这个时间差类会导致数据的变化。<br>比如说一个线程 one 从内存位置 V 中取出 A,这时候另一个线程 two 也从内存中取出 A,并且<br>two 进行了一些操作变成了 B,然后 two 又将 V 位置的数据变成 A,这时候线程 one 进行 CAS 操<br>作发现内存中仍然是 A,然后 one 操作成功。尽管线程 one 的 CAS 操作成功,但是不代表这个过<br>程就是没有问题的。<br>部分乐观锁的实现是通过版本号(version)的方式来解决 ABA 问题,乐观锁每次在执行数据的修<br>改操作时,都会带上一个版本号,一旦版本号和数据的版本号一致就可以执行修改操作并对版本<br>号执行+1 操作,否则就执行失败。因为每次操作的版本号都会随之增加,所以不会出现 ABA 问<br>题,因为版本号只会增加不会减少。</p><h3 id="什么是-AQS-抽象的队列同步器"><a href="#什么是-AQS-抽象的队列同步器" class="headerlink" title="什么是 AQS( 抽象的队列同步器 )"></a>什么是 AQS( 抽象的队列同步器 )</h3><p>AbstractQueuedSynchronizer 类如其名,抽象的队列式的同步器,AQS 定义了一套多线程访问<br>共享资源的同步器框架,许多同步类实现都依赖于它,如常用的<br><code>ReentrantLock/Semaphore/CountDownLatch</code>。</p><p><img src="/resource/img/ABA.png" srcset="/img/loading.gif" alt="avatar"></p><p>它维护了一个 volatile int state(代表共享资源)和一个 FIFO 线程等待队列(多线程争用资源被<br>阻塞时会进入此队列)。这里 volatile 是核心关键词,具体 volatile 的语义,在此不述。state 的<br>访问方式有三种:</p><ul><li>getState()</li><li>setState()</li><li>compareAndSetState()</li></ul><h3 id="AQS-定义两种资源共享方式"><a href="#AQS-定义两种资源共享方式" class="headerlink" title="AQS 定义两种资源共享方式"></a>AQS 定义两种资源共享方式</h3><ul><li>Exclusive 独占资源 -ReentrantLock</li><li>Exclusive(独占,只有一个线程能执行,如 ReentrantLock)</li><li>Share 共享资源 -Semaphore/CountDownLatch</li><li>Share(共享,多个线程可同时执行,如 Semaphore/CountDownLatch)。</li></ul><p>AQS 只是一个框架,具体资源的获取/释放方式交由自定义同步器去实现,AQS 这里只定义了一个接口,具体资源的获取交由自定义同步器去实现了(通过 state 的 get/set/CAS)之所以没有定义成<br>abstract , 是 因 为 独 占 模 式 下 只 用 实 现 tryAcquire-tryRelease , 而 共 享 模 式 下 只 用 实 现tryAcquireShared-tryReleaseShared。如果都定义成 abstract,那么每个模式也要去实现另一模式下的接口。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可,至于具体线程等待队列的维护(如获取资源失败入队/唤醒出队等),AQS 已经在顶层实现好了。自定义同步器实现时主要实现以下几种方法:</p><ol><li>isHeldExclusively():该线程是否正在独占资源。只有用到 condition 才需要去实现它。</li><li>tryAcquire(int):独占方式。尝试获取资源,成功则返回 true,失败则返回 false。</li><li>tryRelease(int):独占方式。尝试释放资源,成功则返回 true,失败则返回 false。</li><li>tryAcquireShared(int):共享方式。尝试获取资源。负数表示失败;0 表示成功,但没有剩余可用资源;正数表示成功,且有剩余资源。</li><li>tryReleaseShared(int):共享方式。尝试释放资源,如果释放后允许唤醒后续等待结点返回true,否则返回 false。</li></ol><h3 id="同步器的实现是-ABS-核心-state-资源状态计数"><a href="#同步器的实现是-ABS-核心-state-资源状态计数" class="headerlink" title="同步器的实现是 ABS 核心( state 资源状态计数)"></a>同步器的实现是 ABS 核心( state 资源状态计数)</h3><p>同步器的实现是 ABS 核心,以 ReentrantLock 为例,state 初始化为 0,表示未锁定状态。A 线程<br>lock()时,会调用 tryAcquire()独占该锁并将 state+1。此后,其他线程再 tryAcquire()时就会失<br>败,直到 A 线程 unlock()到 state=0(即释放锁)为止,其它线程才有机会获取该锁。当然,释放<br>锁之前,A 线程自己是可以重复获取此锁的(state 会累加),这就是可重入的概念。但要注意,<br>获取多少次就要释放多么次,这样才能保证 state 是能回到零态的。<br>以 CountDownLatch 以例,任务分为 N 个子线程去执行,state 也初始化为 N(注意 N 要与<br>线程个数一致)。这 N 个子线程是并行执行的,每个子线程执行完后 countDown()一次,state<br>会 CAS 减 1。等到所有子线程都执行完后(即 state=0),会 unpark()主调用线程,然后主调用线程<br>就会从 await()函数返回,继续后余动作。</p><h3 id="ReentrantReadWriteLock-实现独占和共享两种方式"><a href="#ReentrantReadWriteLock-实现独占和共享两种方式" class="headerlink" title="ReentrantReadWriteLock 实现独占和共享两种方式"></a>ReentrantReadWriteLock 实现独占和共享两种方式</h3><p>一般来说,自定义同步器要么是独占方法,要么是共享方式,他们也只需实现 tryAcquire-tryRelease、tryAcquireShared-tryReleaseShared 中的一种即可。但 AQS 也支持自定义同步器同时实现独占和共享两种方式,如 ReentrantReadWriteLock。</p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Thread</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java 集合</title>
    <link href="/2020/05/29/Java-%E9%9B%86%E5%90%88/"/>
    <url>/2020/05/29/Java-%E9%9B%86%E5%90%88/</url>
    
    <content type="html"><![CDATA[<h1 id="接口继承关系和实现"><a href="#接口继承关系和实现" class="headerlink" title="接口继承关系和实现"></a>接口继承关系和实现</h1><blockquote><p>集合类存放于Java.util包中，主要有三种：<code>set(集)</code>，<code>list(列表包含Queue)</code>，<code>map(映射)</code></p></blockquote><ul><li>Collection:Collection是集合List、Set、Queue的最基本的接口。</li><li>Iterator:迭代器，可以通过迭代器遍历集合中的数据。</li><li>Map:是映射表的基础接口</li></ul><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200529102225.png" srcset="/img/loading.gif" alt="avatar"></p><p>集合框架</p><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200529102233.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="List"><a href="#List" class="headerlink" title="List"></a>List</h1><blockquote><p>Java的List是非常常用的的数据类型。List是有序的Collection。Java List一共三个实现：<code>ArrayList</code>，<code>Vector</code>，<code>LinkedList</code></p></blockquote><p><img src="/resource/img/List.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li><p>ArrayList(数组)</p><blockquote><p>ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速随机访问。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要将已经有数组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。</p></blockquote></li><li><p>Vector(数组实现、线程同步)</p><blockquote><p>Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程同步，即某一刻只有一个线程能够写Vector，避免多线程同时而引起的不一致性，但实现同步需要很高的花费，因此访问它比访问ArrayList慢。</p></blockquote></li><li><p>LinkList(链表)</p><blockquote><p>LinkedList是用链表结构存储数据的，很适合数据的动态插入和删除，随机访问和遍历速度比较慢。另外，他还提供List接口中没有定义的方法，专门用于操作表头和表尾元素，可以当做堆栈、队列和双向队列使用</p></blockquote></li></ul><h1 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h1><blockquote><p>Set注重独一无二的性质，该体系结合用于存储无序(存入存出的顺序不一定相同)元素，值元素不能重复。对象的相等本质是对象的hashCode值(java是依据对象的内存地址计算出的此序号)判断的，如果想让两个不同的对象视为相等的，就必须覆盖Object的hashCode方法和equals方法</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200529175509.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="HashSet-Hash表"><a href="#HashSet-Hash表" class="headerlink" title="HashSet(Hash表)"></a>HashSet(Hash表)</h2><blockquote><p>哈希表存放的是哈希值。HashSet存储元素的顺序并不是按照存入时的顺序<code>(和List显然不同)</code>而是按照哈希值来存的所以取数据也是按照哈希值取的。元素的哈希值是通过元素的<code>hashcode</code>方法获取的，HashSet首先判断两个元素的哈希值，如果哈希值用于，接着会比较<code>equals</code>方法如果equals结果为true，HashSet就视为同一个元素。如果equals为false就不是同一个元素。</p></blockquote><blockquote><p>哈希值相同equals为false的元素是怎么存储呢？就是在同样的哈希值下顺延<code>(可以认为哈希值相同的元素放在一个哈希桶中)</code>也就是哈希一样的存一列。如图1所示表示hashCode值不相同的情况;图2表示hashCode值相同，但是equals不相同情况。</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200529102233.png" srcset="/img/loading.gif" alt="avatar"></p><blockquote><p>HashSet通过hashCode值来确定元素在内存中的位置。一个hashCode位置上可以存放多个元素。</p></blockquote><h2 id="TreeSet-二叉树"><a href="#TreeSet-二叉树" class="headerlink" title="TreeSet(二叉树)"></a>TreeSet(二叉树)</h2><ul><li><p>TreeSet()是使用二叉树的原理对新add()的对象按照指定的顺序排序(升序、降序)，每增加一个对象都会进行进行排序，将对象插入的二叉树指定的位置。</p></li><li><p>Integer和String对象都可以进行默认的TreeSet排序，而自定义类的对象是不可以的，<code>自己定义的类必须实现Comparable接口，并且复写相应的compareTo()函数</code>，才可以正常使用。</p></li><li><p>在覆写compare()函数时，要返回相应的值才能使TreeSet按照一定的规则来排序</p></li><li><p>在比较此对象与指定对象的顺序。如果该对象大小，等于或大于指定对象，则分别防护负整数、零或正整数。</p></li></ul><h2 id="LinkHashSet-HashSet-LinkedHashMap"><a href="#LinkHashSet-HashSet-LinkedHashMap" class="headerlink" title="LinkHashSet(HashSet+LinkedHashMap)"></a>LinkHashSet(HashSet+LinkedHashMap)</h2><blockquote><p>对于LinkedHashSet而言，它继承与HashSet、又基于LinkedHashMap来实现的。LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承于HashSet，其所有的方法操作上又与HashSet相同，因此LinkedHashSet的实现上非常简单，只提供了四个构造方法，并通过传递一个标识参数，调用父类的构造器，底层构造一个LinkedHashMap来实现，在相关操作上与父类HashSet的操作相同，直接调用父类HashSet的方法即可。</p></blockquote><h1 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h1><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200530115930.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="HashMap-数组-链表-红黑树"><a href="#HashMap-数组-链表-红黑树" class="headerlink" title="HashMap(数组+链表+红黑树)"></a>HashMap(数组+链表+红黑树)</h2><blockquote><p>HashMap 根据键的 hashCode 值存储数据,大多数情况下可以直接定位到它的值,因而具有很快<br> 的访问速度,但遍历顺序却是不确定的。 HashMap 最多只允许一条记录的键为 null,允许多条记<br> 录的值为 null。HashMap 非线程安全,即任一时刻可以有多个线程同时写 HashMap,可能会导<br> 致数据的不一致。如果需要满足线程安全,可以用 Collections 的 synchronizedMap 方法使<br> HashMap 具有线程安全的能力,或者使用 ConcurrentHashMap。我们用下面这张图来介绍<br> HashMap 的结构。</p></blockquote><h2 id="Java7实现"><a href="#Java7实现" class="headerlink" title="Java7实现"></a>Java7实现</h2><blockquote><p>Java7HashMap结构</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200530121604.png" srcset="/img/loading.gif" alt="avatar"></p><blockquote><p>大方向上,HashMap 里面是一个数组,然后数组中每个元素是一个单向链表。上图中,每个绿色<br>的实体是嵌套类 Entry 的实例,Entry 包含四个属性:key, value, hash 值和用于单向链表的 next。</p></blockquote><ol><li>capacity:当前数组容量,始终保持 2^n,可以扩容,扩容后数组大小为当前的 2 倍。</li><li>loadFactor:负载因子,默认为 0.75。</li><li>threshold:扩容的阈值,等于 capacity * loadFactor</li></ol><h2 id="Java8实现"><a href="#Java8实现" class="headerlink" title="Java8实现"></a>Java8实现</h2><blockquote><p>Java8 对 HashMap 进行了一些修改,最大的不同就是利用了红黑树,所以其由 数组+链表+红黑<br> 树 组成。<br> 根据 Java7 HashMap 的介绍,我们知道,查找的时候,根据 hash 值我们能够快速定位到数组的<br> 具体下标,但是之后的话,需要顺着链表一个个比较下去才能找到我们需要的,时间复杂度取决<br> 于链表的长度,为 O(n)。为了降低这部分的开销,在 Java8 中,当链表中的元素超过了 8 个以后,<br> 会将链表转换为红黑树,在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。</p></blockquote><blockquote><p>Java8 HashMap结构</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200530121933.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><h3 id="Segment-段"><a href="#Segment-段" class="headerlink" title="Segment 段"></a>Segment 段</h3><blockquote><p>ConcurrentHashMap 和 HashMap 思路是差不多的,但是因为它支持并发操作,所以要复杂一<br>些。整个 ConcurrentHashMap 由一个个 Segment 组成,Segment 代表”部分“或”一段“的<br>意思,所以很多地方都会将其描述为分段锁。注意,行文中,我很多地方用了“槽”来代表一个segment。</p></blockquote><h3 id="线程安全-Segment-继承-ReentrantLock-加锁"><a href="#线程安全-Segment-继承-ReentrantLock-加锁" class="headerlink" title="线程安全(Segment 继承 ReentrantLock 加锁)"></a>线程安全(Segment 继承 ReentrantLock 加锁)</h3><blockquote><p>简单理解就是,ConcurrentHashMap 是一个 Segment 数组,Segment 通过继承<br>ReentrantLock 来进行加锁,所以每次需要加锁的操作锁住的是一个 segment,这样只要保证每<br>个 Segment 是线程安全的,也就实现了全局的线程安全。</p></blockquote><h4 id="Java7-ConcurrentHashMap结构"><a href="#Java7-ConcurrentHashMap结构" class="headerlink" title="Java7 ConcurrentHashMap结构"></a>Java7 ConcurrentHashMap结构</h4><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200530122248.png" srcset="/img/loading.gif" alt="avatar"></p><h4 id="并行度-默认-16"><a href="#并行度-默认-16" class="headerlink" title="并行度(默认 16)"></a>并行度(默认 16)</h4><blockquote><p>concurrencyLevel:并行级别、并发数、Segment 数,怎么翻译不重要,理解它。默认是 16,<br>也就是说 ConcurrentHashMap 有 16 个 Segments,所以理论上,这个时候,最多可以同时支<br>持 16 个线程并发写,只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时<br>候设置为其他值,但是一旦初始化以后,它是不可以扩容的。再具体到每个 Segment 内部,其实<br>每个 Segment 很像之前介绍的 HashMap,不过它要保证线程安全,所以处理起来要麻烦些。</p></blockquote><h4 id="Java8-ConcurrentHashMap结构"><a href="#Java8-ConcurrentHashMap结构" class="headerlink" title="Java8 ConcurrentHashMap结构"></a>Java8 ConcurrentHashMap结构</h4><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200530122718.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="HashTable-线程安全"><a href="#HashTable-线程安全" class="headerlink" title="HashTable(线程安全)"></a>HashTable(线程安全)</h2><p>Hashtable 是遗留类,很多映射的常用功能与 HashMap 类似,不同的是它承自 Dictionary 类,<br>并且是线程安全的,任一时间只有一个线程能写 Hashtable,并发性不如 ConcurrentHashMap,<br>因为 ConcurrentHashMap 引入了分段锁。Hashtable 不建议在新代码中使用,不需要线程安全<br>的场合可以用 HashMap 替换,需要线程安全的场合可以用 ConcurrentHashMap 替换。</p><h2 id="TreeMap-可排序"><a href="#TreeMap-可排序" class="headerlink" title="TreeMap(可排序)"></a>TreeMap(可排序)</h2><p>TreeMap 实现 SortedMap 接口,能够把它保存的记录根据键排序,默认是按键值的升序排序,<br>也可以指定排序的比较器,当用 Iterator 遍历 TreeMap 时,得到的记录是排过序的。<br>如果使用排序的映射,建议使用 TreeMap。<br>在使用 TreeMap 时,key 必须实现 Comparable 接口或者在构造 TreeMap 传入自定义的<br>Comparator,否则会在运行时抛出 java.lang.ClassCastException 类型的异常。</p><p><a href="https://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html" target="_blank" rel="noopener">参考</a></p><h2 id="LinkHashMap-记录插入顺序"><a href="#LinkHashMap-记录插入顺序" class="headerlink" title="LinkHashMap(记录插入顺序)"></a>LinkHashMap(记录插入顺序)</h2><p>LinkedHashMap 是 HashMap 的 一 个 子 类 , 保 存 了 记 录 的 插 入 顺 序 , 在 用 Iterator 遍 历<br>LinkedHashMap 时,先得到的记录肯定是先插入的,也可以在构造时带参数,按照访问次序排序。</p><p><a href="http://www.importnew.com/28263.html" target="_blank" rel="noopener">参考 1</a><br><a href="http://www.importnew.com/20386.html#comment-648123" target="_blank" rel="noopener">参考 2</a></p>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Collection</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>阅读书单</title>
    <link href="/2020/05/27/%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95/"/>
    <url>/2020/05/27/%E9%98%85%E8%AF%BB%E4%B9%A6%E5%8D%95/</url>
    
    <content type="html"><![CDATA[<h1 id="电子书网站"><a href="#电子书网站" class="headerlink" title="电子书网站"></a>电子书网站</h1><p><a href="cn.epubee.com/books">cn.epubee.com</a></p><p><a href="www.jiumodiary.com">www.jiumodiary.com</a></p><p><a href="www.owllook.net">www.owllook.net</a></p><p><a href="mebook.cc">mebook.cc</a></p><p><a href="www.xilinjie.com">www.xilinjie.com</a></p><p><a href="bookfere.com">bookfere.com</a></p><p><a href="www.pansoso.com">www.pansoso.com</a></p><p><a href="dianzishu.renrensousuo.com">dianzishu.renrensousuo.com</a></p><p><a href="www.pdfzj.cn">www.pdfzj.cn</a></p><p><a href="www.book118.com">www.book118.com</a></p><p><a href="sobooks.cc">sobooks.cc</a></p><p><a href="kgbook.com">kgbook.com</a></p><p><a href="www.en8848.com.cn/Soft/">www.en8848.com.cn</a></p><p><a href="cn.epubee.com/books/">cn.epubee.com</a></p><p><a href="bestcbooks.com">bestcbooks.com</a></p><h1 id="智商"><a href="#智商" class="headerlink" title="智商"></a>智商</h1><ul><li><a href="/resource/pdf/艾德勒，范多伦《如何阅读一本书》（美）.pdf">如何阅读一本书</a></li><li>精进</li><li>学习之道</li><li>刻意练习</li><li>学会提问</li><li>撤掉思维里面的墙</li><li>故事思维</li><li>创新：皮克斯的启示</li><li>高效的秘密</li><li>沃顿商学院最欢迎的谈判课</li><li>羊皮卷</li></ul><h1 id="情商"><a href="#情商" class="headerlink" title="情商"></a>情商</h1><ul><li>蔡永康的说话之道</li><li>人性的优点</li><li>人性的弱点</li><li>和任何人都聊得来</li><li>沟通的艺术</li><li>高难度谈话</li><li>情商</li><li>心动开关</li><li>像TED一样演讲</li><li>乔布斯的魔力演讲</li></ul><h1 id="健康"><a href="#健康" class="headerlink" title="健康"></a>健康</h1><p>怎样吃东西才更健康<br>今天的东西为啥不好吃<br>第三个餐盘<br>营养补充剂真的有那么神奇<br>战胜饥饿<br>轻断食<br>食疗圣经<br>大脑塑造者<br>肠子的小心思  </p><h1 id="逆境"><a href="#逆境" class="headerlink" title="逆境"></a>逆境</h1><p>反脆弱<br>怦然心动的人生整理魔法<br>自控力<br>世界如此险恶你要内心强大<br>冲破黑暗<br>告别玻璃心的13件事<br>习惯的力量<br>用毅力走向成功<br>另一种选择<br>不在乎的人生魔法  </p><h1 id="德体"><a href="#德体" class="headerlink" title="德体"></a>德体</h1><p>追风筝的人<br>战争与松脂<br>第23条军规<br>在暗室中<br>双生梦魇<br>百年孤独<br>罪与罚<br>狼图腾<br>平凡的世界<br>奇迹  </p><h1 id="财富"><a href="#财富" class="headerlink" title="财富"></a>财富</h1><p>魔鬼经济学1<br>魔鬼经济学2<br>贫穷的本质<br>负利率时代<br>与巴菲特共进午餐<br>投资中最简单的事<br>滚雪球<br>从零开始稳稳赚<br>百万富翁的思维密码<br>数字黄金  </p><h1 id="视野"><a href="#视野" class="headerlink" title="视野"></a>视野</h1><p>大国游戏  </p><h1 id="豆瓣TOP"><a href="#豆瓣TOP" class="headerlink" title="豆瓣TOP"></a>豆瓣TOP</h1><p>1.《百年孤独》 （豆瓣评分：9.2)<br>2.《如何阅读一本书》 （豆瓣评分：8.5)<br>3.《少有人走的路》 （豆瓣评分：8.4)<br>4.《乌合之众》 （豆瓣评分：8.4)<br>5.《追风筝的人》 （豆瓣评分：8.8)<br>6.《万历十五年》 （豆瓣评分：8.9)<br>7.《红楼梦》 （豆瓣评分：9.5)<br>8.《三体》 （豆瓣评分：8.8)<br>9.《失控》 （豆瓣评分：8.8)<br>10.《白夜行》 （豆瓣评分：9.1)<br>11.《不能承受的生命之轻》 （豆瓣评分：8.4)<br>12.《社会心理学》 （豆瓣评分：9)<br>13.《心理学与生活》 （豆瓣评分：8.7)<br>14.《小王子》 （豆瓣评分：9)<br>15.《影响力》 （豆瓣评分：8.6)<br>16.《哥德尔、艾舍尔、巴赫》 （豆瓣评分：9.4)<br>17.《通往奴役之路》 （豆瓣评分：8.9)<br>18.《历史深处的忧虑》 （豆瓣评分：9)<br>19.《霍乱时期的爱情》 （豆瓣评分：9)<br>20.《枪炮、病菌与钢铁》 （豆瓣评分：8.8)<br>21.《月亮和六便士》 （豆瓣评分：9)<br>22.《论美国的民主》 （豆瓣评分：9.2)<br>23.《送你一颗子弹》 （豆瓣评分：8.6)<br>24.《中国历代政治得失》 （豆瓣评分：9.1)<br>25.《文学回忆录（全2册)   》 （豆瓣评分：9.2)<br>26.《围城》 （豆瓣评分：8.9)<br>27.《民主的细节》 （豆瓣评分：8.6)<br>28.《寻路中国》 （豆瓣评分：9)<br>29.《人类简史》 （豆瓣评分：9.3)<br>30.《艺术的故事》 （豆瓣评分：9.6)<br>31.《解忧杂货店》 （豆瓣评分：8.6)<br>32.《看不见的城市》 （豆瓣评分：8.8)<br>33.《天才在左 疯子在右》 （豆瓣评分：8.3)<br>34.《高效能人士的七个习惯（精华版)   》 （豆瓣评分：8.2)<br>35.《设计中的设计》 （豆瓣评分：8.6)<br>36.《目送》 （豆瓣评分：8.7)<br>37.《看见》 （豆瓣评分：8.8)<br>38.《江城》 （豆瓣评分：9)<br>39.《娱乐至死》 （豆瓣评分：8.6)<br>40.《情人》 （豆瓣评分：8.1)<br>41.《把时间当作朋友》 （豆瓣评分：8.6)<br>42.《社会契约论》 （豆瓣评分：8.8)<br>43.《我们仨》 （豆瓣评分：8.6)<br>44.《社会性动物》 （豆瓣评分：9.1)<br>45.《理想国》 （豆瓣评分：8.7)<br>46.《自控力》 （豆瓣评分：8.3)<br>47.《思考，快与慢》 （豆瓣评分：8.3)<br>48.《国史大纲（上下)   》 （豆瓣评分：9.3)<br>49.《写给大家看的设计书（第3版)   》 （豆瓣评分：8.6)<br>50.《狂热分子》 （豆瓣评分：9.1)<br>51.《遇见未知的自己》 （豆瓣评分：8.1)<br>52.《苏菲的世界》 （豆瓣评分：8.5)<br>53.《天朝的崩溃》 （豆瓣评分：9)<br>54.《这些人，那些事》 （豆瓣评分：8.8)<br>55.《嫌疑人X的献身》 （豆瓣评分：8.9)<br>56.《牧羊少年奇幻之旅》 （豆瓣评分：8.7)<br>57.《浪潮之巅》 （豆瓣评分：9.1)<br>58.《挪威的森林》 （豆瓣评分：8)<br>59.《菊与刀》 （豆瓣评分：8.2)<br>60.《一九八四》 （豆瓣评分：9.3)<br>61.《史记（全十册)   》 （豆瓣评分：9.5)<br>62.《查令十字街84号》 （豆瓣评分：8.4)<br>63.《从一到无穷大》 （豆瓣评分：9.1)<br>64.《爱的艺术》 （豆瓣评分：8.8)<br>65.《决策与判断》 （豆瓣评分：8.5)<br>66.《黑客与画家》 （豆瓣评分：8.8)<br>67.《学会提问》 （豆瓣评分：8.6)<br>68.《心是孤独的猎手》 （豆瓣评分：8.5)<br>69.《点石成金》 （豆瓣评分：8.5)<br>70.《自私的基因》 （豆瓣评分：8.7)<br>71.《孤独六讲》 （豆瓣评分：8.1)<br>72.《最好的告别》 （豆瓣评分：9)<br>73.《卡拉马佐夫兄弟》 （豆瓣评分：9.3)<br>74.《窗边的小豆豆》 （豆瓣评分：8.7)<br>75.《刀锋》 （豆瓣评分：9)<br>76.《三体Ⅱ》 （豆瓣评分：9.2)<br>77.《故事》 （豆瓣评分：9.2)<br>78.《亲爱的安德烈》 （豆瓣评分：8.7)<br>79.《三体Ⅲ》 （豆瓣评分：9.2)<br>80.《卓有成效的管理者》 （豆瓣评分：8.8)<br>81.《沟通的艺术（插图修订第14版)   》 （豆瓣评分：8.7)<br>82.《《华尔街日报》是如何讲故事的》 （豆瓣评分：8.4)<br>83.《当我谈跑步时我谈些什么》 （豆瓣评分：8.1)<br>84.《活着》 （豆瓣评分：9.1)<br>85.《中国大历史》 （豆瓣评分：8.3)<br>86.《西方哲学史（上卷)   》 （豆瓣评分：8.9)<br>87.《夹边沟记事》 （豆瓣评分：9.1)<br>88.《无声告白》 （豆瓣评分：8.2)<br>89.《定位》 （豆瓣评分：8.3)<br>90.《何以笙箫默》 （豆瓣评分：8)<br>91.《总统是靠不住的》 （豆瓣评分：8.8)<br>92.《设计心理学》 （豆瓣评分：8.2)<br>93.《万物静默如谜》 （豆瓣评分：8.5)<br>94.《平凡的世界（全三部)   》 （豆瓣评分：9)<br>95.《我也有一个梦想》 （豆瓣评分：9)<br>96.《最初的爱情 最后的仪式》 （豆瓣评分：8)<br>97.《规训与惩罚》 （豆瓣评分：9.1)<br>98.《认识电影》 （豆瓣评分：8.9)<br>99.《沉默的大多数》 （豆瓣评分：9.1)<br>100.《带一本书去巴黎》 （豆瓣评分：8.5)<br>101.《学习之道（第2版)   》 （豆瓣评分：8.3)<br>102.《君主论》 （豆瓣评分：8.7)<br>103.《耶路撒冷三千年》 （豆瓣评分：8)<br>104.《玫瑰的名字》 （豆瓣评分：8.5)<br>105.《万物：创世》 （豆瓣评分：8.9)<br>106.《拖延心理学》 （豆瓣评分：8.2)<br>107.《进化心理学》 （豆瓣评分：8.9)<br>108.《史蒂夫·乔布斯传》 （豆瓣评分：8.7)<br>109.《悉达多》 （豆瓣评分：9)<br>110.《叫魂》 （豆瓣评分：8.9)<br>111.《非暴力沟通》 （豆瓣评分：8.5)<br>112.《金字塔原理》 （豆瓣评分：8.1)<br>113.《时间简史》 （豆瓣评分：8.8)<br>114.《唯有孤独恒常如新》 （豆瓣评分：8.2)<br>115.《光荣与梦想》 （豆瓣评分：8.9)<br>116.《乡关何处》 （豆瓣评分：8.6)<br>117.《巨流河》 （豆瓣评分：8.7)<br>118.《旧制度与大革命》 （豆瓣评分：8.9)<br>119.《斯通纳》 （豆瓣评分：8.8)<br>120.《恶意》 （豆瓣评分：8.4)<br>121.《灿烂千阳》 （豆瓣评分：8.8)<br>122.《常识》 （豆瓣评分：8.1)<br>123.《发现之旅》 （豆瓣评分：9)<br>124.《悲伤与理智》 （豆瓣评分：8.7)<br>125.《穷查理宝典》 （豆瓣评分：9)<br>126.《永恒的终结》 （豆瓣评分：9)<br>127.《局外人》 （豆瓣评分：9)<br>128.《聪明的投资者》 （豆瓣评分：9)<br>129.《激荡三十年（上)   》 （豆瓣评分：8.8)<br>130.《极权主义的起源》 （豆瓣评分：8.7)<br>131.《计算机程序的构造和解释》 （豆瓣评分：9.5)<br>132.《上帝掷股子吗》 （豆瓣评分：9.2)<br>133.《伟大的博弈》 （豆瓣评分：8.3)<br>134.《三生三世 十里桃花》 （豆瓣评分：8.3)<br>135.《暗时间》 （豆瓣评分：8.5)<br>136.《人生的枷锁》 （豆瓣评分：9)<br>137.《创业维艰》 （豆瓣评分：8.5)<br>138.《开放社会及其敌人（全二卷)   》 （豆瓣评分：8.9)<br>139.《瓦尔登湖》 （豆瓣评分：8.5)<br>140.《动物农场》 （豆瓣评分：9.2)<br>141.《精益创业》 （豆瓣评分：8.4)<br>142.《旅行的艺术》 （豆瓣评分：8.3)<br>143.《论自由》 （豆瓣评分：8.7)<br>144.《三国演义（全二册)   》 （豆瓣评分：9.2)<br>145.《万物有灵且美》 （豆瓣评分：8.8)<br>146.《正义论》 （豆瓣评分：8.8)<br>147.《繁花》 （豆瓣评分：8.7)<br>148.《巴菲特致股东的信》 （豆瓣评分：8.3)<br>149.《别做正常的傻瓜》 （豆瓣评分：8.2)<br>150.《路西法效应》 （豆瓣评分：8.6)<br>151.《经济学原理》 （豆瓣评分：9.4)<br>152.《什么是数学》 （豆瓣评分：9.1)<br>153.《退步集》 （豆瓣评分：8.1)<br>154.《如何阅读一本小说》 （豆瓣评分：8.1)<br>155.《潜规则》 （豆瓣评分：8.3)<br>156.《批评官员的尺度》 （豆瓣评分：8.9)<br>157.《美国大城市的死与生（纪念版)   》 （豆瓣评分：8.7)<br>158.《源泉》 （豆瓣评分：9.1)<br>159.《新教伦理与资本主义精神》 （豆瓣评分：8.8)<br>160.《存在与时间》 （豆瓣评分：8.7)<br>161.《美丽新世界》 （豆瓣评分：8.5)<br>162.《正见》 （豆瓣评分：8.8)<br>163.《万物简史》 （豆瓣评分：8.8)<br>164.《美国宪政历程》 （豆瓣评分：9.1)<br>165.《忧郁的热带》 （豆瓣评分：9.1)<br>166.《香水》 （豆瓣评分：8.5)<br>167.《异乡人》 （豆瓣评分：8.9)<br>168.《华婿引（全二册)   》 （豆瓣评分：8.6)<br>169.《数学之美》 （豆瓣评分：8.7)<br>170.《焚舟纪》 （豆瓣评分：8.5)<br>171.《树上的男爵》 （豆瓣评分：9)<br>172.《上学记》 （豆瓣评分：8.8)<br>173.《国富论》 （豆瓣评分：9)<br>174.《人间词话》 （豆瓣评分：9)<br>175.《24个比利》 （豆瓣评分：8.3)<br>176.《1Q84 BOOK 1》 （豆瓣评分：8.3)<br>177.《与“众”不同的心理学》 （豆瓣评分：8.8)<br>178.《维特根斯坦传》 （豆瓣评分：9.1)<br>179.《微微一笑很倾城》 （豆瓣评分：8.2)<br>180.《午夜之子》 （豆瓣评分：8.4)<br>181.《平如美棠》 （豆瓣评分：9)<br>182.《天真的人类学家》 （豆瓣评分：8.8)<br>183.《人类的群星闪耀时》 （豆瓣评分：8.7)<br>184.《杀死一只知更鸟》 （豆瓣评分：9.2)<br>185.《算法导论（原书第2版)   》 （豆瓣评分：9.4)<br>186.《重来》 （豆瓣评分：8.3)<br>187.《乡土中国》 （豆瓣评分：9.2)<br>188.《疯癫与文明》 （豆瓣评分：8.7)<br>189.《伊斯坦布尔》 （豆瓣评分：8.4)<br>190.《圣经》 （豆瓣评分：9)<br>191.《利维坦》 （豆瓣评分：8.6)<br>192.《昨日的世界》 （豆瓣评分：9.2)<br>193.《肖申克的救赎》 （豆瓣评分：9.1)<br>194.《1984》 （豆瓣评分：9.3)<br>195.《小于一》 （豆瓣评分：8.6)<br>196.《经济学原理（上下)   》 （豆瓣评分：9)<br>197.《代码大全（第2版)   》 （豆瓣评分：9.3)<br>198.《精神分析引论》 （豆瓣评分：8.6)<br>199.《启示录》 （豆瓣评分：8.5)<br>200.《飘（上下)   》 （豆瓣评分：9.3)<br>201.《联邦党人文集》 （豆瓣评分：9)<br>202.《用户体验的要素》 （豆瓣评分：8.2)<br>203.《众病之王》 （豆瓣评分：9.1)<br>204.《一九八四·动物农场》 （豆瓣评分：9.2)<br>205.《情感化设计》 （豆瓣评分：8)<br>206.《哈利·波特与魔法石》 （豆瓣评分：9)<br>207.《追寻记忆的痕迹》 （豆瓣评分：8.9)<br>208.《拆掉思维里的墙》 （豆瓣评分：8)<br>209.《邓小平时代》 （豆瓣评分：8.8)<br>210.《作为意志和表象的世界》 （豆瓣评分：8.9)<br>211.《怪诞行为学》 （豆瓣评分：8.1)<br>212.《哈扎尔辞典（阳本)   》 （豆瓣评分：8.8)<br>213.《时间旅行者的妻子》 （豆瓣评分：8.1)<br>214.《为什么读经典》 （豆瓣评分：8.3)<br>215.《致命的自负》 （豆瓣评分：8.8)<br>216.《安吉拉·卡特的精怪故事集》 （豆瓣评分：8)<br>217.《漫长的告别》 （豆瓣评分：8.1)<br>218.《十一种孤独》 （豆瓣评分：8.1)<br>219.《彼得·林奇的成功投资》 （豆瓣评分：8.7)<br>220.《沉思录》 （豆瓣评分：8.2)<br>221.《观念的水位》 （豆瓣评分：8.3)<br>222.《没有人给他写信的上校》 （豆瓣评分：8.5)<br>223.《晚清七十年 （全五册)   》 （豆瓣评分：8.8)<br>224.《你今天真好看》 （豆瓣评分：8.8)<br>225.《姑获鸟之夏》 （豆瓣评分：8.1)<br>226.《博尔赫斯小说集》 （豆瓣评分：9.1)<br>227.《来自新世界 （上下)   》 （豆瓣评分：9)<br>228.《逃避自由》 （豆瓣评分：8.9)<br>229.《我不知道该说什么，关于死亡还是爱情》 （豆瓣评分：8.9)<br>230.《设计中的设计 | 全本》 （豆瓣评分：9.1)<br>231.《策略思维》 （豆瓣评分：8.5)<br>232.《反脆弱》 （豆瓣评分：8.3)<br>233.《狼图腾》 （豆瓣评分：8.3)<br>234.《亲密关系》 （豆瓣评分：8.7)<br>235.《全球通史(上)》 （豆瓣评分：9.2)<br>236.《创新者的窘境》 （豆瓣评分：8.5)<br>237.《大问题》 （豆瓣评分：9)<br>238.《人间失格》 （豆瓣评分：8.3)<br>239.《简约至上》 （豆瓣评分：8.4)<br>240.《雕刻时光》 （豆瓣评分：9)<br>241.《你一定爱读的极简欧洲史》 （豆瓣评分：8.3)<br>242.《一桩事先张扬的凶杀案》 （豆瓣评分：8.6)<br>243.《达·芬奇密码》 （豆瓣评分：8.2)<br>244.《游戏改变世界》 （豆瓣评分：8.2)<br>245.《福尔摩斯探案全集（上中下)   》 （豆瓣评分：9.2)<br>246.《失物之书》 （豆瓣评分：8.5)<br>247.《股票作手回忆录》 （豆瓣评分：8.7)<br>248.《生命是什么》 （豆瓣评分：8.7)<br>249.《黄金时代》 （豆瓣评分：8.8)<br>250.《那些古怪又让人忧心的问题》 （豆瓣评分：8.2)<br>251.《东方快车谋杀案》 （豆瓣评分：9)<br>252.《顾淮文集》 （豆瓣评分：9.1)<br>253.《富爸爸，穷爸爸》 （豆瓣评分：8.2)<br>254.《论中国》 （豆瓣评分：8.6)<br>255.《金色梦乡》 （豆瓣评分：9)<br>256.《九故事》 （豆瓣评分：8.5)<br>257.《怦然心动的人生整理魔法》 （豆瓣评分：8)<br>258.《爱你就像爱生命》 （豆瓣评分：8.8)<br>259.《中国近代史（上册)   》 （豆瓣评分：9.4)<br>260.《禅与摩托车维修艺术》 （豆瓣评分：8.4)<br>261.《强风吹拂》 （豆瓣评分：9.1)<br>262.《浮生六记》 （豆瓣评分：8.9)<br>263.《活了100万次的猫》 （豆瓣评分：8.9)<br>264.《金融的逻辑》 （豆瓣评分：8)<br>265.《第二性》 （豆瓣评分：8.6)<br>266.《我的孤独是一座花园》 （豆瓣评分：8.7)<br>267.《美的历程》 （豆瓣评分：8.8)<br>268.《火星救援》 （豆瓣评分：8.9)<br>269.《无人生还》 （豆瓣评分：8.9)<br>270.《我执》 （豆瓣评分：8)<br>271.《野蛮大陆》 （豆瓣评分：9)<br>272.《ZOO》 （豆瓣评分：8.6)<br>273.《尤利西斯》 （豆瓣评分：8.4)<br>274.《冬牧场》 （豆瓣评分：9)<br>275.《偷影子的人》 （豆瓣评分：8)<br>276.《激荡三十年（下)   》 （豆瓣评分：8.9)<br>277.《野火集》 （豆瓣评分：8.8)<br>278.《大教堂》 （豆瓣评分：8.5)<br>279.《猜猜我有多爱你》 （豆瓣评分：9.3)<br>280.《了不起的盖茨比》 （豆瓣评分：8.3)<br>281.《一个人的朝圣》 （豆瓣评分：8.1)<br>282.《如彗星划过夜空》 （豆瓣评分：8.9)<br>283.《人性中的善良天使》 （豆瓣评分：8.8)<br>284.《历史研究》 （豆瓣评分：9.1)<br>285.《自由》 （豆瓣评分：8.5)<br>286.《十四堂人生创意课》 （豆瓣评分：8.2)<br>287.《新世界》 （豆瓣评分：8.9)<br>288.《毛姆短篇小说精选集》 （豆瓣评分：9.1)<br>289.《失明症漫记》 （豆瓣评分：9.1)<br>290.《公正》 （豆瓣评分：9.1)<br>291.《血酬定律》 （豆瓣评分：8.2)<br>292.《城记》 （豆瓣评分：8.7)<br>293.《天国之秋》 （豆瓣评分：8.7)<br>294.《美学散步》 （豆瓣评分：8.8)<br>295.《如果在冬夜，一个旅人》 （豆瓣评分：8.7)<br>296.《金融炼金术》 （豆瓣评分：8.4)<br>297.《孙子兵法》 （豆瓣评分：9.3)<br>298.《一个陌生女人的来信》 （豆瓣评分：8.7)<br>299.《德米安》 （豆瓣评分：9)<br>300.《傲慢与偏见》 （豆瓣评分：8.8)<br>301.《边城》 （豆瓣评分：8.6)<br>302.《铁皮鼓》 （豆瓣评分：8.5)<br>303.《悟空传》 （豆瓣评分：8.4)<br>304.《寻找家园》 （豆瓣评分：9.2)<br>305.《从优秀到卓越》 （豆瓣评分：8.1)<br>306.《1453：君士坦丁堡之战》 （豆瓣评分：9)<br>307.《证券分析》 （豆瓣评分：8.8)<br>308.《水浒传（全二册)   》 （豆瓣评分：8.5)<br>309.《秘密花园》 （豆瓣评分：8.1)<br>310.《海边的卡夫卡》 （豆瓣评分：8.1)<br>311.《西藏生死书》 （豆瓣评分：8.6)<br>312.《佛祖在一号线》 （豆瓣评分：8.2)<br>313.《超越时空》 （豆瓣评分：9)<br>314.《改变心理学的40项研究》 （豆瓣评分：8.8)<br>315.《C程序设计语言》 （豆瓣评分：9.4)<br>316.《中国文化要义》 （豆瓣评分：9)<br>317.《哪来的天才？》 （豆瓣评分：8)<br>318.《相约星期二》 （豆瓣评分：8.4)<br>319.《倾城之恋》 （豆瓣评分：8.5)<br>320.《阿拉伯的劳伦斯》 （豆瓣评分：9.1)<br>321.《城门开》 （豆瓣评分：8.4)<br>322.《孩子你慢慢来》 （豆瓣评分：8.8)<br>323.《中国法律与中国社会》 （豆瓣评分：9.2)<br>324.《被淹没和被拯救的》 （豆瓣评分：9.1)<br>325.《第五项修炼》 （豆瓣评分：8.5)<br>326.《日瓦戈医生》 （豆瓣评分：8.6)<br>327.《自由秩序原理》 （豆瓣评分：9)<br>328.《写作这回事》 （豆瓣评分：8.6)<br>329.《人生的智慧》 （豆瓣评分：9.3)<br>330.《占星术杀人魔法》 （豆瓣评分：8.4)<br>331.《基业长青》 （豆瓣评分：8.2)<br>332.《我的阿勒泰》 （豆瓣评分：8.8)<br>333.《江村经济》 （豆瓣评分：8.9)<br>334.《观看之道》 （豆瓣评分：8.3)<br>335.《设计模式》 （豆瓣评分：9.1)<br>336.《经济学的思维方式（第11版)   》 （豆瓣评分：8.7)<br>337.《渴望生活》 （豆瓣评分：9.2)<br>338.《古拉格：一部历史》 （豆瓣评分：9.2)<br>339.《超越死亡》 （豆瓣评分：9)<br>340.《你的灯亮着吗?》 （豆瓣评分：8.2)<br>341.《明朝那些事儿（一)   》 （豆瓣评分：8.8)<br>342.《当世界年纪还小的时候》 （豆瓣评分：8.6)<br>343.《中国哲学简史》 （豆瓣评分：8.8)<br>344.《资治通鑑（全二十册)   》 （豆瓣评分：9.3)<br>345.《生活与命运》 （豆瓣评分：9)<br>346.《西班牙旅行笔记》 （豆瓣评分：8.6)<br>347.《中国近代史》 （豆瓣评分：8.8)<br>348.《向前一步》 （豆瓣评分：8.1)<br>349.《谈谈方法》 （豆瓣评分：8.6)<br>350.《长恨歌》 （豆瓣评分：8.3)<br>351.《奇特的一生》 （豆瓣评分：8.3)<br>352.《夏洛的网》 （豆瓣评分：8.5)<br>353.《银河系漫游指南》 （豆瓣评分：8.8)<br>354.《清明上河图密码》 （豆瓣评分：8.2)<br>355.《二十首情诗和一首绝望的歌》 （豆瓣评分：8.3)<br>356.《中国文化的深层结构》 （豆瓣评分：8.6)<br>357.《简爱》 （豆瓣评分：8.5)<br>358.《一个广告人的自白》 （豆瓣评分：8.4)<br>359.《时间的针脚》 （豆瓣评分：8.4)<br>360.《华夏意匠》 （豆瓣评分：9.2)<br>361.《没有色彩的多崎作和他的巡礼之年》 （豆瓣评分：8.3)<br>362.《野蛮生长》 （豆瓣评分：8.3)<br>363.《我不喜欢这世界，我只喜欢你》 （豆瓣评分：8.2)<br>364.《全球通史(下)》 （豆瓣评分：9.2)<br>365.《魍魉之匣（上)   》 （豆瓣评分：8.5)<br>366.《质数的孤独》 （豆瓣评分：8)<br>367.《思考的技术》 （豆瓣评分：8)<br>368.《自由在高处》 （豆瓣评分：8.1)<br>369.《习惯的力量》 （豆瓣评分：8)<br>370.《刺猬的优雅》 （豆瓣评分：8.1)<br>371.《泛若不系之舟》 （豆瓣评分：8.6)<br>372.《基地》 （豆瓣评分：9.2)<br>373.《最好的我们》 （豆瓣评分：8.9)<br>374.《独裁者手册》 （豆瓣评分：8.9)<br>375.《别闹了，费曼先生》 （豆瓣评分：8.9)<br>376.《穆斯林的葬礼》 （豆瓣评分：8.3)<br>377.《人性的弱点全集》 （豆瓣评分：8.3)<br>378.《蝇王》 （豆瓣评分：8.2)<br>379.《不去会死！》 （豆瓣评分：8.2)<br>380.《我在伊朗长大》 （豆瓣评分：9.3)<br>381.《财富之城》 （豆瓣评分：8.9)<br>382.《逃离》 （豆瓣评分：8)<br>383.《对伪心理学说不》 （豆瓣评分：9.2)<br>384.《金雀花王朝》 （豆瓣评分：8.6)<br>385.《复杂》 （豆瓣评分：8.8)<br>386.《X的悲剧》 （豆瓣评分：8.5)<br>387.《八十年代访谈录》 （豆瓣评分：8.1)<br>388.《万有引力之虹》 （豆瓣评分：8.3)<br>389.《怎样选择成长股》 （豆瓣评分：8.5)<br>390.《我们的祖先》 （豆瓣评分：9.4)<br>391.《想象的共同体》 （豆瓣评分：8.8)<br>392.《此间的少年》 （豆瓣评分：8.4)<br>393.《所罗门王的指环》 （豆瓣评分：9.2)<br>394.《美的历史》 （豆瓣评分：8.4)<br>395.《认得几个字》 （豆瓣评分：8.2)<br>396.《好妈妈胜过好老师》 （豆瓣评分：9.1)<br>397.《万火归一》 （豆瓣评分：8.7)<br>398.《万万没想到》 （豆瓣评分：8.5)<br>399.《风之影》 （豆瓣评分：8.6)<br>400.《恶童日记》 （豆瓣评分：8.6)<br>401.《步步惊心》 （豆瓣评分：8.1)<br>402.《项塔兰》 （豆瓣评分：9.1)<br>403.《惶然录》 （豆瓣评分：9)<br>404.《佳期如梦》 （豆瓣评分：8)<br>405.《大卫，不可以》 （豆瓣评分：8.8)<br>406.《共 产党宣言》 （豆瓣评分：8.6)<br>407.《逻辑哲学论》 （豆瓣评分：9.1)<br>408.《爱弥儿》 （豆瓣评分：8.7)<br>409.《传统十论》 （豆瓣评分：9.1)<br>410.《全球通史（第7版 上册)   》 （豆瓣评分：8.9)<br>411.《奥克诺斯》 （豆瓣评分：9.1)<br>412.《大萝卜和难挑的鳄梨》 （豆瓣评分：8.1)<br>413.《冰与火之歌（卷一)   》 （豆瓣评分：9.3)<br>414.《交往与空间》 （豆瓣评分：8.8)<br>415.《消费社会》 （豆瓣评分：8.4)<br>416.《纯粹理性批判》 （豆瓣评分：8.9)<br>417.《1Q84 BOOK 2》 （豆瓣评分：8.4)<br>418.《一朵桔梗花》 （豆瓣评分：8.5)<br>419.《荆棘鸟》 （豆瓣评分：8.6)<br>420.《大英博物馆世界简史（全3册)   》 （豆瓣评分：9.2)<br>421.《偷书贼》 （豆瓣评分：8)<br>422.《杂草的故事》 （豆瓣评分：8.4)<br>423.《深夜食堂 01》 （豆瓣评分：9)<br>424.《理解媒介》 （豆瓣评分：8.5)<br>425.《毛姆传》 （豆瓣评分：8.4)<br>426.《蛤蟆的油》 （豆瓣评分：8.4)<br>427.《电影艺术（插图第8版)   》 （豆瓣评分：8.9)<br>428.《道德经》 （豆瓣评分：9.4)<br>429.《过于喧嚣的孤独》 （豆瓣评分：8.8)<br>430.《圣诞忆旧集》 （豆瓣评分：8.6)<br>431.《台北人》 （豆瓣评分：8.9)<br>432.《伯罗奔尼撒战争史》 （豆瓣评分：8.9)<br>433.《洞穴奇案》 （豆瓣评分：9.1)<br>434.《万物既伟大又渺小》 （豆瓣评分：9)<br>435.《2666》 （豆瓣评分：8.6)<br>436.《神们自己》 （豆瓣评分：8.4)<br>437.《月光落在左手上》 （豆瓣评分：8.3)<br>438.《给孩子的诗》 （豆瓣评分：8.2)<br>439.《迷宫中的将军》 （豆瓣评分：8.6)<br>440.《天龙八部》 （豆瓣评分：9)<br>441.《老子注译及评介》 （豆瓣评分：9.2)<br>442.《大败局》 （豆瓣评分：8.3)<br>443.《梦中的欢快葬礼和十二个异乡故事》 （豆瓣评分：8.6)<br>444.《重新认识你自己》 （豆瓣评分：8.6)<br>445.《高难度谈话》 （豆瓣评分：8.2)<br>446.《版式设计原理》 （豆瓣评分：8.4)<br>447.《改变》 （豆瓣评分：8.5)<br>448.《追忆似水年华》 （豆瓣评分：9.1)<br>449.《街道的美学》 （豆瓣评分：8.6)<br>450.《社会学的想像力》 （豆瓣评分：8.6)<br>451.《文明的冲突与世界秩序的重建》 （豆瓣评分：8.4)<br>452.《金阁寺》 （豆瓣评分：8.6)<br>453.《未央歌》 （豆瓣评分：8.4)<br>454.《无缘社会》 （豆瓣评分：8.4)<br>455.《没有个性的人》 （豆瓣评分：9)<br>456.《一个村庄里的中国》 （豆瓣评分：8)<br>457.《深入理解计算机系统》 （豆瓣评分：9.5)<br>458.《生活在别处》 （豆瓣评分：8.3)<br>459.《忧伤的时候，到厨房去》 （豆瓣评分：8.2)<br>460.《我的精神家园》 （豆瓣评分：9)<br>461.《纳尔齐斯与歌尔德蒙》 （豆瓣评分：9.2)<br>462.《许三观卖血记》 （豆瓣评分：8.7)<br>463.《文明之光（第一册)   》 （豆瓣评分：9)<br>464.《单向度的人》 （豆瓣评分：8.4)<br>465.《莲花》 （豆瓣评分：8)<br>466.《所有我们看不见的光》 （豆瓣评分：9)<br>467.《门萨的娼妓》 （豆瓣评分：8)<br>468.《脑髓地狱》 （豆瓣评分：8)<br>469.《我爱问连岳》 （豆瓣评分：8.1)<br>470.《信息简史》 （豆瓣评分：8.8)<br>471.《那些回不去的年少时光》 （豆瓣评分：8.5)<br>472.《政府论（下篇)   》 （豆瓣评分：8.9)<br>473.《袁氏当国》 （豆瓣评分：8.5)<br>474.《集体行动的逻辑》 （豆瓣评分：8.5)<br>475.《商业模式新生代》 （豆瓣评分：8.4)<br>476.《童年的消逝》 （豆瓣评分：8.4)<br>477.《寂静的春天》 （豆瓣评分：8.3)<br>478.《呼啸山庄》 （豆瓣评分：8.4)<br>479.《罗伯特议事规则》 （豆瓣评分：8.7)<br>480.《深入理解计算机系统（原书第2版)   》 （豆瓣评分：9.7)<br>481.《纯真博物馆》 （豆瓣评分：8.1)<br>482.《编程珠玑》 （豆瓣评分：9.2)<br>483.《金枝（上下册)   》 （豆瓣评分：8.8)<br>484.《重新发现社会》 （豆瓣评分：8.4)<br>485.《看海的人》 （豆瓣评分：8.4)<br>486.《最好的时光》 （豆瓣评分：8.4)<br>487.《云中歌1》 （豆瓣评分：8.2)<br>488.《就业、利息和货币通论》 （豆瓣评分：8.6)<br>489.《致D》 （豆瓣评分：8.5)<br>490.《世界尽头与冷酷仙境》 （豆瓣评分：8.5)<br>491.《喜宝》 （豆瓣评分：8.1)<br>492.《巴黎评论·作家访谈Ⅰ》 （豆瓣评分：9)<br>493.《西方美学史》 （豆瓣评分：8.7)<br>494.《海子诗全集》 （豆瓣评分：9.2)<br>495.《失落的一角》 （豆瓣评分：8.8)<br>496.《博尔赫斯谈话录》 （豆瓣评分：8.8)<br>497.《自杀论》 （豆瓣评分：8.4)<br>498.《我脑袋里的怪东西》 （豆瓣评分：8.7)<br>499.《诗学》 （豆瓣评分：8.9)<br>500.《如何读，为什么读》 （豆瓣评分：8.4)   </p>]]></content>
    
    
    <categories>
      
      <category>书单</category>
      
    </categories>
    
    
    <tags>
      
      <tag>书籍</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Java IO/NIO</title>
    <link href="/2020/05/27/Java-IO-NIO/"/>
    <url>/2020/05/27/Java-IO-NIO/</url>
    
    <content type="html"><![CDATA[<h1 id="阻塞IO模型"><a href="#阻塞IO模型" class="headerlink" title="阻塞IO模型"></a>阻塞IO模型</h1><blockquote><p>最传统的一种IO模型，即在读写数据过程中会发生阻塞现象。当用户线程发出IO请求之后，内核会去查看数据是否就绪，如果没有就绪就会等待数据就绪，而用户线程就会处于阻塞状态，用户线程交出CPU。当数据就绪之后，内核会将数据拷贝到用户线程，并返回结果给用户线程用户线程才解除block状态。典型的阻塞IO模型的例子为：data = socket.read();如果数据没有就绪就会一种阻塞在read方法。</p></blockquote><h1 id="非阻塞IO模型"><a href="#非阻塞IO模型" class="headerlink" title="非阻塞IO模型"></a>非阻塞IO模型</h1><blockquote><p>当用户线程发起一个read操作后，并不需要等待，而是马上就得到了一个结果。如果结果是一个error时，他就知道数据还没有准备好，于是他可以再次发送read操作。一旦内核中的数据准备好了，并且有再次接收到了用户线程的请求，那么它马上就将数据拷贝到了用户线程，然后返回。所以事实上在非阻塞IO模型中，用户线程需要不断的询问内核数据是否就绪，也就是说非阻塞IO不会交出CPU而是一直占用CPU。典型的非阻塞IO模型如下：</p></blockquote><pre><code class="javascript">while (true) {    data = socket.read();    if (data!= error){        //处理数据        break;    } }</code></pre><p>但是对于非阻塞IO就有一个非常严重的问题，在while循环中需要不断的去询问内核数据是否就绪，这样导致CPU占用率非常高，因此一般情况下很少使用while循环这种方式来读取数据。</p><h1 id="多路复用IO模型"><a href="#多路复用IO模型" class="headerlink" title="多路复用IO模型"></a>多路复用IO模型</h1><blockquote><p>多路复用IO模型是目前使用的比较多的模型。Java NIO实际上就是多路复用IO。在对多路复用IO模型中，会有一个线程不断的去轮询多个socket的状态，只有当socket真正有读写事件时，才正真调用实际的IO读写操作。因为在多路复用IO模型中，只需要使用一个线程就可以管理多个socket，系统不需要建立新的进程或者线程，也不必维护这些线程和进程，并且只有在真正有socket读写事件进行时，才会使用IO资源，所以它大大减少了资源占用。在JavaNIO中，是通过<code>selector,select()</code>去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里，因此这种方式会导致用户线程的阻塞。多路复用IO模式，通过一个线程就可以管理多个socket，只有当socket真正有读写事件发生才会占用资源进行实际的读写操作。因此，多路复用IO比较时候连接数比较多的情况。</p></blockquote><pre><code class="text">另外多路复用IO为何非阻塞IO模型的效率是因为在非阻塞IO中，不断的询问socket状态时通过用户线程去进行的，而在多路复用IO中，轮询每个socket状态是内核在进行的，这个效率要比用户线程高得多。</code></pre><p>不过要注意的是，多路复用IO模型是通过轮询的方式来检测是否有事件到达，并且对到达的事件逐一进行响应。因此对于多路复用IO模型来说，一旦事件响应体很大，那么就会导致后续的事件迟迟得不到处理，并且会影响新的事件轮询。</p><h1 id="信号驱动IO模型"><a href="#信号驱动IO模型" class="headerlink" title="信号驱动IO模型"></a>信号驱动IO模型</h1><p>在信号驱动 IO 模型中,当用户线程发起一个 IO 请求操作,会给对应的 socket 注册一个信号函<br>数,然后用户线程会继续执行,当内核数据就绪时会发送一个信号给用户线程,用户线程接收到<br>信号之后,便在信号函数中调用 IO 读写操作来进行实际的 IO 请求操作。</p><h1 id="异步-IO-模型"><a href="#异步-IO-模型" class="headerlink" title="异步 IO 模型"></a>异步 IO 模型</h1><p>异步 IO 模型才是最理想的 IO 模型,在异步 IO 模型中,当用户线程发起 read 操作之后,立刻就<br>可以开始去做其它的事。而另一方面,从内核的角度,当它受到一个 asynchronous read 之后,<br>它会立刻返回,说明 read 请求已经成功发起了,因此不会对用户线程产生任何 block。然后,内<br>核会等待数据准备完成,然后将数据拷贝到用户线程,当这一切都完成之后,内核会给用户线程<br>发送一个信号,告诉它 read 操作完成了。也就说用户线程完全不需要实际的整个 IO 操作是如何<br>进行的,只需要先发起一个请求,当接收内核返回的成功信号时表示 IO 操作已经完成,可以直接<br>去使用数据了。</p><blockquote><p>也就说在异步 IO 模型中,IO 操作的两个阶段都不会阻塞用户线程,这两个阶段都是由内核自动完<br>成,然后发送一个信号告知用户线程操作已完成。用户线程中不需要再次调用 IO 函数进行具体的<br>读写。这点是和信号驱动模型有所不同的,在信号驱动模型中,当用户线程接收到信号表示数据<br>已经就绪,然后需要用户线程调用 IO 函数进行实际的读写操作;而在异步 IO 模型中,收到信号<br>表示 IO 操作已经完成,不需要再在用户线程中调用 IO 函数进行实际的读写操作。</p></blockquote><p>[注意]<code>异步 IO 是需要操作系统的底层支持,在 Java 7 中,提供了 Asynchronous IO。</code></p><p><a href="http://www.importnew.com/19816.html" target="_blank" rel="noopener">参考</a></p><p><img src="/resource/img/javaio.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="Java-NIO"><a href="#Java-NIO" class="headerlink" title="Java NIO"></a>Java NIO</h1><blockquote><p>NIO主要有三大核心部分:Channel(通道)，Buffer(缓冲区)，Selector。传统IO基于字节流和字符流进行操作而NIO基于Channel和Buffer(缓冲区)进行操作，数据总是从通道读取到缓冲区中，或者从缓冲区写入通道中。Selector(选择区)用于监听多个通道的事件(比如：连接打开，数据到达)。因此，单线程可以监控多个数据通道。</p></blockquote><p><img src="/resource/img/java_nio_network_model.png" srcset="/img/loading.gif" alt="avatar"></p><p>NIO和传统IO之间第一个最大的区别是，<code>IO是面向流的，NIO是面向缓冲区的</code></p><p>NIO的缓冲区</p><blockquote><p>Java IO面向流意味着每次从流中读取一个或者多个字节，直至读取完所有字节，他们没有被缓存在任何地方。此外，他不能前后移动流中的数据，如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。NIO的缓冲导向方法不同。数据读取到一个它稍后处理的缓冲区，需要时刻在缓存区中前后移动。这就增加了处理过程中的灵活性。但是还需要检查是否该缓冲区中包含所有您需要处理的数据，而且需要确保当更多的数据读入缓冲区时，不要覆盖缓冲区里未处理的数据。</p></blockquote><p>NIO的非阻塞</p><blockquote><p>IO的各种流是阻塞的。这意味着当一个线程调用read()或write()时，该线程被阻塞，直到直到有一些数据被读取,或数据完全写入。该线程在此期间不能再干任何事情了。 NIO 的非阻塞模式,使一个线程从某通道发送请求读取数据,但是它仅能得到目前可用的数据,如果目前没有数据可用时,就什么都不会获取。而不是保持线程阻塞,所以直至数据变的可以读取之前,该线程可以继续做其他的事情。 非阻塞写也是如此。一个线程请求写入一些数据到某通道,但不需要等待它完全写入,这个线程同时可以去做别的事情。 线程通常将非阻塞 IO 的空闲时间用于在其它通道上执行 IO 操作,所以一个单独的线程现在可以管理多个输入和输出通道(channel)。</p></blockquote><p><img src="/resource/img/java_nio_package.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="Channel"><a href="#Channel" class="headerlink" title="Channel"></a>Channel</h2><blockquote><p>首先说一下Channel，国内大多数翻译成“通道”。Channel和IO中的Stream(流)是差不多一个等级的。只不过Stream是单向的，譬如：InputStream,OutPutStream,而Channel是双向的，既可以用来进行读操作也可以用来进行写操作。</p></blockquote><p>NIO中的Channel的主要实现有</p><ul><li>FileChannel</li><li>DatagramChannel</li><li>SocketChannel</li><li>ServerSocketChannel</li></ul><blockquote><p>分别对应IO，UDP，TCP(Server和Client)</p></blockquote><h3 id="Buffer"><a href="#Buffer" class="headerlink" title="Buffer"></a>Buffer</h3><blockquote><p>Buffer顾名思义缓冲区实际上是一个容器，是一个连续数组。Channel提供文件，网络读取数据的渠道，但是读取或者写入的数据都必须经由Buffer</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200528214729.png" srcset="/img/loading.gif" alt="avatar"></p><blockquote><p>上图描述一个客户端向服务端发送数据，然后服务端接收数据的过程。客户端发送数据时，必须将数据存入Buffer中，然后将Buffer中的内容写入通道。服务端这边接收数据必须通过Channel将数据读入到Buffer中，然后再从Buffer中取出数据来处理。</p></blockquote><p>在NIO中Buffer是一个顶层父类，他是一个抽象类，常用的Buffer的子类有<code>ByteBuffer、IntBuffer、CharBuffer、LongBuffer、DoubleBuffer、FloatBuffer、ShortBuff</code></p><h3 id="Selector"><a href="#Selector" class="headerlink" title="Selector"></a>Selector</h3><blockquote><p>Selector类是NIO的核心类，Selector能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行相应的响应处理。这样一来只是用一个单线程就可管理多个通道，也就是管理多个连接。这样使得只有在连接真正有读写事件发生时，才会调用函数来进行读写，就大大减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程，并且避免了多线程之间的上下文切换导致的开销。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>IO/NIO</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JVM 知识汇总</title>
    <link href="/2020/05/19/JVM-%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/"/>
    <url>/2020/05/19/JVM-%E7%9F%A5%E8%AF%86%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="JVM-知识汇总"><a href="#JVM-知识汇总" class="headerlink" title="JVM 知识汇总"></a>JVM 知识汇总</h1><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><pre><code class="text">JVM是可运行Java代码的假想计算机，包括一套字节指令集，一组寄存器，一个栈，一个垃圾回收，堆和一个存储方法域．Jvm是运行在操作系统上的他与硬件没有直接的交互．</code></pre><p><img src="/resource/img/jvm.png" srcset="/img/loading.gif" alt="avatar"></p><h1 id="运行过程"><a href="#运行过程" class="headerlink" title="运行过程"></a>运行过程</h1><blockquote><p>我们都知道Java源文件，通过编译器能够生产相应的.Class文件，也就是字节码文件，而字节码文件又通过Java虚拟机中的解释器，编译成特定机器上的机器码</p></blockquote><blockquote><p>Java源文件–&gt;编译器–&gt;字节码文件–&gt;JVM–&gt;机器码</p></blockquote><blockquote><p>每一种平台的解释器是不同的，但是实现的虚拟机是相同的，这也就是Java为什么能够跨平台的原因，当一个程序从开始运行，这时虚拟机就开始实例化了，多个程序启动　就会存在多个虚拟机实例．程序退出或者关闭则虚拟机实例消亡，多个虚拟机实例之间数据不能共享&lt;</p></blockquote><p><img src="/resource/img/RunTimeJvm.png" srcset="/img/loading.gif" alt="avatar"> </p><h1 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h1><blockquote><p>这里所说的线程程序执行过程中的一个线程实体．JVM允许一个应用并发执行多个线程．<code>Hotspot JVM中的Java线程与原生操作系统线程有直接的映射关系</code>．当线程本地存储，缓冲区分配，同步对象，栈，程序计数器等准备好以后，就会创建一个操作系统图原生线程，并把他们分配到任何可以的CPU上．当原生线程初始化完毕，就会调用Java线程的run()方法．当线程结束时，会释放原生线程和Java线程的所有资源</p></blockquote><h3 id="Hotspot-JVM后台运行的系统线程主要有下面几个"><a href="#Hotspot-JVM后台运行的系统线程主要有下面几个" class="headerlink" title="Hotspot JVM后台运行的系统线程主要有下面几个"></a>Hotspot JVM后台运行的系统线程主要有下面几个</h3><p><img src="/resource/img/20200519184914.png" srcset="/img/loading.gif" alt="avatar"> </p><h3 id="JVM-内存区域"><a href="#JVM-内存区域" class="headerlink" title="JVM 内存区域"></a>JVM 内存区域</h3><p><img src="/resource/img/20200519185041.png" srcset="/img/loading.gif" alt="avatar"> </p><blockquote><p>jvm内存区域主要分为线程私有区域［程序计数器，虚拟机栈，本地方法区］，线程共享区域［java堆，方法区］，直接内存．</p></blockquote><p><code>线程私有数据区域生命周期与线程相同，依赖用户线程的启动/结束而创建/销毁(在Hotspot VM内)，每个线程都与操作系统的本地线程直接映射，因此这部分内存区域的存/否跟随本地线程的生/死对应</code></p><h4 id="线程共享区域随虚拟机的启动-关闭而创建-销毁"><a href="#线程共享区域随虚拟机的启动-关闭而创建-销毁" class="headerlink" title="线程共享区域随虚拟机的启动/关闭而创建/销毁"></a>线程共享区域随虚拟机的启动/关闭而创建/销毁</h4><blockquote><p>直接内存并不是JVM运行时数据区的一部分,但也会被频繁的使用:在JDK1.4引入的NIO提供了基于Channel与Buffer的IO方式．他可以使用Native函数库直接分配堆外内存，然后使用DirectByteBuffer对象作为这个内存的引用进行操作，这样避免了在Java堆和Native中来回复制数据，因此在一场场景中可以显著提高性能．</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200519213321.png" srcset="/img/loading.gif" alt="avatar"> </p><h1 id="程序计数器-线程私有"><a href="#程序计数器-线程私有" class="headerlink" title="程序计数器(线程私有)"></a>程序计数器(线程私有)</h1><blockquote><p>一块较小的内存空间，<code>是当前线程所执行的字节码的行号指示器</code>，每条线程都要有一个独立的程序计数器，这类内存也称为<code>线程私有</code>的内存．</p></blockquote><blockquote><p>正在执行Java方法的话，计数器记录的是虚拟机字节码指令的地址(当前指令的地址)．如果还是Native方法则为空．</p></blockquote><blockquote><p>这个内存区域是　唯一一个在虚拟机中没有规定任何OutOfMemoryError情况的区域</p></blockquote><h1 id="虚拟机栈-线程私有"><a href="#虚拟机栈-线程私有" class="headerlink" title="虚拟机栈(线程私有)"></a>虚拟机栈(线程私有)</h1><blockquote><p>是描述Java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧(Stack Frame)用于存储局部变量表，操作数栈，动态链接，方法出口等信息．每一个方法从调用直至执行完成的过程，就对应着一个在虚拟机栈中入栈到出栈的过程</p></blockquote><blockquote><p>栈帧( Frame)是用来存储数据和部分过程结果的数据结构,同时也被用来处理动态链接(Dynamic Linking)、 方法返回值和异常分派( Dispatch Exception)。栈帧随着方法调用而创建,随着方法结束而销毁——无论方法是正常完成还是异常完成(抛出了在方法内未被捕获的异常)都算作方法结束。</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200519213321.png" srcset="/img/loading.gif" alt="avatar"> </p><h1 id="本地方法区-线程私有"><a href="#本地方法区-线程私有" class="headerlink" title="本地方法区(线程私有)"></a>本地方法区(线程私有)</h1><blockquote><p>本地方法区和 Java Stack 作用类似, 区别是虚拟机栈为执行 Java 方法服务, 而本地方法栈则为<br> Native 方法服务, 如果一个 VM 实现使用 C-linkage 模型来支持 Native 调用, 那么该栈将会是一个<br> C 栈,但 HotSpot VM 直接就把本地方法栈和虚拟机栈合二为一。</p></blockquote><h1 id="堆-Heap-线程共享-运行时数据区"><a href="#堆-Heap-线程共享-运行时数据区" class="headerlink" title="堆(Heap-线程共享)-运行时数据区"></a>堆(Heap-线程共享)-运行时数据区</h1><blockquote><p>是被线程共享的一块内存区域，<code>创建的对象和数组都保存在Java堆内存中,也是垃圾收集器进行垃圾收集的最重要的内存区域</code>，由于现代VM采用分代收集算法，因此Java堆从GC的角度还可以细分为：新生代(Eden区，From Survivor区和To Survivor区)和老年代</p></blockquote><h1 id="方法区-永久代-线程共享"><a href="#方法区-永久代-线程共享" class="headerlink" title="方法区/永久代(线程共享)"></a>方法区/永久代(线程共享)</h1><blockquote><p>即我们常说的永久代(Permanent Generation)用于存储被jvm加载的类信息，常量，静态变量，即时编译器编译后的代码等数据．HotSpot VM把GC分代收集扩展至方法区，即使用Java堆的永久代来实现方法区，这样HotSpot的垃圾收集器就可以像管理Java堆一样内存管理这部分内存，而不必为方法区开发专门的内存管理器(永久代的内存回收的主要目标是针对常量池的回收和类型的卸载，因此收益一般很小)</p></blockquote><p>运行时常量</p><blockquote><p>运行时常量池(Runtime Constant Pool)是方法区的一部分。Class 文件中除了有类的版<br> 本、字段、方法、接口等描述等信息外,还有一项信息是常量池(Constant Pool Table),用于存放编译期生成的各种字面量和符号引用,这部分内容将在类加<br> 载后存放到方法区的运行时常量池中。 Java 虚拟机对 Class 文件的每一部分(自然也包括常量<br> 池)的格式都有严格的规定,每一个字节用于存储哪种数据都必须符合规范上的要求,这样才会<br> 被虚拟机认可、装载和执行。</p></blockquote><h1 id="JVM运行时内存"><a href="#JVM运行时内存" class="headerlink" title="JVM运行时内存"></a>JVM运行时内存</h1><blockquote><p>Java堆GC的角度还可以细分为:新生代(Eden区，From Survivor区和To Survivor区)和老年代</p></blockquote><p><img src="/resource/img/Jvm_runtime.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="新生代"><a href="#新生代" class="headerlink" title="新生代"></a>新生代</h2><blockquote><p>是用来存放新生对象的，一般占用堆的1/3空间.由于频繁创建对象，所以新生代会频繁触发MinorGC进行垃圾回收.新生代又分为Eden区、SurvivorFrom、SurvivorTo三个区。</p></blockquote><h3 id="Eden区"><a href="#Eden区" class="headerlink" title="Eden区"></a>Eden区</h3><blockquote><p>Java新对象的出生地<code>（如果新创建的对象占用内存很大，则直接分配到老年代）</code>当Eden区内存不够的时候就会触发MinorGC，对新生代进行一次垃圾回收。</p></blockquote><h3 id="SurvivorFrom"><a href="#SurvivorFrom" class="headerlink" title="SurvivorFrom"></a>SurvivorFrom</h3><blockquote><p>上一次GC的幸存者，作为这一次GC的被扫描者</p></blockquote><h3 id="SurvivorTo"><a href="#SurvivorTo" class="headerlink" title="SurvivorTo"></a>SurvivorTo</h3><blockquote><p>保留了一次MinorGC过程中的幸存者</p></blockquote><h3 id="MinorGC的过程-复制-gt-清空-gt-互换"><a href="#MinorGC的过程-复制-gt-清空-gt-互换" class="headerlink" title="MinorGC的过程(复制-&gt;清空-&gt;互换)"></a>MinorGC的过程(复制-&gt;清空-&gt;互换)</h3><blockquote><p>MinorGC采用复制算法</p></blockquote><ul><li><p>eden、SurvivorFrom、复制到SurvivorTo年龄+1</p><blockquote><p>首先，把Eden和SurvivorFrom区域中存活的对象复制到SurvivorTo区域(如果有对象的年龄以及达到了老年的标准，则赋值到老年代)，同时把这些对象的年龄+1（如果SurvivorTo不够位置了就放到老年区）</p></blockquote></li><li><p>清空Eden、SurvivorFrom</p><blockquote><p>然后清空Eden和SurvivorFrom中的对象</p></blockquote></li><li><p>SurvivorTo 和 SurvivorFrom互换</p><blockquote><p>最后，SurvivorTo和SurvivorFrom互换，原SurvivorFrom成为下一次GC时的SurvivorFrom区</p></blockquote></li></ul><h1 id="老年代"><a href="#老年代" class="headerlink" title="老年代"></a>老年代</h1><p><code>主要存放应用程序中生命周期长的内存对象</code></p><blockquote><p>老年代的对象比较稳定，所以MajorGC不会频繁执行。在进行MajorGC前一般都先进行了一次MinorGC使得有新生代对象晋入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次MajorGC进行垃圾回收腾出空间。</p></blockquote><blockquote><p>MajorGC采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没有标记的对象。MajorGC的耗时比较长，因为要扫描再回收。MajorGC会产生内存碎片为了减少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满足了装不下的时候，就会抛出OOM(OutOfMemory)异常。</p></blockquote><h1 id="永久代"><a href="#永久代" class="headerlink" title="永久代"></a>永久代</h1><blockquote><p>指的是内存的永久保存区域，主要存放Class和Meta(元数据)的信息Class在被加载的时候被放入永久区域，他和存放实例的区域不同　<code>GC不会在主程序运行期对永久区进行清理</code>.所以这也导致了永久代的区域会随着加载的Class的增多而胀满，最终抛出OOM异常。</p></blockquote><h1 id="Java8与元数据"><a href="#Java8与元数据" class="headerlink" title="Java8与元数据"></a>Java8与元数据</h1><blockquote><p>在Java8中，永久代已经被移除，被一个称为“元数据”（元空间）的区域所取代。元空间的本质和永久代类似，元空间与永久代之间的最大区别在于：元空间并不在虚拟机中，而是使用本地内存。因此默认情况下元空间的大小仅仅受本地内存限制。类的元数据放入native memory字符串池和类的静态变量放入Java堆中，这样可以加载多少类的元数据就不会由MaxPermSize控制，而是由系统实际可用空间来控制。</p></blockquote><h1 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h1><p><img src="/resource/img/jvmrubbakc.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="如何确定垃圾"><a href="#如何确定垃圾" class="headerlink" title="如何确定垃圾"></a>如何确定垃圾</h2><ul><li><p>引用计数法</p><blockquote><p>在Java中引用和对象是有关联的。如果要操作对象则必须用引用进行。因此很显然一个简单的办法是通过引用计数来判断一个对象是否可以回收。简单的说，即一个对象如果没有任何与之关联的引用，即他们的引用计数都不为零，则说明对象不太可能在被利用到，那么　这个对象就是可回收对象。</p></blockquote></li><li><p>可达性分析</p><blockquote><p>为了解决引用计数法的循环引用问题，Java使用了可达性分析方法。通过一系列的“GC roots”对象作为起点搜索。如果在“GC roots”和一个对象之间没有可达路径，则称该对象是不可达的。<br>要注意的是不可达对象不等价于回收对象，不可达对象变为可回收对象至少要经过两次标记过程，两次标记后仍然是可回收对象，则将面临回收。</p></blockquote></li><li><p>标记清除法(Mark-Sweep)</p><blockquote><p>最基础的垃圾回收算法，分为两个阶段，标注和清除。标记阶段标记处所有需要回收的对象，清除阶段回收被标记的对象所占用的空间。如图</p></blockquote></li></ul><p><img src="/resource/img/mark_sweep.png" srcset="/img/loading.gif" alt="avatar"></p><p>缺点：<code>内存碎片化严重，后续可能发生大对象不能找到可利用空间的问题</code></p><ul><li>复制算法(copying)<blockquote><p>为了解决Mark-Sweep算法内存碎片化的缺陷而被提出的算法。按内存容量将内存划分为等大小的两块。每次只使用期中一块，当这一块内存满后将尚存活的对象复制到另一块上去，把已使用的内存清掉，如图：</p></blockquote></li></ul><p><img src="/resource/img/copying.png" srcset="/img/loading.gif" alt="avatar"></p><p>缺点：<code>内存被压缩到了原本的一半。且存活对象对象增多的话，Copying算法的效率会大大降低</code></p><ul><li>标记整理算法(Mark-Compact)<blockquote><p>结合以上两个算法，为了避免缺陷而提出。标记阶段和Mark-Sweep算法相同，标记后不是清理对象，而是将存活对象移向内存的一端。然后清除端边界的对象</p></blockquote></li></ul><p><img src="/resource/img/Mark-Compact.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li>分代收集算法<blockquote><p>分代收集法是目前大部分 JVM 所采用的方法,其核心思想是根据对象存活的不同生命周期将内存划分为不同的域,一般情况下将 GC 堆划分为老生代(Tenured/Old Generation)和新生代(YoungGeneration)。老生代的特点是每次垃圾回收时只有少量对象需要被回收,新生代的特点是每次垃圾回收时都有大量垃圾需要被回收,因此可以根据不同区域选择不同的算法。</p></blockquote></li></ul><p>新生代与复制算法</p><blockquote><p>目前大部分 JVM 的 GC 对于新生代都采取 Copying 算法,因为新生代中每次垃圾回收都要<br> 回收大部分对象,即要复制的操作比较少,但通常并不是按照 1:1 来划分新生代。一般将新生代<br> 划分为一块较大的 Eden 空间和两个较小的 Survivor 空间(From Space, To Space),每次使用<br> Eden 空间和其中的一块 Survivor 空间,当进行回收时,将该两块空间中还存活的对象复制到另<br> 一块 Survivor 空间中。<br><img src="/resource/img/young-mark-copy.png" srcset="/img/loading.gif" alt="avatar"></p></blockquote><p>老年代与标记复制算法</p><blockquote><p>而老年代因为每次只回收少量对象,因而采用 Mark-Compact 算法。<br>1.JAVA 虚拟机提到过的处于方法区的永生代(Permanet Generation),它用来存储 class 类,常量,方法描述等。对永生代的回收主要包括废弃常量和无用的类。<br>2.对象的内存分配主要在新生代的 Eden Space 和 Survivor Space 的 From Space(Survivor 目前存放对象的那一块),少数情况会直接分配到老生代。<br>3.当新生代的 Eden Space 和 From Space 空间不足时就会发生一次 GC,进行 GC 后,EdenSpace 和 From Space 区的存活对象会被挪到 To Space,然后将 Eden Space 和 FromSpace 进行清理。<br>4.如果 To Space 无法足够存储某个对象,则将这个对象存储到老生代。<br>5.在进行 GC 后,使用的便是 Eden Space 和 To Space 了,如此反复循环。<br>6.当对象在 Survivor 区躲过一次 GC 后,其年龄就会+1。默认情况下年龄到达 15 的对象会被移到老生代中。</p></blockquote><h1 id="Java-四种引用类型"><a href="#Java-四种引用类型" class="headerlink" title="Java 四种引用类型"></a>Java 四种引用类型</h1><ul><li>强引用<blockquote><p>在 Java 中最常见的就是强引用,把一个对象赋给一个引用变量,这个引用变量就是一个强引<br>用。当一个对象被强引用变量引用时,它处于可达状态,它是不可能被垃圾回收机制回收的,即<br>使该对象以后永远都不会被用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之<br>一。</p></blockquote></li><li>软引用<blockquote><p>软引用需要用 SoftReference 类来实现,对于只有软引用的对象来说,当系统内存足够时它<br>不会被回收,当系统内存空间不足时它会被回收。软引用通常用在对内存敏感的程序中。</p></blockquote></li><li>弱引用<blockquote><p>弱引用需要用 WeakReference 类来实现,它比软引用的生存期更短,对于只有弱引用的对象<br>来说,只要垃圾回收机制一运行,不管 JVM 的内存空间是否足够,总会回收该对象占用的内存。</p></blockquote></li><li>虚引用<blockquote><p>虚引用需要 PhantomReference 类来实现,它不能单独使用,必须和引用队列联合使用。虚<br>引用的主要作用是跟踪对象被垃圾回收的状态。</p></blockquote></li></ul><h1 id="GC-分代收集算法-VS-分区收集算法"><a href="#GC-分代收集算法-VS-分区收集算法" class="headerlink" title="GC 分代收集算法 VS 分区收集算法"></a>GC 分代收集算法 VS 分区收集算法</h1><h3 id="分代收集算法"><a href="#分代收集算法" class="headerlink" title="分代收集算法"></a>分代收集算法</h3><blockquote><p>当前主流VM垃圾收集都采用“分代收集”(Generational Collection)算法，这种算法会根据对象存活周期的不同将内存划分为几块，如JVM中的<code>新生代、老年代、永久代</code>这样就可以根据各年代分别采用最适当的GC算法</p></blockquote><h1 id="在新生代-复制算法"><a href="#在新生代-复制算法" class="headerlink" title="在新生代-复制算法"></a>在新生代-复制算法</h1><p>每次垃圾收集都能发现大批对象已死, 只有少量存活. 因此选用复制算法, 只需要付出少量<br>存活对象的复制成本就可以完成收集.</p><h1 id="在老年代-标记整理算法"><a href="#在老年代-标记整理算法" class="headerlink" title="在老年代-标记整理算法"></a>在老年代-标记整理算法</h1><p>因为对象存活率高、没有额外空间对它进行分配担保, 就必须采用“标记—清理”或“标<br>记—整理”算法来进行回收, 不必进行内存复制, 且直接腾出空闲内存.<br>分区算法则将整个堆空间划分为连续的不同小区间, 每个小区间独立使用, 独立回收. 这样做的<br>好处是可以控制一次回收多少个小区间 , 根据目标停顿时间, 每次合理地回收若干个小区间(而不是<br>整个堆), 从而减少一次 GC 所产生的停顿。</p><h1 id="GC-垃圾收集器"><a href="#GC-垃圾收集器" class="headerlink" title="GC 垃圾收集器"></a>GC 垃圾收集器</h1><p>Java 堆内存被划分为新生代和年老代两部分,新生代主要使用复制和标记-清除垃圾回收 算法 ;<br>年老代主要使用标记-整理垃圾回收算法,因此 java 虚拟中针对新生代和年老代分别提供了多种不<br>同的垃圾收集器,JDK1.6 中 Sun HotSpot 虚拟机的垃圾收集器如下:</p><p><img src="/resource/img/JDK16SunHotspot.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li><p>Serial 垃圾收集器(单线程、复制算法)</p><blockquote><p>Serial(英文连续)是最基本垃圾收集器，使用复制算法，曾经是JDK1.3.1之前新生代唯一的垃圾收集器。Serial是一个单线程的收集器，它不但只会使用一个CPU或一条线程去完成垃圾收集工作而且在进行垃圾收集同时，必须暂停所有的工作线程，但是它简单高效，对于限定单个CPU环境来说，没有线程交互的开销，可以获得最高的单线程垃圾收集效率，因此Serial垃圾收集器依然是Java虚拟机在Client模式下默认的新生代垃圾收集器。</p></blockquote></li><li><p>ParNew垃圾收集器(Serial+多线程)</p><blockquote><p>ParNew垃圾收集器其实是Serial收集器的多线程版本，也是使用多线程进行垃圾收集之外，其余的行为和Serial收集器完全一致，ParNew垃圾收集器在垃圾收集过程中同样也要暂停所有其他的工作线程。ParNew收集器默认开启和CPU数目相同的线程数，可以通过-XX:ParallelGCThreads参数来限制垃圾收集器的线程数。(Parallel:平行的)ParNew虽然是除了多线程和Serial收集器几乎完全一致，但是ParNew垃圾收集器是很多Java虚拟机运行在Server模式下新生代的默认垃圾收集器。</p></blockquote></li><li><p>Parallel Scavenge收集器(多线程复制算法、高效)</p><blockquote><p>Parallel Scavenge收集器也是一个新生代垃圾收集器，同样使用复制算法，也是一个多线程的垃圾收集器，它重点关注的是程序达到一个可控制的吞吐量(Thoughput,CPU用于运行用户代码的时间/CPU总消耗时间，即吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间))，高吞吐量可以最高效率利用CPU时间尽快完成程序运算任务，主要适用在后台运算而不需要太多交互的任务。自适应调节策略也是ParallelScavenge收集器与ParNew收集器的一个重要区别。</p></blockquote></li><li><p>Serial Old收集器(单线程标记整理算法)</p><blockquote><p>Serial Old是Serial 垃圾收集器年代老版本，它同样是单线程的收集器，使用标记-整理算法，这个收集器也主要是运行在Client默认的Java虚拟机默认的年代垃圾收集器。在这个模式下，主要有两个用途：</p></blockquote></li></ul><p>1.在JDK1.5之前版本中与新生代的Parallel　Scavenge收集器搭配使用。</p><p>2.作为年老代中使用CMS收集器的后备垃圾收集方案：</p><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200527092744.png" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="text">新生代 Parallel Scavenge 收集器与 ParNew 收集器工作原理类似,都是多线程的收集器,都使用的是复制算法,在垃圾收集过程中都需要暂停所有的工作线程。新生代 ParallelScavenge/ParNew 与年老代 Serial Old 搭配垃圾收集过程图:</code></pre><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200527092908.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li>Parallel Old收集器(多线程标记整理算法)<blockquote><p>Parallel Old收集器是Parallel Scavenge的年老代版本，使用多线程的标记-整理算法，在JDK1.才开始提供。<br>在JDK1.6之前，新生代使用ParallelScavenge收集器只能搭配年老代的Serial Old收集器只能保证新生代的吞吐量优先，无法保证整体的吞吐量，Parallel Old正是为了在老代同样提供吞吐量优先的垃圾收集的搭配策略。<br>新生代Parallel Scavenge和老年代Parallel Old收集器搭配运行过程图：</p></blockquote></li></ul><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200527095030.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li>CMS收集器(多线程标记清除算法)<blockquote><p>Concurrent mark sweep(CMS)收集器是一种年老代垃圾收集器，其最主要目标是获取最短垃圾回收停顿时间，和其他年老代使用标记-整理算法不同，它使用多线程的标记-清除算法。最短的垃圾收集停顿时间可以为交互比较高的程序提高用户体验。</p></blockquote></li></ul><p><code>CMS工作机制相比其他的垃圾收集器来说更复杂，整个过程分为以下4个阶段：</code></p><p>初始标记</p><blockquote><p>只是标记一下 GC Roots 能直接关联的对象,速度很快,仍然需要暂停所有的工作线程。</p></blockquote><p>并发标记</p><blockquote><p>进行 GC Roots 跟踪的过程,和用户线程一起工作,不需要暂停工作线程。</p></blockquote><p>重新标记</p><blockquote><p>为了修正在并发标记期间,因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录,仍然需要暂停所有的工作线程。</p></blockquote><p>并发标记</p><blockquote><p>清除 GC Roots 不可达对象,和用户线程一起工作,不需要暂停工作线程。由于耗时最长的并发标记和并发清除过程中,垃圾收集线程可以和用户现在一起并发工作,所以总体上来看CMS 收集器的内存回收和用户线程是一起并发地执行。</p></blockquote><p>CMS收集器工作过程</p><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200527100033.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li>G1收集器<blockquote><p>Garbage first 垃圾收集器是目前垃圾收集器理论发展的最前沿成果,相比与 CMS 收集器,G1 收<br>集器两个最突出的改进是:</p></blockquote><ol><li>基于标记-整理算法,不产生内存碎片。</li><li>可以非常精确控制停顿时间,在不牺牲吞吐量前提下,实现低停顿垃圾回收。<blockquote><p>G1 收集器避免全区域垃圾收集,它把堆内存划分为大小固定的几个独立区域,并且跟踪这些区域<br>的垃圾收集进度,同时在后台维护一个优先级列表,每次根据所允许的收集时间,优先回收垃圾<br>最多的区域。区域划分和优先级区域回收机制,确保 G1 收集器可以在有限时间获得最高的垃圾收<br>集效率。</p></blockquote></li></ol></li></ul><h1 id="Jvm类加载机制"><a href="#Jvm类加载机制" class="headerlink" title="Jvm类加载机制"></a>Jvm类加载机制</h1><blockquote><p>JVM类加载机制分为:<code>加载、验证、准备、解析、初始化</code></p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200528223950.png" srcset="/img/loading.gif" alt="avatar"></p><ul><li><p>加载</p><blockquote><p>加载是类加载过程中的一个阶段，这个阶段会在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的入口。注意这里不一定是要从一个Class文件获取，这里既可以从ZIP包中读取(比如jar包和war包中读取)，也可以在运行计算生成(动态代理)，也可以由其它文件生成(比如将jsp文件转换成对应的Class类)。</p></blockquote></li><li><p>验证</p><blockquote><p>这一阶段的主要目的是为了确保Class文件的字节流中包含的信息是否符合当前虚拟机的要求，并且不会危害自身的安全。</p></blockquote></li><li><p>准备</p><blockquote><p>准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间，注意这里所说的初始值概念，比如说一个类变量定义为：</p></blockquote><pre><code class="java">public static int v = 8080;</code></pre><p>实际上变量V在准备阶段过后的初始值为0而不是8080，将V赋值为8080的put static指令是程序被编译后，存放于类构造器<client>方法之中<br>但是注意如果声明为：</p><pre><code class="java">public static  final int v = 8080;</code></pre><p>在编译阶段会为V生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性将V赋值为8080</p></li><li><p>解析</p><blockquote><p>解析阶段是指虚拟机将常量池中的符合引用替换为直接引用的过程。符合引用就是class文件中的<code>CONSTANT_Class_info</code>，<code>CONSTANT_Field_Info</code>，<code>CONSTANT_Method_Info</code>等类型常量。</p></blockquote></li></ul><p>符合引用:</p><blockquote><p>符号引用与虚拟机实现的布局无关,引用的目标并不一定要已经加载到内存中。各种虚拟机实现的内存布局可以各不相同,但是它们能接受的符号引用必须是一致的,因为符号引用的字面量形式明确定义在 Java 虚拟机规范的 Class 文件格式中。</p></blockquote><p>直接引用:</p><blockquote><p>直接引用可以是指向目标的指针,相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用,那引用的目标必定已经在内存中存在.</p></blockquote><p>初始化:</p><blockquote><p>初始化阶段是类加载最后一个阶段,前面的类加载阶段之后,除了在加载阶段可以自定义类加载器以外,其它操作都由 JVM 主导。到了初始阶段,才开始真正执行类中定义的 Java 程序代码。</p></blockquote><p>类构造器:</p><blockquote><p>初始化阶段是执行类构造器<client>方法的过程。<client>方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证子<client>方法执行之前,父类的<client>方法已经执行完毕,如果一个类中没有对静态变量赋值也没有静态语句块,那么编译器可以不为这个类生成<client>()方法。</p></blockquote><p><code>[注]</code>以下几种情况不会执行类初始化：<br>1.通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。<br>2.定义对象数组，不会触发该类的初始化。<br>3.常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，也不会触发定义常量所在的类<br>4.通过类名获取Class对象不会触发类的初始化。<br>5.通过Class.forName加载指定类时，如果指定参数initialize为false时，也不会触发类初始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。<br>6.通过ClassLoader默认的loadClass方法也不会触发初始化动作。</p><h1 id="类加载器"><a href="#类加载器" class="headerlink" title="类加载器"></a>类加载器</h1><blockquote><p>虚拟机设计团队把加载动作放到JVM外部实现，以便让应用程序决定如何获取所需的类，JVM提供了3种类加载器</p></blockquote><ul><li>启动类加载器(Bootstrap ClassLoader)<blockquote><p>负责加载<code>JAVA_HOME\lib</code>目录中的，或者通过<code>-Xbootclasspath</code>参数指定路径中的，且被虚拟机认可(按文件名识别，如rt.jar)的类。</p></blockquote></li><li>扩展类加载器(Extension ClassLoader)<blockquote><p>负责加载<code>JAVA_HOME\lib\ext</code>目录中的，或者通过<code>java.ext.dirs</code>系统变量指定路径中的类库。</p></blockquote></li><li>应用程序类加载器(Application ClassLoader)<blockquote><p>负责加载用户路径(classpath)上的类库。<br>JVM通过双亲委派模型进行类的加载，当然我们也可以通过继承<code>java.lang.ClassLoader</code>实现自定义的类加载器</p></blockquote></li></ul><p><img src="/resource/img/application_classloader.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="双亲委派"><a href="#双亲委派" class="headerlink" title="双亲委派"></a>双亲委派</h2><blockquote><p>当一个类收到类加载请求，他首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，每一层次类加载器都是如此，因此所有的加载请求都应该传送到启动类加载其中，只有当父类加载器反馈自己无法完成这个请求的时候(在它的加载路径下没有找到所需的Class)，子类加载器才会尝试自己去加载。</p></blockquote><blockquote><p>采用双亲委派的好处是比如加载位于<code>rt.jar</code>包中的类<code>java.lang.Object</code>，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同一个Object对象。</p></blockquote><p><img src="/resource/img/TIM%E5%9B%BE%E7%89%8720200529101019.png" srcset="/img/loading.gif" alt="avatar"></p><h3 id="OSGI-动态模型系统"><a href="#OSGI-动态模型系统" class="headerlink" title="OSGI(动态模型系统)"></a>OSGI(动态模型系统)</h3><blockquote><p>OSGI(Open Service Gateway Initiative)，是面向Java的动态模型系统，是Java动态模块化系统的一系列规范。</p></blockquote><h1 id="动态改变构造"><a href="#动态改变构造" class="headerlink" title="动态改变构造"></a>动态改变构造</h1><p>OSGi 服务平台提供在多种网络设备上无需重启的动态改变构造的功能。为了最小化耦合度和促使<br>这些耦合度可管理,OSGi 技术提供一种面向服务的架构,它能使这些组件动态地发现对方。</p><h1 id="模块化编程与热插拔"><a href="#模块化编程与热插拔" class="headerlink" title="模块化编程与热插拔"></a>模块化编程与热插拔</h1><p>OSGi 旨在为实现 Java 程序的模块化编程提供基础条件,基于 OSGi 的程序很可能可以实现模块级的热插拔功能,当程序升级更新时,可以只停用、重新安装然后启动程序的其中一部分,这对企业级程序开发来说是非常具有诱惑力的特性。OSGi 描绘了一个很美好的模块化开发目标,而且定义了实现这个目标的所需要服务与架构,同时也有成熟的框架进行实现支持。但并非所有的应用都适合采用 OSGi 作为基础架构,它在提供强大功能同时,也引入了额外的复杂度,因为它不遵守了类加载的双亲委托模型。</p>]]></content>
    
    
    <categories>
      
      <category>JVM</category>
      
    </categories>
    
    
    <tags>
      
      <tag>JVM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基础知识复习篇</title>
    <link href="/2020/05/17/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0%E7%AF%87/"/>
    <url>/2020/05/17/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%A4%8D%E4%B9%A0%E7%AF%87/</url>
    
    <content type="html"><![CDATA[<h1 id="Java基础"><a href="#Java基础" class="headerlink" title="Java基础"></a>Java基础</h1><details>    <summary>Java基础知识汇总</summary></details><h1 id="Java高级"><a href="#Java高级" class="headerlink" title="Java高级"></a>Java高级</h1><details>    <summary>Java高级知识汇总</summary></details><h1 id="JVM-知识"><a href="#JVM-知识" class="headerlink" title="JVM 知识"></a>JVM 知识</h1><p>   <a href="/2020/05/19/JVM-知识汇总/index.html">JVM 知识汇总</a></p><h1 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h1><details>    <summary>常见算法知识汇总</summary></details><h1 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h1><details>    <summary>常见算法知识汇总</summary></details><h1 id="安全认证"><a href="#安全认证" class="headerlink" title="安全认证"></a>安全认证</h1><details>    <summary>常见算法知识汇总</summary></details><h1 id="计算机网络"><a href="#计算机网络" class="headerlink" title="计算机网络"></a>计算机网络</h1><details>    <summary>常见算法知识汇总</summary></details><h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><details>    <summary>常见算法知识汇总</summary></details><h1 id="微服务"><a href="#微服务" class="headerlink" title="微服务"></a>微服务</h1><details>    <summary>常见算法知识汇总</summary></details><h1 id="主流框架"><a href="#主流框架" class="headerlink" title="主流框架"></a>主流框架</h1><details>    <summary>Spring Fram</summary></details><details>    <summary>Netty</summary></details><details>    <summary>MyBatis</summary></details><details>    <summary>SpringCloud</summary></details><details>    <summary>Grpc</summary></details><h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><details>    <summary>负载均衡</summary></details><h1 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h1><details>    <summary>设计模式</summary></details><h1 id="相关经验"><a href="#相关经验" class="headerlink" title="相关经验"></a>相关经验</h1><details>    <summary>相关经验</summary></details><h1 id="代码库地址"><a href="#代码库地址" class="headerlink" title="代码库地址"></a>代码库地址</h1><p><a href="https://github.com/mikeygithub/InterviewTopics" target="_blank" rel="noopener">mikeygithub</a></p>]]></content>
    
    
    <categories>
      
      <category>面试</category>
      
    </categories>
    
    
    <tags>
      
      <tag>知识汇总</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Lua 脚本学习</title>
    <link href="/2020/05/02/Lua-%E8%84%9A%E6%9C%AC%E5%AD%A6%E4%B9%A0/"/>
    <url>/2020/05/02/Lua-%E8%84%9A%E6%9C%AC%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote><p>Lua is free software distributed in source code. It may be used for any purpose, including commercial purposes, at absolutely no cost.<br>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。</p></blockquote><p>Lua 是巴西里约热内卢天主教大学（Pontifical Catholic University of Rio de Janeiro）里的一个研究小组于 1993 年开发的，该小组成员有：<code>Roberto Ierusalimschy</code>、<code>Waldemar Celes</code> 和 <code>Luiz Henrique de Figueiredo</code>。</p><h2 id="设计目的"><a href="#设计目的" class="headerlink" title="设计目的"></a>设计目的</h2><p>其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。</p><h2 id="Lua-特性"><a href="#Lua-特性" class="headerlink" title="Lua 特性"></a>Lua 特性</h2><ul><li>轻量级: 它用标准C语言编写并以源代码形式开放，编译后仅仅一百余K，可以很方便的嵌入别的程序里。</li><li>可扩展: Lua提供了非常易于使用的扩展接口和机制：由宿主语言(通常是C或C++)提供这些功能，Lua可以使用它们，就像是本来就内置的功能一样。</li></ul><h2 id="其它特性"><a href="#其它特性" class="headerlink" title="其它特性:"></a>其它特性:</h2><ul><li>支持面向过程(procedure-oriented)编程和函数式编程(functional programming)；</li><li>自动内存管理；只提供了一种通用类型的表（table），用它可以实现数组，哈希表，集合，对象；</li><li>语言内置模式匹配；闭包(closure)；函数也可以看做一个值；提供多线程（协同进程，并非操作系统所支持的线程）支持；</li><li>通过闭包和table可以很方便地支持面向对象编程所需要的一些关键机制，比如数据抽象，虚函数，继承和重载等。</li></ul><h1 id="Lua-应用场景"><a href="#Lua-应用场景" class="headerlink" title="Lua 应用场景"></a>Lua 应用场景</h1><ul><li>游戏开发</li><li>独立应用脚本</li><li>Web 应用脚本</li><li>扩展和数据库插件如：MySQL Proxy 和 MySQL WorkBench</li><li>安全系统，如入侵检测系统</li></ul><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><pre><code class="bash">curl -R -O http://www.lua.org/ftp/lua-5.3.5.tar.gztar zxf lua-5.3.5.tar.gzcd lua-5.3.5make linux test</code></pre><p>编译出错<br><img src="/resource/img/complie-error.png" srcset="/img/loading.gif" alt="avatar"><br>解决方法<br><code>sudo apt-get install libreadline7 libreadline-dev</code><br>重新编译<br><code>make linux test</code><br>创建软连接<br><code>sudo ln -s /home/mikey/DATA/DevTools/lua-5.3.5/src/lua /usr/bin/lua</code><br>测试  </p><pre><code>mikey@localhost: luaLua 5.3.5  Copyright (C) 1994-2018 Lua.org, PUC-Rio&gt; print(&quot;Hello Mikey&quot;)Hello Mikey&gt; ```  # Lua 数据库访问Lua 数据库的操作库：LuaSQL。开源，支持的数据库有：ODBC, ADO, Oracle, MySQL, SQLite 和 PostgreSQL。  LuaSQL 可以使用 LuaRocks 来安装可以根据需要安装你需要的数据库驱动。  LuaRocks 安装方法：</code></pre><p>$ wget <a href="http://luarocks.org/releases/luarocks-2.2.1.tar.gz" target="_blank" rel="noopener">http://luarocks.org/releases/luarocks-2.2.1.tar.gz</a><br>$ tar zxpf luarocks-2.2.1.tar.gz<br>$ cd luarocks-2.2.1<br>$ ./configure; sudo make bootstrap<br>$ sudo luarocks install luasocket<br>$ lua<br>Lua 5.3.0 Copyright (C) 1994-2015 Lua.org, PUC-Rio</p><blockquote><p>require “socket”<br>Window 下安装 LuaRocks：<code>https://github.com/keplerproject/luarocks/wiki/Installation-instructions-for-Windows</code></p></blockquote><pre><code>安装不同数据库驱动：</code></pre><p>luarocks install luasql-sqlite3<br>luarocks install luasql-postgres<br>luarocks install luasql-mysql<br>luarocks install luasql-sqlite<br>luarocks install luasql-odbc</p><pre><code>你也可以使用源码安装方式，Lua Github 源码地址：`https://github.com/keplerproject/luasql`Lua 连接MySql 数据库：</code></pre><p>实例<br>require “luasql.mysql”</p><p>–创建环境对象<br>env = luasql.mysql()</p><p>–连接数据库<br>conn = env:connect(“数据库名”,”用户名”,”密码”,”IP地址”,端口)</p><p>–设置数据库的编码格式<br>conn:execute”SET NAMES UTF8”</p><p>–执行数据库操作<br>cur = conn:execute(“select * from role”)</p><p>row = cur:fetch({},”a”)</p><p>–文件对象的创建<br>file = io.open(“role.txt”,”w+”);</p><p>while row do<br>    var = string.format(“%d %s\n”, row.id, row.name)</p><pre><code>print(var)file:write(var)row = cur:fetch(row,&quot;a&quot;)</code></pre><p>end</p><p>file:close()  –关闭文件对象<br>conn:close()  –关闭数据库连接<br>env:close()   –关闭数据库环境</p><pre><code># 参考资料[菜鸟教程](https://www.runoob.com/lua/lua-tutorial.html)[官方手册](https://www.runoob.com/manual/lua53doc/)</code></pre>]]></content>
    
    
    <categories>
      
      <category>后端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>lua</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何让Netty服务随Tomcat启动</title>
    <link href="/2020/05/01/How-to-start-netty-in-Tomcat/"/>
    <url>/2020/05/01/How-to-start-netty-in-Tomcat/</url>
    
    <content type="html"><![CDATA[<h1 id="关于在Tomcat容器中启动Netty服务器的方法"><a href="#关于在Tomcat容器中启动Netty服务器的方法" class="headerlink" title="关于在Tomcat容器中启动Netty服务器的方法"></a>关于在Tomcat容器中启动Netty服务器的方法</h1><blockquote><p>最近在一个web应用上重构一个即时通信功能的,考虑到负载和性能的原因,所以决定采用Netty来作为服务器端,但是如果在主线程中启动netty就会陷入阻塞状态,导致Tomcat无法启动．</p></blockquote><h1 id="实现思路"><a href="#实现思路" class="headerlink" title="实现思路"></a>实现思路</h1><blockquote><p>我们知道，netty在主线程启动会陷入阻塞，那么我们就可以开启一个新线程来启动netty服务器，让主线程启动Tomcat即可</p></blockquote><h1 id="相关代码"><a href="#相关代码" class="headerlink" title="相关代码"></a>相关代码</h1><details>    <summary>application-netty.xml</summary><pre><code class="xml">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot;    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot;    xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans           http://www.springframework.org/schema/beans/spring-beans-4.1.xsd          http://www.springframework.org/schema/context           http://www.springframework.org/schema/context/spring-context-4.1.xsd&quot;&gt;    &lt;!-- 扫描关于Netty Websocket的包 --&gt;    &lt;context:component-scan base-package=&quot;com.gxwzu.websocket&quot;/&gt;    &lt;!-- 把Netty的一些类服务器注册到Spring，方便处理和扩展 --&gt;    &lt;!-- 用于处理客户端连接请求 --&gt;    &lt;bean id=&quot;bossGroup&quot; class=&quot;io.netty.channel.nio.NioEventLoopGroup&quot;/&gt;    &lt;!-- 用于处理客户端I/O操作 --&gt;    &lt;bean id=&quot;workerGroup&quot; class=&quot;io.netty.channel.nio.NioEventLoopGroup&quot;/&gt;    &lt;!-- 服务器启动引导类 --&gt;    &lt;bean id=&quot;serverBootstrap&quot; class=&quot;io.netty.bootstrap.ServerBootstrap&quot; scope=&quot;prototype&quot;/&gt;    &lt;!-- 自定义的Netty Websocket服务器 --&gt;    &lt;bean id=&quot;webSocketServer&quot; class=&quot;com.gxwzu.websocket.WebSocketServer&quot;&gt;        &lt;property name=&quot;port&quot; value=&quot;${chat.server.port}&quot;/&gt;        &lt;property name=&quot;childChannelHandler&quot; ref=&quot;webSocketChildChannelHandler&quot; /&gt;    &lt;/bean&gt;&lt;/beans&gt;</code></pre></details><details>    <summary>WebSocketChildChannelHandler</summary><pre><code class="java">package com.gxwzu.websocket;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelInitializer;import io.netty.channel.socket.SocketChannel;import io.netty.handler.codec.http.HttpObjectAggregator;import io.netty.handler.codec.http.HttpServerCodec;import io.netty.handler.stream.ChunkedWriteHandler;import org.springframework.stereotype.Component;import javax.annotation.Resource;/** * @ProjectName gdm * @Author 麦奇 * @Email biaogejiushibiao@outlook.com * @Date 4/28/20 8:19 AM * @Version 1.0 * @Title: WebSocketChildChannelHandler * @Description: **/@Componentpublic class WebSocketChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; {    @Resource(name = &quot;webSocketServerHandler&quot;)    private ChannelHandler webSocketServerHandler;    @Resource(name = &quot;httpRequestHandler&quot;)    private ChannelHandler httpRequestHandler;    @Override    protected void initChannel(SocketChannel ch) throws Exception {        ch.pipeline().addLast(&quot;http-codec&quot;, new HttpServerCodec()); // HTTP编码解码器        ch.pipeline().addLast(&quot;aggregator&quot;, new HttpObjectAggregator(65536)); // 把HTTP头、HTTP体拼成完整的HTTP请求        ch.pipeline().addLast(&quot;http-chunked&quot;, new ChunkedWriteHandler()); // 分块，方便大文件传输，不过实质上都是短的文本数据        ch.pipeline().addLast(&quot;websocket-handler&quot;,webSocketServerHandler);    }}</code></pre></details><details>    <summary>WebSocketServer</summary><pre><code class="java">kage com.gxwzu.websocket;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.*;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.util.concurrent.Future;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;/** * @ProjectName gdm * @Author 麦奇 * @Email biaogejiushibiao@outlook.com * @Date 4/28/20 8:17 AM * @Version 1.0 * @Title: WebSocketServer * @Description: **/public class WebSocketServer implements Runnable{    private final Logger logger = LoggerFactory.getLogger(WebSocketServer.class);    @Autowired    private EventLoopGroup bossGroup;    @Autowired    private EventLoopGroup workerGroup;    @Autowired    private ServerBootstrap serverBootstrap;    private int port;    private ChannelHandler childChannelHandler;    private ChannelFuture serverChannelFuture;    public WebSocketServer() {}    @Override    public void run() {        build();    }    /**     * 构建服务器     */    public void build() {        try {            long begin = System.currentTimeMillis();            serverBootstrap.group(bossGroup, workerGroup) //boss辅助客户端的tcp连接请求  worker负责与客户端之前的读写操作                    .channel(NioServerSocketChannel.class) //配置客户端的channel类型                    .option(ChannelOption.SO_BACKLOG, 1024) //配置TCP参数，握手字符串长度设置                    .option(ChannelOption.TCP_NODELAY, true) //TCP_NODELAY算法，尽可能发送大块数据，减少充斥的小块数据                    .childOption(ChannelOption.SO_KEEPALIVE, true)//开启心跳包活机制，就是客户端、服务端建立连接处于ESTABLISHED状态，超过2小时没有交流，机制会被启动                    .childOption(ChannelOption.RCVBUF_ALLOCATOR, new FixedRecvByteBufAllocator(592048))//配置固定长度接收缓存区分配器                    .childHandler(childChannelHandler); //绑定I/O事件的处理类,WebSocketChildChannelHandler中定义            long end = System.currentTimeMillis();            logger.info(&quot;Netty Websocket服务器启动完成，耗时 &quot; + (end - begin) + &quot; ms，已绑定端口 &quot; + port + &quot; 阻塞式等候客户端连接&quot;);            serverChannelFuture = serverBootstrap.bind(port).sync();        } catch (Exception e) {            logger.info(e.getMessage());            bossGroup.shutdownGracefully();            workerGroup.shutdownGracefully();            e.printStackTrace();        }    }    /**     * 关闭资源     */    public void close(){        serverChannelFuture.channel().close();        Future&lt;?&gt; bossGroupFuture = bossGroup.shutdownGracefully();        Future&lt;?&gt; workerGroupFuture = workerGroup.shutdownGracefully();        try {            bossGroupFuture.await();            workerGroupFuture.await();        } catch (InterruptedException ignore) {            ignore.printStackTrace();        }    }    public ChannelHandler getChildChannelHandler() {        return childChannelHandler;    }    public void setChildChannelHandler(ChannelHandler childChannelHandler) {        this.childChannelHandler = childChannelHandler;    }    public int getPort() {        return port;    }    public void setPort(int port) {        this.port = port;    }}</code></pre></details><details>    <summary>WebSocketChildChannelHandler</summary><pre><code>package com.gxwzu.websocket;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelInitializer;import io.netty.channel.socket.SocketChannel;import io.netty.handler.codec.http.HttpObjectAggregator;import io.netty.handler.codec.http.HttpServerCodec;import io.netty.handler.stream.ChunkedWriteHandler;import org.springframework.stereotype.Component;import javax.annotation.Resource;/** * @ProjectName gdm * @Author 麦奇 * @Email biaogejiushibiao@outlook.com * @Date 4/28/20 8:19 AM * @Version 1.0 * @Title: WebSocketChildChannelHandler * @Description: **/@Componentpublic class WebSocketChildChannelHandler extends ChannelInitializer&lt;SocketChannel&gt; {    @Resource(name = &quot;webSocketServerHandler&quot;)    private ChannelHandler webSocketServerHandler;    @Resource(name = &quot;httpRequestHandler&quot;)    private ChannelHandler httpRequestHandler;    @Override    protected void initChannel(SocketChannel ch) throws Exception {        ch.pipeline().addLast(&quot;http-codec&quot;, new HttpServerCodec()); // HTTP编码解码器        ch.pipeline().addLast(&quot;aggregator&quot;, new HttpObjectAggregator(65536)); // 把HTTP头、HTTP体拼成完整的HTTP请求        ch.pipeline().addLast(&quot;http-chunked&quot;, new ChunkedWriteHandler()); // 分块，方便大文件传输，不过实质上都是短的文本数据        ch.pipeline().addLast(&quot;http-handler&quot;, httpRequestHandler);        ch.pipeline().addLast(&quot;websocket-handler&quot;,webSocketServerHandler);    }}</code></pre></details><details>    <summary>AppContext</summary><pre><code>package com.gxwzu.websocket;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Scope;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;import javax.annotation.PreDestroy;@Component@Scope()public class AppContext {    private final Logger logger = LoggerFactory.getLogger(AppContext.class);    @Autowired    private WebSocketServer webSocketServer;    private Thread nettyThread;    /**     * 描述：Tomcat加载完ApplicationContext-main和netty文件后：     *      1. 启动Netty WebSocket服务器；     *      2. 加载用户数据；     *      3. 加载用户交流群数据。     */    @PostConstruct    public void init() {        nettyThread = new Thread(webSocketServer);        logger.info(&quot;开启独立线程，启动Netty WebSocket服务器...&quot;);        nettyThread.start();    }    /**     * 描述：Tomcat服务器关闭前需要手动关闭Netty Websocket相关资源，否则会造成内存泄漏。     *      1. 释放Netty Websocket相关连接；     *      2. 关闭Netty Websocket服务器线程。（强行关闭，是否有必要？）     */    @SuppressWarnings(&quot;deprecation&quot;)    @PreDestroy    public void close() {        logger.info(&quot;正在释放Netty Websocket相关连接...&quot;);        webSocketServer.close();        logger.info(&quot;正在关闭Netty Websocket服务器线程...&quot;);        nettyThread.stop();        logger.info(&quot;系统成功关闭！&quot;);    }}</code></pre></details><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/albertfly/article/details/51526423" target="_blank" rel="noopener">Tomcat 通过listener 启动netty 服务</a></p>]]></content>
    
    
    <categories>
      
      <category>网络通信</category>
      
    </categories>
    
    
    <tags>
      
      <tag>netty</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Minikube 使用教程</title>
    <link href="/2020/04/02/Minikube-Use-Tutorials/"/>
    <url>/2020/04/02/Minikube-Use-Tutorials/</url>
    
    <content type="html"><![CDATA[<h2 id="启动-K8s-集群"><a href="#启动-K8s-集群" class="headerlink" title="启动 K8s 集群"></a>启动 K8s 集群</h2><p><code>sudo minikube start --vm-driver=none --image-repository=registry.aliyuncs.com/google_containers</code></p><h3 id="启动GUI"><a href="#启动GUI" class="headerlink" title="启动GUI"></a>启动GUI</h3><p><code>minikube dashboard</code></p><h2 id="K8s-部署应用程序"><a href="#K8s-部署应用程序" class="headerlink" title="K8s 部署应用程序"></a>K8s 部署应用程序</h2><p>Server.js</p><pre><code class="javascript">var http = require(&#39;http&#39;);var handleRequest = function(request, response) {  console.log(&#39;Received request for URL: &#39; + request.url);  response.writeHead(200);  response.end(&#39;Hello World!&#39;);};var www = http.createServer(handleRequest);www.listen(8080);</code></pre><p>Dockerfile</p><pre><code class="yaml">FROM node:6.9.2EXPOSE 8080COPY server.js .CMD node Server.js</code></pre><p>打包镜像</p><p><code>docker build -t hello-node:v1 .</code></p><p>部署应用</p><p><code>kubectl run hello-node --image=hello-node:v1 --port=8080</code></p><p>查看Deployment：</p><p><code>kubectl get deployments</code></p><p>输出：</p><blockquote><p>NAME        DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE<br>hello-node   1         1         1            1           3m</p></blockquote><p>查看Pod：</p><p><code>kubectl get pods</code></p><p>输出：</p><blockquote><p>NAME                        READY     STATUS    RESTARTS   AGE<br>hello-node-714049816-ztzrb   1/1       Running   0          6m</p></blockquote><p>查看群集events：</p><p><code>kubectl get events</code></p><p>查看kubectl配置：</p><p><code>kubectl config view</code></p><p>创建Service</p><blockquote><p>默认情况，这Pod只能通过Kubernetes群集内部IP访问。要使hello-node容器从Kubernetes虚拟网络外部访问，须要使用Kubernetes Service暴露Pod。</p></blockquote><p>我们可以使用kubectl expose命令将Pod暴露到外部环境：</p><p><code>kubectl expose deployment hello-node --type=LoadBalancer</code></p><p>查看刚创建的Service：</p><p><code>kubectl get services</code></p><p>输出：</p><blockquote><p>NAME        CLUSTER-IP   EXTERNAL-IP   PORT(S)    AGE<br>hello-node   10.0.0.71    <pending>     8080/TCP   6m<br>kubernetes   10.0.0.1     <none>        443/TCP    14d</p></blockquote><blockquote><p>通过–type=LoadBalancer flag来在群集外暴露Service，在支持负载均衡的云提供商上，将配置外部IP地址来访问Service。在Minikube上，该LoadBalancer type使服务可以通过minikube Service 命令访问。</p></blockquote><p><code>minikube service hello-node</code></p><p>将打开浏览器，在本地IP地址为应用提供服务，显示“Hello World”的消息。</p><p>最后可以查看到一些日志</p><p><code>kubectl logs &lt;POD-NAME&gt;</code></p><h2 id="K8s-更新应用程序"><a href="#K8s-更新应用程序" class="headerlink" title="K8s 更新应用程序"></a>K8s 更新应用程序</h2><p>编辑server.js文件以返回新消息：</p><p><code>response.end(&#39;Hello World Again!&#39;);</code></p><p>build新版本镜像</p><p><code>docker build -t hello-node:v2 .</code></p><p>Deployment更新镜像：</p><p><code>kubectl set image deployment/hello-node hello-node=hello-node:v2</code></p><p>再次运行应用以查看新消息：</p><p><code>minikube service hello-node</code></p><h2 id="删除-K8s-集群"><a href="#删除-K8s-集群" class="headerlink" title="删除 K8s 集群"></a>删除 K8s 集群</h2><p>现在可以删除在群集中创建的资源：</p><p><code>kubectl delete service hello-node</code><br><code>kubectl delete deployment hello-node</code></p><p>或者停止Minikube：</p><p><code>minikube stop</code></p><h2 id="K8s-kubectl-命令表"><a href="#K8s-kubectl-命令表" class="headerlink" title="K8s kubectl 命令表"></a>K8s kubectl 命令表</h2><p><a href="http://docs.kubernetes.org.cn/683.html" target="_blank" rel="noopener">kubectl命令列表</a></p>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Flutter 快速入门</title>
    <link href="/2020/03/29/Flutter-Quick-Start/"/>
    <url>/2020/03/29/Flutter-Quick-Start/</url>
    
    <content type="html"><![CDATA[<h2 id="Flutter-简单介绍"><a href="#Flutter-简单介绍" class="headerlink" title="Flutter 简单介绍"></a>Flutter 简单介绍</h2><p>Flutter是谷歌的移动UI框架，可以快速在iOS和Android上构建高质量的原生用户界面。 Flutter可以与现有的代码一起工作。在全世界，Flutter正在被越来越多的开发者和组织使用，并且Flutter是完全免费、开源的。</p><h2 id="Flutter-相关特性"><a href="#Flutter-相关特性" class="headerlink" title="Flutter 相关特性"></a>Flutter 相关特性</h2><ul><li><p>快速开发:Flutter的热重载可帮助您快速地进行测试、构建UI、添加功能并更快地修复错误。在iOS和Android模拟器或真机上可以在亚秒内重载，并且不会丢失状态。</p></li><li><p>富有表现力，漂亮的用户界面:使用Flutter内置美丽的Material Design和Cupertino（iOS风格）widget、丰富的motion API、平滑而自然的滑动效果和平台感知，为您的用户带来全新体验。</p></li><li><p>现代的，响应式框架:使用Flutter的现代、响应式框架，和一系列基础widget，轻松构建您的用户界面。使用功能强大且灵活的API（针对2D、动画、手势、效果等）解决艰难的UI挑战。</p></li></ul><h2 id="Flutter-安装教程"><a href="#Flutter-安装教程" class="headerlink" title="Flutter 安装教程"></a>Flutter 安装教程</h2><p>下载 Flutter SDK: </p><p><code>wget https://storage.googleapis.com/flutter_infra/releases/stable/linux/flutter_linux_v1.12.13+hotfix.8-stable.tar.xz</code></p><p>解压:</p><p> <code>cd ~/development</code><br> <code>tar xf ~/Downloads/flutter_linux_v1.12.13+hotfix.8-stable.tar.xz</code></p><p>如果不想安装固定版本的安装包，可以跳过步骤1和2。相反，从GitHub上的Flutter repo获取源代码，并根据需要更改分支或标记。例如：</p><p> <code>git clone https://github.com/flutter/flutter.git -b stable</code></p><p>添加Flutter 工具到你的path路径:</p><pre><code class="bash">export PUB_HOSTED_URL=https://pub.flutter-io.cnexport FLUTTER_STORAGE_BASE_URL=https://storage.flutter-io.cnexport PATH=/home/mikey/DATA/DevTools/flutter/bin:{PATH}:{PATH}:${ANDROID_HOME}/platform-tools</code></pre><p>可选地，预下载开发二进制文件:</p><p><code>lutter precache</code></p><p>运行 flutter doctor</p><p><code>flutter doctor</code></p><p>此命令检查您的环境并向终端窗口显示报告。Dart SDK与Flutter捆绑在一起，不需要单独安装Dart。仔细检查输出是否有其他需要安装的软件或要执行的其他任务。<br>例如:</p><blockquote><p>Android toolchain - develop for Android devices<br>    • Android SDK at /Users/obiwan/Library/Android/sdk<br>    ✗ Android SDK is missing command line tools; download from <a href="https://goo.gl/XxQghQ" target="_blank" rel="noopener">https://goo.gl/XxQghQ</a><br>    • Try re-installing or updating your Android SDK,<br>      visit <a href="https://flutter.dev/setup/#android-setup" target="_blank" rel="noopener">https://flutter.dev/setup/#android-setup</a> for detailed instructions.  </p></blockquote><h2 id="Android-Studio-设置"><a href="#Android-Studio-设置" class="headerlink" title="Android Studio 设置"></a>Android Studio 设置</h2><p>安装插件：</p><p>1.flutter</p><p>2.dart</p><h2 id="Flutter-简单案例"><a href="#Flutter-简单案例" class="headerlink" title="Flutter 简单案例"></a>Flutter 简单案例</h2><p><a href="https://flutterchina.club/get-started/codelab/" target="_blank" rel="noopener">编写您的第一个 Flutter App</a></p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://flutter.dev/docs" target="_blank" rel="noopener">官网文档</a></p><p><a href="https://flutter.dev/docs/get-started/install/linux" target="_blank" rel="noopener">安装教程</a></p><p><a href="https://book.flutterchina.club/" target="_blank" rel="noopener">flutter实战</a></p>]]></content>
    
    
    <categories>
      
      <category>前端</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Flutter</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Minikube 安装教程</title>
    <link href="/2020/03/25/minikube-install-tutorials/"/>
    <url>/2020/03/25/minikube-install-tutorials/</url>
    
    <content type="html"><![CDATA[<h1 id="MINIKUBE-INSTALL-TUTORIALS"><a href="#MINIKUBE-INSTALL-TUTORIALS" class="headerlink" title="MINIKUBE INSTALL TUTORIALS"></a>MINIKUBE INSTALL TUTORIALS</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul><li>Ubuntu16</li></ul><h2 id="安装-kubectl"><a href="#安装-kubectl" class="headerlink" title="安装 kubectl"></a>安装 kubectl</h2><pre><code class="text">curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.18.0/bin/linux/amd64/kubectlchmod +x ./kubectlsudo mv ./kubectl /usr/local/bin/kubectlkubectl version --client</code></pre><h2 id="安装-Minikube"><a href="#安装-Minikube" class="headerlink" title="安装 Minikube"></a>安装 Minikube</h2><pre><code class="text">curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube_1.8.0_amd64.deb &amp;&amp; sudo dpkg -i minikube_1.8.0_amd64.deb</code></pre><blockquote><p>国内可能无法访问,可以采用阿里源</p></blockquote><pre><code class="text">curl -Lo minikube https://github.com/kubernetes/minikube/releases/download/v1.8.0/minikube-linux-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/</code></pre><h2 id="配置-Hypervisor"><a href="#配置-Hypervisor" class="headerlink" title="配置 Hypervisor"></a>配置 Hypervisor</h2><p>验证您的系统是否启用了虚拟化支持：<code>egrep -q &#39;vmx|svm&#39; /proc/cpuinfo &amp;&amp; echo yes || echo no</code></p><blockquote><p>如果上述命令输出“否”：<br> 如果您在虚拟机中运行，那么您的虚拟机监控程序不允许嵌套虚拟化。你需要使用无（裸金属）驱动器<br> 如果您在物理机器上运行，请确保您的BIOS启用了硬件虚拟化</p></blockquote><h2 id="启动-Minikube"><a href="#启动-Minikube" class="headerlink" title="启动 Minikube"></a>启动 Minikube</h2><p><code>sudo minikube start --vm-driver=none --image-repository=registry.aliyuncs.com/google_containers</code></p><h2 id="所需镜像如下"><a href="#所需镜像如下" class="headerlink" title="所需镜像如下"></a>所需镜像如下</h2><blockquote><p>若无法连接谷歌可直接下载以下镜像（要对应版本）</p></blockquote><pre><code class="text">docker pull registry.aliyuncs.com/google_containers/kube-proxy:v1.17.3docker pull registry.aliyuncs.com/google_containers/kube-controller-manager:v1.17.3docker pull registry.aliyuncs.com/google_containers/kube-apiserver:v1.17.3docker pull registry.aliyuncs.com/google_containers/kube-scheduler:v1.17.3docker pull registry.aliyuncs.com/google_containers/coredns:1.6.5docker pull registry.aliyuncs.com/google_containers/etcd:3.4.3-0docker pull registry.aliyuncs.com/google_containers/pause:3.1docker pull registry.aliyuncs.com/google_containers/storage-provisioner:v1.8.1</code></pre><h2 id="Kubernetes-可视化界面"><a href="#Kubernetes-可视化界面" class="headerlink" title="Kubernetes 可视化界面"></a>Kubernetes 可视化界面</h2><p><code>minikube dashboard</code></p><p>访问控制台的连接即可</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://github.com/AliyunContainerService/minikube" target="_blank" rel="noopener">Github代码库</a><br><a href="https://yq.aliyun.com/articles/221687" target="_blank" rel="noopener">参考博文</a><br><a href="https://minikube.sigs.k8s.io/docs/start/" target="_blank" rel="noopener">官方文档</a></p>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K8s 安装教程</title>
    <link href="/2020/03/21/k8s-install-tutorials/"/>
    <url>/2020/03/21/k8s-install-tutorials/</url>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes-安装-kubeadm"><a href="#Kubernetes-安装-kubeadm" class="headerlink" title="Kubernetes 安装 kubeadm"></a>Kubernetes 安装 kubeadm</h1><ul><li>1 事先准备</li><li>2 检查所需端口</li><li>2.1 Master节点</li><li>2.2 工作节点</li><li>3 Docker 安装</li><li>4 kubectl 安装</li><li>5 kubelet和kubeadm 安装</li></ul><h1 id="事先准备"><a href="#事先准备" class="headerlink" title="事先准备"></a>事先准备</h1><ul><li>多台Ubuntu 16.04+、CentOS 7或HypriotOS v1.0.1 + 系统  </li><li>每台机器最少1GB+内存  </li><li>集群中所有机器之间网络连接正常  </li><li>每个节点有唯一MAC地址和product_uuid  </li><li>打开某些端口。请参阅以下部分  </li></ul><h1 id="检查所需端口"><a href="#检查所需端口" class="headerlink" title="检查所需端口"></a>检查所需端口</h1><h2 id="Master节点"><a href="#Master节点" class="headerlink" title="Master节点"></a>Master节点</h2><table><tr><th>端口范围</th><th>用途</th></tr><tr><td>6443 *</td><td>    Kubernetes API server</td></tr><tr><td>2379-2380</td><td>    etcd server client API</td></tr><tr><td>10250</td><td>    Kubelet API</td></tr><tr><td>10251</td><td>    kube-scheduler</td></tr><tr><td>10252</td><td>    kube-controller-manager</td></tr><tr><td>10255</td><td>Read-only Kubelet API (Heapster)</td></tr></table><h2 id="工作节点"><a href="#工作节点" class="headerlink" title="工作节点"></a>工作节点</h2><table><tr><th>端口范围</th><th>用途</th></tr><tr><td>10250</td><td>Kubelet API</td></tr><tr><td>2379-2380</td><td>Read-only Kubelet API (Heapster)</td></tr><tr><td>30000-32767</td><td>NodePort Services默认端口范围。</td></tr></table><h1 id="Docker-安装"><a href="#Docker-安装" class="headerlink" title="Docker 安装"></a>Docker 安装</h1><p>在机器安装Docker，推荐使用1.12 版本（v1.10和v1.11也可以正常使用），1.13和17.03+版本未经过Kubernetes团队的测试和验证。有关安装说明，请参阅Docker官方文档 Docker安装。</p><h1 id="kubectl-安装"><a href="#kubectl-安装" class="headerlink" title="kubectl 安装"></a>kubectl 安装</h1><p>在所有机器上安装kubectl，可参考： kubectl安装。</p><h1 id="kubelet和kubeadm-安装"><a href="#kubelet和kubeadm-安装" class="headerlink" title="kubelet和kubeadm 安装"></a>kubelet和kubeadm 安装</h1><p>在所有机器上安装以下软件包：</p><ul><li>kubelet</li><li>kubeadm</li></ul><p>注意：如果机器上已经安装了kubeadm，则应需要apt-get update &amp;&amp; apt-get upgrade或者yum update获得最新版本的kubeadm。如果想了解不同版本的kubeadm，请参考</p><p>配置机器：</p><p>SSH登录主机。<br>如果使用的是Ubuntu或HypriotOS，请运行：</p><pre><code class="text">apt-get update &amp;&amp; apt-get install -y apt-transport-httpscurl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.listdeb http://apt.kubernetes.io/ kubernetes-xenial mainEOFapt-get updateapt-get install -y kubelet kubeadm</code></pre><p>如果使用的是CentOS，请运行：</p><p><code>cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</code></p><pre><code class="text">[kubernetes]name=Kubernetesbaseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64enabled=1gpgcheck=1repo_gpgcheck=1gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg        https://packages.cloud.google.com/yum/doc/rpm-package-key.gpgEOFsetenforce 0yum install -y kubelet kubeadmsystemctl enable kubelet &amp;&amp; systemctl start kubelet</code></pre><p>执行完后，kubelet会进入每隔几秒重新启动一次的循环模式，因为kubelet在等待kubeadm发出的命令。</p><p>注意：必须使用运行setenforce 0命令来禁用SELinux，因为需要允许容器访问主机文件系统，这是配置pod网络所要求的。（直到kubelet中对SELinux支持得到改进）</p><p>接下来使用kubeadm创建一个集群</p>]]></content>
    
    
    <categories>
      
      <category>DevOps</category>
      
    </categories>
    
    
    <tags>
      
      <tag>k8s</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Knife4j 快速使用</title>
    <link href="/2020/03/21/Knife4j-Tutorials/"/>
    <url>/2020/03/21/Knife4j-Tutorials/</url>
    
    <content type="html"><![CDATA[<h2 id="knife4j简介"><a href="#knife4j简介" class="headerlink" title="knife4j简介"></a>knife4j简介</h2><p>前身:swagger-bootstrap-ui</p><h3 id="swagger简介"><a href="#swagger简介" class="headerlink" title="swagger简介"></a>swagger简介</h3><blockquote><p>Swagger是一个API接口管理工具，支持在线测试接口数据，根据配置自动生成API文档，结合spring mvc而提供界面化方法文档的一个开源框架。</p></blockquote><p>Swagger主要的项目<br>Swagger是一组开源项目，主要项目如下：</p><ul><li>Swagger-tools:提供各种与Swagger进行集成和交互的工具。例如模式检验、Swagger 1.2文档转换成Swagger 2.0文档等功能。</li><li>Swagger-core: 用于Java/Scala的的Swagger实现。与JAX-RS(Jersey、Resteasy、CXF…)、Servlets和Play框架进行集成。</li><li>Swagger-js: 用于JavaScript的Swagger实现。</li><li>Swagger-node-express: Swagger模块，用于node.js的Express web应用框架。</li><li>Swagger-ui：一个无依赖的HTML、JS和CSS集合，可以为Swagger兼容API动态生成优雅文档。</li><li>Swagger-codegen：一个模板驱动引擎，通过分析用户Swagger资源声明以各种语言生成客户端代码。</li><li>Swagger-editor：可让使用者在浏览器里以YAML格式编辑Swagger API规范并实时预览文档。可以生成有效的Swagger JSON描述，并用于所有Swagger工具（代码生成、文档等等）中。</li></ul><h3 id="Swagger-Bootstrap-UI简介"><a href="#Swagger-Bootstrap-UI简介" class="headerlink" title="Swagger-Bootstrap-UI简介"></a>Swagger-Bootstrap-UI简介</h3><blockquote><p>Swagger-Bootstrap-UI是springfox-swagger的增强UI实现，为Java开发者在使用Swagger的时候，能拥有一份简洁、强大的接口文档体验。</p></blockquote><h2 id="knife4j特点"><a href="#knife4j特点" class="headerlink" title="knife4j特点"></a>knife4j特点</h2><p>文档说明：根据Swagger的规范说明，详细列出接口文档的说明，包括接口地址、类型、请求示例、请求参数、响应示例、响应参数、响应码等信息，使用swagger-bootstrap-ui能根据该文档说明，对该接口的使用情况一目了然。</p><p>在线调试：提供在线接口联调的强大功能，自动解析当前接口参数,同时包含表单验证，调用参数可返回接口响应内容、headers、Curl请求命令实例、响应时间、响应状态码等信息，帮助开发者在线调试，而不必通过其他测试工具测试接口是否正确,简介、强大。</p><h2 id="knife4j使用"><a href="#knife4j使用" class="headerlink" title="knife4j使用"></a>knife4j使用</h2><p>1.创建springboot项目</p><p>2.添加依赖</p><pre><code class="text">&lt;dependencies&gt;    &lt;dependency&gt;        &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt;        &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt;        &lt;!--在引用时请在maven中央仓库搜索最新版本号--&gt;        &lt;version&gt;2.0.2&lt;/version&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;</code></pre><p>3.配置类</p><pre><code class="java">@Configuration@EnableSwagger2@EnableKnife4j@Import(BeanValidatorPluginsConfiguration.class)public class SwaggerConfiguration {    @Bean(value = &quot;defaultApi2&quot;)    public Docket defaultApi2() {        Docket docket=new Docket(DocumentationType.SWAGGER_2)                .apiInfo(apiInfo())                //分组名称                .groupName(&quot;2.X版本&quot;)                .select()                //这里指定Controller扫描包路径                .apis(RequestHandlerSelectors.basePackage(&quot;com.swagger.bootstrap.ui.demo.new2&quot;))                .paths(PathSelectors.any())                .build();        return docket;    }　　private ApiInfo apiInfo() {   　　 return new ApiInfoBuilder()      　　  .title(&quot;大学生专业学科竞赛项目过程管理系统&quot;)        　　.description(&quot;大学生专业学科竞赛项目过程管理系统t文档&quot;)        　　.termsOfServiceUrl(&quot;&quot;)        　　.version(&quot;3.0.0&quot;)        　　.build();　　}}</code></pre><p>注解说明</p><p><code>@EnableSwagger2</code></p><p>该注解是Springfox-swagger框架提供的使用Swagger注解，该注解必须加</p><p><code>@EnableKnife4j</code></p><p>该注解是knife4j提供的增强注解,Ui提供了例如动态参数、参数过滤、接口排序等增强功能,如果你想使用这些增强功能就必须加该注解，否则可以不用加</p><p>4.访问</p><p>在浏览器输入地址：<code>http://[you_host]:[you_port]/doc.html</code></p><p> <img src="/resource/img/knife4j-1.jpg" srcset="/img/loading.gif" alt="avatar"></p><h2 id="knife4j资料"><a href="#knife4j资料" class="headerlink" title="knife4j资料"></a>knife4j资料</h2><p><a href="https://doc.xiaominfo.com/guide/useful.html" target="_blank" rel="noopener">文档</a></p><p><a href="https://gitee.com/xiaoym/swagger-bootstrap-ui-demo" target="_blank" rel="noopener">示例</a></p><p><a href="https://www.cnblogs.com/fby698/p/11581845.html" target="_blank" rel="noopener">博文</a></p>]]></content>
    
    
    <categories>
      
      <category>开发组件</category>
      
    </categories>
    
    
    <tags>
      
      <tag>接口文档</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Caliper 性能测试工具配置</title>
    <link href="/2020/03/20/Hyperledger-Caliper-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/"/>
    <url>/2020/03/20/Hyperledger-Caliper-%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="Caliper性能测试工具配置"><a href="#Caliper性能测试工具配置" class="headerlink" title="Caliper性能测试工具配置"></a>Caliper性能测试工具配置</h1><p>基本上都是根据官方doc进行操作，个别部分有坑。</p><p><a href="https://hyperledger.github.io/caliper/docs/1_Getting_Started.html" target="_blank" rel="noopener">官方doc</a></p><p>提前安装</p><blockquote><p>nodejs、node-gyp、docker、docker-compose</p></blockquote><h2 id="代码下载"><a href="#代码下载" class="headerlink" title="代码下载"></a>代码下载</h2><p><code>git clone https://github.com/hyperledger/caliper.git</code></p><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>进入caliper代码根目录，执行以下命令：<br><code>npm install</code><br><code>npm run repoclean</code><br><code>npm run bootstrap</code></p><h2 id="安装caliper"><a href="#安装caliper" class="headerlink" title="安装caliper"></a>安装caliper</h2><p>根据官网步骤进行安装。</p><p><a href="https://github.com/hyperledger/caliper/blob/master/packages/caliper-tests-integration/README.md" target="_blank" rel="noopener">安装步骤</a><br><code>cd ./packages/caliper-tests-integration</code></p><h4 id="开启Verdaccio"><a href="#开启Verdaccio" class="headerlink" title="开启Verdaccio"></a>开启Verdaccio</h4><p><code>npm run start_verdaccio</code></p><p>成功界面：<br><img src="/resource/img/Picture1.png" srcset="/img/loading.gif" alt="avatar"></p><h4 id="发布包"><a href="#发布包" class="headerlink" title="发布包"></a>发布包</h4><p><code>npm run publish_packages</code></p><h4 id="安装caliper-1"><a href="#安装caliper-1" class="headerlink" title="安装caliper"></a>安装caliper</h4><p><code>npm run install_cli</code></p><p>成功界面：<br><img src="/resource/img/Picture2.png" srcset="/img/loading.gif" alt="avatar"></p><h5 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h5><p>1.3.3.1.1.无权限<br>报错：gyp stack Error: EACCES: permission denied, mkdir ‘/usr/local/lib/node_modules/caliper…<br>原因：用户没有/usr/local/lib/node_modules/文件夹的写权限<br>解决方法：<br>（1）官方文档方法：修改npm的安装目录为一个本地用户有权限的目录，命令：<code>npm config set prefix ~/youdir</code>，修改后caliper会安装到此目录。<br>（2）我的方法：不想修改npm安装目录，并且我在root用户下进行的操作，怀疑安装过程中切换了用户。所以我修改了caliper安装命令，添加<code>--unsafe-perm</code>参数，避免用户切换。<br>修改文件：<code>packages/caliper-tests-integration/scripts/npm_install.js</code>第<code>65</code>行  </p><p>修改结果：  </p><p><img src="/resource/img/Picture3.png" srcset="/img/loading.gif" alt="avatar"></p><p>修改完后重新执行 <code>npm run install_cli</code>  </p><p>1.3.3.1.2.卡在<code>node-pre-gyp</code>命令</p><p>若一直卡在如下界面，重新执行<code>npm run install_cli</code>。百度说要vpn，我没有vpn，重新执行命令一样ok。  </p><p><img src="/resource/img/Picture4.png" srcset="/img/loading.gif" alt="avatar"></p><p>1.3.4.验证安装结果执行<code>caliper -v</code>，出现如下结果即安装成功</p><p><img src="/resource/img/Picture5.png" srcset="/img/loading.gif" alt="avatar"></p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>运行caliper提供的fabric1.4的sample。<br><code>cd packages/caliper-samples</code><br><code>caliper benchmark run -w ./ -c benchmark/simple/config.yaml -n network/fabric-v1.4/2org1peergoleveldb/fabric-ccp-go.yaml --caliper-core-skipendscript</code>  </p><p>成功界面：</p><p><img src="/resource/img/Picture6.png" srcset="/img/loading.gif" alt="avatar"></p><p><code>caliper-core-skipendscript</code>加上此参数，caliper执行完会跳过下图配置文件fabric-ccp-go.yaml的end的命令，不关闭fabric环境，这样有助于查看日志。不想保留fabric环境可不加此参数。</p><p><img src="/resource/img/Picture7.png" srcset="/img/loading.gif" alt="avatar"></p><p>Caliper运行日志记录在-w命令指定目录下的log目录中。</p><h2 id="官网的坑"><a href="#官网的坑" class="headerlink" title="官网的坑"></a>官网的坑</h2><p>1.5.1.千万不要执行<code>npm run cleanup</code></p><p><img src="/resource/img/Picture8.png" srcset="/img/loading.gif" alt="avatar"></p><p><code>npm run cleanup</code>执行过程中会删除安装的caliper，执行完此命令，在执行caliper -v会提示找不到命令。</p><p>1.5.2.不能执行One-step install</p><p><img src="/resource/img/Picture9.png" srcset="/img/loading.gif" alt="avatar"></p><p>官网One-step install如下：</p><p>One-step install也包含了npm run cleanup命令。所以安装完你依旧会看到如下界面：</p><p><img src="/resource/img/Picture10.png" srcset="/img/loading.gif" alt="avatar"></p><p>还是不要偷懒使用一步安装了。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="https://github.com/hyperledger/caliper" target="_blank" rel="noopener">https://github.com/hyperledger/caliper</a><br><a href="https://hyperledger.github.io/caliper/docs/1_Getting_Started.html" target="_blank" rel="noopener">https://hyperledger.github.io/caliper/docs/1_Getting_Started.html</a><br><a href="https://github.com/hyperledger/caliper/blob/master/packages/caliper-tests-integration/README.md" target="_blank" rel="noopener">https://github.com/hyperledger/caliper/blob/master/packages/caliper-tests-integration/README.md</a>  </p>]]></content>
    
    
    <categories>
      
      <category>Hyperledger</category>
      
    </categories>
    
    
    <tags>
      
      <tag>区块链</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Iroha</title>
    <link href="/2020/03/18/Hyperledger-Iroha/"/>
    <url>/2020/03/18/Hyperledger-Iroha/</url>
    
    <content type="html"><![CDATA[<h1 id="Hyperledger-Iroha-简介"><a href="#Hyperledger-Iroha-简介" class="headerlink" title="Hyperledger Iroha 简介"></a>Hyperledger Iroha 简介</h1><h2 id="1-1。Iroha的主要特征是什么？"><a href="#1-1。Iroha的主要特征是什么？" class="headerlink" title="1.1。Iroha的主要特征是什么？"></a>1.1。Iroha的主要特征是什么？</h2><ul><li>简单的部署和维护</li><li>面向开发人员的各种库</li><li>基于角色的访问控制</li><li>化设计，由命令-查询分离原理驱动</li><li>和身份管理  </li></ul><p>在我们的质量模型中，我们专注于并不断改进：</p><ul><li>性（容错性，可恢复性）</li><li>效率（尤其是时间行为和资源利用）</li><li>性（易学性，用户错误保护，适当性可识别性）</li></ul><h2 id="在哪里可以使用Iroha？"><a href="#在哪里可以使用Iroha？" class="headerlink" title="在哪里可以使用Iroha？"></a>在哪里可以使用Iroha？</h2><p>Hyperledger Iroha是通用许可的区块链系统，可用于管理数字资产，身份和序列化数据。这对于银行间结算，中央银行数字货币，支付系统，国家ID和物流等应用可能很有用。</p><p>有关详细说明，请检查我们的用例场景部分。</p><p>1.3。它与比特币或以太坊有何不同？<br>比特币和以太坊被设计为无人允许的分类帐，任何人都可以加入并访问所有数据。它们还具有与系统交互所需的本机加密货币。</p><p>在Iroha中，没有本机加密货币。相反，为了满足企业的需求，允许进行系统交互，这意味着只有具有必需访问权限的人才能与系统交互。此外，还允许查询，以便可以控制对所有数据的访问。</p><p>与以太坊的主要区别尤其在于，Hyperledger Iroha允许用户通过使用系统中的预构建命令来执行常见功能，例如创建和传输数字资产。这就消除了编写繁琐且难以测试的智能合约的需要，从而使开发人员能够更快，风险更低地完成简单的任务。</p><p>1.4。它与其他Hyperledger框架或其他许可的区块链有何不同？<br>Iroha具有一种新颖的，具有Crash容错能力的共识算法（称为YAC [1]），该算法具有很高的性能，并允许以低延迟完成事务。</p><p>此外，与其他平台相比，Iroha的内置命令是一个主要优点，因为执行诸如创建数字资产，注册帐户以及在帐户之间转移资产之类的常见任务非常简单。此外，由于故障少，它缩小了攻击媒介，提高了系统的整体安全性。</p><p>最后，Iroha是唯一具有强大权限系统的分类帐，允许为所有命令，查询和网络加入设置权限。</p><p>[1]    另一个共识<br>1.5。如何围绕Iroha创建应用程序？<br>为了将区块链的功能带入您的应用程序，您应该首先考虑它如何与Iroha同行进行接口。一个好的开始是检查“ 概念和体系结构”部分，解释什么是事务和查询，以及应用程序的用户应该如何与之交互。</p><p>我们也有几个客户端库，这些库为开发人员提供了形成构建块的工具，例如签名，命令，向Iroha对等方发送消息并检查状态。</p><p>Hyperledger Iroha 核心概念<br>Why Iroha runs in a network? How to understand the objects inside and outside the system? How peers in the network collaborate and decide which data to put into the blockchain? We will look through the basics of Iroha in this section.</p><ul><li>2.1.1. Account</li><li>2.1.2. Asset</li><li>2.1.3. Block</li><li>2.1.4. Client</li><li>2.1.5. Command</li><li>2.1.6. Consensus</li><li>2.1.7. Domain</li><li>2.1.8. Peer</li><li>2.1.9. Permission</li><li>2.1.10. Proposal</li><li>2.1.11. Query</li><li>2.1.12. Quorum</li><li>2.1.13. Role</li><li>2.1.14. Signatory</li><li>2.1.15. Transaction</li><li>2.1.16. Batch of Transactions</li><li>2.1.17. Multisignature Transactions</li><li>2.1.18. Validation</li><li>2.1.19. Entity-relationship model</li></ul><h1 id="Hyperledger-Iroha-内部组成"><a href="#Hyperledger-Iroha-内部组成" class="headerlink" title="Hyperledger Iroha 内部组成"></a>Hyperledger Iroha 内部组成</h1><p>HL Iroha网络由几个基本组件组成，这些组件提供节点之间的通信。您可以在下面了解它们。</p><h1 id="Iroha体系结构图"><a href="#Iroha体系结构图" class="headerlink" title="Iroha体系结构图"></a>Iroha体系结构图</h1><p>2.2.1。Torii<br>客户的切入点。使用gRPC作为传输。为了与Iroha进行交互，任何人都可以使用gRPC端点（如“ 命令和查询”部分中所述）或使用客户端库。</p><p>2.2.2。MST处理器<br>多签名交易处理器</p><p>这是一项内部gRPC服务，可通过Gossip协议发送和接收来自其他对等方的消息。它的任务是发出尚未收到足够签名以达到法定人数的多重签名交易。</p><p>2.2.3。对等通信服务<br>Iroha的内部组件- 通过MstProcessor将交易从Torii 传输到Ordering Gate的中介。PCS的主要目标是隐藏与共识实现交互的复杂性。</p><p>2.2.4。订购门<br>它是内部Iroha组件（gRPC客户端），可将事务从对等通信服务中继到订购服务。Ordering Gate 从Ordering Service 接收提案（链中的潜在模块），并将其发送到Simulator进行状态验证。它还根据共识回合要求订购服务提供建议。</p><p>2.2.5。订购服务<br>内部Iroha组件（gRPC服务器），该组件从其他对等方接收消息，并将已通过无状态验证传递的多个交易合并到投标中。每个节点都有其自己的订购服务。提案创建可以由以下事件之一触发：</p><p>专用于交易收集的期限已到期。<br>订购服务已收到单个提案允许的最大交易量。<br>这两个参数（超时和建议的最大大小）都是可配置的（请检查特定于环境的参数页面）。</p><p>这两个触发器的共同先决条件是至少一项交易应到达订购服务。否则，将不会形成任何建议。</p><p>订购服务还对提案进行初步验证（例如，从提案中清除无状态拒绝的交易）。</p><p>2.2.6。经过验证的提案创建者<br>内部Iroha组件，对订购服务收到的投标中包含的交易执行状态验证。基于已通过状态验证的事务，将创建经过验证的提议并将其传递给Block Creator。所有未通过状态验证的交易都将被删除，并且不包含在已验证的投标中。</p><p>2.2.7。块造物主<br>系统组件，它通过一系列已通过无状态和有状态验证的事务构成块，以便进一步传播到共识。</p><p>区块创建者与“ 验证提议创建者”一起构成了一个名为Simulator的组件。</p><p>2.2.8。区块共识（YAC）<br>共识，作为一个组成部分</p><p>共识是区块链的核心-它在对等网络中的对等之间保持一致的状态。Iroha使用自己的共识算法，称为“另一个共识”（又名YAC）。</p><p>您可以在此处观看视频，其中对共识和YAC的原理进行了详尽的解释。</p><p>YAC算法的显着特征是它的可伸缩性，性能和崩溃容错能力。</p><p>为了确保网络的一致性，如果缺少块，将通过Synchronizer从另一个对等方下载它们。提交的块存储在Ametsuchi块存储中。</p><p>有关共识的一般定义，请检查此链接。</p><p>2.2.9。同步器<br>是共识的一部分。将缺失的块添加到对等方的链中（从其他对等方下载它们以保持一致性）。</p><p>2.2.10。Ametsuchi Blockstore<br>Iroha存储组件，用于存储块和从块生成的状态，称为World State View。有没有办法让客户端直接与Ametsuchi互动。</p><p>2.2.11。世界状态视图<br>WSV反映了系统的当前状态，可以视为快照。例如，WSV保留有关帐户当前拥有的资产数量的信息 ，但不包含任何交易流的信息历史记录。 </p><h1 id="Hyperledger-Iroha-快速入门"><a href="#Hyperledger-Iroha-快速入门" class="headerlink" title="Hyperledger Iroha 快速入门"></a>Hyperledger Iroha 快速入门</h1><p>在本指南中，我们将创建一个非常基本的Iroha网络，启动它，创建几个事务，并检查写入分类帐中的数据。为简单起见，我们将使用Docker。</p><p>注意</p><p>Ledger是区块链的代名词，Hyperledger Iroha也被称为分布式Ledger技术框架-本质上与“区块链框架”相同。您可以检查“ 核心概念”部分中使用的其余术语。</p><p>3.1。前提条件<br>对于本指南，您需要一台Docker已安装的机器。您可以阅读如何在Docker网站上安装它。</p><p>注意</p><p>当然，您可以从头开始构建Iroha，修改其代码并启动自定义节点！如果您想知道如何做–您可以查看Building Iroha部分。在本指南中，我们将使用Iroha的标准发行版作为docker映像。</p><p>3.2。启动Iroha </p><p>3.2.1。创建一个Docker网络<br>要进行操作，Iroha需要一个PostgreSQL数据库。让我们从创建Docker网络开始，以便Postgres和Iroha的容器可以在同一虚拟网络上运行并成功通信。在本指南中，我们将其称为iroha-network，但您可以使用任何名称。在您的终端中输入以下命令：</p><p>泊坞窗网络创建iroha-network<br>3.2.2。启动PostgreSQL容器<br>现在，我们需要PostgreSQL在容器中运行，将其附加到之前创建的网络，并公开用于通信的端口：</p><pre><code>docker--name some-postgres\ -e POSTGRES_USER = postgres\ -e POSTGRES_PASSWORD = mysecretpassword \ -p 5432：5432 \ --network =iroha-network\ -d postgres：9.5 \ -c &#39;max_prepared_transactions = 100&#39;</code></pre><p>注意</p><p>如果已经在主机系统上的默认端口（5432）上运行了Postgres，则应选择另一个将被占用的空闲端口。例如5433：-p 5433:5432</p><p>3.2.3。创建Blockstore<br>在运行Iroha容器之前，我们可能会创建一个持久卷来存储文件，并为该链存储块。通过以下命令完成：</p><p>码头工人卷创建块存储<br>3.2.4。准备配置文件<br>注意</p><p>为简单起见，在本指南中，我们将创建一个仅包含单个节点的网络。要了解如何运行多个对等节点，请遵循部署</p><p>现在，我们需要配置Iroha网络。这包括创建配置文件，为用户生成密钥对，编写对等方列表以及创建创世块。</p><p>不要害怕-我们已经为本指南准备了一个示例配置，因此您可以立即开始测试Iroha节点。为了获取这些文件，您需要 从Github 克隆Iroha存储库或手动复制它们（不过克隆速度更快）。</p><p><code>git clone -b master https://github.com/hyperledger/iroha --depth = 1</code></p><p>暗示</p><p>–depth=1选项允许我们仅下载最新的提交并节省一些时间和带宽。如果要获取完整的提交历史记录，则可以忽略此选项。</p><p>关于如何设置参数以及如何根据您的环境和负载期望对其进行调整的指南：配置。目前我们不需要这样做。</p><p>3.2.5。启动Iroha容器<br>我们几乎准备启动我们的Iroha集装箱。您只需要知道配置文件的路径（从上述步骤开始）。</p><p>让我们使用以下命令在Docker容器中启动Iroha节点：</p><pre><code>docker run --name iroha \ -d \ -p 50051：50051 \ -v $ { pwd ） / iroha / example：/ opt / iroha_data \ -v blockstore：/ tmp / block_store \ --network = iroha-network \ - e KEY = &#39;node0&#39;  \hyperledger / iroha：latest</code></pre><p>如果成功启动节点，您将在启动容器的同一控制台中看到容器ID。</p><p>让我们详细了解一下此命令的作用：</p><pre><code>docker run --name iroha \ 创建一个容器 iroha-d \ 在后台运行容器-p 50051:50051 \ 公开用于与客户端通信的端口（我们将在以后使用）-v YOUR_PATH_TO_CONF_FILES:/opt/iroha_data \这就是我们如何将配置文件传递到docker容器的方法。示例目录在上面的代码块中指示。-v blockstore:/tmp/block_store \ 将持久性块存储（Docker卷）添加到容器中，以便在我们停止容器后不会丢失块--network=iroha-network \将我们的容器添加到先前创建的iroha-network 用于与PostgreSQL服务器通信的容器-e KEY=&#39;node0&#39; \-在此请指出一个密钥名称，该名称将标识允许其确认操作的节点。密钥应与上述配置文件一起放在目录中。hyperledger/iroha:latest是指向最新版本的图像的引用</code></pre><p>您可以通过运行查看日志。docker logs iroha</p><p>您可以尝试使用示例指南之一，以便将一些事务发送到Iroha并查询其状态。</p><h3 id="3-3。尝试其他指南"><a href="#3-3。尝试其他指南" class="headerlink" title="3.3。尝试其他指南"></a>3.3。尝试其他指南</h3><p>3.3.1。CLI指南：发送您的第一笔交易和查询<br>3.3.1.1。创建第一笔交易<br>3.3.1.2。创建第一个查询<br>3.3.1.3。成为坏蛋<br>3.3.2。使用Python库发送交易<br>3.3.2.1。先决条件<br>3.3.2.2。运行示例交易<br>3.3.2.3。定义命令<br>3.3.2.4。运行命令<br>Hyperledger 综合项目<br>Hyperledger联盟的想法之一是创建可以一起工作以提供最佳区块链体验的解决方案。在Iroha中，我们相信其他出色的Hyperledger工具和解决方案的集成是使Iroha更好地适合您的用例的一种方式。因此，我们致力于与多个项目的集成，并希望向您详细介绍Iroha可以与之合作的内容。</p><h3 id="4-1。Hyperledger-Ursa"><a href="#4-1。Hyperledger-Ursa" class="headerlink" title="4.1。Hyperledger Ursa"></a>4.1。Hyperledger Ursa</h3><p>Hyperledger Ursa是一个共享的密码库，使人们（和项目）可以避免重复其他密码工作，并希望在此过程中提高安全性。该库将是供项目（以及可能还有其他项目）放置和使用加密货币的可选存储库。Hyperledger Ursa由子项目组成，这些子项目是密码代码或密码代码接口的内聚实现。</p><p>通过在构建过程中仅添加一个标志，可以轻松地使用Ursa库构建Iroha 。它将允许您使用Ursa库中的加密算法代替标准的Iroha加密技术。随着Ursa中新图书馆的发展，将为您提供越来越多的选择！</p><h3 id="4-2。Hyperledger-Explorer"><a href="#4-2。Hyperledger-Explorer" class="headerlink" title="4.2。Hyperledger Explorer"></a>4.2。Hyperledger Explorer</h3><p>Hyperledger Explorer是一个区块链模块，是The Linux Foundation托管的Hyperledger项目之一。Hyperledger Explorer旨在创建一个用户友好的Web应用程序，可以查看，调用，部署或查询块，事务和相关数据，网络信息（名称，状态，节点列表），链代码和事务族，以及任何其他相关信息存储在分类帐中。</p><p>在这里，您可以了解如何将Explorer与Iroha结合使用。</p><h3 id="4-3。Hyperledger-Burrow"><a href="#4-3。Hyperledger-Burrow" class="headerlink" title="4.3。Hyperledger Burrow"></a>4.3。Hyperledger Burrow</h3><p>Hyperledger Burrow为模块化区块链客户端提供了一个经过许可的智能合约解释器，该解释器部分已按照以太坊虚拟机（EVM）的规范进行开发。</p><p>我们将很快准备有关如何使用Iroha中集成的Burrow的说明。</p><h1 id="绑定-Iroha"><a href="#绑定-Iroha" class="headerlink" title="绑定 Iroha"></a>绑定 Iroha</h1><p>In this guide we will learn how to install all dependencies, required to build Iroha and how to actually build it.</p><p>There will be 3 steps:</p><p>1.Installing environment prerequisites<br>2.Installing Iroha dependencies (will be performed automatically for Docker)<br>3.Building Iroha  </p><p>Note</p><p>You don’t need to build Iroha to start using it. Instead, you can download prepared Docker image from the Hub, this process explained in details in the Quick Start Guide page of this documentation.</p><p>5.1. Prerequisites<br>In order to successfully build Iroha, we need to configure the environment. There are several ways to do it and we will describe all of them.</p><p>Currently, we support Unix-like systems (we are basically targeting popular Linux distros and MacOS). If you happen to have Windows or you don’t want to spend time installing all dependencies you might want to consider using Docker environment. Also, Windows users might consider using WSL</p><p>Technically Iroha can be built under Windows natively in experimental mode. This guide covers that way too. All the stages related to native Windows build are separated from the main flow due to its significant differences.</p><p>Please choose your preferred platform below for a quick access:</p><ul><li>docker</li><li>linux</li><li>macOS</li><li>windows</li><li>Hint</li></ul><p>Having troubles? Check FAQ section or communicate to us directly, in case you were stuck on something. We don’t expect this to happen, but some issues with an environment are possible.</p><p>5.1.1. Docker<br>First of all, you need to install docker and docker-compose. You can read how to install it on the Docker’s website</p><p>Note</p><p>Please, use the latest available docker daemon and docker-compose.</p><p>Then you should clone the Iroha repository to the directory of your choice:</p><p><code>git clone -b master https://github.com/hyperledger/iroha --depth=1</code></p><p>Hint</p><p>–depth=1 option allows us to download only latest commit and save some time and bandwidth. If you want to get a full commit history, you can omit this option.</p><p>When it is done, you need to run the development environment. Run the scripts/run-iroha-dev.sh script:</p><p>bash scripts/run-iroha-dev.sh<br>Hint</p><p>Please make sure that Docker is running before executing the script. MacOS users could find a Docker icon in system tray, Linux users can use systemctl start docker</p><p>After you execute this script, the following things will happen:</p><p>The script will check whether you have containers with Iroha already running. Successful completion finishes with the new container shell.<br>The script will download hyperledger/iroha:develop-build and postgres images. hyperledger/iroha:develop-build image contains all development dependencies and is based on top of ubuntu:18.04. postgres image is required for starting and running Iroha.<br>Two containers are created and launched.<br>The user is attached to the interactive environment for development and testing with iroha folder mounted from the host machine. Iroha folder is mounted to /opt/iroha in Docker container.<br>Now your are ready to build Iroha! Please go directly to Building Iroha section.</p><p>5.1.2. Linux<br>To build Iroha, you will need the following packages:</p><p>build-essential git ca-certificates tar ninja-build curl unzip cmake</p><p>Use this code to install environment dependencies on Debian-based Linux distro.</p><pre><code>apt-get update; \apt-get -y --no-install-recommends install \build-essential ninja-build \git ca-certificates tar curl unzip cmake</code></pre><p>Note</p><p>If you are willing to actively develop Iroha and to build shared libraries, please consider installing the latest release of CMake.</p><p>Now you are ready to install Iroha dependencies.</p><p>5.1.3. MacOS<br>If you want to build Iroha from scratch and actively develop it, please use the following code to install all environment dependencies with Homebrew:</p><p><code>xcode-select --install</code><br><code>brew install cmake ninja git gcc@7</code></p><p>Hint</p><p>To install the Homebrew itself please run</p><p><code>ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/homebrew/install/master/install)&quot;</code></p><p>Now you are ready to install Iroha dependencies.</p><p>5.1.4. Windows<br>Note</p><p>All the listed commands are designed for building 64-bit version of Iroha.</p><p>5.1.4.1. Chocolatey Package Manager<br>First of all you need Chocolatey package manager installed. Please refer the guide for chocolatey installation.</p><p>5.1.4.2. Building the Toolset<br>Install CMake, Git, Microsoft compilers via chocolatey being in Administrative mode of command prompt:</p><p>choco install cmake git visualstudio2019-workload-vctools ninja<br>PostgreSQL is not a build dependency, but it is recommended to install it now for the testing later:</p><p>choco install postgresql<br>Don’t forget the password you set!<br>Now you are ready to install Iroha dependencies.</p><p>5.2. Installing dependencies with Vcpkg Dependency Manager<br>Currently we use Vcpkg as a dependency manager for all platforms - Linux, Windows and MacOS. We use a fixed version of Vcpkg to ensure the patches we need will work.</p><p>That stable version can only be found inside the Iroha repository, so we will need to clone Iroha. The whole process is pretty similar for all platforms but the exact commands are slightly different.</p><p>5.2.1. Linux and MacOS<br>Run in terminal:</p><p><code>git clone https://github.com/hyperledger/iroha.git</code><br><code>iroha/vcpkg/build_iroha_deps.sh</code><br><code>vcpkg/vcpkg integrate install</code></p><p>After the installation of vcpkg you will be provided with a CMake build parameter like -DCMAKE_TOOLCHAIN_FILE=/path/to/vcpkg/scripts/buildsystems/vcpkg.cmake. Save it somewhere for later use and move to Building Iroha section.</p><p>5.2.2. Windows<br>Execute from Power Shell:</p><p><code>git clone https://github.com/hyperledger/iroha.git</code><br><code>powershell -ExecutionPolicy ByPass -File .\iroha\.packer\win\scripts\vcpkg.ps1 .\vcpkg .\iroha\vcpkg</code></p><p>After the installation of vcpkg you will be provided with a CMake build parameter like -DCMAKE_TOOLCHAIN_FILE=C:/path/to/vcpkg/scripts/buildsystems/vcpkg.cmake. Save it somewhere for later use and move to Building Iroha section.</p><p>Note</p><p>If you plan to build 32-bit version of Iroha - you will need to install all the mentioned librares above prefixed with x86 term instead of x64.</p><p>5.3. Build Process<br>5.3.1. Cloning the Repository<br>This step is currently unnecessary since you have already cloned Iroha in the previous step. But if you want, you can clone the Iroha repository to the directory of your choice.</p><p><code>git clone -b master https://github.com/hyperledger/iroha</code><br><code>cd iroha</code></p><p>Hint</p><p>If you have installed the prerequisites with Docker, you don’t need to clone Iroha again, because when you run run-iroha-dev.sh it attaches to Iroha source code folder. Feel free to edit source code files with your host environment and build it within docker container.</p><p>5.3.2. Building Iroha<br>To build Iroha, use these commands:</p><p><code>cmake -H. -Bbuild -DCMAKE_TOOLCHAIN_FILE=/path/to/vcpkg/scripts/buildsystems/vcpkg.cmake -G &quot;Ninja&quot;</code><br><code>cmake --build build --target irohad -- -j&lt;number of threads&gt;</code></p><p>Note</p><p>On Docker the path to a toolchain file is /opt/dependencies/scripts/buildsystems/vcpkg.cmake. In other environment please use the path you have got in previous steps.</p><p>Number of threads will be defined differently depending on the platform: - On Linux: via nproc. - On MacOS: with sysctl -n hw.ncpu. - On Windows: use echo %NUMBER_OF_PROCESSORS%.</p><p>Note</p><p>When building on Windows do not execute this from the Power Shell. Better use x64 Native tools command prompt.</p><p>Now Iroha is built. Although, if you like, you can build it with additional parameters described below.</p><p>5.3.3. CMake Parameters<br>We use CMake to generate platform-dependent build files. It has numerous flags for configuring the final build. Note that besides the listed parameters cmake’s variables can be useful as well. Also as long as this page can be deprecated (or just not complete) you can browse custom flags via cmake -L, cmake-gui, or ccmake.</p><p>Hint</p><blockquote><p>You can specify parameters at the cmake configuring stage (e.g cmake -DTESTING=ON).</p></blockquote><p>5.3.3.1. Main Parameters<br>Parameter    Possible values    Default    Description<br>TESTING    ON/OFF    ON    Enables or disables build of the tests<br>BENCHMARKING    OFF    Enables or disables build of the Google Benchmarks library<br>COVERAGE    OFF    Enables or disables lcov setting for code coverage generation<br>USE_LIBURSA    OFF    Enables usage of the HL Ursa cryptography instead of the standard one<br>Note</p><blockquote><p>If you would like to use HL Ursa cryptography for your build, please install Rust in addition to other dependencies. Learn more about HL Ursa integration here.</p></blockquote><p>5.3.3.2. Packaging Specific Parameters<br>Parameter    Possible values    Default    Description<br>PACKAGE_ZIP    ON/OFF    OFF    Enables or disables zip packaging<br>PACKAGE_TGZ    OFF    Enables or disables tar.gz packaging<br>PACKAGE_RPM    OFF    Enables or disables rpm packaging<br>PACKAGE_DEB    OFF    Enables or disables deb packaging<br>5.3.4. Running Tests (optional)<br>After building Iroha, it is a good idea to run tests to check the operability of the daemon. You can run tests with this code:</p><p><code>cmake --build build --target test</code><br>Alternatively, you can run the following command in the build folder</p><p><code>cd build</code><br><code>ctest . --output-on-failure</code><br>Note</p><blockquote><p>Some of the tests will fail without PostgreSQL storage running, so if you are not using scripts/run-iroha-dev.sh script please run Docker container or create a local connection with following parameters:</p></blockquote><pre><code>docker run --name some-postgres \-e POSTGRES_USER=postgres \-e POSTGRES_PASSWORD=mysecretpassword \-p 5432:5432 \-d postgres:9.5 \-c &#39;max_prepared_transactions=100&#39;</code></pre><h1 id="Hyperledger-Iroha-相关资料"><a href="#Hyperledger-Iroha-相关资料" class="headerlink" title="Hyperledger Iroha 相关资料"></a>Hyperledger Iroha 相关资料</h1><p><a href="https://iroha.readthedocs.io/en/latest/" target="_blank" rel="noopener">官方文档</a></p>]]></content>
    
    
    <categories>
      
      <category>Hyperledger</category>
      
    </categories>
    
    
    <tags>
      
      <tag>区块链</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hyperledger Caliper 测试框架</title>
    <link href="/2020/03/16/Hyperledger-Caliper/"/>
    <url>/2020/03/16/Hyperledger-Caliper/</url>
    
    <content type="html"><![CDATA[<h2 id="Caliper-简介"><a href="#Caliper-简介" class="headerlink" title="Caliper 简介"></a>Caliper 简介</h2><p>Caliper是一个区块链性能基准框架，允许用户使用自定义用例测试不同的区块链解决方案，并获得一组性能测试结果。</p><blockquote><p>Caliper is a blockchain benchmark framework which allows users to measure the performance of a specific blockchain implementation with a set of predefined use cases. Caliper will produce reports containing a number of performance indicators, such as TPS (Transactions Per Second), transaction latency, resource utilisation etc. The intent is for Caliper results to be used as a reference in supporting the choice of a blockchain implementation suitable for the user-specific use-cases. Given the variety of blockchain configurations, network setup, as well as the specific use-cases in mind, it is not intended to be an authoritative performance assessment, nor to be used for simple comparative purposes (e.g. blockchain A does 5 TPS and blockchain B does 10 TPS, therefore B is better). The Caliper project references the definitions, metrics, and terminology as defined by the Performance &amp; Scalability Working Group (PSWG).</p></blockquote><h2 id="适用平台"><a href="#适用平台" class="headerlink" title="适用平台"></a>适用平台</h2><ul><li>Hyperledger Besu  </li><li>Hyperledger Burrow</li><li>Ethereum  </li><li>Hyperledger Fabric</li><li>FISCO BCOS</li><li>Hyperledger Iroha</li><li>Hyperledger Sawtooth</li><li>Transaction/read throughput</li><li>Transaction/read latency (minimum, maximum, average, percentile)</li><li>Resource consumption (CPU, Memory, Network IO, …)</li></ul><h2 id="安装Caliper"><a href="#安装Caliper" class="headerlink" title="安装Caliper"></a>安装Caliper</h2><p>Caliper is published as the <code>hyperledger/caliper-cli</code> NPM package and the <code>hyperledger/caliper</code><br> Docker image, both containing the CLI binary. Refer to the<br>Installing from NPM<br> and<br>Using the Docker image<br> sections for the available versions and their intricacies.</p><p>Installing and running Caliper usually consists of the following steps, thoroughly detailed by the remaining sections:</p><p>Acquire the Caliper CLI either from NPM or from DockerHub.<br>Execute a bind command through the CLI. This step pulls the specified version of SDK packages for the selected platform.<br>Start the benchmark through the CLI or by starting the Docker container.<br>The examples in the rest of the documentation use the<br>caliper-benchmarks<br> repository as the Caliper workspace since it contains many sample artifacts for benchmarking. Make sure you check out the appropriate tag/commit of the repository, matching the version of Caliper you use.</p><p>To clone the caliper-benchmarks repository, run:</p><pre><code>git clone https://github.com/hyperledger/caliper-benchmarks.gitcd caliper-benchmarksgit checkout &lt;your Caliper version&gt;</code></pre><p><em>Note</em>: </p><blockquote><p>If you are running your custom benchmark, then change this directory path (and other related configurations) accordingly in the examples.</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Hyperledger</category>
      
    </categories>
    
    
    <tags>
      
      <tag>区块链</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>grpc 学习笔记</title>
    <link href="/2019/08/04/grpc-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2019/08/04/grpc-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="https://grpc.io/docs/" target="_blank" rel="noopener">官方文档</a></p>]]></content>
    
    
    <categories>
      
      <category>rpc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>grpc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go-kit 学习笔记</title>
    <link href="/2019/08/03/Go-kit-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2019/08/03/Go-kit-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="https://iris-go.com/" target="_blank" rel="noopener">官网</a></p><p><a href="https://learnku.com/go/t/36923" target="_blank" rel="noopener">参考博文</a></p>]]></content>
    
    
    <categories>
      
      <category>Golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go-iris</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Iris 学习笔记</title>
    <link href="/2019/05/25/Iris-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2019/05/25/Iris-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="https://iris-go.com/" target="_blank" rel="noopener">官网</a></p>]]></content>
    
    
    <categories>
      
      <category>Golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go-iris</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Gin 学习笔记</title>
    <link href="/2019/05/23/Gin-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2019/05/23/Gin-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="https://github.com/gin-gonic/gin" target="_blank" rel="noopener">官网</a><br><a href="https://geektutu.com/post/quick-go-gin.html" target="_blank" rel="noopener">参考博文</a></p>]]></content>
    
    
    <categories>
      
      <category>Golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>go-gin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Beego 学习笔记</title>
    <link href="/2019/05/21/Beego-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2019/05/21/Beego-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Bee-工具的使用"><a href="#Bee-工具的使用" class="headerlink" title="Bee 工具的使用"></a>Bee 工具的使用</h1><h2 id="bee-工具简介"><a href="#bee-工具简介" class="headerlink" title="bee 工具简介"></a>bee 工具简介</h2><p>bee 工具是一个为了协助快速开发 beego 项目而创建的项目，通过 bee 您可以很容易的进行 beego 项目的创建、热编译、开发、测试、和部署。</p><h2 id="bee-工具的安装"><a href="#bee-工具的安装" class="headerlink" title="bee 工具的安装"></a>bee 工具的安装</h2><p>您可以通过如下的方式安装 bee 工具：</p><pre><code>go get github.com/beego/bee</code></pre><p>安装完之后，<code>bee</code> 可执行文件默认存放在 <code>$GOPATH/bin</code> 里面，所以您需要把 <code>$GOPATH/bin</code> 添加到您的环境变量中，才可以进行下一步。</p><blockquote><blockquote><blockquote><p>如何添加环境变量，请自行搜索<br>如果你本机设置了 <code>GOBIN</code>，那么上面的命令就会安装到 <code>GOBIN</code> 下，请添加 GOBIN 到你的环境变量中</p></blockquote></blockquote></blockquote><h2 id="bee-工具命令详解"><a href="#bee-工具命令详解" class="headerlink" title="bee 工具命令详解"></a>bee 工具命令详解</h2><p>我们在命令行输入 <code>bee</code>，可以看到如下的信息：</p><pre><code>Bee is a Fast and Flexible tool for managing your Beego Web Application.Usage:    bee command [arguments]The commands are:    version     show the bee &amp; beego version    migrate     run database migrations    api         create an api application base on beego framework    bale        packs non-Go files to Go source files        new         create an application base on beego framework    run         run the app which can hot compile    pack        compress an beego project    fix         Fixes your application by making it compatible with newer versions of Beego    dlv         Start a debugging session using Delve    dockerize   Generates a Dockerfile for your Beego application    generate    Source code generator    hprose      Creates an RPC application based on Hprose and Beego frameworks    pack        Compresses a Beego application into a single file    rs          Run customized scripts    run         Run the application by starting a local development server    server      serving static content over HTTP on portUse bee help [command] for more information about a command.</code></pre><h3 id="new-命令"><a href="#new-命令" class="headerlink" title="new 命令"></a><code>new</code> 命令</h3><p><code>new</code> 命令是新建一个 Web 项目，我们在命令行下执行 <code>bee new &lt;项目名&gt;</code> 就可以创建一个新的项目。但是注意该命令必须在 <code>$GOPATH/src</code> 下执行。最后会在 <code>$GOPATH/src</code> 相应目录下生成如下目录结构的项目：</p><pre><code>bee new myproject[INFO] Creating application.../gopath/src/myproject//gopath/src/myproject/conf//gopath/src/myproject/controllers//gopath/src/myproject/models//gopath/src/myproject/static//gopath/src/myproject/static/js//gopath/src/myproject/static/css//gopath/src/myproject/static/img//gopath/src/myproject/views//gopath/src/myproject/conf/app.conf/gopath/src/myproject/controllers/default.go/gopath/src/myproject/views/index.tpl/gopath/src/myproject/main.go13-11-25 09:50:39 [SUCC] New application successfully created!</code></pre><pre><code>myproject├── conf│   └── app.conf├── controllers│   └── default.go├── main.go├── models├── routers│   └── router.go├── static│   ├── css│   ├── img│   └── js├── tests│   └── default_test.go└── views    └── index.tpl8 directories, 4 files</code></pre><h3 id="api-命令"><a href="#api-命令" class="headerlink" title="api 命令"></a><code>api</code> 命令</h3><p>上面的 <code>new</code> 命令是用来新建 Web 项目，不过很多用户使用 beego 来开发 API 应用。所以这个 <code>api</code> 命令就是用来创建 API 应用的，执行命令之后如下所示：</p><pre><code>bee api apiprojectcreate app folder: /gopath/src/apiprojectcreate conf: /gopath/src/apiproject/confcreate controllers: /gopath/src/apiproject/controllerscreate models: /gopath/src/apiproject/modelscreate tests: /gopath/src/apiproject/testscreate conf app.conf: /gopath/src/apiproject/conf/app.confcreate controllers default.go: /gopath/src/apiproject/controllers/default.gocreate tests default.go: /gopath/src/apiproject/tests/default_test.gocreate models object.go: /gopath/src/apiproject/models/object.gocreate main.go: /gopath/src/apiproject/main.go</code></pre><p>这个项目的目录结构如下：</p><pre><code>apiproject├── conf│   └── app.conf├── controllers│   └── object.go│   └── user.go├── docs│   └── doc.go├── main.go├── models│   └── object.go│   └── user.go├── routers│   └── router.go└── tests    └── default_test.go</code></pre><p>从上面的目录我们可以看到和 Web 项目相比，少了 static 和 views 目录，多了一个 test 模块，用来做单元测试的。</p><p>同时，该命令还支持一些自定义参数自动连接数据库创建相关 model 和 controller:<br><code>bee api [appname] [-tables=&quot;&quot;] [-driver=mysql] [-conn=&quot;root:&lt;password&gt;@tcp(127.0.0.1:3306)/test&quot;]</code><br>如果 conn 参数为空则创建一个示例项目，否则将基于链接信息链接数据库创建项目。</p><h3 id="run-命令"><a href="#run-命令" class="headerlink" title="run 命令"></a><code>run</code> 命令</h3><p>我们在开发 Go 项目的时候最大的问题是经常需要自己手动去编译再运行，<code>bee run</code> 命令是监控 beego 的项目，通过 <a href="https://github.com/howeyc/fsnotify" target="_blank" rel="noopener">fsnotify</a>监控文件系统。但是注意该命令必须在 <code>$GOPATH/src/appname</code> 下执行。<br>这样我们在开发过程中就可以实时的看到项目修改之后的效果：</p><pre><code>bee run13-11-25 09:53:04 [INFO] Uses &#39;myproject&#39; as &#39;appname&#39;13-11-25 09:53:04 [INFO] Initializing watcher...13-11-25 09:53:04 [TRAC] Directory(/gopath/src/myproject/controllers)13-11-25 09:53:04 [TRAC] Directory(/gopath/src/myproject/models)13-11-25 09:53:04 [TRAC] Directory(/gopath/src/myproject)13-11-25 09:53:04 [INFO] Start building...13-11-25 09:53:16 [SUCC] Build was successful13-11-25 09:53:16 [INFO] Restarting myproject ...13-11-25 09:53:16 [INFO] ./myproject is running...</code></pre><p>我们打开浏览器就可以看到效果 <code>http://localhost:8080/</code>:</p><p><img src="/resource/img/beerun.png" srcset="/img/loading.gif" alt="avatar"></p><p>如果我们修改了 <code>Controller</code> 下面的 <code>default.go</code> 文件，我们就可以看到命令行输出：</p><pre><code>13-11-25 10:11:20 [EVEN] &quot;/gopath/src/myproject/controllers/default.go&quot;: DELETE|MODIFY13-11-25 10:11:20 [INFO] Start building...13-11-25 10:11:20 [SKIP] &quot;/gopath/src/myproject/controllers/default.go&quot;: CREATE13-11-25 10:11:23 [SKIP] &quot;/gopath/src/myproject/controllers/default.go&quot;: MODIFY13-11-25 10:11:23 [SUCC] Build was successful13-11-25 10:11:23 [INFO] Restarting myproject ...13-11-25 10:11:23 [INFO] ./myproject is running...</code></pre><p>刷新浏览器我们看到新的修改内容已经输出。</p><h3 id="pack-命令"><a href="#pack-命令" class="headerlink" title="pack 命令"></a><code>pack</code> 命令</h3><p><code>pack</code> 目录用来发布应用的时候打包，会把项目打包成 zip 包，这样我们部署的时候直接把打包之后的项目上传，解压就可以部署了：</p><pre><code>bee packapp path: /gopath/src/apiprojectGOOS darwin GOARCH amd64build apiprojectbuild successexclude prefix:exclude suffix: .go:.DS_Store:.tmpfile write to `/gopath/src/apiproject/apiproject.tar.gz`</code></pre><p>我们可以看到目录下有如下的压缩文件：</p><pre><code>rwxr-xr-x  1 astaxie  staff  8995376 11 25 22:46 apiproject-rw-r--r--  1 astaxie  staff  2240288 11 25 22:58 apiproject.tar.gzdrwxr-xr-x  3 astaxie  staff      102 11 25 22:31 confdrwxr-xr-x  3 astaxie  staff      102 11 25 22:31 controllers-rw-r--r--  1 astaxie  staff      509 11 25 22:31 main.godrwxr-xr-x  3 astaxie  staff      102 11 25 22:31 modelsdrwxr-xr-x  3 astaxie  staff      102 11 25 22:31 tests</code></pre><h3 id="bale-命令"><a href="#bale-命令" class="headerlink" title="bale 命令"></a><code>bale</code> 命令</h3><p>这个命令目前仅限内部使用，具体实现方案未完善，主要用来压缩所有的静态文件变成一个变量申明文件，全部编译到二进制文件里面，用户发布的时候携带静态文件，包括 js、css、img 和 views。最后在启动运行时进行非覆盖式的自解压。</p><h3 id="version-命令"><a href="#version-命令" class="headerlink" title="version 命令"></a><code>version</code> 命令</h3><p>这个命令是动态获取 bee、beego 和 Go 的版本，这样一旦用户出现错误，可以通过该命令来查看当前的版本</p><pre><code>$ bee versionbee   :1.2.2beego :1.4.2Go    :go version go1.3.3 darwin/amd64</code></pre><h3 id="generate-命令"><a href="#generate-命令" class="headerlink" title="generate 命令"></a><code>generate</code> 命令</h3><p>这个命令是用来自动化的生成代码的，包含了从数据库一键生成 model，还包含了 scaffold 的，通过这个命令，让大家开发代码不再慢</p><pre><code>bee generate scaffold [scaffoldname] [-fields=&quot;&quot;] [-driver=mysql] [-conn=&quot;root:@tcp(127.0.0.1:3306)/test&quot;]    The generate scaffold command will do a number of things for you.    -fields: a list of table fields. Format: field:type, ...    -driver: [mysql | postgres | sqlite], the default is mysql    -conn:   the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/test    example: bee generate scaffold post -fields=&quot;title:string,body:text&quot;bee generate model [modelname] [-fields=&quot;&quot;]    generate RESTful model based on fields    -fields: a list of table fields. Format: field:type, ...bee generate controller [controllerfile]    generate RESTful controllersbee generate view [viewpath]    generate CRUD view in viewpathbee generate migration [migrationfile] [-fields=&quot;&quot;]    generate migration file for making database schema update    -fields: a list of table fields. Format: field:type, ...bee generate docs    generate swagger doc filebee generate test [routerfile]    generate testcasebee generate appcode [-tables=&quot;&quot;] [-driver=mysql] [-conn=&quot;root:@tcp(127.0.0.1:3306)/test&quot;] [-level=3]    generate appcode based on an existing database    -tables: a list of table names separated by &#39;,&#39;, default is empty, indicating all tables    -driver: [mysql | postgres | sqlite], the default is mysql    -conn:   the connection string used by the driver.             default for mysql:    root:@tcp(127.0.0.1:3306)/test             default for postgres: postgres://postgres:postgres@127.0.0.1:5432/postgres    -level:  [1 | 2 | 3], 1 = models; 2 = models,controllers; 3 = models,controllers,router</code></pre><h3 id="migrate-命令"><a href="#migrate-命令" class="headerlink" title="migrate 命令"></a><code>migrate</code> 命令</h3><p>这个命令是应用的数据库迁移命令，主要是用来每次应用升级，降级的SQL管理。</p><pre><code>bee migrate [-driver=mysql] [-conn=&quot;root:@tcp(127.0.0.1:3306)/test&quot;]    run all outstanding migrations    -driver: [mysql | postgresql | sqlite], the default is mysql    -conn:   the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/testbee migrate rollback [-driver=mysql] [-conn=&quot;root:@tcp(127.0.0.1:3306)/test&quot;]    rollback the last migration operation    -driver: [mysql | postgresql | sqlite], the default is mysql    -conn:   the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/testbee migrate reset [-driver=mysql] [-conn=&quot;root:@tcp(127.0.0.1:3306)/test&quot;]    rollback all migrations    -driver: [mysql | postgresql | sqlite], the default is mysql    -conn:   the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/testbee migrate refresh [-driver=mysql] [-conn=&quot;root:@tcp(127.0.0.1:3306)/test&quot;]    rollback all migrations and run them all again    -driver: [mysql | postgresql | sqlite], the default is mysql    -conn:   the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/test</code></pre><h3 id="dockerize-命令"><a href="#dockerize-命令" class="headerlink" title="dockerize 命令"></a><code>dockerize</code> 命令</h3><p>这个命令可以通过生成Dockerfile文件来实现docker化你的应用。</p><p>例子:<br>生成一个以1.6.4版本Go环境为基础镜像的Dockerfile,并暴露9000端口:</p><pre><code>$ bee dockerize -image=&quot;library/golang:1.6.4&quot; -expose=9000______| ___ \| |_/ /  ___   ___| ___ \ / _ \ / _ \| |_/ /|  __/|  __/\____/  \___| \___| v1.6.22016/12/26 22:34:54 INFO     ▶ 0001 Generating Dockerfile...2016/12/26 22:34:54 SUCCESS  ▶ 0002 Dockerfile generated.</code></pre><p>更多帮助信息可执行<code>bee help dockerize</code>.</p><h2 id="bee-工具配置文件"><a href="#bee-工具配置文件" class="headerlink" title="bee 工具配置文件"></a>bee 工具配置文件</h2><p>您可能已经注意到，在 bee 工具的源码目录下有一个 <code>bee.json</code> 文件，这个文件是针对 bee 工具的一些行为进行配置。该功能还未完全开发完成，不过其中的一些选项已经可以使用：</p><ul><li><code>&quot;version&quot;: 0</code>：配置文件版本，用于对比是否发生不兼容的配置格式版本。</li><li><code>&quot;go_install&quot;: false</code>：如果您的包均使用完整的导入路径（例如：<code>github.com/user/repo/subpkg</code>）,则可以启用该选项来进行 <code>go install</code> 操作，加快构建操作。</li><li><code>&quot;watch_ext&quot;: []</code>：用于监控其它类型的文件（默认只监控后缀为 <code>.go</code> 的文件）。</li><li><code>&quot;dir_structure&quot;:{}</code>：如果您的目录名与默认的 MVC 架构的不同，则可以使用该选项进行修改。</li><li><code>&quot;cmd_args&quot;: []</code>：如果您需要在每次启动时加入启动参数，则可以使用该选项。</li><li><code>&quot;envs&quot;: []</code>：如果您需要在每次启动时设置临时环境变量参数，则可以使用该选项。</li></ul><h1 id="路由设置"><a href="#路由设置" class="headerlink" title="路由设置"></a>路由设置</h1><p>什么是路由设置呢？前面介绍的 MVC 结构执行时，介绍过 beego 存在三种方式的路由:固定路由、正则路由、自动路由，接下来详细的讲解如何使用这三种路由。</p><h2 id="基础路由"><a href="#基础路由" class="headerlink" title="基础路由"></a>基础路由</h2><p>从 beego 1.2 版本开始支持了基本的 RESTful 函数式路由,应用中的大多数路由都会定义在 <code>routers/router.go</code> 文件中。最简单的 beego 路由由 URI 和闭包函数组成。</p><h3 id="基本-GET-路由"><a href="#基本-GET-路由" class="headerlink" title="基本 GET 路由"></a>基本 GET 路由</h3><pre><code>beego.Get(&quot;/&quot;,func(ctx *context.Context){     ctx.Output.Body([]byte(&quot;hello world&quot;))})</code></pre><h3 id="基本-POST-路由"><a href="#基本-POST-路由" class="headerlink" title="基本 POST 路由"></a>基本 POST 路由</h3><pre><code>beego.Post(&quot;/alice&quot;,func(ctx *context.Context){     ctx.Output.Body([]byte(&quot;bob&quot;))})</code></pre><h3 id="注册一个可以响应任何-HTTP-的路由"><a href="#注册一个可以响应任何-HTTP-的路由" class="headerlink" title="注册一个可以响应任何 HTTP 的路由"></a>注册一个可以响应任何 HTTP 的路由</h3><pre><code>beego.Any(&quot;/foo&quot;,func(ctx *context.Context){     ctx.Output.Body([]byte(&quot;bar&quot;))})</code></pre><h3 id="所有的支持的基础函数如下所示"><a href="#所有的支持的基础函数如下所示" class="headerlink" title="所有的支持的基础函数如下所示"></a>所有的支持的基础函数如下所示</h3><ul><li>beego.Get(router, beego.FilterFunc)</li><li>beego.Post(router, beego.FilterFunc)</li><li>beego.Put(router, beego.FilterFunc)</li><li>beego.Patch(router, beego.FilterFunc)</li><li>beego.Head(router, beego.FilterFunc)</li><li>beego.Options(router, beego.FilterFunc)</li><li>beego.Delete(router, beego.FilterFunc)</li><li>beego.Any(router, beego.FilterFunc)</li></ul><h3 id="支持自定义的-handler-实现"><a href="#支持自定义的-handler-实现" class="headerlink" title="支持自定义的 handler 实现"></a>支持自定义的 handler 实现</h3><p>有些时候我们已经实现了一些 rpc 的应用,但是想要集成到 beego 中,或者其他的 httpserver 应用,集成到 beego 中来.现在可以很方便的集成:</p><pre><code>s := rpc.NewServer()s.RegisterCodec(json.NewCodec(), &quot;application/json&quot;)s.RegisterService(new(HelloService), &quot;&quot;)beego.Handler(&quot;/rpc&quot;, s)</code></pre><p><code>beego.Handler(router, http.Handler)</code> 这个函数是关键,第一个参数表示路由 URI, 第二个就是你自己实现的 <code>http.Handler</code>, 注册之后就会把所有 rpc 作为前缀的请求分发到 <code>http.Handler</code> 中进行处理.</p><p>这个函数其实还有第三个参数就是是否是前缀匹配,默认是 false, 如果设置了 true, 那么就会在路由匹配的时候前缀匹配,即 <code>/rpc/user</code> 这样的也会匹配去运行</p><h3 id="路由参数"><a href="#路由参数" class="headerlink" title="路由参数"></a>路由参数</h3><p>后面会讲到固定路由,正则路由,这些参数一样适用于上面的这些函数</p><h2 id="RESTful-Controller-路由"><a href="#RESTful-Controller-路由" class="headerlink" title="RESTful Controller 路由"></a>RESTful Controller 路由</h2><p>在介绍这三种 beego 的路由实现之前先介绍 RESTful，我们知道 RESTful 是一种目前 API 开发中广泛采用的形式，beego 默认就是支持这样的请求方法，也就是用户 Get 请求就执行 Get 方法，Post 请求就执行 Post 方法。因此默认的路由是这样 RESTful 的请求方式。</p><h2 id="固定路由"><a href="#固定路由" class="headerlink" title="固定路由"></a>固定路由</h2><p>固定路由也就是全匹配的路由，如下所示：</p><pre><code>beego.Router(&quot;/&quot;, &amp;controllers.MainController{})beego.Router(&quot;/admin&quot;, &amp;admin.UserController{})beego.Router(&quot;/admin/index&quot;, &amp;admin.ArticleController{})beego.Router(&quot;/admin/addpkg&quot;, &amp;admin.AddController{})</code></pre><p>如上所示的路由就是我们最常用的路由方式，一个固定的路由，一个控制器，然后根据用户请求方法不同请求控制器中对应的方法，典型的 RESTful 方式。</p><h2 id="正则路由"><a href="#正则路由" class="headerlink" title="正则路由"></a>正则路由</h2><p>为了用户更加方便的路由设置，beego 参考了 sinatra 的路由实现，支持多种方式的路由：</p><ul><li><p>beego.Router(“/api/?:id”, &amp;controllers.RController{})</p><p>  默认匹配   //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123”</p></li><li><p>beego.Router(“/api/:id”, &amp;controllers.RController{})</p><p>  默认匹配   //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123”，但URL”/api/“匹配失败</p></li><li><p>beego.Router(“/api/:id([0-9]+)”, &amp;controllers.RController{})</p><p>  自定义正则匹配 //例如对于URL”/api/123”可以匹配成功，此时变量”:id”值为”123”</p></li><li><p>beego.Router(“/user/:username([\\w]+)”, &amp;controllers.RController{})</p><p>  正则字符串匹配 //例如对于URL”/user/astaxie”可以匹配成功，此时变量”:username”值为”astaxie”</p></li><li><p>beego.Router(“/download/*.*“, &amp;controllers.RController{})</p><p>  *匹配方式 //例如对于URL”/download/file/api.xml”可以匹配成功，此时变量”:path”值为”file/api”， “:ext”值为”xml”</p></li><li><p>beego.Router(“/download/ceshi/*”, &amp;controllers.RController{})</p><p>  *全匹配方式 //例如对于URL”/download/ceshi/file/api.json”可以匹配成功，此时变量”:splat”值为”file/api.json”</p></li><li><p>beego.Router(“/:id:int”, &amp;controllers.RController{})</p><p>  int 类型设置方式，匹配 :id为int 类型，框架帮你实现了正则 ([0-9]+)</p></li><li><p>beego.Router(“/:hi:string”, &amp;controllers.RController{})</p><p>  string 类型设置方式，匹配 :hi 为 string 类型。框架帮你实现了正则 ([\w]+)</p></li><li><p>beego.Router(“/cms_:id([0-9]+).html”, &amp;controllers.CmsController{})</p><p>  带有前缀的自定义正则 //匹配 :id 为正则类型。匹配 cms_123.html 这样的 url :id = 123</p></li></ul><p>可以在 Controller 中通过如下方式获取上面的变量：</p><pre><code>this.Ctx.Input.Param(&quot;:id&quot;)this.Ctx.Input.Param(&quot;:username&quot;)this.Ctx.Input.Param(&quot;:splat&quot;)this.Ctx.Input.Param(&quot;:path&quot;)this.Ctx.Input.Param(&quot;:ext&quot;)</code></pre><h2 id="自定义方法及-RESTful-规则"><a href="#自定义方法及-RESTful-规则" class="headerlink" title="自定义方法及 RESTful 规则"></a>自定义方法及 RESTful 规则</h2><p>上面列举的是默认的请求方法名（请求的 method 和函数名一致，例如 <code>GET</code> 请求执行 <code>Get</code> 函数，<code>POST</code> 请求执行 <code>Post</code> 函数），如果用户期望自定义函数名，那么可以使用如下方式：</p><pre><code>beego.Router(&quot;/&quot;,&amp;IndexController{},&quot;*:Index&quot;)</code></pre><p>使用第三个参数，第三个参数就是用来设置对应 method 到函数名，定义如下</p><ul><li><code>*</code>表示任意的 method 都执行该函数</li><li>使用 httpmethod:funcname 格式来展示</li><li>多个不同的格式使用 <code>;</code> 分割</li><li>多个 method 对应同一个 funcname，method 之间通过 <code>,</code> 来分割</li></ul><p>以下是一个 RESTful 的设计示例：</p><pre><code>beego.Router(&quot;/api/list&quot;,&amp;RestController{},&quot;*:ListFood&quot;)beego.Router(&quot;/api/create&quot;,&amp;RestController{},&quot;post:CreateFood&quot;)beego.Router(&quot;/api/update&quot;,&amp;RestController{},&quot;put:UpdateFood&quot;)beego.Router(&quot;/api/delete&quot;,&amp;RestController{},&quot;delete:DeleteFood&quot;)</code></pre><p>以下是多个 HTTP Method 指向同一个函数的示例：</p><pre><code>beego.Router(&quot;/api&quot;,&amp;RestController{},&quot;get,post:ApiFunc&quot;)</code></pre><p>以下是不同的 method 对应不同的函数，通过 ; 进行分割的示例：</p><pre><code>beego.Router(&quot;/simple&quot;,&amp;SimpleController{},&quot;get:GetFunc;post:PostFunc&quot;)</code></pre><p>可用的 HTTP Method：</p><ul><li>*: 包含以下所有的函数</li><li>get: GET 请求</li><li>post: POST 请求</li><li>put: PUT 请求</li><li>delete: DELETE 请求</li><li>patch: PATCH 请求</li><li>options: OPTIONS 请求</li><li>head: HEAD 请求</li></ul><p>如果同时存在 * 和对应的 HTTP Method，那么优先执行 HTTP Method 的方法，例如同时注册了如下所示的路由：</p><pre><code>beego.Router(&quot;/simple&quot;,&amp;SimpleController{},&quot;*:AllFunc;post:PostFunc&quot;)</code></pre><p>那么执行 <code>POST</code> 请求的时候，执行 <code>PostFunc</code> 而不执行 <code>AllFunc</code>。</p><blockquote><blockquote><blockquote><p>自定义函数的路由默认不支持 RESTful 的方法，也就是如果你设置了 <code>beego.Router(&quot;/api&quot;,&amp;RestController{},&quot;post:ApiFunc&quot;)</code> 这样的路由，如果请求的方法是 <code>POST</code>，那么不会默认去执行 <code>Post</code> 函数。</p></blockquote></blockquote></blockquote><h2 id="自动匹配"><a href="#自动匹配" class="headerlink" title="自动匹配"></a>自动匹配</h2><p>用户首先需要把需要路由的控制器注册到自动路由中：</p><pre><code>beego.AutoRouter(&amp;controllers.ObjectController{})</code></pre><p>那么 beego 就会通过反射获取该结构体中所有的实现方法，你就可以通过如下的方式访问到对应的方法中：</p><pre><code>/object/login   调用 ObjectController 中的 Login 方法/object/logout  调用 ObjectController 中的 Logout 方法</code></pre><p>除了前缀两个 <code>/:controller/:method</code> 的匹配之外，剩下的 url beego 会帮你自动化解析为参数，保存在 <code>this.Ctx.Input.Params</code> 当中：</p><pre><code>/object/blog/2013/09/12  调用 ObjectController 中的 Blog 方法，参数如下：map[0:2013 1:09 2:12]</code></pre><p>方法名在内部是保存了用户设置的，例如 Login，url 匹配的时候都会转化为小写，所以，<code>/object/LOGIN</code> 这样的 <code>url</code> 也一样可以路由到用户定义的 <code>Login</code> 方法中。</p><p>现在已经可以通过自动识别出来下面类似的所有 url，都会把请求分发到 <code>controller</code> 的 <code>simple</code> 方法：</p><pre><code>/controller/simple/controller/simple.html/controller/simple.json/controller/simple.xml</code></pre><p>可以通过 <code>this.Ctx.Input.Param(&quot;:ext&quot;)</code> 获取后缀名。</p><h2 id="注解路由"><a href="#注解路由" class="headerlink" title="注解路由"></a>注解路由</h2><p>从 beego 1.3 版本开始支持了注解路由，用户无需在 router 中注册路由，只需要 Include 相应地 controller，然后在 controller 的 method 方法上面写上 router 注释（// @router）就可以了，详细的使用请看下面的例子：</p><pre><code>// CMS APItype CMSController struct {    beego.Controller}func (c *CMSController) URLMapping() {    c.Mapping(&quot;StaticBlock&quot;, c.StaticBlock)    c.Mapping(&quot;AllBlock&quot;, c.AllBlock)}// @router /staticblock/:key [get]func (this *CMSController) StaticBlock() {}// @router /all/:key [get]func (this *CMSController) AllBlock() {}</code></pre><p>可以在 <code>router.go</code> 中通过如下方式注册路由：</p><pre><code>beego.Include(&amp;CMSController{})</code></pre><p>beego 自动会进行源码分析，注意只会在 dev 模式下进行生成，生成的路由放在 “/routers/commentsRouter.go” 文件中。</p><p>这样上面的路由就支持了如下的路由：</p><ul><li>GET /staticblock/:key</li><li>GET /all/:key</li></ul><p>其实效果和自己通过 Router 函数注册是一样的：</p><pre><code>beego.Router(&quot;/staticblock/:key&quot;, &amp;CMSController{}, &quot;get:StaticBlock&quot;)beego.Router(&quot;/all/:key&quot;, &amp;CMSController{}, &quot;get:AllBlock&quot;)</code></pre><p>同时大家注意到新版本里面增加了 URLMapping 这个函数，这是新增加的函数，用户如果没有进行注册，那么就会通过反射来执行对应的函数，如果注册了就会通过 interface 来进行执行函数，性能上面会提升很多。</p><h2 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h2><pre><code>//初始化 namespacens :=beego.NewNamespace(&quot;/v1&quot;,    beego.NSCond(func(ctx *context.Context) bool {        if ctx.Input.Domain() == &quot;api.beego.me&quot; {            return true        }        return false    }),    beego.NSBefore(auth),    beego.NSGet(&quot;/notallowed&quot;, func(ctx *context.Context) {        ctx.Output.Body([]byte(&quot;notAllowed&quot;))    }),    beego.NSRouter(&quot;/version&quot;, &amp;AdminController{}, &quot;get:ShowAPIVersion&quot;),    beego.NSRouter(&quot;/changepassword&quot;, &amp;UserController{}),    beego.NSNamespace(&quot;/shop&quot;,        beego.NSBefore(sentry),        beego.NSGet(&quot;/:id&quot;, func(ctx *context.Context) {            ctx.Output.Body([]byte(&quot;notAllowed&quot;))        }),    ),    beego.NSNamespace(&quot;/cms&quot;,        beego.NSInclude(            &amp;controllers.MainController{},            &amp;controllers.CMSController{},            &amp;controllers.BlockController{},        ),    ),)//注册 namespacebeego.AddNamespace(ns)</code></pre><p>上面这个代码支持了如下这样的请求 URL</p><ul><li>GET /v1/notallowed</li><li>GET /v1/version</li><li>GET /v1/changepassword</li><li>POST /v1/changepassword</li><li>GET /v1/shop/123</li><li>GET /v1/cms/ 对应 MainController、CMSController、BlockController 中得注解路由</li></ul><p>而且还支持前置过滤,条件判断,无限嵌套 namespace</p><p>namespace 的接口如下:</p><ul><li><p>NewNamespace(prefix string, funcs …interface{})</p><p>  初始化 namespace 对象,下面这些函数都是 namespace 对象的方法,但是强烈推荐使用 NS 开头的相应函数注册，因为这样更容易通过 gofmt 工具看的更清楚路由的级别关系</p></li><li><p>NSCond(cond namespaceCond)</p><p>  支持满足条件的就执行该 namespace, 不满足就不执行</p></li><li><p>NSBefore(filiterList …FilterFunc)</p></li><li><p>NSAfter(filiterList …FilterFunc)</p><p>  上面分别对应 beforeRouter 和 FinishRouter 两个过滤器，可以同时注册多个过滤器</p></li><li><p>NSInclude(cList …ControllerInterface)</p></li><li><p>NSRouter(rootpath string, c ControllerInterface, mappingMethods …string)</p></li><li><p>NSGet(rootpath string, f FilterFunc)</p></li><li><p>NSPost(rootpath string, f FilterFunc)</p></li><li><p>NSDelete(rootpath string, f FilterFunc)</p></li><li><p>NSPut(rootpath string, f FilterFunc)</p></li><li><p>NSHead(rootpath string, f FilterFunc)</p></li><li><p>NSOptions(rootpath string, f FilterFunc)</p></li><li><p>NSPatch(rootpath string, f FilterFunc)</p></li><li><p>NSAny(rootpath string, f FilterFunc)</p></li><li><p>NSHandler(rootpath string, h http.Handler)</p></li><li><p>NSAutoRouter(c ControllerInterface)</p></li><li><p>NSAutoPrefix(prefix string, c ControllerInterface)</p><p>  上面这些都是设置路由的函数,详细的使用和上面 beego 的对应函数是一样的</p></li><li><p>NSNamespace(prefix string, params …innnerNamespace)</p><p>  嵌套其他 namespace</p><pre><code>  ns :=    beego.NewNamespace(&quot;/v1&quot;,      beego.NSNamespace(&quot;/shop&quot;,          beego.NSGet(&quot;/:id&quot;, func(ctx *context.Context) {              ctx.Output.Body([]byte(&quot;shopinfo&quot;))          }),      ),      beego.NSNamespace(&quot;/order&quot;,          beego.NSGet(&quot;/:id&quot;, func(ctx *context.Context) {              ctx.Output.Body([]byte(&quot;orderinfo&quot;))          }),      ),      beego.NSNamespace(&quot;/crm&quot;,          beego.NSGet(&quot;/:id&quot;, func(ctx *context.Context) {              ctx.Output.Body([]byte(&quot;crminfo&quot;))          }),      ),  )</code></pre></li></ul><p>下面这些函数都是属于 *Namespace 对象的方法：不建议直接使用，当然效果和上面的 NS 开头的函数是一样的，只是上面的方式更优雅，写出来的代码更容易看得懂</p><ul><li><p>Cond(cond namespaceCond)</p><p>  支持满足条件的就执行该 namespace, 不满足就不执行,例如你可以根据域名来控制 namespace</p></li><li><p>Filter(action string, filter FilterFunc)</p><p>  action 表示你需要执行的位置, before 和 after 分别表示执行逻辑之前和执行逻辑之后的 filter</p></li><li><p>Router(rootpath string, c ControllerInterface, mappingMethods …string)</p></li></ul><ul><li><p>AutoRouter(c ControllerInterface)</p></li><li><p>AutoPrefix(prefix string, c ControllerInterface)</p></li><li><p>Get(rootpath string, f FilterFunc)</p></li><li><p>Post(rootpath string, f FilterFunc)</p></li><li><p>Delete(rootpath string, f FilterFunc)</p></li><li><p>Put(rootpath string, f FilterFunc)</p></li><li><p>Head(rootpath string, f FilterFunc)</p></li><li><p>Options(rootpath string, f FilterFunc)</p></li><li><p>Patch(rootpath string, f FilterFunc)</p></li><li><p>Any(rootpath string, f FilterFunc)</p></li><li><p>Handler(rootpath string, h http.Handler)</p><p>  上面这些都是设置路由的函数,详细的使用和上面 beego 的对应函数是一样的</p></li><li><p>Namespace(ns …*Namespace)</p></li></ul><p>更多的例子代码：</p><pre><code>//APISns :=    beego.NewNamespace(&quot;/api&quot;,        //此处正式版时改为验证加密请求        beego.NSCond(func(ctx *context.Context) bool {            if ua := ctx.Input.Request.UserAgent(); ua != &quot;&quot; {                return true            }            return false        }),        beego.NSNamespace(&quot;/ios&quot;,            //CRUD Create(创建)、Read(读取)、Update(更新)和Delete(删除)            beego.NSNamespace(&quot;/create&quot;,                // /api/ios/create/node/                beego.NSRouter(&quot;/node&quot;, &amp;apis.CreateNodeHandler{}),                // /api/ios/create/topic/                beego.NSRouter(&quot;/topic&quot;, &amp;apis.CreateTopicHandler{}),            ),            beego.NSNamespace(&quot;/read&quot;,                beego.NSRouter(&quot;/node&quot;, &amp;apis.ReadNodeHandler{}),                beego.NSRouter(&quot;/topic&quot;, &amp;apis.ReadTopicHandler{}),            ),            beego.NSNamespace(&quot;/update&quot;,                beego.NSRouter(&quot;/node&quot;, &amp;apis.UpdateNodeHandler{}),                beego.NSRouter(&quot;/topic&quot;, &amp;apis.UpdateTopicHandler{}),            ),            beego.NSNamespace(&quot;/delete&quot;,                beego.NSRouter(&quot;/node&quot;, &amp;apis.DeleteNodeHandler{}),                beego.NSRouter(&quot;/topic&quot;, &amp;apis.DeleteTopicHandler{}),            )        ),    )beego.AddNamespace(ns)</code></pre><h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="https://beego.me/" target="_blank" rel="noopener">Beego官网</a></p>]]></content>
    
    
    <categories>
      
      <category>Golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>beego</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang 学习笔记一</title>
    <link href="/2019/05/18/Golang-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80/"/>
    <url>/2019/05/18/Golang-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80/</url>
    
    <content type="html"><![CDATA[<h1 id="Go语言简介"><a href="#Go语言简介" class="headerlink" title="Go语言简介"></a>Go语言简介</h1><p>Go语言（或 Golang）起源于 2007 年，并在 2009 年正式对外发布。Go 是非常年轻的一门语言，它的主要目标是“兼具 Python 等动态语言的开发速度和 C/C++ 等编译型语言的性能与安全性”。</p><p>Go语言是编程语言设计的又一次尝试，是对类C语言的重大改进，它不但能让你访问底层操作系统，还提供了强大的网络编程和并发编程支持。Go语言的用途众多，可以进行网络编程、系统编程、并发编程、分布式编程。</p><p>Go语言的推出，旨在不损失应用程序性能的情况下降低代码的复杂性，具有“部署简单、并发性好、语言设计良好、执行性能好”等优势，目前国内诸多 IT 公司均已采用Go语言开发项目。</p><p>Go语言有时候被描述为“C 类似语言”，或者是“21 世纪的C语言”。Go 从C语言继承了相似的表达式语法、控制流结构、基础数据类型、调用参数传值、指针等很多思想，还有C语言一直所看中的编译后机器码的运行效率以及和现有操作系统的无缝适配。</p><p>因为Go语言没有类和继承的概念，所以它和 Java 或 C++ 看起来并不相同。但是它通过接口（interface）的概念来实现多态性。Go语言有一个清晰易懂的轻量级类型系统，在类型之间也没有层级之说。因此可以说Go语言是一门混合型的语言。</p><p>此外，很多重要的开源项目都是使用Go语言开发的，其中包括 Docker、Go-Ethereum、Thrraform 和 Kubernetes。</p><h3 id="Go语言创始人"><a href="#Go语言创始人" class="headerlink" title="Go语言创始人"></a>Go语言创始人</h3><p>对语言进行评估时，明白设计者的动机以及语言要解决的问题很重要。Go语言出自 Ken Thompson 和 Rob Pike、Robert Griesemer 之手，他们都是计算机科学领域的重量级人物。</p><p>1) Ken Thompson<br>贝尔实验室 Unix 团队成员，C语言、Unix 和 Plan 9 的创始人之一，在 20 世纪 70 年代，设计并实现了最初的 UNIX 操作系统，仅从这一点说，他对计算机科学的贡献怎么强调都不过分。他还与 Rob Pike 合作设计了 UTF-8 编码方案。<br>2) Rob Pike<br>Go语言项目总负责人，贝尔实验室 Unix 团队成员，除帮助设计 UTF-8 外，还帮助开发了分布式多用户操作系统 Plan 9、Inferno 操作系统和 Limbo 编程语言，并与人合著了《The Unix Programming Environment》，对 UNIX 的设计理念做了正统的阐述。<br>3) Robert Griesemer<br>就职于 Google，参与开发 Java HotSpot 虚拟机，对语言设计有深入的认识，并负责 Chrome 浏览器和 Node.js 使用的 Google V8 JavaScript 引擎的代码生成部分。</p><p>这些计算机科学领城的重量级人物设计Go语言的初衷是满足 Google 的需求。设计此语言花费了两年的时间，融入了整个团队多年的经验及对编程语言设计的深入认识。设计团队借鉴了 Pascal、Oberon 和C语言的设计智慧，同时让Go语言具备动态语言的便利性。因此，Go语言体现了经验丰富的计算机科学家的语言设计理念，是为全球最大的互联网公司之一设计的。</p><p>Go语言的所有设计者都说，设计Go语言是因为 C++ 给他们带来了挫败感。在 Google I/O 2012 的 Go 设计小组见面会上，Rob Pike 是这样说的：<br>我们做了大量的 C++ 开发，厌烦了等待编译完成，尽管这是玩笑，但在很大程度上来说也是事实。<br>Go 是编译型语言<br>Go 使用编译器来编译代码。编译器将源代码编译成二进制（或字节码）格式；在编译代码时，编译器检查错误、优化性能并输出可在不同平台上运行的二进制文件。要创建并运行 Go 程序，程序员必须执行如下步骤。<br>使用文本编辑器创建 Go 程序；<br>保存文件；<br>编译程序；<br>运行编译得到的可执行文件。</p><p>这不同于 Python、Ruby 和 JavaScript 等语言，它们不包含编译步骤。Go 自带了编译器，因此无须单独安装编译器。</p><h3 id="为什么要学习Go语言"><a href="#为什么要学习Go语言" class="headerlink" title="为什么要学习Go语言"></a>为什么要学习Go语言</h3><p>如果你要创建系统程序，或者基于网络的程序，Go语言是很不错的选择。作为一种相对较新的语言，它是由经验丰富且受人尊敬的计算机科学家设计的，旨在应对创建大型并发网络程序面临的挑战。</p><p>在Go语言出现之前，开发者们总是面临非常艰难的抉择，究竟是使用执行速度快但是编译速度并不理想的语言（如：C++），还是使用编译速度较快但执行效率不佳的语言（如：.NET、Java），或者说开发难度较低但执行速度一般的动态语言呢？显然，Go语言在这 3 个条件之间做到了最佳的平衡：快速编译，高效执行，易于开发。</p><p>Go语言支持交叉编译，比如说你可以在运行 Linux 系统的计算机上开发可以在 Windows 上运行的应用程序。这是第一门完全支持 UTF-8 的编程语言，这不仅体现在它可以处理使用 UTF-8 编码的字符串，就连它的源码文件格式都是使用的 UTF-8 编码。Go语言做到了真正的国际化！<br>Go语言吉祥物<br>Go语言有一个吉祥物，在会议、文档页面和博文中，大多会包含下图所示的 Go Gopher，这是才华横溢的插画家 Renee French 设计的，她也是 Go 设计者之一 Rob Pike 的妻子。</p><h2 id="2-Go语言的特性"><a href="#2-Go语言的特性" class="headerlink" title="2.Go语言的特性"></a>2.Go语言的特性</h2><p>Go语言也称为 Golang，是由 Google 公司开发的一种静态强类型、编译型、并发型、并具有垃圾回收功能的编程语言。</p><p>接下来从几个方面来具体介绍一下Go语言的特性。<br>语法简单<br>抛开语法样式不谈，单就类型和规则而言，Go 与 C99、C11 相似之处颇多，这也是Go语言被冠以“NextC”名号的重要原因。</p><p>Go语言的语法处于简单和复杂的两极。C语言简单到你每写下一行代码，都能在脑中想象出编译后的模样，指令如何执行，内存如何分配，等等。而 C 的复杂在于，它有太多隐晦而不着边际的规则，着实让人头疼。相比较而言，Go 从零开始，没有历史包袱，在汲取众多经验教训后，可从头规划一个规则严谨、条理简单的世界。</p><p>Go语言的语法规则严谨，没有歧义，更没什么黑魔法变异用法。任何人写出的代码都基本一致，这使得Go语言简单易学。放弃部分“灵活”和“自由”，换来更好的维护性，我觉得是值得的。</p><p>将“++”、“–”从运算符降级为语句，保留指针，但默认阻止指针运算，带来的好处是显而易见的。还有，将切片和字典作为内置类型，从运行时的层面进行优化，这也算是一种“简单”。<br>并发模型<br>时至今日，并发编程已成为程序员的基本技能，在各个技术社区都能看到诸多与之相关的讨论主题。在这种情况下Go语言却一反常态做了件极大胆的事，从根本上将一切都并发化，运行时用 Goroutine 运行所有的一切，包括 main.main 入口函数。</p><p>可以说，Goroutine 是 Go 最显著的特征。它用类协程的方式来处理并发单元，却又在运行时层面做了更深度的优化处理。这使得语法上的并发编程变得极为容易，无须处理回调，无须关注线程切换，仅一个关键字，简单而自然。</p><p>搭配 channel，实现 CSP 模型。将并发单元间的数据耦合拆解开来，各司其职，这对所有纠结于内存共享、锁粒度的开发人员都是一个可期盼的解脱。若说有所不足，那就是应该有个更大的计划，将通信从进程内拓展到进程外，实现真正意义上的分布式。<br>内存分配<br>将一切并发化固然是好，但带来的问题同样很多。如何实现高并发下的内存分配和管理就是个难题。好在 Go 选择了 tcmalloc，它本就是为并发而设计的高性能内存分配组件。</p><p>可以说，内存分配器是运行时三大组件里变化最少的部分。刨去因配合垃圾回收器而修改的内容，内存分配器完整保留了 tcmalloc 的原始架构。使用 cache 为当前执行线程提供无锁分配，多个 central 在不同线程间平衡内存单元复用。在更高层次里，heap 则管理着大块内存，用以切分成不同等级的复用内存块。快速分配和二级内存平衡机制，让内存分配器能优秀地完成高压力下的内存管理任务。</p><p>在最近几个版本中，编译器优化卓有成效。它会竭力将对象分配在栈上，以降低垃圾回收压力，减少管理消耗，提升执行性能。可以说，除偶尔因性能问题而被迫采用对象池和自主内存管理外，我们基本无须参与内存管理操作。<br>垃圾回收<br>垃圾回收一直是个难题。早年间，Java 就因垃圾回收低效被嘲笑了许久，后来 Sun 连续收纳了好多人和技术才发展到今天。可即便如此，在 Hadoop 等大内存应用场景下，垃圾回收依旧捉襟见肘、步履维艰。</p><p>相比 Java，Go 面临的困难要更多。因指针的存在，所以回收内存不能做收缩处理。幸好，指针运算被阻止，否则要做到精确回收都难。</p><p>每次升级，垃圾回收器必然是核心组件里修改最多的部分。从并发清理，到降低 STW 时间，直到 Go 的 1.5 版本实现并发标记，逐步引入三色标记和写屏障等等，都是为了能让垃圾回收在不影响用户逻辑的情况下更好地工作。尽管有了努力，当前版本的垃圾回收算法也只能说堪用，离好用尚有不少距离。<br>静态链接<br>Go 刚发布时，静态链接被当作优点宣传。只须编译后的一个可执行文件，无须附加任何东西就能部署。这似乎很不错，只是后来风气变了。连着几个版本，编译器都在完善动态库 buildmode 功能，场面一时变得有些尴尬。</p><p>暂不说未完工的 buildmode 模式，静态编译的好处显而易见。将运行时、依赖库直接打包到可执行文件内部，简化了部署和发布操作，无须事先安装运行环境和下载诸多第三方库。这种简单方式对于编写系统软件有着极大好处，因为库依赖一直都是个麻烦。<br>标准库<br>功能完善、质量可靠的标准库为编程语言提供了充足动力。在不借助第三方扩展的情况下，就可完成大部分基础功能开发，这大大降低了学习和使用成本。最关键的是，标准库有升级和修复保障，还能从运行时获得深层次优化的便利，这是第三方库所不具备的。</p><p>Go 标准库虽称不得完全覆盖，但也算极为丰富。其中值得称道的是 net/http，仅须简单几条语句就能实现一个高性能 Web Server，这从来都是宣传的亮点。更何况大批基于此的优秀第三方 Framework 更是将 Go 推到 Web/Microservice 开发标准之一的位置。</p><p>当然，优秀第三方资源也是语言生态圈的重要组成部分。近年来崛起的几门语言中，Go 算是独树一帜，大批优秀作品频繁涌现，这也给我们学习 Go 提供了很好的参照。<br>工具链<br>完整的工具链对于日常开发极为重要。Go 在此做得相当不错，无论是编译、格式化、错误检查、帮助文档，还是第三方包下载、更新都有对应的工具。其功能未必完善，但起码算得上简单易用。</p><p>内置完整测试框架，其中包括单元测试、性能测试、代码覆盖率、数据竞争，以及用来调优的 pprof，这些都是保障代码能正确而稳定运行的必备利器。</p><p>除此之外，还可通过环境变量输出运行时监控信息，尤其是垃圾回收和并发调度跟踪，可进一步帮助我们改进算法，获得更佳的运行期表现。</p><h2 id="3-Go语言为并发而生"><a href="#3-Go语言为并发而生" class="headerlink" title="3.Go语言为并发而生"></a>3.Go语言为并发而生</h2><p>在早期 CPU 都是以单核的形式顺序执行机器指令。Go语言的祖先C语言正是这种顺序编程语言的代表。顺序编程语言中的顺序是指：所有的指令都是以串行的方式执行，在相同的时刻有且仅有一个 CPU 在顺序执行程序的指令。</p><p>随着处理器技术的发展，单核时代以提升处理器频率来提高运行效率的方式遇到了瓶颈，单核 CPU 发展的停滞，给多核 CPU 的发展带来了机遇。相应地，编程语言也开始逐步向并行化的方向发展。</p><p>虽然一些编程语言的框架在不断地提高多核资源使用效率，例如 Java 的 Netty 等，但仍然需要开发人员花费大量的时间和精力搞懂这些框架的运行原理后才能熟练掌握。</p><p>作为程序员，要开发出能充分利用硬件资源的应用程序是一件很难的事情。现代计算机都拥有多个核，但是大部分编程语言都没有有效的工具让程序可以轻易利用这些资源。编程时需要写大量的线程同步代码来利用多个核，很容易导致错误。</p><p>Go语言正是在多核和网络化的时代背景下诞生的原生支持并发的编程语言。Go语言从底层原生支持并发，无须第三方库，开发人员可以很轻松地在编写程序时决定怎么使用 CPU 资源。</p><p>Go语言的并发是基于 goroutine 的，goroutine 类似于线程，但并非线程。可以将 goroutine 理解为一种虚拟线程。Go语言运行时会参与调度 goroutine，并将 goroutine 合理地分配到每个 CPU 中，最大限度地使用 CPU 性能。</p><p>多个 goroutine 中，Go语言使用通道（channel）进行通信，通道是一种内置的数据结构，可以让用户在不同的 goroutine 之间同步发送具有类型的消息。这让编程模型更倾向于在 goroutine 之间发送消息，而不是让多个 goroutine 争夺同一个数据的使用权。</p><p>程序可以将需要并发的环节设计为生产者模式和消费者的模式，将数据放入通道。通道另外一端的代码将这些数据进行并发计算并返回结果，如下图所示。</p><p><img src="/resource/img/golang-concurrent.jpg" srcset="/img/loading.gif" alt="avatar"></p><pre><code class="go">package mainimport (&quot;fmt&quot;&quot;math/rand&quot;&quot;time&quot;)// 数据生产者func producer(header string, channel chan&lt;- string) {    // 无限循环, 不停地生产数据    for {        // 将随机数和字符串格式化为字符串发送给通道        channel &lt;- fmt.Sprintf(&quot;%s: %v&quot;, header, rand.Int31())        // 等待1秒        time.Sleep(time.Second)    }}// 数据消费者func customer(channel &lt;-chan string) {    // 不停地获取数据    for {        // 从通道中取出数据, 此处会阻塞直到信道中返回数据        message := &lt;-channel        // 打印数据        fmt.Println(message)    }}func main() {    // 创建一个字符串类型的通道    channel := make(chan string)    // 创建producer()函数的并发goroutine    go producer(&quot;cat&quot;, channel)    go producer(&quot;dog&quot;, channel)    // 数据消费函数    customer(channel)}</code></pre><p>运行结果</p><pre><code class="go">dog: 1298498081cat: 2019727887dog: 939984059cat: 1427131847cat: 911902081dog: 1474941318cat: 336122540dog: 140954425dog: 208240456cat: 646203300dog: 1106410694cat: 1747278511dog: 460128162cat: 817455089</code></pre><p>对代码的分析：<br>第 03 行，导入格式化（fmt）、随机数（math/rand）、时间（time）包参与编译。<br>第 10 行，生产数据的函数，传入一个标记类型的字符串及一个只能写入的通道。<br>第 13 行，for{} 构成一个无限循环。<br>第 15 行，使用 rand.Int31() 生成一个随机数，使用 fmt.Sprintf() 函数将 header 和随机数格式化为字符串。<br>第 18 行，使用 time.Sleep() 函数暂停 1 秒再执行这个函数。如果在 goroutine 中执行时，暂停不会影响其他 goroutine 的执行。<br>第 23 行，消费数据的函数，传入一个只能写入的通道。<br>第 26 行，构造一个不断消费消息的循环。<br>第 28 行，从通道中取出数据。<br>第 31 行，将取出的数据进行打印。<br>第 35 行，程序的入口函数，总是在程序开始时执行。<br>第 37 行，实例化一个字符串类型的通道。<br>第 39 行和第 40 行，并发执行一个生产者函数，两行分别创建了这个函数搭配不同参数的两个 goroutine。<br>第 42 行，执行消费者函数通过通道进行数据消费。</p><p>整段代码中，没有线程创建，没有线程池也没有加锁，仅仅通过关键字 go 实现 goroutine，和通道实现数据交换。</p><h2 id="4-哪些项目使用Go语言开发？"><a href="#4-哪些项目使用Go语言开发？" class="headerlink" title="4.哪些项目使用Go语言开发？"></a>4.哪些项目使用Go语言开发？</h2><p>列举的是原生使用Go语言进行开发的部分项目。</p><ul><li>Docker<br>Docker 是一种操作系统层面的虚拟化技术，可以在操作系统和应用程序之间进行隔离，也可以称之为容器。Docker 可以在一台物理服务器上快速运行一个或多个实例。例如，启动一个 CentOS 操作系统，并在其内部命令行执行指令后结束，整个过程就像自己在操作系统一样高效。</li></ul><p>项目链接：<a href="https://github.com/docker/docker" target="_blank" rel="noopener">https://github.com/docker/docker</a></p><ul><li>Go语言<br>Go语言自己的早期源码使用C语言和汇编语言写成。从 Go 1.5 版本后，完全使用Go语言自身进行编写。Go语言的源码对了解Go语言的底层调度有极大的参考意义，建议希望对Go语言有深入了解的读者读一读。</li></ul><p>项目链接：<a href="https://github.com/golang/go" target="_blank" rel="noopener">https://github.com/golang/go</a></p><ul><li>Kubernetes<br>Google 公司开发的构建于 Docker 之上的容器调度服务，用户可以通过 Kubernetes 集群进行云端容器集群管理。系统会自动选取合适的工作节点来执行具体的容器集群调度处理工作。其核心概念是 Container Pod（容器仓）。</li></ul><p>项目链接：<a href="https://github.com/kubernetes/kubernetes" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes</a></p><ul><li>etcd<br>一款分布式、可靠的 KV 存储系统，可以快速进行云配置。由 CoreOS 开发并维护键值存储系统，它使用Go语言编写，并通过 Raft 一致性算法处理日志复制以保证强一致性。</li></ul><p>项目链接：<a href="https://github.com/coreos/etcd" target="_blank" rel="noopener">https://github.com/coreos/etcd</a></p><ul><li>beego<br>beego 是一个类似 Python 的 Tornado 框架，采用了 RESTFul 的设计思路，使用Go语言编写的一个极轻量级、高可伸缩性和高性能的 Web 应用框架。</li></ul><p>项目链接：<a href="https://github.com/astaxie/beego" target="_blank" rel="noopener">https://github.com/astaxie/beego</a></p><ul><li>martini<br>一款快速构建模块化的 Web 应用的Go语言框架。</li></ul><p>项目链接：<a href="https://github.com/go-martini/martini" target="_blank" rel="noopener">https://github.com/go-martini/martini</a></p><ul><li>codis<br>国产的优秀分布式 Redis 解决方案。可以将 codis 理解成为 Web 服务领域的 Nginx，它实现了对 Redis 的反向代理和负载均衡。</li></ul><p>项目链接：<a href="https://github.com/CodisLabs/codis" target="_blank" rel="noopener">https://github.com/CodisLabs/codis</a></p><ul><li>delve<br>Go语言强大的调试器，被很多集成环境和编辑器整合。</li></ul><p>项目链接：<a href="https://github.com/derekparker/delve" target="_blank" rel="noopener">https://github.com/derekparker/delve</a></p><h2 id="5-哪些大公司正在使用Go语言"><a href="#5-哪些大公司正在使用Go语言" class="headerlink" title="5.哪些大公司正在使用Go语言"></a>5.哪些大公司正在使用Go语言</h2><p>Go语言是谷歌在 2009 年发布的一款编程语言，自面世以来它以高效的开发效率和完美的运行速度迅速风靡全球，被誉为“21 世纪的C语言”。</p><p>现在越来越多的公司开始使用Go语言开发自己的服务，同时也诞生了很多使用Go语言开发的服务和应用，比如 Docker、k8s 等，下面我们来看一下，有哪些大公司在使用Go语言。</p><ul><li>Google<br>作为创造了Go语言的 google 公司，当然会力挺Go语言了。Google 有很多基于 Go 开发的开源项目，比如 kubernets，docker，大家可以参考《哪些项目使用Go语言开发》一节了解更多的Go语言开源项目。</li><li>Facebook<br>Facebook 也在使用Go语言，为此他们还专门在 Github 上建立了一个开源组织 facebookgo。大家可以通过 <a href="https://github.com/facebookgo" target="_blank" rel="noopener">https://github.com/facebookgo</a> 访问查看 facebook 开源的项目，其中最具代表性的就是著名平滑重启工具 grace。</li><li>腾讯<br>腾讯在 15 年就已经做了 Docker 万台规模的实践。因为腾讯主要的开发语言是 C/C++ ，所以在使用Go语言方面会方便很多，也有很多优势，不过日积月累的 C/C++ 代码很难改造，也不敢动，所以主要在新业务上尝试使用 Go。</li><li>百度<br>百度主要在运维方面使用到了Go语言，比如百度运维的一个 BFE 项目，主要负责前端流量的接入，其次就是百度消息通讯系统的服务器端也使用到了Go语言。</li><li>七牛云<br>七牛云算是国内第一家选Go语言做服务端的公司。早在 2011 年，当Go语言的语法还没完全稳定下来的情况下，七牛云就已经选择将 Go 作为存储服务端的主体语言。</li><li>京东<br>京东云消息推送系统、云存储，以及京东商城的列表页等都是使用Go语言开发的。</li><li>小米<br>小米对Go语言的支持，在于运维监控系统的开源，它的<a href="http://open-falcon.org/" target="_blank" rel="noopener">官方网址</a>。此外，小米互娱、小米商城、小米视频、小米生态链等团队都在使用Go语言。</li><li>360<br>360 对Go语言的使用也不少，比如开源的日志搜索系统 Poseidon，大家可以通过 <a href="https://github.com/Qihoo360/poseidon" target="_blank" rel="noopener">https://github.com/Qihoo360/poseidon</a> 查看，还有 360 的推送团队也在使用Go语言。</li></ul><p>除了上面提到的，还有很多公司开始尝试使用Go语言，比如美团、滴滴、新浪等。</p><p>Go语言的强项在于它适合用来开发网络并发方面的服务，比如消息推送、监控、容器等，所以在高并发的项目上大多数公司会优先选择 Golang 作为开发语言</p><h2 id="6-Go语言适合做什么"><a href="#6-Go语言适合做什么" class="headerlink" title="6.Go语言适合做什么"></a>6.Go语言适合做什么</h2><p>一、我们为什么选择Go语言<br>选择Go语言的原因可能会有很多，关于Go语言的特性、优势等，我们在之前的文档中也已经介绍了很多了。但是最主要的原因，应该是基于以下两方面的考虑：</p><p>1、执行性能<br>毕竟是类C的执行速度，对于一些服务来说，性能是极其重要的一环，事关系统的吞吐、访问的延迟，进而会影响用户的体验，Go语言通过协程可以方便的实现并行处理，达到处理效率的最大化 ，提升系统的吞吐能力。</p><p>2、开发效率<br>GO语言使用起来简单、代码描述效率高、编码规范统一、上手快。 通过少量的代码，即可实现框架的标准化，能快速的构建各种通用组件和公共类库，进一步提升开发效率，实现特定场景下的功能量产。</p><p>二、Go语言能做什么<br>Go 语言从发布 1.0 版本以来备受众多开发者关注并得到广泛使用，Go 语言的简单、高效、并发特性吸引了众多传统语言开发者的加入，而且人数越来越多。</p><p>鉴于Go语言的特点和设计的初衷，Go语言作为服务器编程语言，很适合处理日志、数据打包、虚拟机处理、文件系统、分布式系统、数据库代理等；网络编程方面，Go语言广泛应用于Web 应用、API应用、下载应用等；除此之外，Go语言还适用于内存数据库和云平台领域，目前国外很多云平台都是采用Go开发。</p><p>1、服务器编程，以前你如果使用C或者C++做的那些事情，用Go来做很合适，例如处理日志、数据打包、虚拟机处理、文件系统等。</p><p>2、分布式系统、数据库代理器、中间件等，例如Etcd。</p><p>3、网络编程，这一块目前应用最广，包括Web应用、API应用、下载应用，而且Go内置的net/http包基本上把我们平常用到的网络功能都实现了。</p><p>4、数据库操作</p><p>5、开发云平台，目前国外很多云平台在采用Go开发</p><p>三、国内外有哪些企业或项目使用Go语言<br>Go发布之后，很多公司特别是云计算公司开始用Go重构他们的基础架构，很多都是直接采用Go进行了开发，最近热火朝天的Docker就是采用Go开发的。</p><p>使用 Go 语言开发的开源项目非常多。早期的 Go 语言开源项目只是通过 Go 语言与传统项目进行C语言库绑定实现，例如 Qt、Sqlite 等；后期的很多项目都使用 Go 语言进行重新原生实现，这个过程相对于其他语言要简单一些，这也促成了大量使用 Go 语言原生开发项目的出现。</p><p>1、云计算基础设施领域<br>代表项目：docker、kubernetes、etcd、consul、cloudflare CDN、七牛云存储等。</p><p>2、基础软件<br>代表项目：tidb、influxdb、cockroachdb等。</p><p>3、微服务<br>代表项目：go-kit、micro、monzo bank的typhon、bilibili等。</p><p>4、互联网基础设施<br>代表项目：以太坊、hyperledger等。</p><p>采用Go的一些国外公司，如Google、Docker、Apple、Cloud Foundry、CloudFlare、Couchbase、CoreOS、Dropbox、MongoDB、AWS等公司；<br>采用Go开发的国内企业：如阿里云CDN、百度、小米、七牛、PingCAP、华为、金山软件、猎豹移动、饿了么等公司。</p><p>还有很多，比如阿里中间件、聚美优品、高升控股、探探、斗鱼直播、人人车、亚信、Udesk、方付通、招财猫、三一集团、美餐网等。一般的选择，都是选择用于自己公司合适的产品系统来做，比如消息推送的、监控的、容器的等，Golang特别适合做网络并发的服务，这是他的强项，所以也是被优先用于这些项目。Go语言作为一门大型项目开发语言，在很多大公司相继使用，甚至完全转向Go开发。</p><p>四、写在最后<br>当然，一个技术能不能发展起来，关键还要看三点。</p><p>有没有一个比较好的社区。</p><p>像 C、C++、Java、Python 和 JavaScript 的生态圈都是非常丰富和火爆的。尤其是有很多商业机构参与的社区那就更为人气爆棚了，比如 Linux 的社区。</p><p>有没有一个工业化的标准。</p><p>像 C、C++、Java 都是有标准化组织的。尤其是 Java，其在架构上还搞出了像 J2EE 这样的企业级标准。</p><p>有没有一个或多个杀手级应用。</p><p>C、C++ 和 Java 的杀手级应用不用多说了，就算是对于 PHP 这样还不能算是一个好的编程语言来说，因为是 Linux 时代的第一个杀手级解决方案 LAMP 中的关键技术，所以，也发展起来了。</p><p>上述的这三点是非常关键的，新的技术只需要占到其中一到两点就已经很不错了，何况有的技术，比如 Java，是三点全占到了，所以，Java 的发展是如此好。当然，除了上面这三点重要的，还有一些其它的影响因素，比如：</p><p>学习曲线是否低，上手是否快。</p><p>这点非常重要，C++ 在这点上越做越不好了。</p><p>有没有一个不错的提高开发效率的开发框架。</p><p>如：Java 的 Spring 框架，C++ 的 STL 等。</p><p>是否有一个或多个巨型的技术公司作为后盾。</p><p>如：Java 和 Linux 后面的 IBM、Sun……</p><p>有没有解决软件开发中的痛点。</p><p>如：Java 解决了 C 和 C++ 的内存管理问题。</p><p>用这些标尺来量一下 Go 语言，我们可以清楚地看到：</p><p>Go 语言容易上手；<br>Go 语言解决了并发编程和写底层应用开发效率的痛点；<br>Go 语言有 Google 这个世界一流的技术公司在后面；<br>Go 语言的杀手级应用是 Docker，而 Docker 的生态圈在这几年完全爆棚了。<br>所以，Go 语言的未来是不可限量的。当然，我个人觉得，Go 可能会吞食很多 C、C++、Java 的项目。不过，Go 语言所吞食主要的项目应该是中间层的项目，既不是非常底层也不会是业务层。</p><p>也就是说，Go 语言不会吞食底层到 C 和 C++ 那个级别的，也不会吞食到高层如 Java 业务层的项目。Go 语言能吞食的一定是 PaaS 上的项目，比如一些消息缓存中间件、服务发现、服务代理、控制系统、Agent、日志收集等等，没有复杂的业务场景，也到不了特别底层（如操作系统）的中间平台层的软件项目或工具。而 C 和 C++ 会被打到更底层，Java 会被打到更上层的业务层。</p><p>好了，我们再用上面的标尺来量一下 Go 语言的杀手级应用 Docker，你会发现基本是一样的。</p><p>Docker 上手很容易。<br>Docker 解决了运维中的环境问题以及服务调度的痛点。<br>Docker 的生态圈中有大公司在后面助力。比如 Google。<br>Docker 产出了工业界标准 OCI。<br>Docker 的社区和生态圈已经出现像 Java 和 Linux 那样的态势。<br>……<br>所以，虽然几年前的 Docker ，当时的坑儿还很多，但是，相对于这些大的因素来说，那些小坑儿都不是问题。只是需要一些时间，这些小坑儿在未来 5-10 年就可以完全被填平了。</p><p>同样，我们可以看到 Kubernetes 作为服务和容器调度的关键技术一定会是最后的赢家。</p><p>最后，我还要说一下，为什么要早一点地进入这些新技术，而不是等待这些技术成熟了后再进入。原因有这么几个。</p><p>技术的发展过程非常重要。因为你可以清楚地看到了这种新技术的生态圈发展过程。让我们收获最大的并不是这些技术本身，而是一个技术的变迁和行业的发展。</p><p>从中，我们看到了非常具体的各种思潮和思路，这些东西比起 技术本身来说更有价值。因为，这不但让我们重新思考已经掌握的技术以及如何更好地解决已有的问题，而且还让我看到了未来。不但有了技术优势，而且这些知识还让我们的技术生涯多了很多的可能性。</p><p>这些关键新技术，可以让你拿到技术的先机。这些对一个需要技术领导力的个人或公司来说都是非常重要的。</p><p>一个公司或是个人能够占有技术先机，就会比其它公司或个人有更大的影响力。一旦未来行业需求引爆，那么这个公司或是个人的影响力就会形成一个比较大的护城河，并可以快速地产生经济利益。</p><p>Go的应用范围一直在扩大，云计算，微服务，区块链，哪里都有用Go写的重量级项目。docker/kubernetes生态圈，几百/千万行代码，基本统治了云原生应用市场。去年大热的区块链，以太坊的geth，比特币的btcd，闪电网络的lnd，都是Go语言开发。还是那句话，多看看各种语言的生态，或许都并没有你想象的那么不堪。。。Go语言设计上确实不够“先进”，但也是另一种“务实”。其实go不管在国内还是国外已经很受待见了，国外google用的很多，uber也在用，国内有著名的今日头条，每日千亿级的访问妥妥的。多少语言终其一生都没有这么大的应用场景。</p><h2 id="7-Go语言和其它编程语言的对比"><a href="#7-Go语言和其它编程语言的对比" class="headerlink" title="7.Go语言和其它编程语言的对比"></a>7.Go语言和其它编程语言的对比</h2><h2 id="8-Go语言的性能如何？"><a href="#8-Go语言的性能如何？" class="headerlink" title="8.Go语言的性能如何？"></a>8.Go语言的性能如何？</h2><h2 id="9-Go语言标准库强大"><a href="#9-Go语言标准库强大" class="headerlink" title="9.Go语言标准库强大"></a>9.Go语言标准库强大</h2><h2 id="10-Go语言上手简单"><a href="#10-Go语言上手简单" class="headerlink" title="10.Go语言上手简单"></a>10.Go语言上手简单</h2><h2 id="11-Go语言代码风格清晰、简单"><a href="#11-Go语言代码风格清晰、简单" class="headerlink" title="11.Go语言代码风格清晰、简单"></a>11.Go语言代码风格清晰、简单</h2><h2 id="12-Go语言是怎么完成编译的"><a href="#12-Go语言是怎么完成编译的" class="headerlink" title="12.Go语言是怎么完成编译的"></a>12.Go语言是怎么完成编译的</h2><h2 id="13-在Windows上安装Go语言开发包"><a href="#13-在Windows上安装Go语言开发包" class="headerlink" title="13.在Windows上安装Go语言开发包"></a>13.在Windows上安装Go语言开发包</h2><h2 id="14-在Linux上安装Go语言开发包"><a href="#14-在Linux上安装Go语言开发包" class="headerlink" title="14.在Linux上安装Go语言开发包"></a>14.在Linux上安装Go语言开发包</h2><h2 id="15-在Mac-OS上安装Go语言开发包"><a href="#15-在Mac-OS上安装Go语言开发包" class="headerlink" title="15.在Mac OS上安装Go语言开发包"></a>15.在Mac OS上安装Go语言开发包</h2><h2 id="16-Go语言集成开发环境"><a href="#16-Go语言集成开发环境" class="headerlink" title="16.Go语言集成开发环境"></a>16.Go语言集成开发环境</h2><h2 id="17-Go语言工程结构详述"><a href="#17-Go语言工程结构详述" class="headerlink" title="17.Go语言工程结构详述"></a>17.Go语言工程结构详述</h2><h2 id="18-Go语言依赖管理"><a href="#18-Go语言依赖管理" class="headerlink" title="18.Go语言依赖管理"></a>18.Go语言依赖管理</h2><h2 id="19-第一个Go语言程序"><a href="#19-第一个Go语言程序" class="headerlink" title="19.第一个Go语言程序"></a>19.第一个Go语言程序</h2><h2 id="20-Go语言程序的编译和运行"><a href="#20-Go语言程序的编译和运行" class="headerlink" title="20.Go语言程序的编译和运行"></a>20.Go语言程序的编译和运行</h2><h2 id="21-Goland下载和安装"><a href="#21-Goland下载和安装" class="headerlink" title="21.Goland下载和安装"></a>21.Goland下载和安装</h2><h2 id="22-Goland入门指南"><a href="#22-Goland入门指南" class="headerlink" title="22.Goland入门指南"></a>22.Goland入门指南</h2><h2 id="23-Goland常用快捷键"><a href="#23-Goland常用快捷键" class="headerlink" title="23.Goland常用快捷键"></a>23.Goland常用快捷键</h2><h2 id="24-LiteIDE搭建Go语言开发环境"><a href="#24-LiteIDE搭建Go语言开发环境" class="headerlink" title="24.LiteIDE搭建Go语言开发环境"></a>24.LiteIDE搭建Go语言开发环境</h2><h1 id="Go语言基本语法"><a href="#Go语言基本语法" class="headerlink" title="Go语言基本语法"></a>Go语言基本语法</h1><p>  1.Go语言变量的声明<br>  2.Go语言变量的初始化<br>  3.Go语言多个变量同时赋值<br>  4.Go语言匿名变量<br>  5.Go语言变量的作用域<br>  6.Go语言整型（整数类型）<br>  7.Go语言浮点类型（小数类型）<br>  8.Go语言复数<br>  9.实例：输出正弦函数（Sin）图像<br>  10.Go语言bool类型（布尔类型）<br>  11.Go语言字符串<br>  12.Go语言字符类型（byte和rune）<br>  13.Go语言数据类型转换<br>  14.Go语言指针<br>  15.Go语言变量逃逸分析<br>  16.Go语言变量的生命周期<br>  17.Go语言常量<br>  18.Go语言模拟枚举<br>  19.Go语言类型别名<br>  20.Go语言注释的定义及使用<br>  21.Go语言关键字与标识符<br>  22.Go语言运算符的优先级<br>  23.Go语言字符串和数值类型的相互转换</p><h1 id="Go语言容器"><a href="#Go语言容器" class="headerlink" title="Go语言容器"></a>Go语言容器</h1><p>  1.Go语言数组<br>  2.Go语言多维数组<br>  3.Go语言切片<br>  4.使用append()为切片添加元素<br>  5.Go语言切片复制<br>  6.Go语言从切片中删除元素<br>  7.Go语言range关键字<br>  8.Go语言多维切片<br>  9.Go语言map（映射）<br>  10.Go语言遍历map<br>  11.map元素的删除和清空<br>  12.Go语言map的多键索引<br>  13.Go语言sync.Map<br>  14.Go语言list（列表）<br>  15.Go语言nil：空值/零值<br>  16.Go语言make和new关键字的区别及实现原理</p><h1 id="流程控制"><a href="#流程控制" class="headerlink" title="流程控制"></a>流程控制</h1><p>  1.Go语言分支结构<br>  2.Go语言循环结构<br>  3.输出九九乘法表<br>  4.Go语言键值循环<br>  5.Go语言switch语句<br>  6.Go语言goto语句<br>  7.Go语言break（跳出循环）<br>  8.Go语言continue<br>  9.示例：聊天机器人<br>  10.示例：词频统计<br>  11.示例：缩进排序<br>  12.示例：二分查找算法<br>  13.示例：冒泡排序<br>  14.Go语言分布式id生成器</p><h1 id="Go语言函数"><a href="#Go语言函数" class="headerlink" title="Go语言函数"></a>Go语言函数</h1><p>  1.Go语言函数声明<br>  2.示例：将秒转换为具体的时间<br>  3.示例：函数中的参数传递效果测试<br>  4.Go语言函数变量<br>  5.Go语言字符串的链式处理<br>  6.Go语言匿名函数<br>  7.Go语言函数类型实现接口<br>  8.Go语言闭包（Closure）<br>  9.Go语言可变参数<br>  10.Go语言defer（延迟执行语句）<br>  11.Go语言递归函数<br>  12.Go语言处理运行时错误<br>  13.Go语言宕机（panic）<br>  14.Go语言宕机恢复（recover）<br>  15.Go语言计算函数执行时间<br>  16.示例：通过内存缓存来提升性能<br>  17.Go语言哈希函数<br>  18.Go语言函数的底层实现<br>  19.Go语言Test功能测试函数</p><h1 id="Go语言结构体"><a href="#Go语言结构体" class="headerlink" title="Go语言结构体"></a>Go语言结构体</h1><p>  1.Go语言结构体定义<br>  2.Go语言实例化结构体<br>  3.初始化结构体的成员变量<br>  4.Go语言构造函数<br>  5.Go语言方法和接收器<br>  6.为任意类型添加方法<br>  7.示例：使用事件系统实现事件的响应和处理<br>  8.类型内嵌和结构体内嵌<br>  9.结构体内嵌模拟类的继承<br>  10.初始化内嵌结构体<br>  11.内嵌结构体成员名字冲突<br>  12.示例：使用匿名结构体解析JSON数据<br>  13.Go语言垃圾回收和SetFinalizer<br>  14.示例：将结构体数据保存为JSON格式数据<br>  15.Go语言链表操作<br>  16.Go语言数据I/O对象及操作</p><h1 id="Go语言接口"><a href="#Go语言接口" class="headerlink" title="Go语言接口"></a>Go语言接口</h1><p>  1.Go语言接口声明（定义）<br>  2.Go语言实现接口的条件<br>  3.Go语言类型与接口的关系<br>  4.接口的nil判断<br>  5.Go语言类型断言<br>  6.示例：Go语言实现日志系统<br>  7.Go语言排序<br>  8.Go语言接口的嵌套组合<br>  9.Go语言接口和类型之间的转换<br>  10.Go语言空接口类型<br>  11.示例：使用空接口实现可以保存任意值的字典<br>  12.Go语言类型分支<br>  13.Go语言error接口<br>  14.Go语言接口内部实现<br>  15.示例：表达式求值器<br>  16.示例：简单的Web服务器<br>  17.部署Go语言程序到Linux服务器<br>  18.示例：音乐播放器<br>  19.示例：实现有限状态机（FSM）<br>  20.示例：二叉树数据结构的应用</p><h1 id="Go语言接口-1"><a href="#Go语言接口-1" class="headerlink" title="Go语言接口"></a>Go语言接口</h1><p>  1.Go语言接口声明（定义）<br>  2.Go语言实现接口的条件<br>  3.Go语言类型与接口的关系<br>  4.接口的nil判断<br>  5.Go语言类型断言<br>  6.示例：Go语言实现日志系统<br>  7.Go语言排序<br>  8.Go语言接口的嵌套组合<br>  9.Go语言接口和类型之间的转换<br>  10.Go语言空接口类型<br>  11.示例：使用空接口实现可以保存任意值的字典<br>  12.Go语言类型分支<br>  13.Go语言error接口<br>  14.Go语言接口内部实现<br>  15.示例：表达式求值器<br>  16.示例：简单的Web服务器<br>  17.部署Go语言程序到Linux服务器<br>  18.示例：音乐播放器<br>  19.示例：实现有限状态机（FSM）<br>  20.示例：二叉树数据结构的应用</p><h1 id="Go语言并发"><a href="#Go语言并发" class="headerlink" title="Go语言并发"></a>Go语言并发</h1><p>  1.Go语言并发简述<br>  2.Go语言轻量级线程<br>  3.Go语言并发通信<br>  4.Go语言竞争状态<br>  5.Go语言调整并发的运行性能<br>  6.并发和并行的区别<br>  7.goroutine和coroutine的区别<br>  8.Go语言通道（chan）<br>  9.示例：并发打印<br>  10.Go语言单向通道<br>  11.Go语言无缓冲的通道<br>  12.Go语言带缓冲的通道<br>  13.Go语言channel超时机制<br>  14.Go语言通道的多路复用<br>  15.Go语言模拟远程过程调用<br>  16.示例：使用通道响应计时器的事件<br>  17.Go语言关闭通道后继续使用通道<br>  18.Go语言多核并行化<br>  19.Go语言Telnet回音服务器<br>  20.检测代码在并发环境下可能出现的问题<br>  21.互斥锁和读写互斥锁<br>  22.Go语言等待组<br>  23.死锁、活锁和饥饿概述<br>  24.示例：封装qsort快速排序函数<br>  25.Go语言CSP：通信顺序进程简述<br>  26.示例：聊天服务器<br>  27.高效地使用Go语言并发特性<br>  28.使用select切换协程<br>  29.Go语言加密通信</p><h1 id="Go语言反射"><a href="#Go语言反射" class="headerlink" title="Go语言反射"></a>Go语言反射</h1><p>  1.Go语言反射（reflection）<br>  2.Go语言反射规则浅析<br>  3.反射——性能和灵活性的双刃剑<br>  4.通过反射获取类型信息<br>  5.通过反射获取指针指向的元素类型<br>  6.通过反射获取结构体的成员类型<br>  7.Go语言结构体标签<br>  8.通过反射获取值信息<br>  9.通过反射访问结构体成员的值<br>  10.判断反射值的空和有效性<br>  11.通过反射修改变量的值<br>  12.通过类型信息创建实例<br>  13.通过反射调用函数<br>  14.Go语言inject库：依赖注入</p><h1 id="Go语言文件处理"><a href="#Go语言文件处理" class="headerlink" title="Go语言文件处理"></a>Go语言文件处理</h1><p>  1.Go语言自定义数据文件<br>  2.Go语言JSON文件的读写操作<br>  3.Go语言XML文件的读写操作<br>  4.Go语言使用Gob传输数据<br>  5.Go语言纯文本文件的读写操作<br>  6.Go语言二进制文件的读写操作<br>  7.Go语言自定义二进制文件的读写操作<br>  8.Go语言zip归档文件的读写操作<br>  9.Go语言tar归档文件的读写操作<br>  10.Go语言使用buffer读取文件<br>  11.示例：并发目录遍历<br>  12.示例：从INI配置文件中读取需要的值<br>  13.Go语言文件的写入、追加、读取、复制操作<br>  14.Go语言文件锁操作</p><h1 id="Go语言编译与工具"><a href="#Go语言编译与工具" class="headerlink" title="Go语言编译与工具"></a>Go语言编译与工具</h1><p>  1.go build命令<br>  2.go clean命令<br>  3.go run命令<br>  4.go fmt命令<br>  5.go install命令<br>  6.go get命令<br>  7.go generate命令<br>  8.go test命令<br>  9.go pprof命令<br>  10.与C/C++进行交互<br>  11.Go语言内存管理<br>  12.Go语言垃圾回收<br>  13.Go语言实现RSA和AES加解密</p><h1 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h1><p><a href="https://github.com/mikeygithub/go-study.git" target="_blank" rel="noopener">相关资料</a></p><p><a href="http://c.biancheng.net/golang/" target="_blank" rel="noopener">学习网站</a></p>]]></content>
    
    
    <categories>
      
      <category>Golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>核心编程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Centos安装图形化界面</title>
    <link href="/2018/07/05/Centos%E5%AE%89%E8%A3%85%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%95%8C%E9%9D%A2/"/>
    <url>/2018/07/05/Centos%E5%AE%89%E8%A3%85%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%95%8C%E9%9D%A2/</url>
    
    <content type="html"><![CDATA[<blockquote><p>最近有重新来捣鼓捣鼓Linux了，这次撸的版本是centos7.4的，虽然说是不要桌面，但是感觉初学者还是安装一下比较好balalalala。。。。。。。。。废话不说的直接进入正题：</p></blockquote><h1 id="安装X"><a href="#安装X" class="headerlink" title="安装X"></a>安装X</h1><blockquote><p>首先安装X(X Window System),如果不是root用户请先切换到root用户才能操作，命令为：</p></blockquote><p><code>su root</code> </p><p>命令为</p><p><code>yum groupinstall &quot;X Window System&quot;</code></p><p>回车，安装时间可能会比较长，安装完出现complete！提示，如果出现要确认其他信息则一路输入输入 “y”回车</p><p>查看已装软件及可装软件：</p><p><code>yum grouplist</code></p><p>由于本屌已经安装好了所以就在已经安装的分组的啦</p><h1 id="安装图形界面软件GNOME-GNOME-Desktop"><a href="#安装图形界面软件GNOME-GNOME-Desktop" class="headerlink" title="安装图形界面软件GNOME(GNOME Desktop)"></a>安装图形界面软件GNOME(GNOME Desktop)</h1><blockquote><p>这里需要特别注意！！！！一定要注意 名称必须对应 不同版本的centOS的软件名可能不同 其他Linux系统类似否则会出现No packages in any requested group available to install or update 的错误。</p></blockquote><p><code>yum groupinstall &quot;GNOME Desktop&quot;</code></p><p> 回车，出现提示一路输入”y”确认</p><p>这次的安装会更慢，内心等待，安装完会出现complete！提示。</p><h1 id="进入图形化界面"><a href="#进入图形化界面" class="headerlink" title="进入图形化界面"></a>进入图形化界面</h1><p>输入</p><p><code>startX</code></p><p>速度可能比较慢，可尝试重启</p><p><code>reboot</code></p><p>完成.</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>centos</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux 命令汇总</title>
    <link href="/2018/07/03/Linux-%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/"/>
    <url>/2018/07/03/Linux-%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</url>
    
    <content type="html"><![CDATA[<table><tbody><tr><td style="text-align: center;" colspan="29" height="48"><span style="font-family: 楷体; font-size: 18pt;"><strong>Linux 命令汇总</strong></span></td></tr><tr><td colspan="4" height="19">NO</td><td colspan="4" height="19">分类</td><td colspan="4" height="19">命令名</td><td colspan="8" height="19">用法及参数</td><td colspan="8" height="19">功能注解</td></tr><tr><td colspan="4" height="19">1</td><td colspan="4" height="19">文件管理</td> <td colspan="4"  height="19">ls</td><td colspan="8"  height="19">ls-a</td><td colspan="8"  height="19">列出当前目录下的所有文件，包括以.头的隐含文件</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">ls</td><td colspan="8" height="19">ls-l或ll</td><td colspan="8" height="19">列出当前目录下文件的详细信息</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">pwd</td><td colspan="8" height="19">pwd</td><td colspan="8" height="19">查看当前所在目录的绝对路经</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">cd</td><td colspan="8" height="19">cd..</td><td colspan="8" height="19">回当前目录的上一级目录</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">cd</td><td colspan="8" height="19">cd-</td><td colspan="8" height="19">回上一次所在的目录</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">cd</td><td colspan="8" height="19">cd~或cd</td><td colspan="8" height="19">回当前用户的宿主目录</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">cd</td><td colspan="8" height="19">cd~用户名</td><td colspan="8" height="19">回指定用户的宿主目录</td></tr><tr><td colspan="4" height="19">2</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">mkdir</td><td colspan="8" height="19">mkdir目录名</td><td colspan="8" height="19">创建一个目录</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">mkdir</td><td colspan="8" height="19">mkdir–p</td><td colspan="8" height="19">递归式去创建一些嵌套目录</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">rmdir</td><td colspan="8" height="19">Rmdir空目录名</td><td colspan="8" height="19">删除一个空目录</td></tr><tr><td colspan="4" height="19">3</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">rm</td><td colspan="8" height="19">rm文件名文件名</td><td colspan="8" height="19">删除一个文件或多个文件</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">rm</td><td colspan="8" height="19">rm-rf非空目录名</td><td colspan="8" height="19">递归删除一个非空目录下的一切，不让提式-f</td></tr><tr><td colspan="4" height="19">4</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">cat</td><td colspan="8" height="19">cat文件名</td><td colspan="8" height="19">一屏查看文件内容</td></tr><tr><td colspan="4" height="19">5</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">more</td><td colspan="8" height="19">more文件名</td><td colspan="8" height="19">分页查看文件内容</td></tr><tr><td colspan="4" height="19">6</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">less</td><td colspan="8" height="19">less文件名</td><td colspan="8" height="19">可控分页查看文件内容</td></tr><tr><td colspan="4" height="19">7</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">grep</td><td colspan="8" height="19">grep字符文件名</td><td colspan="8" height="19">根据字符匹配来查看文件部分内容</td></tr><tr><td colspan="4" height="19">8</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">mv</td><td colspan="8" height="19">mv路经/文件/经/文件</td><td colspan="8" height="19">移动相对路经下的文件到绝对路经下</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">mv</td><td colspan="8" height="19">mv文件名新名称</td><td colspan="8" height="19">在当前目录下改名</td></tr><tr><td colspan="4" height="19">9</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">cp</td><td colspan="8" height="19">cp/路经/文件./</td><td colspan="8" height="19">移动绝对路经下的文件到当前目录下</td></tr><tr><td colspan="4" height="19">10</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">find</td><td colspan="8" height="19">find路经-name“字符串”</td><td colspan="8" height="19">查找路经所在范围内满足字符串匹配的文件和目录</td></tr><tr><td colspan="4" height="19">11</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">ln</td><td colspan="8" height="19">ln源文件链接名</td><td colspan="8" height="19">创建当前目录源文件的硬链接</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19"></td><td colspan="4" height="19"></td><td colspan="8" height="19">ln/home/test/usr/test1</td><td colspan="8" height="19">在/usr下建立/home/test的硬链接</td></tr><tr><td colspan="4" height="19">12</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">ln</td><td colspan="8" height="19">Ln-sab</td><td colspan="8" height="19">创建当前目录下a的符号链接b</td></tr><tr><td colspan="4" height="19">13</td><td colspan="4" height="19">文件管理</td> <td colspan="4" height="19">touch</td><td colspan="8" height="19">touchfile1file2</td><td colspan="8" height="19">创建两个空文件</td></tr><tr><td colspan="4" height="19">14</td><td colspan="4" height="19">磁盘管理</td> <td colspan="4" height="19">df</td><td colspan="8" height="19">df</td><td colspan="8" height="19">用于报告文件系统的总容量，使用量，剩余容量。</td></tr><tr><td colspan="4" height="19">15</td><td colspan="4" height="19">磁盘管理</td> <td colspan="4" height="19">du</td><td colspan="8" height="19">du-b/home</td><td colspan="8" height="19">查看目前/HOME目录的容量(k)及子目录的容量(k)。</td></tr><tr><td colspan="4" height="19">16</td><td colspan="4" height="19">磁盘管理</td> <td colspan="4" height="19">fdisk</td><td colspan="8" height="19">fdisk-l</td><td colspan="8" height="19">查看系统分区信息</td></tr><tr><td colspan="4" height="19">17</td><td colspan="4" height="19">磁盘管理</td> <td colspan="4" height="19">fdisk</td><td colspan="8" height="19">fdisk/dev/sdb</td><td colspan="8" height="19">为一块新的SCSI硬盘进行分区</td></tr><tr><td rowspan="2" colspan="4" height="38">18</td><td rowspan="2" colspan="4" height="38">磁盘管理</td><td rowspan="2" colspan="4" height="38">mkfs.ext3</td><td rowspan="2" colspan="8" height="38">Mkfs.ext3/dev/sdb1</td><td colspan="8" height="19">为第一块SCSI硬盘的第一主分区格式化成</td></tr><tr><td class="et16" colspan="8" height="19">ext3的文件系统</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19"></td><td colspan="4" height="19">mkfs.ext2</td><td colspan="8" height="19">Mkfs.ext2/dev/sdb2</td><td colspan="10" height="19">格式化成ext2文件系统</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">磁盘管理</td><td colspan="4" height="19"></td><td colspan="8" height="19">vfat</td><td colspan="8" height="19">Fat文件系统(windows)</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">挂载光驱</td> <td colspan="20"  height="19">mount–tiso9660/dev/cdrom/mnt/cdrom</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19">挂载FAT</td> <td colspan="14 height="19">mount–tvfat/dev/hda5/mnt/cdrom</td><td colspan="8" height="19">挂第一个ide的第五个逻辑分区</td></tr><tr><td colspan="4" height="19">17</td><td colspan="4" height="19">磁盘管理</td> <td colspan="8" height="19">Umount/mnt/cdrom</td><td colspan="12" height="19">卸载/mnt/cdrom为空</td></tr><tr><td colspan="4" height="19">18</td><td colspan="4" height="19">文件权限</td> <td colspan="5" height="19">chmod</td><td colspan="7" height="19">chmodu+sfile</td><td colspan="8" height="19">为file的属主加上特殊权限</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19"></td><td colspan="12" height="19">chmodg+rfile</td><td colspan="12" height="19">为file的属组加上读权限</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19"></td><td colspan="12" height="19">chmodo+wfile</td><td colspan="12" height="19">为file的其它用户加上写权限</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19"></td><td colspan="12" height="19">chmoda-xfile</td><td colspan="12" height="19">为file的所有用户减去执行权限</td></tr><tr><td colspan="4" height="19"></td><td colspan="4" height="19"></td><td colspan="12" height="19">chmod 765 file</td><td colspan="10">为file的属主设为完全权限，属组设成读写权，其它用户具有读和执心权限</td></tr><tr><td colspan="4" height="19">19</td><td colspan="4" height="19">文件权限</td><td colspan="6" height="19">chown</td><td colspan="7" height="19">chownroot/home</td><td colspan="7" height="19">把/home的属主改成root用户</td></tr><tr><td colspan="4" height="19">20</td><td colspan="4" height="19">文件权限</td><td colspan="6" height="19">chgrp</td><td colspan="7" height="19">chgrproot/home</td><td colspan="6" height="19">把/home的属组改成root组</td></tr><tr><td colspan="4" height="19">21</td><td colspan="4" height="19">打印管理</td><td colspan="13"  height="19">redhat-config-printer-tui</td><td colspan="6" height="19">进入安装打印机界面</td></tr><tr><td colspan="4" height="19">22</td><td colspan="4" height="19">打印管理</td><td colspan="6" height="19">lp</td><td colspan="7" height="19">lp–dhptrfile</td><td colspan="6" height="19">打印file到hptr的打印机上</td></tr><tr><td colspan="4" height="19">23</td><td colspan="4" height="19">打印管理</td><td colspan="6" height="19">lpq</td><td colspan="7" height="19">Lpq–P打印机名</td><td colspan="6" height="19">查看打印机的状态</td></tr><tr><td colspan="4" height="19">24</td><td colspan="4" height="19">打印管理</td><td colspan="6" height="19">lprm</td><td colspan="7" height="19">Lprm–P打印机名a</td><td colspan="6" height="19">删除打印机内的打印作业</td></tr><tr><td colspan="4" height="19">25</td><td colspan="4" height="19">打印管理</td><td class="et8" colspan="4" height="19">disable</td><td colspan="8" height="19">Disable–r“changingpaper”HPtr</td><td colspan="9" height="19">禁用打印机并提示原因</td></tr><tr><td colspan="4" height="19">26</td><td colspan="4" height="19">打印管理</td><td colspan="6" height="19">enable</td><td colspan="5" height="19">EnableHPtr</td><td colspan="9" height="19">重新启用被禁用的</td></tr><tr><td colspan="4" height="19">27</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">useradd</td><td colspan="5" height="19">Useradd</td><td colspan="7" height="19">创建一个新的用户</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">28</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">groupadd</td><td colspan="5" height="19">Groupadd组名</td><td colspan="7" height="19">创建一个新的组</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">29</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">passwd</td><td colspan="5" height="19">Passwd用户名</td><td colspan="7" height="19">为用户创建密码</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">30</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Passwd-d</td><td colspan="5" height="19">Passwd-d用户名</td><td colspan="7" height="19">删除用户密码也能登陆</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">31</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Passwd-l</td><td colspan="5" height="19">Passwd-l用户名</td><td colspan="7" height="19">锁定账号密码</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">32</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Passwd-u</td><td colspan="5" height="19">Passwd-u用户名</td><td colspan="7" height="19">解锁账号密码</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">33</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Passwd-S</td><td colspan="5" height="19">Passwd-S用户名</td><td colspan="7" height="19">查询账号密码</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">34</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Usermod-l</td><td colspan="10" height="19">Usermod-l新用户名老用户名</td><td colspan="2" height="19">为用户改名</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">35</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Usermod-L</td><td colspan="10" height="19">Usermod-L要锁定用户名</td><td colspan="2" height="19">锁定用户登陆</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">36</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Usermod-U</td><td colspan="10" height="19">Usermod–U解锁用户名</td><td colspan="2" height="19">解锁用户登陆</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">37</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Usermod-u</td><td colspan="10" height="19">Usermod–u501用户名</td><td colspan="2" height="19">改变用户UID</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">38</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Userdel</td><td colspan="10" height="19">Userdel–r用户名</td><td colspan="2" height="19">删除用户一切</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">39</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Groupmod-n</td><td colspan="10" height="19">Groupmod–n新用户名老用户名</td><td colspan="2" height="19">为组改名</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">40</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Groupmod-g</td><td colspan="10" height="19">Groupmod–g501组名</td><td colspan="2" height="19">改变组GID</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">41</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">groupdel</td><td colspan="10" height="19">Groupdel组名先应删它的用户</td><td colspan="2" height="19">删除组</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">42</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">gpasswd-a</td><td colspan="10" height="19">gpasswd-a用户名组名</td><td colspan="2" height="19">增加用户到组</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">43</td><td colspan="4" height="19">用户管理</td><td colspan="6" height="19">Id</td><td colspan="10" height="19">id用户名</td><td colspan="2" height="19">查用户信息</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">44</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-qa</td><td colspan="10" height="19">rpm–qa|less</td><td colspan="2" height="19">查询已安装RPM</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">45</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19"></td><td colspan="10" height="19">rpm–qa|grepftp</td><td colspan="2" height="19">查询指定RPM</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">46</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-q</td><td colspan="10" height="19">rpm-q已安装的RPM包</td><td colspan="2" height="19">查是否安装</td><td colspan="2" height="19"></td></tr><tr><td colspan="4" height="19">47</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19"></td><td colspan="10" height="19">rpm-qtelnet-server</td><td colspan="4" height="19">查看telnet服务器包</td></tr><tr><td colspan="4" height="19">48</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-qi</td><td colspan="10" height="19">rpm–qi软件包名称</td><td colspan="4" height="19">查看软件的描述信息</td></tr><tr><td colspan="4" height="19">49</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-ql</td><td colspan="10" height="19">rpm–ql软件包名称</td><td colspan="4" height="19">查询软件包的文件列表</td></tr><tr><td colspan="4" height="19">50</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-qf</td><td colspan="10" height="19">rpm–qf软件包名称</td><td colspan="4" height="19">查询某个文件所属的软件包</td></tr><tr><td colspan="4" height="19">51</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-qp</td><td colspan="10" height="19">rpm–qp软件包全名</td><td colspan="4" height="19">查询未安装的软件包信息</td></tr><tr><td colspan="4" height="19">52</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-e</td><td colspan="10" height="19">rpm–e软件包名称</td><td colspan="4" height="19">删除具体的软件包</td></tr><tr><td colspan="4" height="19">53</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-U</td><td colspan="10" height="19">rpm–Uvh软件包全名</td><td colspan="4" height="19">升级软件包并显示过程</td></tr><tr><td colspan="4" height="19">54</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-ivh</td><td colspan="10" height="19">rpm–ivh软件包全名</td><td colspan="4" height="19">安装软件包并显示过程</td></tr><tr><td colspan="4" height="19">55</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">rpm-V</td><td colspan="10" height="19">rpm–V软件包名称</td><td colspan="4" height="19">验证软件包的大小，类型等</td></tr><tr><td colspan="4" height="19">56</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar</td><td colspan="14" height="19">-c创建包–x释放包-v显示命令过程–z代表压缩包</td></tr><tr><td colspan="4" height="19">57</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar-cf</td><td colspan="10" height="19">tar–cvfbenet.tar/home/benet</td><td colspan="4" height="19">把/home/benet目录打包</td></tr><tr><td colspan="4" height="19">58</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar-czf</td><td colspan="10" height="19">tar–zcvfbenet.tar.gz/mnt</td><td colspan="4" height="19">把目录打包并压缩</td></tr><tr><td colspan="4" height="19">59</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar–tf</td><td colspan="10" height="19">tar–tfbenet.tar</td><td colspan="4" height="19">看非压缩包的文件列表</td></tr><tr><td colspan="4" height="19">60</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar–tzf</td><td colspan="10" height="19">tar–tfbenet.tar.gz</td><td colspan="4" height="19">看压缩包的文件列表</td></tr><tr><td colspan="4" height="19">61</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar–xf</td><td colspan="10" height="19">tar–xfbenet.tar</td><td colspan="4" height="19">非压缩包的文件恢复</td></tr><tr><td colspan="4" height="19">62</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar–zxvf</td><td colspan="10" height="19">tar–zxvfbenet.tar.gz</td><td colspan="4" height="19">压缩包的文件解压恢复</td></tr><tr><td colspan="4" height="19">63</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">tar-jxvf</td><td colspan="10" height="19">tar–jxvfbenet.tar.bz2</td><td colspan="4" height="19"></td></tr><tr><td colspan="4" height="19">64</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">diff</td><td colspan="10" height="19">difffile1file2补丁名.patch</td><td colspan="4" height="19">为新旧文件生成补丁文件</td></tr><tr><td colspan="4" height="19">65</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">diff</td><td colspan="10" height="19">difffile1file2</td><td colspan="4" height="19">比较两个文件的区别</td></tr><tr><td colspan="4" height="19">66</td><td colspan="4" height="19">软件管理</td><td colspan="6" height="19">Patch</td><td colspan="10" height="19">Patchfile补丁名.patch</td><td colspan="4" height="19">打补丁</td></tr><tr><td colspan="4" height="19">67</td><td colspan="4" height="19">软件管理</td><td colspan="16" height="19">./configure--prefix=/usr/l数据库专家认证l/</td><td colspan="4" height="19">编译前配置</td></tr><tr><td colspan="4" height="19">68</td><td colspan="4" height="19">软件管理</td><td colspan="16" height="19">make</td><td colspan="4" height="19">编译</td></tr><tr><td colspan="4" height="19">69</td><td colspan="4" height="19">软件管理</td><td colspan="16" height="19">makeinstall</td><td colspan="4" height="19">安装编译好的源码包</td></tr><tr><td colspan="4" height="19">70</td><td colspan="4" height="19">启动管理</td><td colspan="8" height="19">reboot</td><td colspan="8" height="19">Init6</td><td colspan="4" height="19">重启LINUX系统</td></tr><tr><td colspan="4" height="19">71</td><td colspan="4" height="19">启动管理</td><td colspan="3" height="19">Halt</td><td colspan="6" height="19">Init0</td><td colspan="7" height="19">Shutdown–hnow</td><td colspan="4" height="19">关闭LINUX系统</td></tr><tr><td colspan="4" height="19">72</td><td colspan="4" height="19">启动管理</td><td colspan="8" height="19">runlevel</td><td colspan="8" height="19"></td><td colspan="4" height="19">显示系统运行级</td></tr><tr><td colspan="4" height="19">73</td><td colspan="4" height="19">启动管理</td><td colspan="8" height="19">Init[0123456]</td><td colspan="8" height="19"></td><td colspan="4" height="19">改变系统运行级,7种</td></tr><tr><td colspan="4" height="19">74</td><td colspan="4" height="19">启动管理</td><td colspan="16" height="19">Chkconfig–-list[服务名称]</td><td colspan="4" height="19">查看服务的状态</td></tr><tr><td colspan="4" height="19">75</td><td colspan="4" height="19">启动管理</td><td colspan="17"  height="19">Chkconfig–-level 运行级 服务名on|off|set</td><td colspan="3"  height="19">设置服务的启动状态</td></tr><tr><td colspan="4" height="19">76</td><td colspan="4" height="19">启动管理</td><td colspan="17" height="19">Chkconfig 服务名on|off|set</td><td colspan="3" height="19">设置非独立服务启状态</td></tr><tr><td colspan="4" height="19">77</td><td colspan="4" height="19">进程管理</td><td colspan="4" height="19">Top动态</td><td colspan="6" height="19">Ps-aux静态</td><td colspan="7" height="19">进程树pstree</td><td colspan="3" height="19">查看系统进程</td></tr><tr><td colspan="4" height="19">78</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">程序名</td><td colspan="10" height="19">后台运行程序</td><td colspan="3"  height="19"></td></tr><tr><td colspan="4" height="19">79</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">fg</td><td colspan="10" height="19">把后台运行的进程调回前台</td><td colspan="3"  height="19"></td></tr><tr><td colspan="4" height="19">80</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">bg</td><td colspan="10" height="19">把前台运行进程调到后台</td><td colspan="3"  height="19"></td></tr><tr><td colspan="4" height="19">81</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">renice</td><td colspan="7" height="19">Renice+1180</td><td colspan="6" height="19">把180号进程的优先级加1</td></tr><tr><td colspan="4" height="19">82</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">kill</td><td colspan="7" height="19">KillPID</td><td colspan="6" height="19">终止某个PID进程</td></tr><tr><td rowspan="2" colspan="4" height="38">83</td><td rowspan="2" colspan="4" height="38">进程管理</td><td class="et8" rowspan="2" colspan="4" height="38">#</td><td rowspan="2" colspan="7" height="38">at</td><td colspan="7" height="19">at5pm+3days</td><td rowspan="2" colspan="6" height="38">指定三天后下午5:00执行/bin/ls</td></tr><tr><td class="et16" colspan="7" height="19">/bin/ls</td></tr><tr><td colspan="4" height="19">84</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">crontab</td><td colspan="7" height="19">Crontab-e</td><td colspan="6" height="19">用VI的形式来编辑自动周期性任务</td></tr><tr><td colspan="4" height="19">85</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">crontab</td><td colspan="7" height="19">Crontab-l</td><td colspan="6" height="19">查看自动周期性任务</td></tr><tr><td colspan="4" height="19">86</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">crontab</td><td colspan="7" height="19">Crontab-r</td><td colspan="6" height="19">删除自动周期性任务</td></tr><tr><td colspan="4" height="19">87</td><td colspan="4" height="19">进程管理</td><td colspan="7" height="19">crond</td><td colspan="13"  height="19">Servicecrond start|stop|restart|status</td></tr><tr><td colspan="4" height="19"></td><td colspan="12" height="19">马上启动自动周期性服务</td><td colspan="13"  height="19">Servicecrond 启动|停止|重启|状态</td></tr><tr><td colspan="4" height="19"></td><td colspan="12" height="19"></td><td colspan="13"  height="19"></td></tr><tr><td rowspan="20" colspan="4" height="380"></td><td rowspan="20" colspan="4" height="380">实现磁盘配额</td><td colspan="22" height="19">(注安装LINUX时建立/home分区）</td></tr><tr><td  colspan="22"  height="19">目标：对用户zhao在/home目录上实现softlimit为5k,hardlimit为10k的磁盘配额</td></tr><tr><td  colspan="22"  height="19">实现步骤：</td></tr><tr><td  colspan="22"  height="19">1.修改包含/home的行，#vi/etc/fstab，改为：defaults,usrquota。也就是增加usrquota项。然后保存退出。</td></tr><tr><td  colspan="22"  height="19">2、卸载/home目录#umount/home</td></tr><tr><td  colspan="22"  height="19">3.挂接/home目录#mount/home</td></tr><tr><td  colspan="22"  height="19">4、增加用户zhao#useraddzhao</td></tr><tr><td  colspan="22"  height="19">5、修改密码#passwdzhao</td></tr><tr><td  colspan="22"  height="19">6、生成关于/home目录的quota信息#quotacheck-cmug/home</td></tr><tr><td  colspan="22"  height="19">#quotacheck-vu/home</td></tr><tr><td  colspan="22"  height="19">7、查看所有用户的信息#repquota-au</td></tr><tr><td  colspan="22"  height="19">8、设置配额#edquota-uzhao</td></tr><tr><td  colspan="22"  height="19">将soft和hard分别改为5和10</td></tr><tr><td  colspan="22"  height="19">9、保存并退出#wq!</td></tr><tr><td  colspan="22"  height="19">10、修改时间#edquota-t</td></tr><tr><td  colspan="22"  height="19">11、#wq!</td></tr><tr><td  colspan="22"  height="19">12.开启/home上的磁盘配额功能#quotaon/home</td></tr><tr><td  colspan="22"  height="19">13.查询配额#quota-uzhao</td></tr><tr><td  colspan="22"  height="19">14.验证配额#su-zhao</td></tr><tr><td colspan="22"  height="19">$touchmyfile</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>Java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
